---
title: How to Generate TOC
author: Tao He
date: 2021-08-10
category: Jekyll
layout: post
---

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.00-1.jpeg)

**Data Structures And          Algorithms    Made Easy**

**-To All My Readers**

**By                  Narasimha Karumanchi**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.002.png)

Copyright© 2017 by *[CareerMonk.com*](http://CareerMonk.com)*

Allrights reserved.               Designed by *Narasimha Karumanchi*

Copyright© 2017 CareerMonk Publications. Allrights reserved.

Allrights reserved. No part of this book may be reproduced in any form or by any electronic or mechanicalmeans, including information storage and retrievalsystems, without written permission from the publisher or author.

**Acknowledgements**

*Mother* and *Father*, it is impossible to thank you adequately for everything you have done, from loving me unconditionally to raising me in a stable household, where your persistent efforts and traditional values taught your children to celebrate and embrace life. I could not have asked for better parents or role-models. You showed me that anything is possible with faith, hard work and determination.

This book would not have been possible without the help of many people. I would like to express my gratitude to all of the people who provided support, talked things over, read, wrote, offered comments, allowed me to quote their remarks and assisted inthe editing, proofreadingand design. Inparticular, I would like to thankthe followingindividuals:

- *Mohan Mullapudi*, IIT Bombay, Architect, dataRPM Pvt. Ltd.
- *Navin Kumar Jaiswal*, Senior Consultant, Juniper Networks Inc.
- *A. Vamshi Krishna*, IIT Kanpur, Mentor Graphics Inc.
- *Cathy Reed, BA, MA*, CopyEditor

–*Narasimha Karumanchi* M-Tech, *IIT Bombay* Founder, *[CareerMonk.com*](http://CareerMonk.com)*

**Preface**

**DearReader,**

**Please hold on!** I know many people typically do not read the Preface of a book. But I strongly recommend that youread this particular Preface.

It is not the main objective of this book to present you with the theorems and proofs on *data structures* and *algorithms*. I have followed a pattern of improving the problem solutions with different complexities (for each problem, you will find multiple solutions with different, and reduced, complexities). Basically, it’s an enumeration of possible solutions. With this approach, even if you get a new question, it will show you a way to *think* about the possible solutions. You will find this book useful for interview preparation, competitive exams preparation, and campus interview preparations.

As a *job seeker*, if you read the complete book, I am sure you will be able to challenge the interviewers. If you read it as an *instructor*, it will help you to deliver lectures with an approach that is easyto follow, and as a result your students will appreciate the fact that theyhave opted for Computer Science / InformationTechnologyas their degree.

This book is also useful for *Engineering degree students* and *Masters degree students* during their academic preparations. In all the chapters you will see that there is more emphasis on problems and their analysis rather than on theory. In each chapter, you will first read about the basic required theory, which is then followed by a section on problem sets. In total, there are approximately700 algorithmic problems, all withsolutions.

If you read the book as a *student* preparing for competitive exams for Computer Science / Information Technology, the content covers *all the required topics* in full detail. While writing this book, mymainfocus was to help students who are preparingfor these exams.

In all the chapters you will see more emphasis on problems and analysis rather than on theory. In eachchapter, youwill first see the basic required theoryfollowed byvarious problems.

For many problems, *multiple* solutions are provided with different levels of complexity. We start withthe *brute force* solutionand slowlymove toward the *best solution* possible for that problem. For each problem, we endeavor to understand how much time the algorithm takes and how much memorythe algorithmuses.

It is recommended that the reader does at least one *complete* reading of this book to gain a full understanding of all the topics that are covered. Then, in subsequent readings you can skip directly to any chapter to refer to a specific topic. Even though many readings have been done for the purpose of correcting errors, there could still be some minor typos in the book. If any are found, they will be updated at *[www.CareerMonk.com*](http://www.CareerMonk.com)*. You can monitor this site for any corrections and also for new problems and solutions. Also, please provide your valuable suggestions at: *<Info@CareerMonk.com>.*

I wishyouall the best and I amconfident that youwill find this bookuseful.

–*Narasimha Karumanchi* M-Tech, *I IT Bombay* Founder, *[CareerMonk.com*](http://CareerMonk.com)*

**Other Books by Narasimha Karumanchi**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.003.png) **IT Interview Questions**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.003.png) **Data Structures andAlgorithms forGATE**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.003.png) **Data Structures andAigorithms Made Easy inJava ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.003.png) Coding Interview Questions**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.003.png) **Peeling DesignPatterns**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.003.png) **Elements of ComputerNetworking**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.003.png) **Data Structures andAlgorithmic Thinking withPython**

**Table of Contents**

1. [Introduction](#_page15_x28.00_y82.94)
2. [Variables](#_page15_x28.00_y611.26)
3. [Data Types](#_page16_x28.00_y126.95)
4. [Data Structures](#_page17_x28.00_y269.62)
5. [Abstract Data Types (ADTs)](#_page17_x28.00_y546.24)
6. [What is anAlgorithm?](#_page18_x28.00_y292.77)
7. [Whythe Analysis of Algorithms?](#_page18_x28.00_y734.22)
8. [Goal of the Analysis of Algorithms](#_page19_x28.00_y160.07)
9. [What is RunningTime Analysis?](#_page19_x28.00_y262.64)
10. [How to Compare Algorithms](#_page19_x28.00_y472.92)
11. [What is Rate of Growth?](#_page19_x28.00_y708.31)
12. [CommonlyUsed Rates of Growth](#_page20_x28.00_y326.72)
13. [Types of Analysis](#_page22_x28.00_y278.15)
14. [Asymptotic Notation](#_page23_x28.00_y202.05)
15. [Big-O Notation\[Upper BoundingFunction\]](#_page23_x28.00_y337.75)
16. [Omega-Q Notation\[Lower BoundingFunction\]](#_page25_x28.00_y592.86)
17. [Theta-Θ Notation\[Order Function\]](#_page27_x28.00_y27.00)
18. [Important Notes](#_page28_x28.00_y385.27)
19. [Whyis it called Asymptotic Analysis?](#_page28_x28.00_y620.44)
20. [Guidelines for Asymptotic Analysis](#_page29_x28.00_y77.27)
21. [Simplyfyingproperties of asymptotic notations](#_page31_x28.00_y441.84)
22. [Commonlyused Logarithms and Summations](#_page31_x28.00_y668.98)
23. [Master Theoremfor Divide and Conquer Recurrences](#_page32_x28.00_y641.21)
24. [Divide and Conquer Master Theorem: Problems & Solutions](#_page33_x28.00_y400.47)
25. [Master Theoremfor Subtract and Conquer Recurrences](#_page34_x28.00_y729.68)
26. [Variant of Subtractionand Conquer Master Theorem](#_page35_x28.00_y274.88)
27. [Method of Guessingand Confirming](#_page35_x28.00_y377.46)
28. [Amortized Analysis](#_page37_x28.00_y713.09)
29. [Algorithms Analysis: Problems & Solutions](#_page38_x28.00_y587.17)
30. [Recursionand Backtracking](#_page61_x28.00_y82.94)
    1. [Introduction](#_page61_x28.00_y497.99)
    1. [What is Recursion?](#_page61_x28.00_y600.57)
    1. [WhyRecursion?](#_page62_x28.00_y27.00)
    1. [Format of a Recursive Function](#_page62_x28.00_y196.29)
    1. [Recursionand Memory(Visualization)](#_page63_x28.00_y249.35)
    1. [Recursionversus Iteration](#_page64_x28.00_y654.93)
    1. [Notes onRecursion](#_page65_x28.00_y370.67)
    1. [Example Algorithms of Recursion](#_page65_x28.00_y589.16)
    1. [Recursion: Problems & Solutions](#_page66_x28.00_y77.27)
    1. [What is Backtracking?](#_page67_x28.00_y564.74)
    1. [Example Algorithms of Backtracking](#_page68_x28.00_y471.03)
    1. [Backtracking: Problems & Solutions](#_page68_x28.00_y656.40)
31. [Linked Lists](#_page73_x28.00_y82.94)
    1. [What is a Linked List?](#_page73_x28.00_y494.39)
    1. [Linked Lists ADT](#_page74_x28.00_y170.15)
    1. [WhyLinked Lists?](#_page74_x28.00_y468.92)
    1. [Arrays Overview](#_page74_x28.00_y621.18)
    1. [Comparisonof Linked Lists withArrays & Dynamic Arrays](#_page76_x28.00_y619.52)
    1. [SinglyLinked Lists](#_page77_x28.00_y335.75)
    1. [DoublyLinked Lists](#_page87_x28.00_y402.93)
    1. [Circular Linked Lists](#_page95_x28.00_y736.18)
    1. AMemory-efficient DoublyLinked List
    1. Unrolled Linked Lists
    1. Skip Lists
    1. Linked Lists: Problems & Solutions
32. Stacks
33. What is a Stack?
34. How Stacks are used
35. StackADT
36. Applications
37. Implementation
38. Comparisonof Implementations
39. Stacks: Problems & Solutions
40. Queues
    1. What is a Queue?
    1. How are Queues Used?
    1. Queue ADT
    1. Exceptions
    1. Applications
    1. Implementation
    1. Queues: Problems & Solutions
41. Trees
    1. What is a Tree?
    1. Glossary
    1. BinaryTrees
    1. Types of BinaryTrees
    1. Properties of BinaryTrees
    1. BinaryTree Traversals
    1. Generic Trees (*N*-aryTrees)
    1. Threaded BinaryTree Traversals (Stackor Queue-less Traversals)
    1. ExpressionTrees
    1. XOR Trees
    1. BinarySearchTrees (BSTs)
    1. Balanced BinarySearchTrees
    1. AVL(Adelson-Velskii and Landis) Trees
    1. Other Variations onTrees
42. PriorityQueues and Heaps
43. What is a PriorityQueue?
44. PriorityQueue ADT
45. PriorityQueue Applications
46. PriorityQueue Implementations
47. Heaps and BinaryHeaps
48. BinaryHeaps
49. Heapsort
50. PriorityQueues [Heaps]: Problems & Solutions
51. Disjoint Sets ADT
52. Introduction
53. Equivalence Relations and Equivalence Classes
54. Disjoint Sets ADT
55. Applications
56. Tradeoffs inImplementingDisjoint Sets ADT
57. Fast UNION Implementation(Slow FIND)
58. Fast UNION Implementations (QuickFIND)
59. Summary
60. Disjoint Sets: Problems & Solutions
61. GraphAlgorithms
    1. Introduction
    1. Glossary
    1. Applications of Graphs
    1. GraphRepresentation
    1. GraphTraversals
    1. Topological Sort
    1. Shortest PathAlgorithms
    1. Minimal SpanningTree
    1. GraphAlgorithms: Problems & Solutions
62. Sorting
63. What is Sorting?
64. Whyis SortingNecessary?
65. Classificationof SortingAlgorithms
66. Other Classifications
67. Bubble Sort
68. SelectionSort
69. InsertionSort
70. Shell Sort
71. Merge Sort
72. Heap Sort
73. QuickSort
74. Tree Sort
75. Comparisonof SortingAlgorithms
76. Linear SortingAlgorithms
77. CountingSort
78. Bucket Sort (or BinSort)
79. RadixSort
80. Topological Sort
81. External Sorting
82. Sorting: Problems & Solutions
83. Searching
    1. What is Searching?
    1. Whydo we need Searching?
    1. Types of Searching
    1. Unordered Linear Search
    1. Sorted/Ordered Linear Search
    1. BinarySearch
    1. InterpolationSearch
    1. ComparingBasic SearchingAlgorithms
    1. Symbol Tables and Hashing
    1. StringSearchingAlgorithms
    1. Searching: Problems & Solutions
84. SelectionAlgorithms [Medians]
85. What are SelectionAlgorithms?
86. SelectionbySorting
87. Partition-based SelectionAlgorithm
88. Linear SelectionAlgorithm- Medianof Medians Algorithm
89. Findingthe K Smallest Elements inSorted Order
90. SelectionAlgorithms: Problems & Solutions
91. Symbol Tables
    1. Introduction
    1. What are Symbol Tables?
    1. Symbol Table Implementations
    1. ComparisonTable of Symbols for Implementations
92. Hashing
    1. What is Hashing?
    1. WhyHashing?
    1. HashTable ADT
    1. UnderstandingHashing
    1. Components of Hashing
    1. HashTable
    1. HashFunction
    1. Load Factor
    1. Collisions
    1. CollisionResolutionTechniques
    1. Separate Chaining
    1. OpenAddressing
    1. Comparisonof CollisionResolutionTechniques
    1. How HashingGets O(1) Complexity?
    1. HashingTechniques
    1. Problems for whichHashTables are not suitable
    1. BloomFilters
    1. Hashing: Problems & Solutions
93. StringAlgorithms
94. Introduction
95. StringMatchingAlgorithms
96. Brute Force Method
97. Rabin-Karp StringMatchingAlgorithm
98. StringMatchingwithFinite Automata
99. KMPAlgorithm
100. Boyer-Moore Algorithm

     8. Data Structures for StoringStrings
     8. HashTables for Strings
     8. BinarySearchTrees for Strings
     8. Tries
     8. TernarySearchTrees
     8. ComparingBSTs, Tries and TSTs
     8. SuffixTrees
     8. StringAlgorithms: Problems & Solutions
101. Algorithms DesignTechniques
     1. Introduction
     1. Classification
     1. ClassificationbyImplementationMethod
     1. ClassificationbyDesignMethod
     1. Other Classifications
102. GreedyAlgorithms
     1. Introduction
     1. GreedyStrategy
     1. Elements of GreedyAlgorithms
     1. Does GreedyAlways Work?
     1. Advantages and Disadvantages of GreedyMethod
     1. GreedyApplications
     1. UnderstandingGreedyTechnique
     1. GreedyAlgorithms: Problems & Solutions
103. Divide and Conquer Algorithms
104. Introduction
105. What is the Divide and Conquer Strategy?
106. Does Divide and Conquer Always Work?
107. Divide and Conquer Visualization
108. UnderstandingDivide and Conquer
109. Advantages of Divide and Conquer
110. Disadvantages of Divide and Conquer
111. Master Theorem
112. Divide and Conquer Applications
113. Divide and Conquer: Problems & Solutions
114. Dynamic Programming
     1. Introduction
     1. What is Dynamic ProgrammingStrategy?
     1. Properties of Dynamic ProgrammingStrategy
     1. CanDynamic ProgrammingSolve All Problems?
     1. Dynamic ProgrammingApproaches
     1. Examples of Dynamic ProgrammingAlgorithms
     1. UnderstandingDynamic Programming
     1. Longest CommonSubsequence
     1. Dynamic Programming: Problems & Solutions
115. ComplexityClasses
     1. Introduction
     1. Polynomial/Exponential Time
     1. What is a DecisionProblem?
     1. DecisionProcedure
     1. What is a ComplexityClass?
     1. Types of ComplexityClasses
     1. Reductions
     1. ComplexityClasses: Problems & Solutions
116. Miscellaneous Concepts
117. Introduction
118. Hacks onBit-wise Programming
119. Other ProgrammingQuestions

References

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.004.png)

The objective of this chapter is to explain the importance of the analysis of algorithms, their notations, relationships and solving as many problems as possible. Let us first focus on understanding the basic elements of algorithms, the importance of algorithm analysis, and then slowly move toward the other topics as mentioned above. After completing this chapter, you should be able to find the complexityof anygivenalgorithm(especiallyrecursive functions).

1. **Variables**

Before goingto the definitionof variables, let us relate themto old mathematical equations. All of us have solved many mathematical equations since childhood. As an example, consider the below equation:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.005.png)We don’t have to worry about the use of this equation. The important thing that we need to understand is that the equation has names (*x* and *y*), which hold values (data). That means the *names* (*x* and *y*) are placeholders for representing data. Similarly, in computer science programmingwe need somethingfor holdingdata, and *variables* is the wayto do that.

2. **Data Types**

In the above-mentioned equation, the variables *x* and y can take any values such as integral numbers (10, 20), real numbers (0.23, 5.5), or just 0 and 1. To solve the equation, we need to relate themto the kind of values theycantake, and *data type* is the name used incomputer science programming for this purpose. A *data type* in a programming language is a set of data with predefined values. Examples of data types are: integer, floating point, unit number, character, string, etc.

Computer memory is all filled with zeros and ones. If we have a problemand we want to code it, it’s very difficult to provide the solution in terms of zeros and ones. To help users, programming languages and compilers provide us with data types. For example, *integer* takes 2 bytes (actual value depends on compiler), *float* takes 4 bytes, etc. This says that in memory we are combining 2 bytes (16 bits) and calling it an *integer*. Similarly, combining 4 bytes (32 bits) and calling it a *float*. Adata type reduces the codingeffort. At the top level, there are two types of data types:

- System-defined data types (also called *Primitive* data types)
- User-defined data types

**System-defined data types (Primitive data types)**

Data types that are defined by system are called *primitive* data types. The primitive data types provided by many programming languages are: int, float, char, double, bool, etc. The number of bits allocated for each primitive data type depends on the programming languages, the compiler and the operating system. For the same primitive data type, different languages may use different sizes. Depending on the size of the data types, the total available values (domain) will also change.

For example, *“int”* maytake 2 bytes or 4 bytes. If it takes 2 bytes (16 bits), thenthe total possible values are minus 32,768 to plus 32,767 (-215 *to* 215-1). If it takes 4 bytes (32 bits), then the possible values are between -2,147,483,648 and +2,147,483,647 (-231 *to* 231-1). The same is the case withother data types.

**User defined data types**

If the system-defined data types are not enough, then most programming languages allow the users

to define their own data types, called *user* – *defined data types*. Good examples of user defined data types are: structures in *C/C +* + and classes in *Java*. For example, in the snippet below, we are combining many system-defined data types and calling the user defined data type by the name *“newType”*. This gives more flexibilityand comfort indealingwithcomputer memory.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.006.png)

3. **Data Structures**

Based on the discussion above, once we have data in variables, we need some mechanism for manipulating that data to solve problems. *Data structure* is a particular way of storing and organizing data in a computer so that it can be used efficiently. A *data structure* is a special format for organizing and storing data. General data structure types include arrays, files, linked lists, stacks, queues, trees, graphs and so on.

Dependingonthe organizationof the elements, data structures are classified into two types:

1) *Linear data structures:* Elements are accessed in a sequential order but it is not compulsory to store all elements sequentially. *Examples:* Linked Lists, Stacks and Queues.
1) *Non* – *linear data structures:* Elements of this data structure are stored/accessed ina non-linear order. *Examples:* Trees and graphs.

4. **Abstract Data Types (ADTs)**

Before defining abstract data types, let us consider the different view of system-defined data types. We all know that, by default, all primitive data types (int, float, etc.) support basic operations such as addition and subtraction. The system provides the implementations for the primitive data types. For user-defined data types we also need to define operations. The implementation for these operations can be done when we want to actually use them. That means, ingeneral, user defined data types are defined alongwiththeir operations.

To simplifythe process of solvingproblems, we combine the data structures withtheir operations and we call this *Abstract Data Types* (ADTs). AnADT consists of *two parts:*

1. Declarationof data
2. Declarationof operations

Commonly used ADTs *include:* Linked Lists, Stacks, Queues, Priority Queues, Binary Trees, Dictionaries, Disjoint Sets (Union and Find), Hash Tables, Graphs, and many others. For example, stack uses LIFO (Last-In-First-Out) mechanismwhile storing the data in data structures. The last element inserted into the stack is the first element that gets deleted. Common operations

of it are: creating the stack, pushing an element onto the stack, popping an element from stack, findingthe current top of the stack, findingnumber of elements inthe stack, etc.

While defining the ADTs do not worry about the implementation details. They come into the picture only when we want to use them. Different kinds of ADTs are suited to different kinds of applications, and some are highly specialized to specific tasks. By the end of this book, we will go through many of them and you will be in a position to relate the data structures to the kind of problems theysolve.

5. **What is an Algorithm?**

Let us consider the problem of preparing an *omelette*. To prepare an omelette, we follow the steps givenbelow:

1) Get the fryingpan.
1) Get the oil.

a. Do we have oil?

1. If yes, put it inthe pan.
1. If no, do we want to buyoil?
   1. If yes, thengo out and buy.
   1. If no, we canterminate.

3) Turnonthe stove, etc...

What we are doing is, for a given problem (preparing an omelette), we are providing a step-by- step procedure for solvingit. The formal definitionof analgorithmcanbe stated as:

Analgorithmis the step-by-step unambiguous instructions to solve a givenproblem.

In the traditional study of algorithms, there are two main criteria for judging the merits of algorithms: correctness (does the algorithm give solution to the problem in a finite number of steps?) and efficiency (how much resources (in terms of memory and time) does it take to execute the).

**Note:** We do not have to prove eachstep of the algorithm.

6. **Why the Analysis of Algorithms?**

To go fromcity *“A”* to city *“B”*, there can be many ways of accomplishing this: by flight, by bus, by train and also by bicycle. Depending on the availability and convenience, we choose the one that suits us. Similarly, in computer science, multiple algorithms are available for solving the same problem (for example, a sorting problem has many algorithms, like insertion sort, selection sort, quick sort and many more). Algorithm analysis helps us to determine which algorithm is most efficient interms of time and space consumed.

7. **Goalof the Analysis of Algorithms**

The goal of the *analysis of algorithms* is to compare algorithms (or solutions) mainly in terms of runningtime but also interms of other factors (e.g., memory, developer effort, etc.)

8. **What is Running Time Analysis?**

It is the process of determining how processing time increases as the size of the problem (input size) increases. Input size is the number of elements in the input, and depending on the problem type, the input maybe of different types. The followingare the commontypes of inputs.

- Size of anarray
- Polynomial degree
- Number of elements ina matrix
- Number of bits inthe binaryrepresentationof the input
- Vertices and edges ina graph.

9. **How to Compare Algorithms**

To compare algorithms, let us define a *few objective measures:*

**Executiontimes?** *Not a good measure* as executiontimes are specific to a particular computer.

**Number of statements executed?** *Not a good measure*, since the number of statements varies withthe programminglanguage as well as the style of the individual programmer.

**Ideal solution?** Let us assume that we express the running time of a given algorithmas a function of the input size *n* (i.e., *f*(*n*)) and compare these different functions corresponding to running times. This kind of comparisonis independent of machine time, programmingstyle, etc.

10. **What is Rate of Growth?**

The rate at which the running time increases as a function of input is called *rate of growth*. Let us

assume that you go to a shop to buy a car and a bicycle. If your friend sees you there and asks what you are buying, then in general you say *buying a car*. This is because the cost of the car is high compared to the cost of the bicycle (approximating the cost of the bicycle to the cost of the car).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.007.png)

For the above-mentioned example, we can represent the cost of the car and the cost of the bicycle in terms of function, and for a given function ignore the low order terms that are relatively

insignificant (for large value of input size, *n*). As an example, in the case below, *n*4, 2*n*2, 100*n* and 500 are the individual costs of some function and approximate to *n*4 since *n*4 is the highest rate of growth.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.008.png)

11. **Commonly Used Rates of Growth**

The diagrambelow shows the relationship betweendifferent rates of growth.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.009.jpeg)

Below is the list of growthrates youwill come across inthe followingchapters.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.010.png)

12. **Types of Analysis**

To analyze the given algorithm, we need to know with which inputs the algorithm takes less time (performing wel1) and with which inputs the algorithm takes a long time. We have already seen that an algorithm can be represented in the form of an expression. That means we represent the algorithmwith multiple expressions: one for the case where it takes less time and another for the case where it takes more time.

In general, the first case is called the *best case* and the second case is called the *worst case* for the algorithm. To analyze an algorithm we need some kind of syntax, and that forms the base for asymptotic analysis/notation. There are three types of analysis:

- **Worst case**
- Defines the input for which the algorithm takes a long time (slowest time to complete).
- Input is the one for whichthe algorithmruns the slowest.
- **Best case**
- Defines the input for which the algorithm takes the least time (fastest time to complete).
- Input is the one for whichthe algorithmruns the fastest.
- **Average case**
- Provides a predictionabout the runningtime of the algorithm.
- Run the algorithm many times, using many different inputs that come from some distribution that generates these inputs, compute the total running time (by adding the individual times), and divide by the number of trials.
- Assumes that the input is random.

*Lower Bound <= Average Time <= Upper Bound*

For a given algorithm, we can represent the best, worst and average cases in the form of expressions. As anexample, let *f*(*n*) be the functionwhichrepresents the givenalgorithm.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.011.png)

Similarly for the average case. The expression defines the inputs with which the algorithm takes the average runningtime (or memory).

13. **Asymptotic Notation**

Having the expressions for the best, average and worst cases, for all three cases we need to identify the upper and lower bounds. To represent these upper and lower bounds, we need some kind of syntax, and that is the subject of the following discussion. Let us assume that the given algorithmis represented inthe formof function*f*(*n*).

14. **Big-O Notation [Upper Bounding Function]**

This notationgives the *tight* upper bound of the givenfunction. Generally, it is represented as *f*(*n*)

- O(*g*(*n*)). That means, at larger values of *n*, the upper bound of *f*(*n*) is *g*(*n*). For example, if *f*(*n*)
- *n*4 + 100*n*2 + 10*n* + 50 is the given algorithm, then *n*4 *is g*(*n*). That means *g*(*n*) gives the maximumrate of growthfor *f*(*n*) at larger values of *n*.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.012.jpeg)Let us see the O–notation with a little more detail. O–notation defined as O(*g*(*n*)) = {*f*(*n*): there exist positive constants *c* and n0 such that 0 ≤ *f*(*n*) ≤ *cg*(*n*) for all *n* > *n*0}. *g*(*n*) is an asymptotic

tight upper bound for *f*(*n*). Our objective is to give the smallest rate of growth *g*(*n*) which is greater thanor equal to the givenalgorithms’ rate of growth/(*n*).

Generallywe discard lower values of *n*. That means the rate of growthat lower values of *n* is not important. In the figure, *n*0 is the point from which we need to consider the rate of growth for a

given algorithm. Below *n*0, the rate of growth could be different. *n*0 is called threshold for the

givenfunction.

**Big-O Visualization**

O(*g*(*n*)) is the set of functions with smaller or the same order of growth as *g*(*n*). For example; O(*n*2) includes O(1), O(*n*), O(*nlogn*), etc.

**Note:** Analyze the algorithms at larger values of *n* only. What this means is, below *n*0 we do not care about the rate of growth.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.013.png)

**Big-O Examples**

**Example-1** Find upper bound for *f*(*n*) = 3*n* + 8

**Solution:** 3*n* + 8 ≤ 4*n*, for all *n* ≥ 8

∴3*n* + 8 = O(*n*) withc = 4 and *n*0 = 8

**Example-2** Find upper bound for *f*(*n*) *= n*2 + 1

**Solution:** *n*2 + 1 ≤ 2*n*2, for all *n* ≥ 1

∴*n*2 + 1 = O(*n*2) with*c =* 2 and *n*0 = 1 **Example-3** Find upper bound for *f*(*n*) *= n*4 + 100*n*2 + 50 **Solution:** *n*4 + 100*n*2 + 50 ≤ 2*n*4, for all *n* ≥ 11

∴*n*4 + 100*n*2 + 50 = O(*n*4 ) with*c =* 2 and *n*0 = 11 **Example-4** Find upper bound for *f*(*n*) = 2*n*3 – 2*n*2

**Solution:** 2*n*3 – 2*n*2 ≤ 2*n*3, for all *n >* 1

∴2*n*3 – 2*n*2 = O(*n*3 ) with*c =* 2 and *n*0 = 1 **Example-5** Find upper bound for *f*(*n*) = *n*

**Solution:** *n* ≤ *n*, for all *n* ≥ 1

∴*n =* O(*n*) with*c =* 1 and *n*0 = 1

**Example-6** Find upper bound for *f*(*n*) = 410

**Solution:** 410 ≤ 410, for all *n >* 1

∴410 = O(1) with*c =* 1 and *n*0 = 1

**No Uniqueness?**

There is no unique set of values for n0 and *c* in proving the asymptotic bounds. Let us consider, 100*n* + 5 = O(*n*). For this functionthere are multiple *n*0 and *c* values possible.

**Solution1:** 100*n* + 5 ≤ 100*n* + *n =* 101*n ≤* 101*n*, for all *n* ≥ 5, *n*0 = 5 and *c =* 101 is a solution. **Solution2:** 100*n* + 5 ≤ 100*n* + 5*n* = 105*n* ≤ 105*n*, for all *n >* 1, *n*0 = 1 and *c =* 105 is also a

solution.

15. **Omega-Q Notation [Lower Bounding Function]**

Similar to the O discussion, this notation gives the tighter lower bound of the given algorithmand we represent it as *f*(*n*) = Ω(*g*(*n*)). That means, at larger values of *n*, the tighter lower bound of *f*(*n*) is *g*(*n*). For example, if *f*(*n*) = 100*n*2 + 10*n* + 50, *g*(*n*) is Ω(*n*2).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.014.jpeg)

The Ω notationcanbe defined as Ω(g(*n*)) = {f(n): there exist positive constants c and *n*0 such that 0 ≤ *cg*(*n*) ≤ *f*(*n*) for all n ≥ *n*0}. *g*(*n*) is an asymptotic tight lower bound for *f*(*n*). Our objective is to give the largest rate of growth *g*(*n*) which is less than or equal to the given algorithm’s rate of growth*f*(*n*).

**Ω Examples**

**Example-1** Find lower bound for *f*(*n*) = 5*n*2.

**Solution:** ∃*c, n*0 Suchthat: 0 ≤ *cn*2*≤* 5*n*2 ⇒ *cn*2 ≤ 5*n*2 ⇒ *c =* 5 and *n*0 = 1

∴5*n*2 = Ω(*n*2) with*c =* 5 and *n*0 = 1

**Example-2** Prove *f*(*n*) = 100*n* + 5 ≠ Ω(*n*2).

**Solution:** ∃c, *n*0 Suchthat: 0 *≤ cn*2 ≤ 100*n* + 5

100*n* + 5 ≤ 100*n* + 5*n*(*∀n ≥* 1) = 105*n*

*cn*2 ≤ 105*n* ⇒ *n*(*cn -* 105) ≤ 0

Since *n* is positive *⇒cn -* 105 ≤0 ⇒ *n ≤*105/*c*

*⇒* Contradiction: *n* cannot be smaller thana constant

**Example-3** 2*n* = Q(*n*), *n*3 = Q(*n*3), = O(*logn*).

16. **Theta-Θ Notation [Order Function]**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.015.jpeg)

This notation decides whether the upper and lower bounds of a given function (algorithm) are the same. The average running time of an algorithmis always between the lower bound and the upper bound. If the upper bound (O) and lower bound (Ω) give the same result, then the Θ notation will also have the same rate of growth.

As an example, let us assume that *f*(*n*) = 10*n + n* is the expression. Then, its tight upper bound *g*(*n*) is O(*n*). The rate of growthinthe best case is *g*(*n*) = O(*n*).

In this case, the rates of growth in the best case and worst case are the same. As a result, the average case will also be the same. For a given function (algorithm), if the rates of growth (bounds) for O and Ω are not the same, thenthe rate of growthfor the Θ case maynot be the same. In this case, we need to consider all possible time complexities and take the average of those (for example, for a quicksort average case, refer to the *Sorting* chapter).

Now consider the definition *of* Θ notation. It is defined as Θ(*g*(*n*)) = {*f*(*n*): there exist positive constants *c*1*,c*2 and *n*0 such that 0 ≤ *c*1*g*(*n*) *≤ f*(*n*) *≤ c*2*g*(*n*) for all *n* ≥ *n*0}*. g*(*n*) is an asymptotic

tight bound for *f*(*n*). Θ(*g*(*n*)) is the set of functions withthe same order of growthas *g*(*n*).

**Θ Examples**

**Example 1** Find Θ bound for ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.016.png)

**Solution: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.017.png)** for all, *n* ≥ 2

- ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.018.png) with*c*1 = 1/5,*c*2 = 1 and *n*0 = 2

**Example 2** Prove *n* ≠ Θ(*n*2)

**Solution:** *c*1 *n*2 *≤ n ≤ c*2*n*2 ⇒ onlyholds for: *n* ≤ 1/*c*1

∴*n* ≠ Θ(*n*2)

**Example 3** Prove 6*n*3 ≠ Θ(*n*2)

**Solution:** *c n*2*≤* 6*n*3 ≤ *c n*2 ⇒ onlyholds for: *n ≤ c* /6

1 2 2

∴6*n*3 ≠ Θ(*n*2)

**Example 4** Prove *n* ≠ Θ(*logn*)

**Solution:** c1*logn ≤ n ≤ c*2*logn* ⇒ c2 ≥ ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.019.png), ∀*n* ≥ *n*0 – Impossible

17. **Important Notes**

For analysis (best case, worst case and average), we try to give the upper bound (O) and lower bound (Ω) and average running time (Θ). From the above examples, it should also be clear that, for a given function (algorithm), getting the upper bound (O) and lower bound (Ω) and average running time (Θ) may not always be possible. For example, if we are discussing the best case of an algorithm, we try to give the upper bound (O) and lower bound (Ω) and average running time (Θ).

In the remaining chapters, we generally focus on the upper bound (O) because knowing the lower bound (Ω) of an algorithm is of no practical importance, and we use the Θ notation if the upper bound (O) and lower bound (Ω) are the same.

18. **Why is it called Asymptotic Analysis?**

From the discussion above (for all three notations: worst case, best case, and average case), we can easily understand that, in every case for a given function *f*(*n*) we are trying to find another

function *g*(*n*) which approximates *f*(*n*) at higher values of *n*. That means *g*(*n*) is also a curve whichapproximates *f*(*n*) at higher values of *n*.

In mathematics we call such a curve an *asymptotic curve*. In other terms, *g*(*n*) is the asymptotic

curve for *f*(*n*). For this reason, we call algorithmanalysis *asymptotic analysis.*

19. **Guidelines for Asymptotic Analysis**

There are some general rules to help us determine the runningtime of analgorithm.

1) **Loops:** The running time of a loop is, at most, the running time of the statements inside the loop (includingtests) multiplied bythe number of iterations.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.020.png)

Total time = a constant *c* × *n = c n =* O(*n*).

2) **Nested loops:** Analyze from the inside out. Total running time is the product of the sizes of all the loops.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.021.png)

Total time = *c* × *n* × *n = cn*2 = O(*n*2).

3) **Consecutive statements:** Add the time complexities of eachstatement.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.022.png)

Total time = *c*0 + *c n* + *c*2*n*2 = O(*n*2).

1

4) **If-then-else statements:** Worst-case running time: the test, plus *either* the *then* part *or* the *else* part (whichever is the larger).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.023.png)

Total time = *c*0 + *c*1 + (*c*2 + *c*3) \**n =* O(*n*).

5) **Logarithmic complexity:** An algorithm is O(*logn*) if it takes a constant time to cut the problem size by a fraction (usually by ½). As an example let us consider the followingprogram:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.024.png)

If we observe carefully, the value of *i* is doubling every time. Initially *i =* 1, in next step *i*

- 2, and in subsequent steps *i =* 4,8 and so on. Let us assume that the loop is executing some *k* times. At *kth* step 2*k* = *n*, and at (*k* + 1)*th* step we come out of the *loop*. Taking logarithmonbothsides, gives

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.025.png)

Total time = O(*logn*).

**Note:** Similarly, for the case below, the worst case rate of growth is O(*logn*). The same discussionholds good for the decreasingsequence as well.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.026.png)

Another example: binarysearch(findinga word ina dictionaryof *n* pages)

- Lookat the center point inthe dictionary
- Is the word towards the left or right of center?
- Repeat the process withthe left or right part of the dictionaryuntil the word is found.

20. **Simplyfying properties of asymptotic notations**

- Transitivity: *f*(*n*) = Θ(*g*(*n*)) and *g*(*n*) = Θ(*h*(*n*)) ⇒ *f*(*n*) = Θ(*h*(*n*)). Valid for O and Ω as well.
- Reflexivity: *f*(*n*) = Θ(*f*(*n*)). Valid for O and Ω.
- Symmetry: *f*(*n*) = Θ(*g*(*n*)) if and onlyif *g*(*n*) = Θ(*f*(*n*)).
- Transpose symmetry: *f*(*n*) = O(*g*(*n*)) if and onlyif *g*(*n*) = Ω(*f*(*n*)).
- If *f*(*n*) is inO(*kg*(*n*)) for anyconstant *k >* 0, then*f*(*n*) is inO(*g*(*n*)).
- If *f*1(*n*) is in O(*g*1(*n*)) and *f*2(*n*) is in O(*g*2(*n*)), then (*f*1 + *f*2)(*n*) is in O(max(*g*1(*n*)), (*g*1(*n*))).
- If *f*1(*n*) is inO(*g*1(*n*)) and *f*2(*n*) is inO(*g*2(*n*)) then*f*1(*n*) *f*2(*n*) is inO(*g*1(*n*) *g*1(*n*)).

21. **Commonly used Logarithms and Summations**

Logarithms

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.027.png)

Arithmetic series

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.028.png)

Geometric series

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.029.png)

Harmonic series

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.030.png)

Other important formulae

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.031.png)

22. **Master Theorem for Divide and Conquer Recurrences**

All divide and conquer algorithms (also discussed in detail in the *Divide and Conquer* chapter) divide the problem into sub-problems, each of which is part of the original problem, and then perform some additional work to compute the final answer. As an example, a merge sort algorithm [for details, refer to *Sorting* chapter] operates on two sub-problems, each of which is half the size of the original, and then performs O(*n*) additional work for merging. This gives the

runningtime equation:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.032.png)

The following theorem can be used to determine the running time of divide and conquer algorithms. For a given program (algorithm), first we try to find the recurrence relation for the problem. If the recurrence is of the below formthen we can directly give the answer without fully

solving it. If the recurrence is of the form ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.033.png), where *a* ≥ 1*,b >* 1,*k* ≥ 0 and p is a real number, then:

1) If a > *bk*, then![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.034.png)
1) If a= *bk*

1. If *p* > –1, then![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.035.png)
1. If *p* = –1, then![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.036.png)
1. If *p* < –1, then![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.034.png)

3) If *a* < *bk*

1. If *p* ≥ 0, then*T*(*n*) = Θ(*nklogpn*)
2. If *p* < 0, then*T*(*n*) = O(*nk*)
3. **Divide and Conquer Master Theorem: Problems & Solutions**

For each of the following recurrences, give an expression for the runtime *T*(*n*) if the recurrence can be solved with the Master Theorem. Otherwise, indicate that the Master Theorem does not apply.

**Problem-1**  *T*(*n*) = 3*T* (*n*/2) + *n*2

**Solution:** *T*(*n*) = 3*T* (*n*/2) *+ n*2 *=> T* (*n*) =Θ(*n*2) (Master TheoremCase 3.a) **Problem-2**  *T*(*n*) = 4*T* (*n*/2) + *n*2

**Solution:** *T*(*n*) = 4*T* (*n*/2) + *n*2 => *T* (*n*) = Θ(*n*2*logn*) (Master TheoremCase 2.a) **Problem-3**  *T*(*n*) *= T*(*n/*2) *+ n*2

**Solution:** *T*(*n*) *= T*(*n/*2) + *n*2 => Θ(*n*2) (Master TheoremCase 3.a)

**Problem-4**  *T*(*n*) = 2*nT*(*n/*2) + *nn*

**Solution:** *T*(*n*) = 2*nT*(*n/*2) + *nn =>* Does not apply(a is not constant)

**Problem-5**  *T*(*n*) = 16*T*(*n*/4) + *n*

**Solution:** *T*(*n*) = 16*T* (*n*/4) + *n* => *T*(*n*) = Θ(*n*2) (Master TheoremCase 1)

**Problem-6**  *T*(*n*) = 2*T*(*n*/2) + *nlogn*

**Solution:** *T*(*n*) = 2*T*(*n*/2) + *nlogn => T*(*n*) = Θ(*nlog*2*n*) (Master TheoremCase 2.a)

**Problem-7**  *T*(*n*) = 2*T*(*n*/2) + *n/logn*

**Solution:** *T*(*n*) = 2*T*(*n/*2)*+ n/logn =>T*(*n*) = Θ(*nloglogn*) (Master TheoremCase 2. b)

**Problem-8**  *T*(*n*) = 2*T* (*n*/4) + *n*051

**Solution:** *T*(*n*) = 2*T*(*n*/4) + *n*051 => *T* (*n*) = Θ(*n*0.51) (Master TheoremCase 3.b)

**Problem-9**  *T*(*n*) = 0.5*T*(*n*/2) + 1/*n*

**Solution:** *T*(*n*) = 0.5*T*(*n*/2) + 1/*n* => Does not apply(*a* < 1)

**Problem-10**  *T* (*n*) = 6*T*(*n/*3)*+ n*2 *logn*

**Solution:** *T*(*n*) = 6*T*(*n*/3) + *n*2*logn => T*(*n*) = Θ(*n*2*logn*) (Master TheoremCase 3.a)

**Problem-11**  *T*(*n*) = 64*T*(*n*/8) – *n*2*logn*

**Solution:** *T*(*n*) = 64*T*(*n*/8) – *n*2*logn* => Does not apply(functionis not positive)

**Problem-12**  *T*(*n*) = 7T(*n*/3) + *n*2

**Solution:** *T*(*n*) = 7*T*(*n*/3) + *n*2 => *T*(*n*) = Θ(*n*2) (Master TheoremCase 3.as)

**Problem-13**  *T*(*n*) = 4*T*(*n*/2) + *logn*

**Solution:** *T*(*n*) = 4*T*(*n*/2) + *logn => T*(*n*) = Θ(*n*2) (Master TheoremCase 1)

**Problem-14**  *T*(*n*) = 16*T* (*n*/4) + *n*!

**Solution:** *T*(*n*) = 16*T* (*n*/4) + *n*! => *T*(*n*) = Θ(*n*!) (Master TheoremCase 3.a)

**Problem-15**  *T*(*n*) = ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.037.png)*T*(*n*/2) + *logn*

**Solution:** *T*(*n*) = ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.037.png)*T*(*n*/2) + *logn => T*(*n*) = Θ(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)) (Master TheoremCase 1) **Problem-16**  *T*(*n*) = 3*T*(*n/*2) *+ n*

**Solution:** *T*(*n*) = 3*T*(*n*/2) + *n =>T*(*n*) = Θ(*nlog*3) (Master TheoremCase 1) **Problem-17**  *T*(*n*) = 3*T*(*n*/3) + ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)

**Solution:** *T*(*n*) = 3*T*(*n*/3) + ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png) => *T*(*n*) = Θ(*n*) (Master TheoremCase 1)

**Problem-18**  *T*(*n*) = 4*T*(*n*/2) + *cn*

**Solution:** *T*(*n*) = 4T(*n*/2) + *cn => T*(*n*) = Θ(*n*2) (Master TheoremCase 1)

**Problem-19**  *T*(*n*) = 3*T*(*n*/4) + *nlogn*

**Solution:** *T*(*n*) = 3*T*(*n*/4) + *nlogn => T*(*n*) = Θ(*nlogn*) (Master TheoremCase 3.a)

**Problem-20**  *T* (*n*) = 3*T*(*n/*3) *+ n/*2

**Solution:** *T*(*n*) = 3*T*(*n/*3)*+ n/*2 *=> T* (*n*) = Θ(*nlogn*) (Master TheoremCase 2.a)

24. **Master Theorem for Subtract and Conquer Recurrences**

Let *T*(*n*) be a functiondefined onpositive n, and havingthe property

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.039.png)

for some constants *c,a* > 0,b ≥ 0,*k* ≥ 0, and function*f*(*n*). If *f*(*n*) is inO(*nk*), then

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.040.png)

25. **Variant of Subtraction and Conquer Master Theorem**

The solution to the equation *T*(*n*) *= T*(*α n*) + T((1 – *α*)*n*) *+ βn*, where 0 < *α* < 1 and *β* > 0 are constants, is O(*nlogn*).

26. **Method of Guessing and Confirming**

Now, let us discuss a method which can be used to solve any recurrence. The basic idea behind this method is:

*guess* the answer; and then*prove* it correct byinduction.

Inother words, it addresses the question: What if the givenrecurrence doesn’t seemto matchwith any of these (master theorem) methods? If we guess a solution and then try to verify our guess inductively, usually either the proof will succeed (in which case we are done), or the proof will fail (inwhichcase the failure will help us refine our guess).

As an example, consider the recurrence ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.041.png). This doesn’t fit into the form required by the Master Theorems. Carefully observing the recurrence gives us the impression that it is similar to the divide and conquer method (dividing the problem into ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png) subproblems each

with size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)). As we can see, the size of the subproblems at the first level of recursion is *n*. So, let us guess that T(*n*) = O(*nlogn*), and thentryto prove that our guess is correct.

Let’s start bytryingto prove an*upper* bound T(*n*) < *cnlogn:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.042.png)

The last inequality assumes only that 1 ≤ c.![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.043.png)*.logn*. This is correct if *n* is sufficiently large and for

any constant *c*, no matter how small. From the above proof, we can see that our guess is correct for the upper bound. Now, let us prove the *lower* bound for this recurrence.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.044.png)

The last inequality assumes only that 1 ≥ *k.![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.043.png).logn*. This is incorrect if n is sufficiently large and

for any constant *k*. From the above proof, we can see that our guess is incorrect for the lower bound.

Fromthe above discussion, we understood that Θ(*nlogn*) is too big. How about Θ(*n*)? The lower bound is easyto prove directly:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.045.png)

Now, let us prove the upper bound for this Θ(*n*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.046.png)

From the above induction, we understood that Θ(*n*) is too small and Θ(*nlogn*) is too big. So, we need somethingbigger than*n* and smaller than*nlogn*. How about ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.047.png)?

Provingthe upper bound for ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.047.png):

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.048.png)

Provingthe lower bound for ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.047.png):

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.049.png)

The last step doesn’t work. So, Θ(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.047.png)) doesn’t work. What else is between *n* and *nlogn?* How about *nloglogn?* Provingupper bound for *nloglogn:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.050.png)

Provinglower bound for *nloglogn:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.051.png)

Fromthe above proofs, we cansee that T(*n*) ≤ *cnloglogn*, if *c* ≥ 1 and T(*n*) ≥ *knloglogn*, if *k* ≤ 1. Technically, we’re still missing the base cases in both proofs, but we can be fairly confident at this point that T(*n*) = Θ(*nloglogn*).

27. **Amortized Analysis**

Amortized analysis refers to determining the time-averaged running time for a sequence of operations. It is different from average case analysis, because amortized analysis does not make any assumption about the distribution of the data values, whereas average case analysis assumes the data are not “bad” (e.g., some sorting algorithms do well *on average* over all input orderings but very badly on certain input orderings). That is, amortized analysis is a worst-case analysis, but for a sequence of operations rather thanfor individual operations.

The motivation for amortized analysis is to better understand the running time of certain techniques, where standard worst case analysis provides an overly pessimistic bound. Amortized analysis generally applies to a method that consists of a sequence of operations, where the vast majority of the operations are cheap, but some of the operations are expensive. If we can show that the expensive operations are particularly rare we can *change them* to the cheap operations, and onlybound the cheap operations.

The general approachis to assignanartificial cost to eachoperationinthe sequence, suchthat the total of the artificial costs for the sequence of operations bounds the total of the real costs for the sequence. This artificial cost is called the amortized cost of an operation. To analyze the running time, the amortized cost thus is a correct way of understanding the overall running time – but note that particular operations can still take longer so it is not a way of bounding the running time of anyindividual operationinthe sequence.

Whenone event ina sequence affects the cost of later events:

- One particular taskmaybe expensive.
- But it mayleave data structure ina state that the next few operations become easier.

**Example:** Let us consider an array of elements from which we want to find the *kth* smallest element. We can solve this problem using sorting. After sorting the given array, we just need to

returnthe *kth* element fromit. The cost of performing the sort (assuming comparison based sorting algorithm) is O(*nlogn*). If we performn such selections then the average cost of each selection is O(*nlogn/n*) = O(*logn*). This clearly indicates that sorting once is reducing the complexity of subsequent operations.

28. **Algorithms Analysis: Problems & Solutions**

**Note:** From the following problems, try to understand the cases which have different complexities (O(*n*), O(*logn*), O(*loglogn*) etc.).

**Problem-21**  Find the complexityof the below recurrence:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.052.png)

**Solution:** Let us trysolvingthis functionwithsubstitution.

*T*(*n*) = 3*T*(*n –* 1)

*T*(*n*) = 3(3*T*(*n* – 2)) = 32*T*(*n* – 2) *T*(*n*) = 32(3*T*(*n* – 3))

.

.

*T*(*n*) = 3*nT*(*n* – *n*) = 3*nT*(0) = 3*n*

This clearlyshows that the complexityof this functionis O(3*n*).

**Note:** We canuse the *Subtraction and Conquer* master theoremfor this problem. **Problem-22**  Find the complexityof the below recurrence:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.053.png)

**Solution:** Let us trysolvingthis functionwithsubstitution.

*T*(*n*) = 2*T*(*n* – 1) – 1

*T*(*n*) = 2(2*T*(*n* – 2) – 1) – 1 = 22*T*(*n* – 2) – 2 – 1

*T*(*n*) = 22(2*T*(*n* – 3) – 2 – 1) – 1 = 23*T*(*n* – 4) – 22 – 21 – 20 *T*(*n*) = 2*nT*(*n* – *n*) – 2*n*–1 – 2*n*–2 – 2*n*–3 .... 22 – 21 – 20

*T*(*n*) =2*n* – 2*n*–1 *–* 2*n*–2 *–* 2*n* – 3 *...*. 22 – 21 – 20

*T*(*n*) =2*n* – (2*n* – 1) [*note:* 2*n*–1 + 2*n*–2 + ··· + 20 = 2*n*]

*T*(*n*) = 1

- Time Complexity is O(1). Note that while the recurrence relation looks exponential, the solutionto the recurrence relationhere gives a different result.

**Problem-23**  What is the runningtime of the followingfunction?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.054.png)

**Solution:** Consider the comments inthe below function:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.055.png)

We can define the *‘s’* terms according to the relation *si = si–*1 *+ i*. The value oft’ increases by 1

for each iteration. The value contained in *‘s’* at the *ith* iteration is the sum of the first ‘(‘positive integers. If *k* is the total number of iterations taken by the program, then the *while* loop terminates if:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.056.png)

**Problem-24**  Find the complexityof the functiongivenbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.057.png)

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.058.png)

In the above-mentioned function the loop will end, if *i*2 *> n* ⇒ *T*(*n*) = O(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)). This is similar to [Problem-23](#_page39_x66.91_y666.25).

**Problem-25**  What is the complexityof the programgivenbelow:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.059.png)

**Solution:** Consider the comments inthe followingfunction.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.060.png)

The complexityof the above functionis O(*n*2*logn*).

**Problem-26**  What is the complexityof the programgivenbelow:


![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.061.png)

**Solution:** Consider the comments inthe followingfunction.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.062.png)

The complexityof the above functionis O(*nlog*2*n*). **Problem-27**  Find the complexityof the programbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.063.jpeg)

**Solution:** Consider the comments inthe functionbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.064.png)

The complexity of the above function is O(*n*). Even though the inner loop is bounded by *n*, due to the breakstatement it is executingonlyonce.

**Problem-28**  Write a recursive function for the running time T(*n*) of the function given below.

Prove usingthe iterative method that *T*(*n*) = Θ(*n*3).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.065.png)

**Solution:** Consider the comments inthe functionbelow:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.066.png)

The recurrence for this code is clearly T(*n*) = *T*(*n* – 3) + *cn*2 for some constant *c >* 0 since each call prints out *n*2 asterisks and calls itself recursivelyon*n* – 3. Using the iterative method we get: *T*(*n*) *= T*(*n* – 3) + *cn*2. Usingthe *Subtraction and Conquer* master theorem, we get *T*(*n*) = Θ(*n*3).

**Problem-29**  Determine Θ bounds for the recurrence relation: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.067.png)

**Solution:** UsingDivide and Conquer master theorem, we get O(*nlog*2*n*).

**Problem-30**  Determine Θ bounds for the recurrence:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.068.png)

**Solution:** Substituting in the recurrence equation, we get: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.069.png), where *k* is a constant. This clearly

says Θ(*n*).

**Problem-31**  Determine Θ bounds for the recurrence relation: *T*(*n*) *= T*(⌈*n/*2⌉) + 7. **Solution:** UsingMaster Theoremwe get: Θ(*logn*).

**Problem-32**  Prove that the runningtime of the code below is Ω(*logn*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.070.png)

**Solution:** The *while* loop will terminate once the value of *‘k’* is greater than or equal to the value of *‘n’*. In each iteration the value of *‘k’* is multiplied by 3. If *i* is the number of iterations, then *‘k’*

has the value of 3*i* after *i* iterations. The loop is terminated upon reaching *i* iterations when 3*i* ≥ *n*

↔ *i ≥* log3 *n*, whichshows that *i = Ω*(*logn*). **Problem-33**  Solve the followingrecurrence.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.071.png)

**Solution:** Byiteration:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.072.jpeg)

**Note:** We canuse the *Subtraction and Conquer* master theoremfor this problem. **Problem-34**  Consider the followingprogram:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.073.png)

**Solution:** The recurrence relation for the running time of this programis: T(*n*) = *T*(*n* – 1) + *T*(*n* – 2) + *c*. Note *T*(*n*) has two recurrence calls indicatinga binarytree. Eachstep recursivelycalls the program for *n* reduced by 1 and 2, so the depth of the recurrence tree is O(*n*). The number of

leaves at depth *n* is 2*n* since this is a full binary tree, and each leaf takes at least O(1) computations for the constant factor. Runningtime is clearlyexponential innand it is O(2*n*).

**Problem-35**  Runningtime of followingprogram?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.074.png)

**Solution:** Consider the comments inthe functionbelow:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.075.png)

In the above code, inner loop executes *n/i* times for each value of *i*. Its running time is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.076.png).

**Problem-36**  What is the complexityof ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.077.png)

**Solution:** Using the logarithmic property, *logxy = logx + logy*, we can see that this problem is equivalent to

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.078.png)

This shows that the time complexity= O(*nlogn*).

**Problem-37**  What is the running time of the following recursive function (specified as a

function of the input value *n*)? First write the recurrence formula and then find its complexity.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.079.png)

**Solution:** Consider the comments inthe below function:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.080.png)

We can assume that for asymptotical analysis *k =* ⌈*k*⌉for every integer *k ≥* 1. The recurrence for this code is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.081.png). Usingmaster theorem, we get T(*n*) = Θ(*n*).

**Problem-38**  What is the running time of the following recursive function (specified as a

functionof the input value *n*)? First write a recurrence formula, and show its solutionusing induction.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.082.png)

**Solution:** Consider the comments inthe functionbelow:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.083.png)

The *if* statement requires constant time [O(1)]. With the *for* loop, we neglect the loop overhead and only count three times that the function is called recursively. This implies a time complexity recurrence:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.084.png)

Usingthe *Subtraction and Conquer* master theorem, we get *T*(*n*) = Θ(3*n*).

**Problem-39**  Write a recursion formula for the running time *T*(*n*) of the function whose code

is below.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.085.png)

**Solution:** Consider the comments inthe functionbelow:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.086.png)

The recurrence for this piece of code is *T*(*n*) = T(.8*n*) + O(*n*) = *T*(4/5*n*) *+* O(*n*) =4/5 *T*(*n*) + O(*n*). Applyingmaster theorem, we get *T*(*n*) = O(*n*).

**Problem-40**  Find the complexityof the recurrence: *T*(*n*) = 2T(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)) + *logn*

**Solution:** The givenrecurrence is not inthe master theoremformat. Let us tryto convert this to the master theorem format by assuming *n* = 2*m*. Applying the logarithm on both sides gives, *logn = mlogl* ⇒ *m = logn*. Now, the givenfunctionbecomes:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.087.png)

To make it simple we assume

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.088.png).

Applyingthe master theoremformat would result in*S*(*m*) = O(*mlogm*). If we substitute *m* = *logn* back, *T*(*n*) = *S*(*logn*) = O((*logn*) *loglogn*).

**Problem-41**  Find the complexityof the recurrence: *T*(*n*) *= T*(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)) + 1

**Solution:** Applying the logic of [Problem-40](#_page48_x66.91_y459.29) gives ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.089.png). Applying the master theorem would result in *S*(*m*) = O(*logm*). Substituting *m* = *logn*, gives *T*(*n*) *= S*(*logn*) = O(*loglogn*).

**Problem-42**  Find the complexityof the recurrence: *T*(*n*) = 2*T*(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)) + 1

**Solution:** Applying the logic of [Problem-40](#_page48_x66.91_y459.29) gives: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.090.png). Using the master theoremresults *S*(*m*) = ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.091.png). Substituting*m* = *logn* gives *T*(*n*) =O(*logn*).

**Problem-43**  Find the complexityof the below function.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.092.png)

**Solution:** Consider the comments inthe functionbelow:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.093.png)

For the above code, the recurrence function can be given as: *T*(*n*) *= T*(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)) + 1. This is same as that of [Problem-41](#_page48_x66.91_y708.04).

**Problem-44**  Analyze the runningtime of the followingrecursive pseudo-code as a functionof

*n.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.094.jpeg)

**Solution:** Consider the comments in below pseudo-code and call running time of function(n) as *T*(*n*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.095.png)

*T*(*n*) canbe defined as follows:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.096.png)

Usingthe master theoremgives: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.097.png). **Problem-45**  Find the complexityof the below pseudocode:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.098.png)

**Solution:** Consider the comments inthe pseudocode below:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.099.png)

The recurrence for this functionis *T*(*n*) *= T*(*n*/2) + *n*. Usingmaster theorem, we get *T*(*n*) = O(*n*).

**Problem-46**  Runningtime of the followingprogram?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.100.png)

**Solution:** Consider the comments inthe below function:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.101.png)

Complexityof above programis: O(*nlogn*).

**Problem-47**  Runningtime of the followingprogram?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.102.png)

**Solution:** Consider the comments inthe below function:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.103.png)

The time complexityof this programis: O(*n*2). **Problem-48**  Find the complexityof the below function:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.104.png)

**Solution:** Consider the comments inthe below function:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.105.png)

The recurrence for this function is: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.106.png). Using master theorem, we get *T*(*n*) = O(*n*).

**Problem-49**  Find the complexityof the below function:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.107.png)

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.108.png)

Time Complexity: O(*logn \* logn*) = O(*log*2*n*).

**Problem-50**  ∑*i≤k≤n* O(*n*), where O(*n*) stands for order *n* is:

1) O(*n*)
1) O(*n*2)
1) O(*n*3)
1) O(3*n*2)
1) O(1.5*n*2)

**Solution: (B)**. ∑*i≤k≤n* O(*n*) = O(*n*) ∑*i≤k≤n* 1 = O(*n*2).

**Problem-51**  Whichof the followingthree claims are correct?

I (*n* + *k*)*m*= Θ(*nm*), where *k* and mare constants

II 2*n*+1 = O(2*n*)

III 22*n*+1 = O(2*n*)

1) I and II
1) I and III
1) II and III
1) I, II and III

**Solution: (A).** (I) (*n + k*)*m*=*nh +* c1\**nk*–1 + ... *km=* Θ(*nh*) and (II) 2*n*+1 = 2\*2*n* = O(2*n*)

**Problem-52**  Consider the followingfunctions:

f(*n*) = 2*n*

g(*n*) = *n*!

h(*n*) = *nlogn*

Which of the following statements about the asymptotic behavior of f(*n*), g(*n*), and h(*n*) is true?

1) f(*n*) = O(g(*n*)); g(*n*) = O(h(*n*))
1) f(*n*) = Ω (g(*n*)); g(*n*) = O(h(*n*))


3) g(*n*) = O(f(*n*)); h(*n*) = O(f(*n*))
3) h(*n*) = O(f(*n*)); g(*n*) = Ω (f(*n*))

**Solution: (D).** According to the rate of growth: h(*n*) < f(*n*) < g(*n*) (g(*n*) is asymptotically greater than f(*n*), and f(*n*) is asymptotically greater than h(*n*)). We can easily see the above order by takinglogarithms of the given3 functions: *lognlogn* < *n* < *log*(*n*!). Note that, *log*(*n*!) = O(*nlogn*).

**Problem-53**  Consider the followingsegment of C-code:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.109.png)

The number of comparisons made inthe executionof the loop for any*n* > 0 is:

1) ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.110.png)
1) *n*
1) ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.111.png)
1) ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.112.png)

**Solution: (a).** Let us assume that the loop executes *k* times. After *kth* step the value *of j* is 2*k*. Taking logarithms on both sides gives ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.113.png). Since we are doing one more comparison for exitingfromthe loop, the answer is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.110.png).

**Problem-54**  Consider the followingC code segment. Let T(*n*) denote the number of times the

for loop is executed bythe programoninput *n*. Whichof the followingis true?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.114.png)

1) T(*n*) = O(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)) and T(*n*) = Ω(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png))
1) T(*n*) = O(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)) and T(*n*) = Ω(1)
1) T(*n*) = O(*n*) and T(*n*) = Ω(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png))
1) None of the above

**Solution: (B).** Big O notation describes the tight upper bound and Big Omega notation describes the tight lower bound for analgorithm. The *for* loop inthe questionis runmaximum![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png) times and

minimum1 time. Therefore, T(*n*) = O(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.038.png)) and T(*n*) = Ω(1).

**Problem-55**  In the following C function, let *n* ≥ *m*. How many recursive calls are made by

this function?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.115.png)

1) ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.116.png)
1) Ω(*n*)
1) ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.117.png)
1) Θ(*n*)

**Solution:** No option is correct. Big O notation describes the tight upper bound and Big Omega notationdescribes the tight lower bound for analgorithm. For *m =* 2 and for all n= 2*i*, the running time is O(1) whichcontradicts everyoption.

**Problem-56**  Suppose *T*(*n*) = 2*T*(*n*/2) + *n*, T(O)=T(1)=1. Whichone of the followingis false?

1) *T*(*n*) = O(*n*2)
1) *T*(*n*) = Θ(*nlogn*)
1) *T*(*n*) = Q(*n*2)
1) *T*(*n*) = O(*nlogn*)

**Solution: (C).** Big O notation describes the tight upper bound and Big Omega notation describes the tight lower bound for an algorithm. Based on master theorem, we get *T*(*n*) = Θ(*nlogn*). This indicates that tight lower bound and tight upper bound are the same. That means, O(*nlogn*) and Ω(*nlogn*) are correct for givenrecurrence. So option(C) is wrong.

**Problem-57**  Find the complexityof the below function:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.118.jpeg)

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.119.png)

Time Complexity: O(*n*5).

**Problem-58**  To calculate 9*n*, give analgorithmand discuss its complexity. **Solution:** Start with1 and multiplyby9 until reaching9*n*.

Time Complexity: There are *n* – 1 multiplications and each takes constant time giving a Θ(*n*) algorithm.

**Problem-59**  For [Problem-58](#_page56_x66.91_y465.77), canwe improve the time complexity?

**Solution:** Refer to the *Divide and Conquer* chapter.

**Problem-60**  Find the time complexityof recurrence ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.120.png).

**Solution:** Let us solve this problem by method of guessing. The total size on each level of the recurrance tree is less than *n*, so we guess that *f*(*n*) *= n* will dominate. Assume for all *i* < *n* that *c*1*n ≤* T(*i*) < *c*2*n*. Then,

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.121.png)

If *c*1 *≥* 8k and *c*2 *≤* 8k, then *c*1*n =* T(*n*) *= c*2*n*. So, T(*n*) = Θ(*n*). In general, if you have multiple recursive calls, the sum of the arguments to those calls is less than *n* (in this case ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.122.png)), and *f*(*n*) is reasonablylarge, a good guess is T(*n*) = Θ(f(*n*)).

**Problem-61**  Solve the following recurrence relation using the recursion tree method:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.123.png).

**Solution:** How muchworkdo we do ineachlevel of the recursiontree?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.124.png)

Inlevel 0, we take *n*2 time. At level 1, the two subproblems take time:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.125.png)

At level 2 the four subproblems are of size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.126.png) and ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.127.png) respectively. These two subproblems take time:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.128.png)

Similarlythe amount of workat level *k* is at most ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.129.png). Let ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.130.png), the total runtime is then:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.131.png)

That is, the first level provides a constant fractionof the total runtime.

**Problem-62**  Rankthe followingfunctions byorder of growth: (*n* + 1)!, *n*!, 4*n*, *n* × 3*n*, 3*n* + *n*2

\+ 20*n*, ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.132.png), *n*2 + 200, 20*n* + 500, 2*lgn*, *n*2/3, 1.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.133.jpeg)

**Problem-63**  Find the complexityof the below function:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.134.jpeg)

**Solution:** Consider the worst-case.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.135.png)

Time Complexity: O(*n*2).

**Problem-64**  Canwe say![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.136.png)?

**Solution:** Yes: because ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.137.png)

**Problem-65**  Canwe say23*n* = O(2*n*)?

**Solution:** No: because 23*n* = (23)*n* = 8*n* not less than2*n*.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.138.png)

1. **Introduction**

In this chapter, we will look at one of the important topics, *“recursion”*, which will be used in almost everychapter, and also its relative *“backtracking”.*

2. **What is Recursion?**

Any function which calls itself is called *recursive*. A recursive method solves a problem by calling a copy of itself to work on a smaller problem. This is called the recursion step. The recursionstep canresult inmanymore suchrecursive calls.

It is important to ensure that the recursion terminates. Each time the function calls itself with a slightly simpler version of the original problem. The sequence of smaller problems must eventuallyconverge onthe base case.

3. **Why Recursion?**

Recursion is a useful technique borrowed from mathematics. Recursive code is generally shorter and easier to write than iterative code. Generally, loops are turned into recursive functions when theyare compiled or interpreted.

Recursion is most useful for tasks that can be defined in terms of similar subtasks. For example, sort, search, and traversal problems oftenhave simple recursive solutions.

4. **Format of a Recursive Function**

A recursive function performs a task in part by calling itself to perform the subtasks. At some point, the function encounters a subtask that it can performwithout calling itself. This case, where the function does not recur, is called the *base case*. The former, where the function calls itself to perform a subtask, is referred to as the *ecursive case*. We can write all recursive functions using the format:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.139.png)

As an example consider the factorial function: *n*! is the product of all integers between *n* and 1. The definitionof recursive factorial looks like:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.140.png)

This definition can easily be converted to recursive implementation. Here the problem is determining the value of *n*!, and the subproblem is determining the value of (*n* – *l*)!. In the recursive case, when *n* is greater than 1, the function calls itself to determine the value of (*n* – *l*)! and multiplies that with*n.*

Inthe base case, when*n* is 0 or 1, the functionsimplyreturns 1. This looks like the following:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.141.png)

5. **Recursion and Memory (Visualization)**

Each recursive call makes a new copy of that method (actually only the variables) in memory. Once a method ends (that is, returns some data), the copy of that returning method is removed from memory. The recursive solutions look simple but visualization and tracing takes time. For better understanding, let us consider the followingexample.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.142.png)

For this example, if we call the print function with n=4, visually our memory assignments may looklike:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.143.png)

Now, let us consider our factorial function. The visualization of factorial function with n=4 will looklike:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.144.png)

6. **Recursion versus Iteration**

While discussing recursion, the basic question that comes to mind is: which way is better? – iteration or recursion? The answer to this question depends on what we are trying to do. A recursive approach mirrors the problem that we are trying to solve. A recursive approach makes it simpler to solve a problemthat may not have the most obvious of answers. But, recursion adds

overhead for eachrecursive call (*n*eeds space onthe stackframe).

**Recursion**

- Terminates whena base case is reached.
- Eachrecursive call requires extra space onthe stackframe (memory).
- If we get infinite recursion, the program may run out of memory and result in stack overflow.
- Solutions to some problems are easier to formulate recursively.

**Iteration**

- Terminates whena conditionis provento be false.
- Eachiterationdoes not require extra space.
- Aninfinite loop could loop forever since there is no extra memorybeingcreated.
- Iterative solutions to a problem may not always be as obvious as a recursive solution.

7. **Notes on Recursion**

- Recursive algorithms have two types of cases, recursive cases and base cases.
- Everyrecursive functioncase must terminate at a base case.
- Generally, iterative solutions are more efficient than recursive solutions [due to the overhead of functioncalls].
- A recursive algorithm can be implemented without recursive function calls using a stack, but it’s usually more trouble than its worth. That means any problem that can be solved recursivelycanalso be solved iteratively.
- For some problems, there are no obvious iterative algorithms.
- Some problems are best suited for recursive solutions while others are not.

8. **Example Algorithms of Recursion**

- Fibonacci Series, Factorial Finding
- Merge Sort, QuickSort
- BinarySearch
- Tree Traversals and manyTree Problems: InOrder, PreOrder PostOrder
- GraphTraversals: DFS [DepthFirst Search] and BFS [BreadthFirst Search]
- Dynamic ProgrammingExamples
- Divide and Conquer Algorithms
- Towers of Hanoi
- BacktrackingAlgorithms [we will discuss innext section]

9. **Recursion: Problems & Solutions**

In this chapter we cover a few problems with recursion and we will discuss the rest in other chapters. By the time you complete reading the entire book, you will encounter many recursion problems.

**Problem-1**  Discuss Towers of Hanoi puzzle.

**Solution:** The Towers of Hanoi is a mathematical puzzle. It consists of three rods (or pegs or towers), and a number of disks of different sizes which can slide onto any rod. The puzzle starts with the disks on one rod in ascending order of size, the smallest at the top, thus making a conical shape. The objective of the puzzle is to move the entire stack to another rod, satisfying the followingrules:

- Onlyone diskmaybe moved at a time.
- Each move consists of taking the upper disk from one of the rods and sliding it onto another rod, ontop of the other disks that mayalreadybe present onthat rod.
- No diskmaybe placed ontop of a smaller disk.

**Algorithm:**

- Move the top *n* – 1 disks from*Source* to *Auxiliary* tower,
- Move the *nth* diskfrom*Source* to *Destination* tower,
- Move the *n* – 1 disks from*Auxiliary* tower to *Destination* tower.
- Transferring the top *n* – 1 disks from*Source* to *Auxiliary* tower can again be thought of as a fresh problemand can be solved in the same manner. Once we solve *Towers of Hanoi* with three disks, we can solve it with any number of disks with the above algorithm.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.145.png)

**Problem-2**  Givenanarray, checkwhether the arrayis insorted order withrecursion. **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.146.png)

Time Complexity: O(*n*). Space Complexity: O(*n*) for recursive stackspace.

10. **What is Backtracking?**

Backtracking is an improvement of the brute force approach. It systematically searches for a solution to a problem among all available options. In backtracking, we start with one possible option out of many available options and try to solve the problem if we are able to solve the problemwith the selected move then we will print the solution else we will backtrack and select some other option and try to solve it. If none if the options work out we will claimthat there is no solutionfor the problem.

Backtracking is a form of recursion. The usual scenario is that you are faced with a number of options, and you must choose one of these. After you make your choice you will get a new set of options; just what set of options you get depends on what choice you made. This procedure is repeated over and over until you reach a final state. If you made a good sequence of choices, your final state is a goal state; if youdidn’t, it isn’t.

Backtracking can be thought of as a selective tree/graph traversal method. The tree is a way of representing some initial starting position (the root node) and a final goal state (one of the leaves). Backtracking allows us to deal with situations in which a raw brute-force approach would explode into animpossible number of options to consider. Backtrackingis a sort of refined brute force. At each node, we eliminate choices that are obviously not possible and proceed to recursivelycheckonlythose that have potential.

What’s interestingabout backtrackingis that we backup onlyas far as needed to reacha previous decision point with an as-yet-unexplored alternative. In general, that will be at the most recent decision point. Eventually, more and more of these decision points will have been fully explored, and we will have to backtrack further and further. If we backtrack all the way to our initial state and have explored all alternatives from there, we can conclude the particular problem is unsolvable. In such a case, we will have done all the work of the exhaustive recursion and known that there is no viable solutionpossible.

- Sometimes the best algorithmfor a problemis to tryall possibilities.
- This is always slow, but there are standard tools that canbe used to help.
- Tools: algorithms for generating basic objects, such as binary strings [2*n* possibilities for n-bit string], permutations [*n*!], combinations [*n*!*/r*!(*n* – *r*)!], general strings [*k* –arystrings of lengthnhas *kn* possibilities], etc...
- Backtrackingspeeds the exhaustive searchbypruning.

11. **Example Algorithms of Backtracking**

- BinaryStrings: generatingall binarystrings
- Generating*k* – aryStrings
- N-Queens Problem
- The KnapsackProblem
- Generalized Strings
- HamiltonianCycles [refer to *Graphs* chapter]
- GraphColoringProblem

12. **Backtracking: Problems & Solutions**

**Problem-3**  Generate all the strings of *n* bits. Assume *A*[0*..n* – 1] is anarrayof size *n.* **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.147.png)

Let *T*(*n*) be the runningtime *of binary*(*n*). Assume function*printf* takes time O(1).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.148.png)

Using Subtraction and Conquer Master theorem we get: *T*(*n*) = O(2*n*). This means the algorithm for generatingbit-strings is optimal.

**Problem-4**  Generate all the strings of lengthndrawnfrom0... *k* – 1.

**Solution:** Let us assume we keep current k-ary string in an array *A*[0*.. n* – 1]. Call function *k- string*(n, k):

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.149.png)

Let *T*(*n*) be the runningtime of *k* – *string*(*n*). Then,

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.150.png)

UsingSubtractionand Conquer Master theoremwe get: *T*(*n*) = O(*kn*). **Note:** For more problems, refer to *String Algorithms* chapter.

**Problem-5  Finding the length of connected cells of 1s (regions) in an matrix of Os and**

**1s:** Givena matrix, eachof whichmaybe 1 or 0. The filled cells that are connected forma region. Two cells are said to be connected if they are adjacent to each other horizontally, vertically or diagonally. There may be several regions in the matrix. How do you find the largest region(interms of number of cells) inthe matrix?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.151.png)

**Solution:** The simplest idea is: for each location traverse in all 8 directions and in each of those directions keep trackof maximumregionfound.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.152.jpeg)

*Sample Call:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.153.png)

**Problem-6**  Solve the recurrence T(*n*) = 2T(*n* – 1) + 2*n*.

**Solution:** At each level of the recurrence tree, the number of problems is double from the previous level, while the amount of work being done in each problem is half from the previous

level. Formally, the *ith* level has 2*i* problems, each requiring 2*n*–*i* work. Thus the *ith* level requires exactly 2*n* work. The depth of this tree is *n*, because at the *ith* level, the originating call will be T(*n* – *i*). Thus the total complexityfor T(*n*) is T(*n*2*n*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.154.png)

1. **What is a Linked List?**

Alinked list is a data structure used for storing collections of data. Alinked list has the following properties.

- Successive elements are connected bypointers
- The last element points to NULL
- Cangrow or shrinkinsize duringexecutionof a program
- Canbe made just as longas required (until systems memoryexhausts)
- Does not waste memory space (but takes some extra memory for pointers). It allocates memoryas list grows.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.155.png)

2. **Linked Lists ADT**

The followingoperations make linked lists anADT:

**Main Linked Lists Operations**

- Insert: inserts anelement into the list
- Delete: removes and returns the specified positionelement fromthe list

**Auxiliary Linked Lists Operations**

- Delete List: removes all elements of the list (disposes the list)
- Count: returns the number of elements inthe list
- Find *nth* node fromthe end of the list

3. **Why Linked Lists?**

There are many other data structures that do the same thing as linked lists. Before discussing linked lists it is important to understand the difference between linked lists and arrays. Both linked lists and arrays are used to store collections of data, and since both are used for the same purpose, we need to differentiate their usage. That means in which cases *arrays* are suitable and inwhichcases *linked lists* are suitable.

4. **Arrays Overview**

One memory block is allocated for the entire array to hold the elements of the array. The array elements can be accessed in constant time by using the index of the particular element as the subscript.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.156.png)

**Why Constant Time for Accessing Array Elements?**

To access an array element, the address of an element is computed as an offset from the base address of the array and one multiplication is needed to compute what is supposed to be added to the base address to get the memory address of the element. First the size of an element of that data type is calculated and then it is multiplied with the index of the element to get the value to be added to the base address.

This process takes one multiplication and one addition. Since these two operations take constant time, we cansaythe arrayaccess canbe performed inconstant time.

**Advantages of Arrays**

- Simple and easyto use
- Faster access to the elements (constant access)

**Disadvantages of Arrays**

- Preallocates all needed memoryup front and wastes memoryspace for indices inthe arraythat are empty.
- **Fixedsize:** The size of the arrayis static (specifythe arraysize before usingit).
- **One block allocation:** To allocate the array itself at the beginning, sometimes it may not be possible to get the memoryfor the complete array(if the arraysize is big).
- **Complex position-basedinsertion:** To insert anelement at a givenposition, we may need to shift the existing elements. This will create a position for us to insert the new element at the desired position. If the position at which we want to add an element is at the beginning, thenthe shiftingoperationis more expensive.

**Dynamic Arrays**

Dynamic array(also called as *growable array, resizable array, dynamic table*, or *array list*) is a randomaccess, variable-size list data structure that allows elements to be added or removed.

One simple way of implementing dynamic arrays is to initially start with some fixed size array. As soon as that array becomes full, create the new array double the size of the original array.

Similarly, reduce the arraysize to half if the elements inthe arrayare less thanhalf.

**Note:** We will see the implementation for *dynamic arrays* in the *Stacks, Queues* and *Hashing* chapters.

**Advantages of Linked Lists**

Linked lists have bothadvantages and disadvantages. The advantage of linked lists is that theycan be *expanded* in constant time. To create an array, we must allocate memory for a certain number of elements. To add more elements to the array when full, we must create a new array and copy the old arrayinto the new array. This cantake a lot of time.

We can prevent this by allocating lots of space initially but then we might allocate more than we need and waste memory. With a linked list, we can start with space for just one allocated element and *add* onnew elements easilywithout the need to do anycopyingand reallocating.

**Issues with Linked Lists (Disadvantages)**

There are a number of issues with linked lists. The main disadvantage of linked lists is *access time* to individual elements. Array is random-access, which means it takes O(1) to access any element in the array. Linked lists take O(*n*) for access to an element in the list in the worst case. Another advantage of arrays in access time is *spacial locality* in memory. Arrays are defined as contiguous blocks of memory, and so anyarrayelement will be physicallynear its neighbors. This greatlybenefits frommodernCPUcachingmethods.

Although the dynamic allocation of storage is a great advantage, the *overhead* with storing and retrieving data can make a big difference. Sometimes linked lists are *hard to manipulate*. If the last itemis deleted, the last but one must then have its pointer changed to hold a NULLreference. This requires that the list is traversed to find the last but one link, and its pointer set to a NULL reference.

Finally, linked lists waste memoryinterms of extra reference points.

5. **Comparison of Linked Lists with Arrays & Dynamic Arrays**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.157.png)

6. **Singly Linked Lists**

Generally“linked list” means a singlylinked list. This list consists of a number of nodes inwhich each node has a *next* pointer to the following element. The link of the last node in the list is NULL, whichindicates the end of the list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.158.png)

Followingis a type declarationfor a linked list of integers:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.159.png)

**Basic Operations on a List**

- Traversingthe list
- Insertinganiteminthe list
- Deletinganitemfromthe list

**Traversing the Linked List**

Let us assume that the *head* points to the first node of the list. To traverse the list we do the following

- Follow the pointers.
- Displaythe contents of the nodes (or count) as theyare traversed.
- Stop whenthe next pointer points to NULL.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.160.png)

The ListLength() function takes a linked list as input and counts the number of nodes in the list. The functiongivenbelow canbe used for printingthe list data withextra print function.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.161.png)

Time Complexity: O(*n*), for scanningthe list of size *n*. Space Complexity: O(1), for creatinga temporaryvariable.

**Singly Linked List Insertion**

Insertioninto a singly-linked list has three cases:

- Insertinga new node before the head (at the beginning)
- Insertinga new node after the tail (at the end of the list)
- Insertinga new node at the middle of the list (randomlocation)

**Note:** To insert an element in the linked list at some position *p*, assume that after inserting the element the positionof this new node is *p*.

**Inserting a Node in Singly Linked List at the Beginning**

In this case, a new node is inserted before the current head node. *Only one next pointer* needs to be modified (*n*ew node’s next pointer) and it canbe done intwo steps:

- Update the next pointer of new node, to point to the current head.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.162.png)

- Update head pointer to point to the new node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.163.png)

**Inserting a Node in Singly Linked List at the Ending**

In this case, we need to modify *two next pointers* (last nodes next pointer and new nodes next pointer).

- New nodes next pointer points to NULL.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.164.png)

- Last nodes next pointer points to the new node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.165.png)

**Inserting a Node in Singly Linked List at the Middle**

Let us assume that we are given a position where we want to insert the new node. In this case also, we need to modifytwo next pointers.

- If we want to add an element at position 3 then we stop at position 2. That means we traverse 2 nodes and insert the new node. For simplicity let us assume that the second node is called *position* node. The new node points to the next node of the positionwhere we want to add this node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.166.png)

- Positionnode’s next pointer now points to the new node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.167.png)

Let us write the code for all three cases. We must update the first element pointer in the calling function, not just in the called function. For this reason we need to send a double pointer. The followingcode inserts a node inthe singlylinked list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.168.jpeg)

**Note:** We canimplement the three variations of the *insert* operationseparately.

Time Complexity: O(*n*), since, in the worst case, we may need to insert the node at the end of the list.

Space Complexity: O(1), for creatingone temporaryvariable.

**Singly Linked List Deletion**

Similar to insertion, here we also have three cases.

- Deletingthe first node
- Deletingthe last node
- Deletinganintermediate node.

**Deleting the First Node in Singly Linked List**

First node (current head node) is removed fromthe list. It canbe done intwo steps:

- Create a temporarynode whichwill point to the same node as that of head.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.169.png)

- Now, move the head nodes pointer to the next node and dispose of the temporary node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.170.png)

**Deleting the Last Node in Singly Linked List**

In this case, the last node is removed from the list. This operation is a bit trickier than removing the first node, because the algorithm should find a node, which is previous to the tail. It can be done inthree steps:

- Traverse the list and while traversing maintain the previous node address also. By the time we reach the end of the list, we will have two pointers, one pointing to the *tail* node and the other pointingto the node *before* the tail node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.171.png)

- Update previous node’s next pointer withNULL.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.172.png)

- Dispose of the tail node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.173.png)

**Deleting an Intermediate Node in Singly Linked List**

In this case, the node to be removed is *always located between* two nodes. Head and tail links are not updated inthis case. Sucha removal canbe done intwo steps:

- Similar to the previous case, maintain the previous node while traversing the list. Once we find the node to be deleted, change the previous node’s next pointer to the next pointer of the node to be deleted.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.174.png)

- Dispose of the current node to be deleted.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.175.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.176.jpeg)

Time Complexity: O(*n*). Inthe worst case, we mayneed to delete the node at the end of the list. Space Complexity: O(1), for one temporaryvariable.

**Deleting Singly Linked List**

This works by storing the current node in some temporary variable and freeing the current node. After freeing the current node, go to the next node with a temporary variable and repeat this process for all nodes.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.177.png)

Time Complexity: O(*n*), for scanningthe complete list of size n. Space Complexity: O(1), for creatingone temporaryvariable.

7. **Doubly Linked Lists**

The *advantage* of a doubly linked list (also called *two* – *way linked list*) is that given a node in the list, we can navigate in both directions. A node in a singly linked list cannot be removed unless we have the pointer to its predecessor. But in a doubly linked list, we can delete a node even if we don’t have the previous node’s address (since each node has a left pointer pointing to the previous node and canmove backward).

The primary*disadvantages* of doublylinked lists are:

- Eachnode requires anextra pointer, requiringmore space.
- The insertionor deletionof a node takes a bit longer (more pointer operations).

Similar to a singly linked list, let us implement the operations of a doubly linked list. If you understand the singly linked list operations, then doubly linked list operations are obvious. Followingis a type declarationfor a doublylinked list of integers:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.178.png)

**Doubly Linked List Insertion**

Insertioninto a doubly-linked list has three cases (same as singlylinked list):

- Insertinga new node before the head.
- Insertinga new node after the tail (at the end of the list).
- Insertinga new node at the middle of the list.

**Inserting a Node in Doubly Linked List at the Beginning**

In this case, new node is inserted before the head node. Previous and next pointers need to be modified and it canbe done intwo steps:

- Update the right pointer of the new node to point to the current head node (dotted linkinbelow figure) and also make left pointer of new node as NULL.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.179.png)

- Update head node’s left pointer to point to the new node and make new node as head. Head

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.180.png)

**Inserting a Node in Doubly Linked List at the Ending**

Inthis case, traverse the list till the end and insert the new node.

- New node right pointer points to NULLand left pointer points to the end of the list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.181.png)

- Update right pointer of last node to point to new node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.182.png)

**Inserting a Node in Doubly Linked List at the Middle**

As discussed insinglylinked lists, traverse the list to the positionnode and insert the new node.

- *New node* right pointer points to the next node of the *position node* where we want to insert the new node. Also, *new node* left pointer points to the *position node.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.183.png)

- Positionnode right pointer points to the new node and the *next node* of positionnode left pointer points to new node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.184.png)

Now, let us write the code for all of these three cases. We must update the first element pointer in the calling function, not just in the called function. For this reason we need to send a double pointer. The followingcode inserts a node inthe doublylinked list

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.185.jpeg)Time Complexity: O(*n*). Inthe worst case, we mayneed to insert the node at the end of the list. Space Complexity: O(1), for creatingone temporaryvariable.

**Doubly Linked List Deletion**

Similar to singlylinked list deletion, here we have three cases:

- Deletingthe first node
- Deletingthe last node
- Deletinganintermediate node

**Deleting the First Node in Doubly Linked List**

In this case, the first node (current head node) is removed from the list. It can be done in two steps:

- Create a temporarynode whichwill point to the same node as that of head.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.186.png)

- Now, move the head nodes pointer to the next node and change the heads left pointer to NULL. Then, dispose of the temporarynode.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.187.png)

**Deleting the Last Node in Doubly Linked List**

This operation is a bit trickier than removing the first node, because the algorithm should find a node, whichis previous to the tail first. This canbe done inthree steps:

- Traverse the list and while traversing maintain the previous node address also. By the time we reach the end of the list, we will have two pointers, one pointing to the tail and the other pointingto the node before the tail.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.188.png)

- Update the next pointer of previous node to the tail node withNULL.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.189.png)

- Dispose the tail node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.190.png)

**Deleting an Intermediate Node in Doubly Linked List**

In this case, the node to be removed is *always located between* two nodes, and the head and tail links are not updated. The removal canbe done intwo steps:

- Similar to the previous case, maintain the previous node while also traversing the list. Upon locating the node to be deleted, change the previous node’s next pointer to the next node of the node to be deleted.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.191.png)

- Dispose of the current node to be deleted.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.192.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.193.jpeg)

Time Complexity: O(*n*), for scanningthe complete list of size *n*. Space Complexity: O(1), for creatingone temporaryvariable.

8. **Circular Linked Lists**

In singly linked lists and doubly linked lists, the end of lists are indicated with NULLvalue. But circular linked lists do not have ends. While traversing the circular linked lists we should be careful; otherwise we will be traversingthe list infinitely. Incircular linked lists, eachnode has a successor. Note that unlike singly linked lists, there is no node with NULLpointer in a circularly linked list. Insome situations, circular linked lists are useful.

For example, when several processes are using the same computer resource (CPU) for the same amount of time, we have to assure that no process accesses the resource before all other processes do (round robin algorithm). The following is a type declaration for a circular linked list of integers:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.194.png)

In a circular linked list, we access the elements using the *head* node (similar to *head* node in singlylinked list and doublylinked lists).

**Counting Nodes in a Circular Linked List**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.195.png)

The circular list is accessible throughthe node marked *head*. To count the nodes, the list has to be traversed from the node marked *head*, with the help of a dummy node *current*, and stop the countingwhen*current* reaches the startingnode *head.*

If the list is empty, *head* will be NULL, and in that case set *count* = 0. Otherwise, set the current pointer to the first node, and keep oncountingtill the current pointer reaches the startingnode.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.196.png)

Time Complexity: O(*n*), for scanningthe complete list of size *n*. Space Complexity: O(1), for creatingone temporaryvariable.

**Printing the Contents of a Circular Linked List**

We assume here that the list is being accessed by its *head* node. Since all the nodes are arranged in a circular fashion, the *tail* node of the list will be the node previous to the *head* node. Let us assume we want to print the contents of the nodes starting with the *head* node. Print its contents, move to the next node and continue printingtill we reachthe *head* node again.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.197.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.198.png)

Time Complexity: O(*n*), for scanningthe complete list of size *n.* Space Complexity: O(1), for temporaryvariable.

**Inserting a Node at the End of a Circular Linked List**

Let us add a node containing *data*, at the end of a list (circular list) headed by *head*. The new node will be placed just after the tail node (whichis the last node of the list), whichmeans it will have to be inserted inbetweenthe tail node and the first node.

- Create a new node and initiallykeep its next pointer pointingto itself.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.199.png)

- Update the next pointer of the new node with the head node and also traverse the list to the tail. That means in a circular list we should stop at the node whose next node is head.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.200.png)

- Update the next pointer of the previous node to point to the new node and we get the list as shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.e308439e-06c6-4ac6-8865-2e4663aed459.201.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.001.jpeg)

Time Complexity: O(*n*), for scanningthe complete list of size *n.* Space Complexity: O(1), for temporaryvariable.

**Inserting a Node at the Front of a Circular Linked List**

The only difference between inserting a node at the beginning and at the end is that, after inserting the new node, we just need to update the pointer. The steps for doingthis are givenbelow:

- Create a new node and initiallykeep its next pointer pointingto itself.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.002.png)

- Update the next pointer of the new node with the head node and also traverse the list until the tail. That means in a circular list we should stop at the node which is its previous node inthe list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.003.png)

- Update the previous head node inthe list to point to the new node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.004.png)

- Make the new node as the head.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.005.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.006.png)

Time Complexity: O(*n*), for scanningthe complete list of size *n.* Space Complexity: O(1), for temporaryvariable.

**Deleting the Last Node in a Circular Linked List**

The list has to be traversed to reach the last but one node. This has to be named as the tail node, and its next field has to point to the first node. Consider the followinglist.

To delete the last node 40, the list has to be traversed till you reach 7. The next field of 7 has to

be changed to point to 60, and this node must be renamed *pTail.*

- Traverse the list and find the tail node and its previous node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.007.png)

- Update the next pointer of tail node’s previous node to point to head.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.008.png)

- Dispose of the tail node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.009.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.010.png)

Time Complexity: O(*n*), for scanning the complete list of size *n*. Space Complexity: O(1), for a temporaryvariable.

**Deleting the First Node in a Circular List**

The first node can be deleted by simply replacing the next field of the tail node with the next field of the first node.

- Find the tail node of the linked list by traversing the list. Tail node is the previous node to the head node whichwe want to delete.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.011.png)

- Create a temporary node which will point to the head. Also, update the tail nodes next pointer to point to next node of head (as shownbelow).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.012.png)

- Now, move the head pointer to next node. Create a temporary node which will point to head. Also, update the tail nodes next pointer to point to next node of head (as shownbelow).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.013.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.014.png)

Time Complexity: O(*n*), for scanningthe complete list of size *n.* Space Complexity: O(1), for a temporaryvariable.

**Applications of Circular List**

Circular linked lists are used in managing the computing resources of a computer. We can use circular lists for implementingstacks and queues.

9. **AMemory-efficient Doubly Linked List**

In conventional implementation, we need to keep a forward pointer to the next itemon the list and a backward pointer to the previous item. That means elements in doubly linked list implementations consist of data, a pointer to the next node and a pointer to the previous node in the list as shownbelow.

**Conventional Node Definition**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.015.png)

Recently a journal (Sinha) presented an alternative implementation of the doubly linked list ADT, with insertion, traversal and deletion operations. This implementation is based on pointer difference. Eachnode uses onlyone pointer field to traverse the list backand forth.

**New Node Definition**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.016.png)

The *ptrdiff* pointer field contains the difference between the pointer to the next node and the pointer to the previous node. The pointer difference is calculated by using exclusive-or (⊕) operation.

*ptrdiff = pointer to previous node* ⊕ *pointer to next node.*

The *ptrdiff* of the start node (head node) is the ⊕ of NULL and *next* node (*n*ext node to head). Similarly, the *ptrdiff* of end node is the ⊕ of *previous* node (previous to end node) and NULL. As anexample, consider the followinglinked list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.017.png)

Inthe example above,

- The next pointer of Ais: NULL⊕ B
- The next pointer of B is: A⊕ C
- The next pointer of C is: B ⊕ D
- The next pointer of D is: C ⊕ NULL

**Why does it work?**

To find the answer to this questionlet us consider the properties of ⊕:

X ⊕ X=0

X ⊕ 0 = X

X ⊕ Y= Y⊕ X (symmetric)

(X ⊕ Y) ⊕ Z= X ⊕ (Y⊕ Z) (transitive)

For the example above, let us assume that we are at C node and want to move to B. We know that C’s *ptrdiff* is defined as B ⊕ D. If we want to move to B, performing ⊕ on C’s *ptrdiff* with D would give B. This is due to the fact that

(B ⊕ D) ⊕ D = B(since, D ⊕ D= 0)

Similarly, if we want to move to D, thenwe have to apply⊕ to C’s *ptrdiff* withB to give D.

(B ⊕ D) ⊕ B = D (since, B © B=0)

From the above discussion we can see that just by using a single pointer, we can move back and forth. A memory-efficient implementation of a doubly linked list is possible with minimal compromisingof timingefficiency.

10. **Unrolled Linked Lists**

One of the biggest advantages of linked lists over arrays is that inserting an element at any location takes only O(1) time. However, it takes O(*n*) to search for an element in a linked list. There is a simple variationof the singlylinked list called *unrolled linked lists.*

An unrolled linked list stores multiple elements in each node (let us call it a block for our convenience). Ineachblock, a circular linked list is used to connect all nodes.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.018.png)

Assume that there will be no more than n elements in the unrolled linked list at any time. To simplifythis problem, all blocks, except the last one, should containexactly![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.019.png) elements. Thus,

there will be no more than![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.019.png) blocks at anytime.

**Searching for an element in Unrolled Linked Lists**

Inunrolled linked lists, we canfind the *kth* element inO(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.020.png)):

\1. Traverse the *list of blocks* to the one that contains the *kth* node, i.e., the ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.021.png) block. It takes O(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.020.png)) since we may find it by going through no more than ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.020.png)

blocks. 2. Find the (*k* mod ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.019.png))th node in the circular linked list of this block. It also takes O( ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.020.png)) since there are no more than![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.019.png) nodes ina single block.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.022.png)

**Inserting an element in Unrolled Linked Lists**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.023.png)When inserting a node, we have to re-arrange the nodes in the unrolled linked list to maintain the properties previously mentioned, that each block contains ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.019.png) nodes. Suppose that we insert a

node *x* after the *ith* node, and *x* should be placed in the *jth* block. Nodes in the *jth* block and in the blocks after the *jth* block have to be shifted toward the tail of the list so that each of them still have ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.019.png) nodes. In addition, a new block needs to be added to the tail if the last block of the list is out of space, i.e., it has more than![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.019.png) nodes.

**Performing Shift Operation**

Note that each*shift* operation, which includes removing a node fromthe tail of the circular linked list in a block and inserting a node to the head of the circular linked list in the block after, takes onlyO(1). The total time complexityof aninsertionoperationfor unrolled linked lists is therefore O(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.020.png)); there are at most O(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.020.png)) blocks and therefore at most O(![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.020.png)) shift operations.

1. Atemporarypointer is needed to store the tail of *A.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.024.png)

2. Inblock*A*, move the next pointer of the head node to point to the second-to-last node, so that the tail node of *A*canbe removed.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.025.png)

3. Let the next pointer of the node, whichwill be shifted (the tail node of *A*), point to the tail node of *B.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.026.png)

4. Let the next pointer of the head node of *B* point to the node *temp* points to.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.027.png)

5. Finally, set the head pointer of *B* to point to the node *temp* points to. Now the node *temp* points to becomes the new head node of *B.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.028.png)

6. *temp* pointer can be thrown away. We have completed the shift operation to move the original tail node of *A*to become the new head node of *B.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.029.png)

**Performance**

With unrolled linked lists, there are a couple of advantages, one in speed and one in space. First, if the number of elements in each block is appropriately sized (e.g., at most the size of one cache line), we get noticeably better cache performance from the improved memory locality. Second, since we have O(*n*/*m*) links, where *n* is the number of elements inthe unrolled linked list and *m* is the number of elements we can store in any block, we can also save an appreciable amount of space, whichis particularlynoticeable if eachelement is small.

**Comparing Linked Lists and Unrolled Linked Lists**

To compare the overhead for an unrolled list, elements in doubly linked list implementations consist of data, a pointer to the next node, and a pointer to the previous node in the list, as shown below.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.030.png)

Assumingwe have 4 byte pointers, eachnode is goingto take 8 bytes. But the allocationoverhead for the node could be anywhere between 8 and 16 bytes. Let’s go with the best case and assume it will be 8 bytes. So, if we want to store IK items in this list, we are going to have 16KB of overhead.

Now, let’s think about an unrolled linked list node (let us call it *LinkedBlock*). It will look somethinglike this:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.031.png)

Therefore, allocating a single node (12 bytes + 8 bytes of overhead) with an array of 100 elements (400 bytes + 8 bytes of overhead) will now cost 428 bytes, or 4.28 bytes per element. Thinking about our IK items from above, it would take about 4.2KB of overhead, which is close to 4xbetter thanour original list. Evenif the list becomes severelyfragmented and the itemarrays are only 1/2 full on average, this is still an improvement. Also, note that we can tune the array size to whatever gets us the best overhead for our application.

**Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.032.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.033.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.034.jpeg)

11. **Skip Lists**

Binary trees can be used for representing abstract data types such as dictionaries and ordered lists. They work well when the elements are inserted in a random order. Some sequences of operations, such as inserting the elements in order, produce degenerate data structures that give very poor performance. If it were possible to randomly permute the list of items to be inserted, trees would work well with high probability for any input sequence. In most cases queries must be answered on-line, so randomlypermutingthe input is impractical. Balanced tree algorithms re- arrange the tree as operations are performed to maintain certain balance conditions and assure good performance.

Skip lists are a probabilistic alternative to balanced trees. Skip list is a data structure that can be used as an alternative to balanced binary trees (refer to *Trees* chapter). As compared to a binary tree, skip lists allow quick search, insertion and deletion of elements. This is achieved by using probabilistic balancing rather than strictly enforce balancing. It is basically a linked list with additional pointers such that intermediate nodes can be skipped. It uses a random number generator to make some decisions.

In an ordinary sorted linked list, search, insert, and delete are in O(*n*) because the list must be scanned node-by-node from the head to find the relevant node. If somehow we could scan down the list in bigger steps (skip down, as it were), we would reduce the cost of scanning. This is the fundamental idea behind Skip Lists.

**Skip Lists with One Level**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.035.png)

**Skip Lists with Two Levels**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.036.png)

**Skip Lists with Three Levels**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.037.png)

**Performance**

In a simple linked list that consists of n elements, to performa search n comparisons are required in the worst case. If a second pointer pointing two nodes ahead is added to every node, the number of comparisons goes downto *n/*2 + 1 inthe worst case.

Adding one more pointer to every fourth node and making them point to the fourth node ahead reduces the number of comparisons to ⌈*n/*2⌉+ 2. If this strategy is continued so that every node with *i* pointers points to 2 \* *i* – 1 nodes ahead, O(*logn*) performance is obtained and the number of pointers has onlydoubled (*n* + *n*/2 + *n*/4 + *n*/8 + *n*/16 + .... = 2*n*).

The find, insert, and remove operations on ordinary binary search trees are efficient, O(*logn*), when the input data is random; but less efficient, O(*n*), when the input data is ordered. Skip List performance for these same operations and for any data set is about as good as that of randomly- built binarysearchtrees - namelyO(*logn*).

**Comparing Skip Lists and Unrolled Linked Lists**

Insimple terms, Skip Lists are sorted linked lists withtwo differences:

- The nodes in an ordinary list have one next reference. The nodes in a Skip List have many*next* references (also called *forward* references).
- The number of *forward* references for a givennode is determined probabilistically.

We speak of a Skip List node having levels, one level per forward reference. The number of levels in a node is called the *size* of the node. In an ordinary sorted list, insert, remove, and find operations require sequential traversal of the list. This results in O(*n*) performance per operation. Skip Lists allow intermediate nodes in the list to be skipped during a traversal - resulting in an expected performance of O(*logn*) per operation.

**Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.038.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.039.jpeg)

12. **Linked Lists: Problems & Solutions**

**Problem-1**  Implement StackusingLinked List. **Solution:** Refer to *[Stacks*](#_page62_x28.00_y82.94)* chapter.

**Problem-2**  Find *nth* node fromthe end of a Linked List.

**Solution: Brute-Force Method:** Start with the first node and count the number of nodes present after that node. If the number of nodes is < *n* – 1 then return saying “fewer number of nodes in the list”. If the number of nodes is > *n* – 1 then go to next node. Continue this until the numbers of nodes after current node are *n* – 1.

Time Complexity: O(*n*2), for scanningthe remaininglist (fromcurrent node) for eachnode. Space Complexity: O(1).

**Problem-3**  Canwe improve the complexityof [Problem-2](#_page22_x66.91_y149.39)?

**Solution: Yes,** usinghashtable. As anexample consider the followinglist.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.040.png)

In this approach, create a hash table whose entries are < *position of node, node address >*. That means, keyis the positionof the node inthe list and value is the address of that node.



| PositioninList                                               | Address of Node    |
| ------------------------------------------------------------ | ------------------ |
| 1                                                            | Address of 5 node  |
| 2                                                            | Address of 1 node  |
| 3                                                            | Address of 17 node |
| 4                                                            | Address of 4 node  |
| By the time we traverse the complete list (for creating the hash table), we can find the list length. Let us say the list length is M. To find *nth* fromthe end of linked list, we can convert this to *M- n* |                    |

+ 1*th* from the beginning. Since we already know the length of the list, it is just a matter of

returning*M- n* + 1*th* keyvalue fromthe hashtable.

Time Complexity: Time for creatingthe hashtable, *T*(*m*) = O(*m*).

Space Complexity: Since we need to create a hashtable of size m, O(*m*).

**Problem-4**  Can we use the [Problem-3](#_page22_x66.91_y314.09) approach for solving [Problem-2](#_page22_x66.91_y149.39) without creating the

hashtable?

**Solution: Yes.** If we observe the [Problem-3](#_page22_x66.91_y314.09) solution, what we are actually doing is finding the size of the linked list. That means we are usingthe hashtable to find the size of the linked list. We canfind the lengthof the linked list just bystartingat the head node and traversingthe list.

So, we can find the length of the list without creating the hash table. After finding the length, compute *M* – *n* + 1 and with one more scan we can get the *M* – *n+* 1*th* node from the beginning. This solution needs two scans: one for finding the length of the list and the other for finding *M* –

*n+* 1*th* node fromthe beginning.

Time Complexity: Time for finding the length + Time for finding the *M* – *n +* 1*th* node from the beginning. Therefore, *T*(*n*) = O(*n*) + O(*n*) *≈* O(*n*). Space Complexity: O(1). Hence, no need to create the hashtable.

**Problem-5**  Canwe solve [Problem-2](#_page22_x66.91_y149.39) inone scan?

**Solution: Yes. Efficient Approach:** Use two pointers *pNthNode* and *pTemp*. Initially, both point to head node of the list. *pNthNode* starts movingonlyafter *pTemp* has made *n* moves.

From there both move forward until *pTemp* reaches the end of the list. As a result *pNthNode* points to *nth* node fromthe end of the linked list.

**Note:** At anypoint of time bothmove one node at a time.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.041.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-6**  Check whether the given linked list is either NULL-terminated or ends in a cycle

(cyclic).

**Solution: Brute-Force Approach.** As an example, consider the following linked list which has a loop in it. The difference between this list and the regular list is that, in this list, there are two nodes whose next pointers are the same. Inregular singlylinked lists (without a loop) eachnode’s next pointer is unique.

That means the repetitionof next pointers indicates the existence of a loop.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.042.jpeg)

One simple and brute force way of solving this is, start with the first node and see whether there is any node whose next pointer is the current node’s address. If there is a node with the same address then that indicates that some other node is pointing to the current node and we can say a loop exists. Continue this process for all the nodes of the linked list.

**Does this method work?** As per the algorithm, we are checking for the next pointer addresses, but how do we find the end of the linked list (otherwise we will end up inaninfinite loop)?

**Note:** If we start witha node ina loop, this method mayworkdependingonthe size of the loop. **Problem-7**  Canwe use the hashingtechnique for solving[Problem-6](#_page24_x66.91_y431.71)?

**Solution: Yes.** UsingHashTables we cansolve this problem. **Algorithm:**

- Traverse the linked list nodes one byone.
- Checkif the address of the node is available inthe hashtable or not.
- If it is already available in the hash table, that indicates that we are visiting the node that was already visited. This is possible only if the given linked list has a loop in it.
- If the address of the node is not available inthe hashtable, insert that node’s address into the hashtable.
- Continue this process until we reachthe end of the linked list *or* we find the loop.

Time Complexity; O(*n*) for scanning the linked list. Note that we are doing a scan of only the input.

Space Complexity; O(*n*) for hashtable.

**Problem-8**  Canwe solve [Problem-6](#_page24_x66.91_y431.71) usingthe sortingtechnique?

**Solution: No.** Consider the following algorithmwhich is based on sorting. Then we see why this

algorithmfails.

**Algorithm:**

- Traverse the linked list nodes one by one and take all the next pointer values into an array.
- Sort the arraythat has the next node pointers.
- If there is a loop in the linked list, definitely two next node pointers will be pointing to the same node.
- After sorting if there is a loop in the list, the nodes whose next pointers are the same will end up adjacent inthe sorted list.
- If anysuchpair exists inthe sorted list thenwe saythe linked list has a loop init.

Time Complexity; O(*nlogn*) for sortingthe next pointers array. Space Complexity; O(*n*) for the next pointers array.

**Problemwiththe above algorithm:** The above algorithmworks only if we can find the length of the list. But if the list has a loop then we may end up in an infinite loop. Due to this reason the algorithmfails.

**Problem-9**  Canwe solve the [Problem-6](#_page24_x66.91_y431.71) inO(*n*)?

**Solution: Yes. Efficient Approach (Memoryless Approach):** This problem was solved by *Floyd*. The solution is named the Floyd cycle finding algorithm. It uses *two* pointers moving at different speeds to walk the linked list. Once they enter the loop they are expected to meet, which denotes that there is a loop.

This works because the only way a faster moving pointer would point to the same location as a slower moving pointer is if somehow the entire list or a part of it is circular. Think of a tortoise

and a hare running on a track. The faster running hare will catch up with the tortoise if they are running in a loop. As an example, consider the following example and trace out the Floyd algorithm. From the diagrams below we can see that after the final step they are meeting at some point inthe loop whichmaynot be the startingpoint of the loop.

**Note:** *slowPtr* (*tortoise*) moves one pointer at a time and *fastPtr* (*hare*) moves two pointers at a time.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.043.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.044.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-10**  are given a pointer to the first element of a linked list *L*. There are two

possibilities for *L:* it either ends (snake) or its last element points back to one of the earlier elements in the list (snail). Give an algorithm that tests whether a given list *L* is a snake or a snail.

**Solution:** It is the same as [Problem-6](#_page24_x66.91_y431.71).

**Problem-11**  Check whether the given linked list is NULL-terminated or not. If there is a

cycle find the start node of the loop.

**Solution:** The solution is an extension to the solution in [Problem-9](#_page26_x66.91_y345.23). After finding the loop in the linked list, we initialize the *slowPtr* to the head of the linked list. From that point onwards both *slowPtr* and *fastPtr* move only one node at a time. The point at which they meet is the start of the loop. Generallywe use this method for removingthe loops.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.045.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-12**  From the previous discussion and problems we understand that the meeting of

tortoise and hare concludes the existence of the loop, but how does moving the tortoise to the beginning of the linked list while keeping the hare at the meeting place, followed by movingbothone step at a time, make themmeet at the startingpoint of the cycle?

**Solution:** This problem is at the heart of number theory. In the Floyd cycle finding algorithm, notice that the tortoise and the hare will meet when they are *n* × *L*, where L is the loop length. Furthermore, the tortoise is at the midpoint between the hare and the beginning of the sequence because of the way they move. Therefore the tortoise is *n* × *L* away from the beginning of the sequence as well. If we move both one step at a time, from the position of the tortoise and from the start of the sequence, we know that they will meet as soon as both are in the loop, since they are *n* × *L*, a multiple of the loop length, apart. One of themis already in the loop, so we just move the other one in single step until it enters the loop, keeping the other *n* × *L* away from it at all times.

**Problem-13**  In the Floyd cycle finding algorithm, does it work if we use steps 2 and 3

instead of 1 and 2?

**Solution: Yes,** but the complexitymight be high. Trace out anexample.

**Problem-14**  Check whether the given linked list is NULL-terminated. If there is a cycle, find

the lengthof the loop.

**Solution:** This solutionis also anextensionof the basic cycle detectionproblem. After findingthe loop in the linked list, keep the *slowPtr* as it is. The *fastPtr* keeps on moving until it again comes backto *slowPtr*. While moving*fastPtr*, use a counter variable whichincrements at the rate of 1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.046.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-15**  Insert a node ina sorted linked list.

**Solution:** Traverse the list and find a positionfor the element and insert it.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.047.png)

Time Complexity: O(*n*). Space Complexity: O(1). **Problem-16**  Reverse a singlylinked list. **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.048.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Recursive version:** We will find it easier to start from the bottom up, by asking and answering tinyquestions (this is the approachinThe Little Lisper):

- What is the reverse of NULL(the emptylist)? NULL.
- What is the reverse of a one element list? The element itself.
- What is the reverse of an*n* element list? The reverse of the second element followed bythe first element.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.049.png)

Time Complexity: O(*n*). Space Complexity: O(*n*),for recursive stack.

**Problem-17**  Suppose there are two singly linked lists both of which intersect at some point

and become a single linked list. The head or start pointers of both the lists are known, but the intersecting node is not known. Also, the number of nodes in each of the lists before they intersect is unknown and may be different in each list. *List*1 may have n nodes before it reaches the intersection point, and *List*2 might have *m* nodes before it reaches the intersection point where *m* and n may be *m = n,m < n* or *m > n*. Give an algorithm for findingthe mergingpoint.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.050.png)

**Solution: Brute-Force Approach:** One easysolutionis to compare everynode pointer inthe first list witheveryother node pointer inthe second list bywhichthe matchingnode pointers will lead us to the intersecting node. But, the time complexity in this case will be O(*mn*) which will be high.

Time Complexity: O(*mn*). Space Complexity: O(1).

**Problem-18**  Canwe solve [Problem-17](#_page32_x66.91_y374.22) usingthe sortingtechnique?

**Solution: No.** Consider the following algorithm which is based on sorting and see why this algorithmfails.

**Algorithm:**

- Take first list node pointers and keep theminsome arrayand sort them.
- Take second list node pointers and keep theminsome arrayand sort them.
- After sorting, use two indexes: one for the first sorted array and the other for the second sorted array.
- Start comparing values at the indexes and increment the index according to whichever has the lower value (increment onlyif the values are not equal).
- At any point, if we are able to find two indexes whose values are the same, then that indicates that those two nodes are pointing to the same node and we return that node.

Time Complexity: Time for sortinglists + Time for scanning(for comparing)

= O(*mlogm*) *+*O(*nlogn*) +O(*m* + *n*) We need to consider the one that gives the maximumvalue.

Space Complexity: O(1).

**Any problem with the above algorithm? Yes.** In the algorithm, we are storing all the node pointers of boththe lists and sorting. But we are forgettingthe fact that there canbe manyrepeated elements. This is because after the merging point, all node pointers are the same for both the lists. The algorithm works fine only in one case and it is when both lists have the ending node at their merge point.

**Problem-19**  Canwe solve [Problem-17](#_page32_x66.91_y374.22) usinghashtables? **Solution: Yes.**

**Algorithm:**

- Select a list which has less number of nodes (If we do not know the lengths beforehand thenselect one list randomly).
- Now, traverse the other list and for each node pointer of this list check whether the same node pointer exists inthe hashtable.
- If there is a merge point for the given lists then we will definitely encounter the node pointer inthe hashtable.

Time Complexity: Time for creating the hash table + Time for scanning the second list = O(*m*) + O(*n*) (or O(*n*) + O(*m*), depending on which list we select for creating the hash table. But in both

cases the time complexityis the same. Space Complexity: O(*n*) or O(*m*). **Problem-20**  Canwe use stacks for solvingthe [Problem-17](#_page32_x66.91_y374.22)?

**Solution: Yes. Algorithm:**

- Create two stacks: one for the first list and one for the second list.
- Traverse the first list and pushall the node addresses onto the first stack.
- Traverse the second list and pushall the node addresses onto the second stack.
- Now bothstacks containthe node address of the correspondinglists.
- Now compare the top node address of bothstacks.
- If they are the same, take the top elements from both the stacks and keep them in some temporary variable (since both node addresses are node, it is enough if we use one temporaryvariable).
- Continue this process until the top node addresses of the stacks are not the same.
- This point is the one where the lists merge into a single list.
- Returnthe value of the temporaryvariable.

Time Complexity: O(*m* + *n*), for scanningboththe lists.

Space Complexity: O(*m* + *n*), for creatingtwo stacks for boththe lists.

**Problem-21**  Is there anyother wayof solving[Problem-17](#_page32_x66.91_y374.22)?

**Solution: Yes.** Using “finding the first repeating number” approach in an array (for algorithm refer to *Searching* chapter).

**Algorithm:**

- Create anarray*A*and keep all the next pointers of boththe lists inthe array.
- In the array find the first repeating element [Refer to *Searching* chapter for algorithm].
- The first repeatingnumber indicates the mergingpoint of boththe lists.

Time Complexity: O(*m* + *n*). Space Complexity: O(*m* + *n*).

**Problem-22**  Canwe still thinkof findinganalternative solutionfor [Problem-17](#_page32_x66.91_y374.22)?

**Solution: Yes.** Bycombiningsortingand searchtechniques we canreduce the complexity. **Algorithm:**

- Create anarray*A*and keep all the next pointers of the first list inthe array.
- Sort these arrayelements.
- Then, for each of the second list elements, search in the sorted array (let us assume

that we are usingbinarysearchwhichgives O(*logn*)).

- Since we are scanning the second list one by one, the first repeating element that appears inthe arrayis nothingbut the mergingpoint.

Time Complexity: Time for sorting+ Time for searching= O(*Max*(*mlogm, nlogn*)). Space Complexity: O(*Max*(*m*, *n*)).

**Problem-23**  Canwe improve the complexityfor [Problem-17](#_page32_x66.91_y374.22)? **Solution: Yes.**

**Efficient Approach:**

- Find lengths (L1 and L2) of bothlists - O(*n*) + O(*m*) = O(*max*(*m*, *n*)).
- Take the difference *d* of the lengths -- O(1).
- Make *d* steps inlonger list -- O(*d*).
- Step inbothlists inparallel until links to next node match-- O(*min*(*m, n*)).
- Total time complexity= O(*max*(*m*, *n*)).
- Space Complexity= O(1).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.051.jpeg)

**Problem-24**  How will youfind the middle of the linked list?

**Solution: Brute-Force Approach:** For each of the node, count how many nodes are there in the list, and see whether it is the middle node of the list.

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-25**  Canwe improve the complexityof [Problem-24](#_page36_x66.91_y602.03)?

**Solution: Yes. Algorithm:**

- Traverse the list and find the lengthof the list.
- After findingthe length, againscanthe list and locate *n*/2 node fromthe beginning.

Time Complexity: Time for findingthe lengthof the list + Time for locatingmiddle node = O(*n*) + O(*n*) *≈* O(*n*).

Space Complexity: O(1).

**Problem-26**  Canwe use the hashtable for solving[Problem-24](#_page36_x66.91_y602.03)? **Solution: Yes.** The reasoningis the same as that of [Problem-3](#_page22_x66.91_y314.09).

Time Complexity: Time for creatingthe hashtable. Therefore, *T*(*n*) = O(*n*). Space Complexity: O(*n*). Since we need to create a hashtable of size *n*.

**Problem-27**  Canwe solve [Problem-24](#_page36_x66.91_y602.03) just inone scan?

**Solution: Efficient Approach:** Use two pointers. Move one pointer at twice the speed of the second. When the first pointer reaches the end of the list, the second pointer will be pointing to the middle node.

**Note:** If the list has anevennumber of nodes, the middle node will be of ⌊*n/*2⌋.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.052.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-28**  How will youdisplaya Linked List fromthe end?

**Solution:** Traverse recursively till the end of the linked list. While coming back, start printing the elements.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.053.png)

Time Complexity: O(*n*). Space Complexity: O(*n*)→ for Stack.

**Problem-29**  Checkwhether the givenLinked List lengthis evenor odd?

**Solution:** Use a 2*x* pointer. Take a pointer that moves at 2*x* [two nodes at a time]. At the end, if the lengthis even, thenthe pointer will be NULL; otherwise it will point to the last node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.054.png)

Time Complexity: O(⌊*n*/2⌋) ≈ O(*n*). Space Complexity: O(1).

**Problem-30**  If the head of a Linked List is pointing to *kth* element, then how will you get the

elements before *kth* element?

**Solution:** Use MemoryEfficient Linked Lists [XOR Linked Lists].

**Problem-31**  Given two sorted Linked Lists, how to merge them into the third list in sorted

order?

**Solution:** Assume the sizes of lists are *m* and *n.* **Recursive:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.055.png)

Time Complexity: O(*n* + *m*), where nand *m* are lengths of two lists. **Iterative:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.056.jpeg)

Time Complexity: O(*n* + *m*), where *n* and *m* are lengths of two lists.

**Problem-32**  Reverse the linked list in pairs. If you have a linked list that holds 1 → 2 → 3

→ 4 → *X*, then after the function has been called the linked list would hold 2 → 1 → 4 → 3 → *X.*

**Solution: Recursive:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.057.png)

**Iterative:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.058.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-33**  Givena binarytree convert it to doublylinked list. **Solution:** Refer *Trees* chapter.

**Problem-34**  How do we sort the Linked Lists?

**Solution:** Refer *Sorting* chapter.

**Problem-35**  Split a Circular Linked List into two equal parts. If the number of nodes in the

list are odd thenmake first list one node extra thansecond list.

**Solution:**

**Algorithm:**

- Store the mid and last pointers of the circular linked list using Floyd cycle finding algorithm.
- Make the second half circular.
- Make the first half circular.
- Set head pointers of the two linked lists.

As anexample, consider the followingcircular list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.059.png)

After the split, the above list will looklike:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.060.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.061.jpeg)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-36**  If we want to concatenate two linked lists which of the following gives O(1)

complexity?

1) Singlylinked lists
1) Doublylinked lists
1) Circular doublylinked lists

**Solution:** Circular Doubly Linked Lists. This is because for singly and doubly linked lists, we

need to traverse the first list till the end and append the second list. But in the case of circular doublylinked lists we don’t have to traverse the lists.

**Problem-37**  How will youcheckif the linked list is palindrome or not? **Solution:**

**Algorithm:**

1. Get the middle of the linked list.
1. Reverse the second half of the linked list.
1. Compare the first half and second half.
1. Construct the original linked list by reversing the second half again and attachingit backto the first half.

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-38**  For a given*K* value (*K >* 0) reverse blocks of *K* nodes ina list. **Example:** Input: 1 2 3 4 5 6 7 8 9 10. Output for different *K* values:

For *K =* 2: 2 1 4 3 6 5 8 7 10 9

For *K =* 3: 3 2 1 6 5 4 9 8 7 10

For *K =* 4: 4 3 2 1 8 7 6 5 9 10

**Solution:**

**Algorithm:** This is anextensionof swappingnodes ina linked list.

1) Checkif remaininglist has *K* nodes.

1. If yes get the pointer of *K* + 1*th* node.
1. Else return.

2) Reverse first *K* nodes.
2) Set next of last node (after reversal) to *K* + 1*th* node.
2) Move to *K* + 1*th* node.
2) Go to step 1.
2) *K* – 1*th* node of first *K* nodes becomes the new head if available. Otherwise, we can returnthe head.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.062.jpeg)

**Problem-39**  Is it possible to get O(1) access time for Linked Lists?

**Solution: Yes.** Create a linked list and at the same time keep it in a hash table. For n elements we have to keep all the elements in a hash table which gives a preprocessing time of O(*n*).To read any element we require only constant time O(1) and to read *n* elements we require *n \** 1 unit of time = *n* units. Hence by using amortized analysis we can say that element access can be performed withinO(1) time.

Time Complexity– O(1) [Amortized]. Space Complexity- O(*n*) for HashTable.

**Problem-40  Josephus Circle:** *N* people have decided to elect a leader by arranging

themselves in a circle and eliminating every *Mth* person around the circle, closing ranks as eachpersondrops out. Find whichpersonwill be the last one remaining(withrank1).

**Solution:** Assume the input is a circular linked list with *N* nodes and each node has a number (range 1 to *N*) associated withit. The head node has number 1 as data.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.063.jpeg)

**Problem-41**  Given a linked list consists of data, a next pointer and also a random pointer

whichpoints to a randomnode of the list. Give analgorithmfor cloningthe list.

**Solution:** We can use a hash table to associate newly created nodes with the instances of node in the givenlist.

**Algorithm:**

- Scan the original list and for each node *X*, create a new node *Y* with data of *X*, then store the pair (*X, Y*) in hash table using *X* as a key. Note that during this scan set *Y*
  - *next* and *Y*→ *random* to *NULL* and we will fixtheminthe next scan.
- Now for each node *X* in the original list we have a copy *Y* stored in our hash table. We scanthe original list againand set the pointers buildingthe new list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.064.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-42**  Canwe solve [Problem-41](#_page47_x66.91_y550.91) without anyextra space?

**Solution: Yes.**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.065.jpeg)

Time Complexity: O(3n) *≈* O(*n*). Space Complexity: O(1).

**Problem-43**  We are givena pointer to a node (*n*ot the tail node) ina singlylinked list. Delete

that node fromthe linked list.

**Solution:** To delete a node, we have to adjust the next pointer of the previous node to point to the

next node instead of the current one. Since we don’t have a pointer to the previous node, we can’t redirect its next pointer. So what do we do? We can easily get away by moving the data from the next node into the current node and thendeletingthe next node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.066.png)

Time Complexity: O(1). Space Complexity: O(1).

**Problem-44**  Given a linked list with even and odd numbers, create an algorithm for making

changes to the list insucha waythat all evennumbers appear at the beginning.

**Solution:** To solve this problem, we can use the splitting logic. While traversing the list, split the linked list into two: one contains all even nodes and the other contains all odd nodes. Now, to get the final list, we cansimplyappend the odd node linked list after the evennode linked list.

To split the linked list, traverse the original linked list and move all odd nodes to a separate linked list of all odd nodes. At the end of the loop, the original list will have all the even nodes

and the odd node list will have all the odd nodes. To keep the ordering of all nodes the same, we must insert all the odd nodes at the end of the odd node list.

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-45**  In a linked list with *n* nodes, the time taken to insert an element after an element

pointed bysome pointer is

1) O(1)
1) O(*logn*)
1) O(*n*)
1) O(*nlogn*)

**Solution: A.**

**Problem-46  Find modular node:** Given a singly linked list, write a function to find the last element fromthe beginning whose *n*%*k* == 0, where *n* is the number of elements in the list

and *k* is an integer constant. For example, if *n =* 19 and *k* = 3 then we should return 18*th* node.

**Solution:** For this problemthe value of *n* is not knowninadvance.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.067.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-47  Findmodular node fromthe end:** Given a singly linked list, write a function to

find the first from the end whose *n*%*k* == 0, where *n* is the number of elements in the list and *k* is aninteger constant. If *n =* 19 and *k* = 3 thenwe should return16*th* node.

**Solution:** For this problemthe value of *n* is not knowninadvance and it is the same as findingthe *kth* element fromthe end of the the linked list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.068.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-48  Find fractional node:** Given a singly linked list, write a function to find the

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.069.png) element, where *n* is the number of elements inthe list.

**Solution:** For this problemthe value of *n* is not knowninadvance.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.070.jpeg)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-49  Find![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.071.png) node:** Given a singly linked list, write a function to find the ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.072.png)

element, where *n* is the number of elements in the list. Assume the value of *n* is not known inadvance.

**Solution:** For this problemthe value of *n* is not knowninadvance.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.073.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-50**  Given two lists List 1 = {*A*1*, A*2*, . . . , An*) and List2 = {*B*1*, B*2*, . . . , Bm*} with

data (both lists) in ascending order. Merge them into the third list in ascending order so that the merged list will be:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.074.png)

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.075.jpeg)

Time Complexity: The *while* loop takes O(*min*(*n,m*)) time as it will run for *min*(*n,m*) times. The other steps run in O(1). Therefore the total time complexity is O(*min*(*n,m*)). Space Complexity: O(1).

**Problem-51**  Medianinaninfinite series of integers

**Solution:** Median is the middle number in a sorted list of numbers (if we have an odd number of elements). If we have an even number of elements, the median is the average of two middle numbers in a sorted list of numbers. We can solve this problemwith linked lists (with both sorted and unsorted linked lists).

*First*, let us try with an *unsorted* linked list. In an unsorted linked list, we can insert the element either at the head or at the tail. The disadvantage with this approach is that finding the median takes O(*n*). Also, the insertionoperationtakes O(1).

Now, let us try with a *sorted* linked list. We can find the median in O(1) time if we keep track of

the middle elements. Insertion to a particular location is also O(1) in any linked list. But, finding the right location to insert is not O(*logn*) as in a sorted array, it is instead O(*n*) because we can’t performbinary search in a linked list even if it is sorted. So, using a sorted linked list isn’t worth the effort as insertion is O(*n*) and finding median is O(1), the same as the sorted array. In the sorted arraythe insertionis linear due to shifting, but here it’s linear because we can’t do a binary searchina linked list.

**Note:** For anefficient algorithmrefer to the *Priority Queues and Heaps* chapter.

**Problem-52**  Given a linked list, how do you modify it such that all the even numbers appear

before all the odd numbers inthe modified linked list?

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.076.jpeg)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-53**  Given two linked lists, each list node with one integer digit, add these two

linked lists. The result should be stored inthe third linked list. Also note that the head node contains the most significant digit of the number.

**Solution:** Since the integer additionstarts fromthe least significant digit, we first need to visit the last node of bothlists and add themup, create a new node to store the result, take care of the carry if any, and link the resulting node to the node which will be added to the second least significant node and continue.

First of all, we need to take into account the difference inthe number of digits inthe two numbers. So before starting recursion, we need to do some calculation and move the longer list pointer to the appropriate place so that we need the last node of both lists at the same time. The other thing we need to take care of is *carry*. If two digits add up to more than 10, we need to forward the *carry* to the next node and add it. If the most significant digit addition results in a *carry*, we need to create anextra node to store the *carry.*

The function below is actually a wrapper function which does all the housekeeping like calculating lengths of lists, calling recursive implementation, creating an extra node for the *carry* inthe most significant digit, and addinganyremainingnodes left inthe longer list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.077.jpeg)

Time Complexity: O(*max*(*List*1 *length,List*2 *length*)).

Space Complexity: O(*min*(*List*1 *length, List*1 *length*)) for recursive stack.

**Note:** It canalso be solved usingstacks.

**Problem-54**  Whichsortingalgorithmis easilyadaptable to singlylinked lists?

**Solution:** Simple Insertion sort is easily adabtable to singly linked lists. To insert an element, the linked list is traversed until the proper position is found, or until the end of the list is reached. It is inserted into the list bymerelyadjustingthe pointers without shiftinganyelements, unlike inthe array. This reduces the time required for insertion but not the time required for searching for the proper position.

**Problem-55**  Given a list, List1 = {*A*1, *A*2, . . . *An*–1; *An*) with data, reorder it to {*A*1,

*An,A*2*,An–*1} without usinganyextra space.

**Solution:** Find the middle of the linked list. We cando it by*slow* and *fast* pointer approach. After finding the middle node, we reverse the right halfl then we do a in place merge of the two halves of the linked list.

**Problem-56**  Given two sorted linked lists, given an algorithm for the printing common

elements of them.

**Solution:** The solution is based on merge sort logic. Assume the given two linked lists are: list1 and list2. Since the elements are in sorted order, we run a loop till we reach the end of either of the list. We compare the values of list1 and list2. If the values are equal, we add it to the common list. We move list1/list2/both nodes ahead to the next pointer if the values pointed by list1 was less / more / equal to the value pointed bylist2.

Time complexity O(*m* + *n*), where m is the lengh of list1 and n is the length of list2. Space Complexity: O(1).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.078.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.079.png)

1. **What is a Stack?**

A stack is a simple data structure used for storing data (similar to Linked Lists). In a stack, the order in which the data arrives is important. Apile of plates in a cafeteria is a good example of a stack. The plates are added to the stackas theyare cleaned and theyare placed onthe top. Whena plate, is required it is taken fromthe top of the stack. The first plate placed on the stack is the last one to be used.

**Definition:** A*stack* is an ordered list in which insertion and deletion are done at one end, called *top*. The last element inserted is the first one to be deleted. Hence, it is called the Last in First out (LIFO) or First inLast out (FILO) list.

Special names are given to the two changes that can be made to a stack. When an element is inserted ina stack, the concept is called *push*, and whenanelement is removed fromthe stack, the concept is called *pop*. Trying to pop out an empty stack is called *underflow* and trying to push an element in a full stack is called *overflow*. Generally, we treat themas exceptions. As an example,

consider the snapshots of the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.080.png)

2. **How Stacks are used**

Consider a working day in the office. Let us assume a developer is working on a long-term project. The manager then gives the developer a new task which is more important. The developer puts the long-termproject aside and begins workonthe new task. The phone rings, and this is the highest priority as it must be answered immediately. The developer pushes the present taskinto the pendingtrayand answers the phone.

When the call is complete the task that was abandoned to answer the phone is retrieved from the pending tray and work progresses. To take another call, it may have to be handled in the same manner, but eventually the new task will be finished, and the developer can draw the long-term project fromthe pendingtrayand continue withthat.

3. **Stack ADT**

The followingoperations make a stackanADT. For simplicity, assume the data is aninteger type.

**Main stack operations**

- Push(int data): Inserts *data* onto stack.
- int Pop(): Removes and returns the last inserted element fromthe stack.

**Auxiliary stack operations**

- int Top(): Returns the last inserted element without removingit.
- int Size(): Returns the number of elements stored inthe stack.
- int IsEmptyStack(): Indicates whether anyelements are stored inthe stackor not.
- int IsFullStack(): Indicates whether the stackis full or not.

**Exceptions**

Attempting the execution of an operation may sometimes cause an error condition, called an exception. Exceptions are said to be “thrown” by an operation that cannot be executed. In the Stack ADT, operations pop and top cannot be performed if the stack is empty. Attempting the execution of pop (top) on an empty stack throws an exception. Trying to push an element in a full stackthrows anexception.

4. **Applications**

Followingare some of the applications inwhichstacks playanimportant role.

**Direct applications**

- Balancingof symbols
- Infix-to-postfixconversion
- Evaluationof postfixexpression
- Implementingfunctioncalls (includingrecursion)
- Findingof spans (findingspans instockmarkets, refer to *[Problems*](#_page73_x28.00_y243.09)* section)
- Page-visited historyina Web browser [BackButtons]
- Undo sequence ina text editor
- MatchingTags inHTMLand XML

**Indirect applications**

- Auxiliarydata structure for other algorithms (Example: Tree traversal algorithms)
- Component of other data structures (Example: Simulating queues, refer *Queues* chapter)

5. **Implementation**

There are manyways of implementingstackADT; below are the commonlyused methods.

- Simple arraybased implementation
- Dynamic arraybased implementation
- Linked lists implementation

**Simple Array Implementation**

This implementation of stack ADT uses an array. In the array, we add elements from left to right and use a variable to keep trackof the indexof the top element.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.081.png)

The array storing the stack elements may become full. A push operation will then throw a *full stack exception*. Similarly, if we try deleting an element from an empty stack it will throw *stack empty exception.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.082.jpeg)

**Performance & Limitations Performance**

Let *n* be the number of elements in the stack. The complexities of stack operations with this representationcanbe givenas:



| Space Complexity(for npushoperations) | O(*n*) |
| ------------------------------------- | ------ |
| Time Complexityof Push()              | O(1)   |
| Time Complexityof Pop()               | O(1)   |
| Time Complexityof Size()              | O(1)   |
| Time Complexityof IsEmptyStack()      | O(1)   |
| Time Complexityof IsFullStackf)       | O(1)   |
| Time Complexityof DeleteStackQ        | O(1)   |
| **Limitations**                       |        |

The maximum size of the stack must first be defined and it cannot be changed. Trying to push a new element into a full stackcauses animplementation-specific exception.

**Dynamic Array Implementation**

First, let’s consider how we implemented a simple array based stack. We took one index variable *top* whichpoints to the indexof the most recentlyinserted element inthe stack. To insert (or push) anelement, we increment *top* indexand thenplace the new element at that index.

Similarly, to delete (or pop) an element we take the element at *top* index and then decrement the *top* index. We represent an empty queue with *top* value equal to –1. The issue that still needs to be resolved is what we do whenall the slots inthe fixed size arraystackare occupied?

**First try:** What if we increment the size of the arrayby1 everytime the stackis full?

- Push(); increase size of S[] by1
- Pop(): decrease size of S[] by1

**Problems withthis approach?**

This way of incrementing the array size is too expensive. Let us see the reason for this. For example, at *n* = 1, to push an element create a new array of size 2 and copy all the old array elements to the new array, and at the end add the new element. At *n* = 2, to push an element create a new array of size 3 and copy all the old array elements to the new array, and at the end add the new element.

Similarly, at *n* = *n* – 1, if we want to pushanelement create a new arrayof size nand copyall the old array elements to the new array and at the end add the new element. After n push operations

the total time *T*(*n*) (*n*umber of copyoperations) is proportional to 1 + 2 + ... + *n* ≈ O(*n*2). **Alternative Approach: RepeatedDoubling**

Let us improve the complexity by using the array *doubling* technique. If the array is full, create a new array of twice the size, and copy the items. With this approach, pushing *n* items takes time

proportional to *n* (not *n*2).

For simplicity, let us assume that initially we started with *n* = 1 and moved up to *n* = 32. That means, we do the doubling at 1,2,4,8,16. The other way of analyzing the same approach is: at *n* = 1, if we want to add (push) an element, double the current size of the array and copy all the elements of the old arrayto the new array.

At *n* = 1, we do 1 copy operation, at *n* = 2, we do 2 copy operations, and at *n =* 4, we do 4 copy operations and so on. Bythe time we reach*n* = 32, the total number of copyoperations is 1+2 + 4

+ 8+16 = 31 which is approximately equal to 2*n* value (32). If we observe carefully, we are doing the doubling operation *logn* times. Now, let us generalize the discussion. For n push operations we double the array size *logn* times. That means, we will have *logn* terms in the expressionbelow. The total time *T*(*n*) of a series of npushoperations is proportional to

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.083.png)

*T*(*n*) is O(*n*) and the amortized time of a pushoperationis O(1) .

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.084.jpeg)

**Performance**

Let *n* be the number of elements in the stack. The complexities for operations with this representationcanbe givenas:



| Space Complexity(for *n* pushoperations)                     | O(*n*)         |
| ------------------------------------------------------------ | -------------- |
| Time Complexityof CreateStack()                              | O(1)           |
| Time Complexityof PushQ                                      | O(1) (Average) |
| Time Complexityof PopQ                                       | O(1)           |
| Time Complexityof Top()                                      | O(1)           |
| Time Complexityof IsEmpryStackf)                             | O(1))          |
| Time Complexityof IsFullStackf)                              | O(1)           |
| Time Complexityof DeleteStackQ                               | O(1)           |
| **Note:** Too manydoublings maycause memoryoverflow exception. |                |

**Linked List Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.085.png)

The other way of implementing stacks is by using Linked lists. Push operation is implemented by inserting element at the beginning of the list. Pop operation is implemented by deleting the node fromthe beginning(the header/top node).


![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.086.jpeg)

**Performance**

Let *n* be the number of elements in the stack. The complexities for operations with this representationcanbe givenas:



| Space Complexity(for *n* pushoperations) | O(*n*)         |
| ---------------------------------------- | -------------- |
| Time Complexityof CreateStack()          | O(1)           |
| Time Complexityof Push()                 | O(1) (Average) |
| Time Complexityof Pop()                  | O(1)           |
| Time Complexityof Top()                  | O(1)           |
| Time Complexityof IsEmptyStack()         | O(1)           |
| Time Complexityof DeleteStack()          | O(*n*)         |

6. **Comparison of Implementations**

**Comparing IncrementalStrategy and Doubling Strategy**

We compare the incremental strategy and doubling strategy by analyzing the total time *T*(*n*) needed to perform a series of n push operations. We start with an empty stack represented by an arrayof size 1.

We call *amortized* time of a push operation is the average time taken by a push over the series of operations, that is, *T*(*n*)*/n.*

**Incremental Strategy**

The amortized time (average time per operation) of a pushoperationis O(*n*) [O(*n*2)/*n*]. **Doubling Strategy**

Inthis method, the amortized time of a pushoperationis O(1) [O(*n*)/*n*].

**Note:** For analysis, refer to the *[Implementation*](#_page64_x28.00_y705.74)* section.

**Comparing Array Implementation and Linked List Implementation**


**Array Implementation**

- Operations take constant time.
- Expensive doublingoperationeveryonce ina while.
- Anysequence of noperations (startingfromemptystack) – *“amortized”* bound takes time proportional to n.

**LinkedList Implementation**

- Grows and shrinks gracefully.
- Everyoperationtakes constant time O(1).
- Everyoperationuses extra space and time to deal withreferences.

7. **Stacks: Problems & Solutions**

**Problem-1**  Discuss how stacks canbe used for checkingbalancingof symbols.

**Solution:** Stacks can be used to check whether the given expression has balanced symbols. This algorithm is very useful in compilers. Each time the parser reads one character at a time. If the character is an opening delimiter such as (, {, or [- then it is written to the stack. When a closing delimiter is encountered like ), }, or ]-the stackis popped.

The opening and closing delimiters are then compared. If they match, the parsing of the string continues. If they do not match, the parser indicates that there is an error on the line. Alinear-time O(*n*) algorithmbased onstackcanbe givenas:

**Algorithm:**

1) Create a stack.
1) while (end of input is not reached) {
1) If the character read is not a symbol to be balanced, ignore it.
1) If the character is anopeningsymbol like (, [, {, pushit onto the stack
1) If it is a closing symbol like ),],}, then if the stack is empty report an error. Otherwise pop the stack.
1) If the symbol popped is not the correspondingopeningsymbol, report an error.

}

3) At end of input, if the stackis not emptyreport anerror

**Examples:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.087.png)

For tracingthe algorithmlet us assume that the input is: () (() [()])

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.088.jpeg)Time Complexity: O(*n*). Since we are scanning the input only once. Space Complexity: O(*n*) [for stack].

**Problem-2**  Discuss infixto postfixconversionalgorithmusingstack.

**Solution:** Before discussing the algorithm, first let us see the definitions of infix, prefix and postfixexpressions.

**Infix:** An infix expression is a single letter, or an operator, proceeded by one infix string and followed byanother Infixstring.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.089.png)

**Prefix:** A prefix expression is a single letter, or an operator, followed by two prefix strings. Every prefix string longer than a single variable contains an operator, first operand and second operand.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.090.png)

**Postfix:** A postfix expression (also called Reverse Polish Notation) is a single letter or an operator, preceded by two postfix strings. Every postfix string longer than a single variable contains first and second operands followed byanoperator.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.091.png)

Prefix and postfix notions are methods of writing mathematical expressions without parenthesis. Time to evaluate a postfix and prefix expression is O(*n*), where n is the number of elements in the array.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.092.png)

Now, let us focus on the algorithm. In infix expressions, the operator precedence is implicit

unless we use parentheses. Therefore, for the infix to postfix conversion algorithm we have to define the operator precedence (or priority) inside the algorithm.

The table shows the precedence and their associativity(order of evaluation) amongoperators.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.093.jpeg)

**Important Properties**

- Let us consider the infix expression 2 + 3\*4 and its postfix equivalent 234\*+. Notice that between infix and postfix the order of the numbers (or operands) is unchanged. It is 2 3 4 in both cases. But the order of the operators \* and + is affected in the two expressions.
- Only one stack is enough to convert an infix expression to postfix expression. The stackthat we use inthe algorithmwill be used to change the order of operators from infix to postfix. The stack we use will only contain operators and the open parentheses symbol ‘(‘.

Postfix expressions do not contain parentheses. We shall not output the parentheses in the postfix output.

**Algorithm:**

1) Create a stack
1) for eachcharacter t inthe input stream}

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.094.png)

3) pop and output tokens until the stackis empty

For better understandinglet us trace out anexample: A\*B- (C + D) + E

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.095.png)

**Problem-3**  Discuss postfixevaluationusingstacks? **Solution:**

**Algorithm:**

1  Scanthe Postfixstringfromleft to right.
1  Initialize anemptystack.
1  Repeat steps 4 and 5 till all the characters are scanned.
1  If the scanned character is anoperand, pushit onto the stack.
1  If the scanned character is an operator, and if the operator is a unary operator, then pop an element from the stack. If the operator is a binary operator, then pop two elements from the stack. After popping the elements, apply the operator to those popped elements. Let the result of this operationbe retVal onto the stack.
1  After all characters are scanned, we will have onlyone element inthe stack.
1  Returntop of the stackas result.

**Example:** Let us see how the above-mentioned algorithm works using an example. Assume that the postfixstringis 123\*+5-.

Initially the stack is empty. Now, the first three characters scanned are 1, 2 and 3, which are operands. Theywill be pushed into the stackinthat order.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.096.jpeg)

The next character scanned is “\*”, which is an operator. Thus, we pop the top two elements from the stack and perform the “\*” operation with the two operands. The second operand will be the first element that is popped.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.097.jpeg)

The value of the expression(2\*3) that has beenevaluated (6) is pushed into the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.098.jpeg)

The next character scanned is “+”, which is an operator. Thus, we pop the top two elements from the stack and perform the “+” operation with the two operands. The second operand will be the first element that is popped.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.099.jpeg)

The value of the expression(1+6) that has beenevaluated (7) is pushed into the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.100.jpeg)

The next character scanned is “5”, whichis added to the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.101.jpeg)

The next character scanned is “-”, which is an operator. Thus, we pop the top two elements from the stack and perform the “-” operation with the two operands. The second operand will be the first element that is popped.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.102.jpeg)

The value of the expression(7-5) that has beenevaluated(23) is pushed into the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.103.jpeg)

Now, since all the characters are scanned, the remaining element in the stack (there will be only one element inthe stack) will be returned. End result:

- PostfixString: 123\*+5-
- Result : 2

**Problem-4**  Canwe evaluate the infixexpressionwithstacks inone pass?

**Solution:** Using 2 stacks we can evaluate an infix expression in 1 pass without converting to postfix.

**Algorithm:**

1) Create anemptyoperator stack
2) Create anemptyoperand stack
3) For eachtokeninthe input string

1. Get the next tokeninthe infixstring
1. If next tokenis anoperand, place it onthe operand stack
1. If next tokenis anoperator

i. Evaluate the operator (*n*ext op)

4) While operator stack is not empty, pop operator and operands (left and right), evaluate left operator right and pushresult onto operand stack
4) Pop result fromoperator stack

**Problem-5**  How to designa stacksuchthat GetMinimum( ) should be O(1)?

**Solution:** Take an auxiliary stack that maintains the minimum of all values in the stack. Also, assume that each element of the stack is less than its below elements. For simplicity let us call the auxiliarystack*min stack.*

Whenwe *pop* the main stack, *pop* the min stack too. When we push the main stack, push either the new element or the current minimum, whichever is lower. At any point, if we want to get the minimum, then we just need to return the top element from the min stack. Let us take an example and trace it out. Initially let us assume that we have pushed 2, 6, 4, 1 and 5. Based on the above- mentioned algorithmthe *min stack* will looklike:



| Mainstack                  | Minstack |
| -------------------------- | -------- |
| 5 → top                    | 1 → top  |
| 1                          | 1        |
| 4                          | 2        |
| 6                          | 2        |
| 2                          | 2        |
| After poppingtwice we get: |          |



| Mainstack                                                    | Minstack |
| ------------------------------------------------------------ | -------- |
| 4 -→ top                                                     | 2 → top  |
| 6                                                            | 2        |
| 2                                                            | 2        |
| Based onthe discussionabove, now let us code the push, pop and GetMinimum() operations. |          |

![](https://raw.githubusercontent.com/xuelove0001/imgCCCC/master/https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.104.jpeg)

Time complexity: O(1). Space complexity: O(*n*) [for Min stack]. This algorithm has much better space usage if we rarelyget a “new minimumor equal”.

**Problem-6**  For [Problem-5](#_page82_x66.91_y170.96) is it possible to improve the space complexity?

**Solution:** Yes. The main problem of the previous approach is, for each push operation we are pushing the element on to min stack also (either the new element or existing minimum element). That means, we are pushingthe duplicate minimumelements onto the stack.

Now, let us change the algorithmto improve the space complexity. We still have the minstack, but we only pop from it when the value we pop from the main stack is equal to the one on the min stack. We only *push* to the min stack when the value being pushed onto the main stack is less than *or equal* to the current min value. In this modified algorithm also, if we want to get the minimum then we just need to return the top element from the min stack. For example, taking the original versionand pushing1 again, we’d get:



| Mainstack                                                    | Minstack |
| ------------------------------------------------------------ | -------- |
| 1 → top                                                      |          |
| 5                                                            |          |
| 1                                                            |          |
| 4                                                            | 1 → top  |
| 6                                                            | 1        |
| 2                                                            | 2        |
| Poppingfromthe above pops frombothstacks because 1 == 1, leaving: |          |



| Mainstack                                                 | Minstack |
| --------------------------------------------------------- | -------- |
| 5 → top                                                   |          |
| 1                                                         |          |
| 4                                                         |          |
| 6                                                         | 1 → top  |
| 2                                                         | 2        |
| Poppingagain*only* pops fromthe mainstack, because 5 > 1: |          |



| Mainstack                                                    | Minstack |
| ------------------------------------------------------------ | -------- |
| 1 → top                                                      |          |
| 4                                                            |          |
|                                                              |          |
| 6 1 → top 2![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.105.png)![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.106.png) 2 |          |

Poppingagainpops bothstacks because 1 == 1:



| Mainstack                                               | Minstack |
| ------------------------------------------------------- | -------- |
| 4 → top                                                 |          |
| 6                                                       |          |
| 2                                                       | 2 → top  |
| **Note:** The difference is onlyinpush& pop operations. |          |

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.107.jpeg)

Time complexity: O(1). Space complexity: O(*n*) [for Min stack]. But this algorithm has much better space usage if we rarelyget a “new minimumor equal”.

**Problem-7**  For a givenarraywithnsymbols how manystackpermutations are possible?

**Solution:** The number of stackpermutations withnsymbols is represented byCatalannumber and we will discuss this inthe *Dynamic Programming* chapter.

**Problem-8**  Given an array of characters formed with a’s and b’s. The string is marked with

special character X which represents the middle of the list (for example: ababa...ababXbabab baaa). Checkwhether the stringis palindrome.

**Solution:** This is one of the simplest algorithms. What we do is, start two indexes, one at the beginningof the stringand the other at the end of the string. Eachtime compare whether the values at both the indexes are the same or not. If the values are not the same then we say that the given stringis not a palindrome.

If the values are the same then increment the left index and decrement the right index. Continue this process until boththe indexes meet at the middle (at X) or if the stringis not palindrome.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.108.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-9**  For [Problem-8](#_page87_x66.91_y71.59), if the input is in singly linked list then how do we check whether the list elements forma palindrome (That means, movingbackward is not possible).

**Solution:** Refer Linked Lists chapter.

**Problem-10**  Canwe solve [Problem-8](#_page87_x66.91_y71.59) usingstacks?

**Solution: Yes.**

**Algorithm:**

- Traverse the list till we encounter X as input element.
- Duringthe traversal pushall the elements (until X) onto the stack.
- For the second half of the list, compare each element’s content with top of the stack. If theyare the same thenpop the stackand go to the next element inthe input list.
- If theyare not the same thenthe givenstringis not a palindrome.
- Continue this process until the stackis emptyor the stringis not a palindrome.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.109.png)

Time Complexity: O(*n*). Space Complexity: O(*n*/2) *≈* O(*n*).

**Problem-11**  Given a stack, how to reverse the elements of the stack using only stack

operations (push& pop)?

**Solution: Algorithm:**

- First pop all the elements of the stacktill it becomes empty.
- For eachupward step inrecursion, insert the element at the bottomof the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.110.png)

Time Complexity: O(*n*2). Space Complexity: O(*n*), for recursive stack.

**Problem-12**  Show how to implement one queue efficiently using two stacks. Analyze the

runningtime of the queue operations.

**Solution:** Refer Queues chapter.

**Problem-13**  Show how to implement one stack efficiently using two queues. Analyze the

runningtime of the stackoperations.

**Solution:** Refer Queues chapter.

**Problem-14**  How do we implement *two* stacks using only one array? Our stack routines

should not indicate anexceptionunless everyslot inthe arrayis used?

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.111.png)

**Algorithm:**

- Start two indexes one at the left end and the other at the right end.
- The left indexsimulates the first stackand the right indexsimulates the second stack.
- If we want to push an element into the first stack then put the element at the left index.
- Similarly, if we want to push an element into the second stack then put the element at the right index.
- The first stackgrows towards the right, and the second stackgrows towards the left.

Time Complexityof pushand pop for bothstacks is O(1). Space Complexityis O(1). **Problem-15**  3 stacks inone array: How to implement 3 stacks inone array?

**Solution:** For this problem, there could be other ways of solving it. Given below is one possibilityand it works as longas there is anemptyspace inthe array.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.112.png)

To implement 3 stacks we keep the followinginformation.

- The indexof the first stack(Topi): this indicates the size of the first stack.
- The indexof the second stack(Top2): this indicates the size of the second stack.
- Startingindexof the third stack(base address of third stack).
- Top indexof the third stack.

Now, let us define the pushand pop operations for this implementation.

**Pushing:**

- For pushing on to the first stack, we need to see if adding a new element causes it to bump into the third stack. If so, try to shift the third stack upwards. Insert the new

element at (start1 + Top1).

- For pushing to the second stack, we need to see if adding a new element causes it to bump into the third stack. If so, try to shift the third stack downward. Insert the new element at (start2 - Top2).
- When pushing to the third stack, see if it bumps into the second stack. If so, try to shift the third stack downward and try pushing again. Insert the new element at (start3 + Top3).

Time Complexity: O(*n*). Since we mayneed to adjust the third stack. Space Complexity: O(1). **Popping:** For popping, we don’t need to shift, just decrement the size of the appropriate stack.

Time Complexity: O(1). Space Complexity: O(1).

**Problem-16**  For [Problem-15](#_page90_x66.91_y338.64), is there anyother wayimplementingthe middle stack?

**Solution: Yes.** When either the left stack (which grows to the right) or the right stack (which grows to the left) bumps into the middle stack, we need to shift the entire middle stack to make room. The same happens if a pushonthe middle stackcauses it to bump into the right stack.

To solve the above-mentioned problem (*n*umber of shifts) what we can do is: alternating pushes can be added at alternating sides of the middle list (For example, even elements are pushed to the left, odd elements are pushed to the right). This would keep the middle stack balanced in the center of the array but it would still need to be shifted when it bumps into the left or right stack, whether by growing on its own or by the growth of a neighboring stack. We can optimize the initial locations of the three stacks if they grow/shrink at different rates and if they have different average sizes. For example, suppose one stack doesn’t change much. If we put it at the left, then the middle stack will eventually get pushed against it and leave a gap between the middle and right stacks, which grow toward each other. If they collide, then it’s likely we’ve run out of space in the array. There is no change in the time complexity but the average number of shifts will get reduced.

**Problem-17**  Multiple (*m*) stacks in one array: Similar to [Problem-15](#_page90_x66.91_y338.64), what if we want to

implement *m* stacks inone array?

[**Solution:** Let us assume that array indexes are from1 to *n*. Similar to the discussion in Problem- 15, to implement *m* stacks in one array, we divide the array into *m* parts (as shown below). The](#_page90_x66.91_y338.64)

size of eachpart is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.113.png).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.114.png)

From the above representation we can see that, first stack is starting at index 1 (starting index is stored in Base[l]), second stack is starting at index ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.113.png) (starting index is stored in Base[2]), third

stackis startingat index![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.115.png) (startingindexis stored inBase[3]), and so on. Similar to *Base* array,

let us assume that *Top* array stores the top indexes for each of the stack. Consider the following terminologyfor the discussion.

- Top[i], for 1 ≤ *i* ≤ *m* will point to the topmost element of the stack*i.*
- If Base[i] == Top[i], thenwe cansaythe stack*i* is empty.
- If Top[i] == Base[i+1], thenwe cansaythe stacki is full.

InitiallyBase[i] = Top[i] = ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.113.png) (*i* – 1), for 1 ≤ *i* ≤ *m.*

- The *ith* stackgrows fromBase[i]+1 to Base[i+1].

**Pushing onto** *ith* **stack:**

1) For pushing on to the *ith* stack, we check whether the top of *ith* stack is pointing to Base[i+1] (this case defines that *ith* stack is full). That means, we need to see if adding a new element causes it to bump into the *i* + 1*th* stack. If so, try to shift the stacks from *i +* 1*th* stack to *mth* stack toward the right. Insert the new element at (Base[i] + Top[i]).
1) If right shiftingis not possible thentryshiftingthe stacks from1 to *i* –1*th* stacktoward the left.
1) If bothof themare not possible thenwe cansaythat all stacks are full.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.116.png)

Time Complexity: O(*n*). Since we mayneed to adjust the stacks. Space Complexity: O(1).

**Popping from** *ith* **stack:** For popping, we don’t need to shift, just decrement the size of the appropriate stack. The onlycase to checkis stackemptycase.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.117.png)

Time Complexity: O(1). Space Complexity: O(1).

**Problem-18**  Consider anemptystackof integers. Let the numbers 1,2,3,4,5,6 be pushed onto

this stack in the order they appear fromleft to right. Let 5 indicate a push and *X* indicate a pop operation. Cantheybe permuted into the order 325641(output) and order 154623?

**Solution:** SSSXXSSXSXXX outputs 325641. 154623 cannot be output as 2 is pushed much before 3 so canappear onlyafter 3 is output.

**Problem-19**  Earlier in this chapter, we discussed that for dynamic array implementation of

stacks, the ‘repeated doubling’ approach is used. For the same problem, what is the complexityif we create a new arraywhose size is n+ if instead of doubling?

**Solution:** Let us assume that the initial stack size is 0. For simplicity let us assume that *K* = 10. For inserting the element we create a new array whose size is 0 + 10 = 10. Similarly, after 10 elements we again create a new array whose size is 10 + 10 = 20 and this process continues at values: 30,40 ... That means, for a given n value, we are creating the new arrays at:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.118.png) The total number of copyoperations is:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.119.png)

If we are performing*n* pushoperations, the cost per operationis O(*logn*).

**Problem-20**  Given a string containing *n S’s* and *n X’s* where 5 indicates a push operation and

*X* indicates a pop operation, and with the stack initially empty, formulate a rule to check whether a givenstring5 of operations is admissible or not?

**Solution:** Given a string of length 2*n*, we wish to check whether the given string of operations is permissible or not with respect to its functioning on a stack. The only restricted operation is pop whose prior requirement is that the stack should not be empty. So while traversing the string from left to right, prior to any pop the stack shouldn’t be empty, which means the number of *S’s* is always greater thanor equal to that of *X*’s. Hence the conditionis at anystage of processingof the string, the number of pushoperations (*S*) should be greater thanthe number of pop operations (*X*).

**Problem-21**  Suppose there are two singly linked lists which intersect at some point and

become a single linked list. The head or start pointers of both the lists are known, but the intersecting node is not known. Also, the number of nodes in each of the lists before they intersect are unknown and both lists may have a different number. *List*1 may have *n* nodes before it reaches the intersection point and *List*2 may have *m* nodes before it reaches the intersection point where *m* and n may be *m = n,m < n* or *m > n*. Can we find the merging point usingstacks?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.120.png)

**Solution: Yes.** For algorithmrefer to *Linked Lists* chapter.

**Problem-22  Finding Spans:** Given an array *A*, the span *S*[*i*] of *A*[*i*] is the maximum number

of consecutive elements *A*[*j*] immediatelypreceding*A*[*i*] and suchthat *A*[*j*] *< A*[*i*]?

**Other way of asking:** Given an array *A*of integers, find the maximumof *j* – *i* subjected to the constraint of *A*[*i*] *< A*[*j*].

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.121.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.122.png)

This is a very common problem in stock markets to find the peaks. Spans are used in financial analysis (E.g., stock at 52-week high). The span of a stock price on a certain day, *i*, is the maximum number of consecutive days (up to the current day) the price of the stock has been less thanor equal to its price on*i.*

As an example, let us consider the table and the corresponding spans diagram. In the figure the arrows indicate the length of the spans. Now, let us concentrate on the algorithm for finding the spans. One simple way is, each day, check how many contiguous days have a stock price that is

less thanthe current price.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.123.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-23**  Canwe improve the complexityof [Problem-22](#_page94_x66.91_y531.91)?

**Solution:** Fromthe example above, we can see that span *S*[*i*] on day *i* can be easily calculated if we know the closest day preceding *i*, such that the price is greater on that day than the price on day*i*. Let us call sucha dayas *P*. If sucha dayexists thenthe spanis now defined as *S*[*i*] *= i* – *P.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.124.png)Time Complexity: Each index of the array is pushed into the stack exactly once and also popped from the stack at most once. The statements in the while loop are executed at most *n* times. Even thoughthe algorithmhas nested loops, the complexityis O(*n*) as the inner loop is executing only *n* times during the course of the algorithm (trace out an example and see how many times the inner loop becomes successful). Space Complexity: O(*n*) [for stack].

**Problem-24  Largest rectangle under histogram:** A histogram is a polygon composed of a

sequence of rectangles aligned at a common base line. For simplicity, assume that the rectangles have equal widths but may have different heights. For example, the figure on the left shows a histogram that consists of rectangles with the heights 3,2,5,6,1,4,4, measured in units where 1 is the width of the rectangles. Here our problem is: given an array with heights of rectangles (assuming width is 1), we need to find the largest rectangle possible. For the givenexample, the largest rectangle is the shared part.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.125.png)

**Solution:** A straightforward answer is to go to each bar in the histogram and find the maximum possible area in the histogramfor it. Finally, find the maximumof these values. This will require O(*n*2).

**Problem-25**  For [Problem-24](#_page97_x66.91_y121.28), canwe improve the time complexity?

**Solution: Linear search using a stack of incomplete sub problems:** There are many ways of solving this problem. *Judge* has given a nice algorithm for this problem which is based on stack. Process the elements inleft-to-right order and maintaina stackof informationabout started but yet unfinished sub histograms.

If the stack is empty, open a new sub problem by pushing the element onto the stack. Otherwise compare it to the element on top of the stack. If the new one is greater we again push it. If the new one is equal we skip it. In all these cases, we continue with the next new element. If the new one is less, we finish the topmost sub problem by updating the maximum area with respect to the element at the top of the stack. Then, we discard the element at the top, and repeat the procedure keepingthe current new element.

This way, all sub problems are finished when the stack becomes empty, or its top element is less than or equal to the new element, leading to the actions described above. If all elements have been processed, and the stack is not yet empty, we finish the remaining sub problems by updating the maximumarea withrespect to the elements at the top.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.126.jpeg)

At the first impression, this solution seems to be having O(*n*2) complexity. But if we look carefully, every element is pushed and popped at most once, and in every step of the function at least one element is pushed or popped. Since the amount of work for the decisions and the update is constant, the complexity of the algorithm is O(*n*) by amortized analysis. Space Complexity: O(*n*) [for stack].

**Problem-26**  Ona givenmachine, how do youcheckwhether the stackgrows up or down?

**Solution:** Try noting down the address of a local variable. Call another function with a local variable declared init and checkthe address of that local variable and compare.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.38a46437-5ce7-44a1-b4a2-0950e50a5748.127.png)

Time Complexity: O(1). Space Complexity: O(1).

**Problem-27**  Given a stack of integers, how do you check whether each successive pair of

numbers in the stack is consecutive or not. The pairs can be increasing or decreasing, and if the stack has an odd number of elements, the element at the top is left out of a pair. For example, if the stack of elements are [4, 5, -2, -3, 11, 10, 5, 6, 20], then the output should be true because each of the pairs (4, 5), (-2, -3), (11, 10), and (5, 6) consists of consecutive numbers.

**Solution:** Refer to *Queues* chapter.

**Problem-28**  Recursively remove all adjacent duplicates: Given a string of characters,

recursively remove adjacent duplicate characters from string. The output string should not have anyadjacent duplicates.



| *Input:* careermonk *Output:* camonk                         | *Input:* mississippi *Output:* m |
| :----------------------------------------------------------- | :------------------------------- |
| **Solution:** This solution runs with the concept of in-place stack. When element on stack doesn’t match the current character, we add it to stack. When it matches to stack top, we skip characters until the element matches the top of stackand remove the element fromstack. |                                  |

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.001.png)

Time Complexity: O(*n*). Space Complexity: O(1) as the stacksimulationis done inplace.

**Problem-29**  Given an array of elements, replace every element with nearest greater element

onthe right of that element.

**Solution:** One simple approach would involve scanning the array elements and for each of the elements, scanthe remainingelements and find the nearest greater element.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.002.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-30**  For [Problem-29](#_page0_x66.91_y428.11), canwe improve the complexity?

**Solution:** The approach is pretty much similar to Problem-22. Create a stack and push the first element. For the rest of the elements, mark the current element as *nextNearestGreater*. If stack is not empty, then pop an element from stack and compare it with *nextNearestGreater*. If *nextNearestGreater* is greater than the popped element, then *nextNearestGreater* is the next greater element for the popped element. Keep poppingfromthe stackwhile the popped element is smaller than *nextNearestGreater. nextNearestGreater* becomes the next greater element for all such popped elements. If *nextNearestGreater* is smaller than the popped element, then push the popped element back.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.003.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-31**  How to implement a stackwhichwill support followingoperations inO(1) time

complexity?

- Pushwhichadds anelement to the top of stack.
- Pop whichremoves anelement fromtop of stack.
- Find Middle whichwill returnmiddle element of the stack.
- Delete Middle whichwill delete the middle element.

**Solution:** We can use a LinkedList data structure with an extra pointer to the middle element. Also, we need another variable to store whether the LinkedList has an even or odd number of elements.

- *Push:* Add the element to the head of the LinkedList. Update the pointer to the middle element accordingto variable.
- *Pop:* Remove the head of the LinkedList. Update the pointer to the middle element accordingto variable.
- *Find Middle:* Find Middle whichwill returnmiddle element of the stack.
- *Delete Middle:* Delete Middle which will delete the middle element use the logic of Problem-43 from*Linked Lists* chapter.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.004.png)

1. **What is a Queue?**

Aqueue is a data structure used for storingdata (similar to Linked Lists and Stacks). Inqueue, the order in which data arrives is important. In general, a queue is a line of people or things waiting to be served insequential order startingat the beginningof the line or sequence.

**Definition:** A *queue* is an ordered list in which insertions are done at one end (*rear*) and deletions are done at other end (*front*). The first element to be inserted is the first one to be deleted. Hence, it is called First inFirst out (FIFO) or Last inLast out (LILO) list.

Similar to *Stacks*, special names are given to the two changes that can be made to a queue. When an element is inserted in a queue, the concept is called *EnQueue*, and when an element is removed fromthe queue, the concept is called *DeQueue.*

*DeQueueing* an empty queue is called *underflow* and *EnQueuing* an element in a full queue is called *overflow*. Generally, we treat themas exceptions. As an example, consider the snapshot of

the queue.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.005.png)

2. **How are Queues Used?**

The concept of a queue can be explained by observing a line at a reservation counter. When we enter the line we stand at the end of the line and the personwho is at the front of the line is the one who will be served next. He will exit the queue and be served.

As this happens, the next person will come at the head of the line, will exit the queue and will be served. As each person at the head of the line keeps exiting the queue, we move towards the head of the line. Finally we will reach the head of the line and we will exit the queue and be served. This behavior is veryuseful incases where there is a need to maintainthe order of arrival.

3. **Queue ADT**

The following operations make a queue an ADT. Insertions and deletions in the queue must follow the FIFO scheme. For simplicitywe assume the elements are integers.

**MainQueue Operations**

- EnQueue(int data): Inserts anelement at the end of the queue
- int DeQueue(): Removes and returns the element at the front of the queue

**Auxiliary Queue Operations**

- int Front(): Returns the element at the front without removingit
- int QueueSize(): Returns the number of elements stored inthe queue
- int IsEmptyQueueQ: Indicates whether no elements are stored inthe queue or not

4. **Exceptions**

Similar to other ADTs, executing *DeQueue* on an empty queue throws an *“Empty Queue Exception”* and executing*EnQueue* ona full queue throws *“Full Queue Exception”.*

5. **Applications**

Followingare some of the applications that use queues.

**Direct Applications**

- Operating systems schedule jobs (with equal priority) in the order of arrival (e.g., a print queue).
- Simulation of real-world queues such as lines at a ticket counter or any other first- come first-served scenario requires a queue.
- Multiprogramming.
- Asynchronous data transfer (file IO, pipes, sockets).
- Waitingtimes of customers at call center.
- Determiningnumber of cashiers to have at a supermarket.

**Indirect Applications**

- Auxiliarydata structure for algorithms
- Component of other data structures

6. **Implementation**

There are many ways (similar to Stacks) of implementing queue operations and some of the commonlyused methods are listed below.

- Simple circular arraybased implementation
- Dynamic circular arraybased implementation
- Linked list implementation

**Why Circular Arrays?**

First, let us see whether we can use simple arrays for implementing queues as we have done for stacks. We know that, in queues, the insertions are performed at one end and deletions are performed at the other end. After performing some insertions and deletions the process becomes easyto understand.

In the example shown below, it can be seen clearly that the initial slots of the array are getting wasted. So, simple array implementation for queue is not efficient. To solve this problem we assume the arrays as circular arrays. That means, we treat the last element and the first array elements as contiguous. With this representation, if there are any free slots at the beginning, the rear pointer caneasilygo to its next free slot.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.006.png)

**Note:** The simple circular array and dynamic circular array implementations are very similar to stackarrayimplementations. Refer to *Stacks* chapter for analysis of these implementations.

**Simple Circular Array Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.007.jpeg)

This simple implementation of Queue ADT uses an array. In the array, we add elements circularly and use two variables to keep track of the start element and end element. Generally, *front* is used to indicate the start element and *rear* is used to indicate the end element in the queue. The array storing the queue elements may become full. An *EnQueue* operation will then throw a *full queue exception*. Similarly, if we try deleting an element from an empty queue it will throw *empty queue exception.*

**Note:** Initially, bothfront and rear points to -1 whichindicates that the queue is empty.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.008.jpeg)

**Performance and Limitations**

**Performance:** Let *n* be the number of elements inthe queue:



| Space Complexity(for nEnQueue operations)                    | O(*n*) |
| ------------------------------------------------------------ | ------ |
| Time Complexityof EnQueue()                                  | O(1)   |
| Time Complexityof DeQueue()                                  | O(1)   |
| Time Complexityof IsEmptyQueue()                             | O(1)   |
| Time Complexityof IsFullQueue()                              | O(1)   |
| Time Complexityof QueueSize()                                | O(1)   |
| Time Complexityof DeleteQueue()                              | O(1)   |
| **Limitations:** The maximum size of the queue must be defined as prior and cannot be changed. Tryingto *EnQueue* a new element into a full queue causes animplementation-specific exception. |        |

**Dynamic Circular Array Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.009.jpeg)


Let *n* be the number of elements inthe queue.



| Space Complexity(for *n* EnQueue operations) | O(*n*)         |
| -------------------------------------------- | -------------- |
| Time Complexityof EnQueue()                  | O(1) (Average) |
| Time Complexityof DeQueue()                  | O(1)           |
| Time Complexityof QueueSize()                | O(1)           |
| Time Complexityof IsEmptyQueue()             | O(1)           |
| Time Complexityof IsFullQueue()              | O(1)           |
| Time Complexityof QueueSize()                | O(1)           |
| Time Complexityof DeleteQueue()              | O(1)           |
| **Linked List Implementation**               |                |

Another way of implementing queues is by using Linked lists. *EnQueue* operation is implemented by inserting an element at the end of the list. *DeQueue* operation is implemented by deleting an element fromthe beginningof the list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.010.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.011.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.012.jpeg)

Let *n* be the number of elements inthe queue, then



| Space Complexity(for nEnQueue operations) | O(*n*)         |
| ----------------------------------------- | -------------- |
| Time Complexityof EnQueue()               | O(1) (Average) |
| Time Complexityof DeQueue()               | O(1)           |
| Time Complexityof IsEmptyQueue()          | O(1)           |
| Time Complexityof DeleteQueue()           | O(1)           |
| **Comparison of Implementations**         |                |

**Note:** Comparisonis verysimilar to stackimplementations and *Stacks* chapter.

7. **Queues: Problems & Solutions**

**Problem-1**  Give an algorithm for reversing a queue *Q*. To access the queue, we are only

allowed to use the methods of queue ADT.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.013.png)

Time Complexity: O(*n*).

**Problem-2**  How canyouimplement a queue usingtwo stacks?

**Solution:** Let SI and S2 be the two stacks to be used in the implementation of queue. All we have to do is to define the EnQueue and DeQueue operations for the queue.


![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.014.png)

**EnQueue Algorithm**

- Just pushonto stackS1

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.015.png)

Time Complexity: O(1). **DeQueue Algorithm**

- If stackS2 is not emptythenpop fromS2 and returnthat element.
- If stack is empty, then transfer all elements from SI to S2 and pop the top element from S2 and return that popped element [we can optimize the code a little by

transferring only *n* – 1 elements from SI to S2 and pop the *nth* element from SI and returnthat popped element].

- If stackS1 is also emptythenthrow error.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.016.png)

Time Complexity: From the algorithm, if the stack S2 is not empty then the complexity is O(1). If the stack S2 is empty, then we need to transfer the elements from SI to S2. But if we carefully observe, the number of transferred elements and the number of popped elements from S2 are equal. Due to this the average complexity of pop operation in this case is O(1).The amortized complexityof pop operationis O(1).

**Problem-3**  Show how you can efficiently implement one stack using two queues. Analyze the

runningtime of the stackoperations.

**Solution:** Yes, it is possible to implement the Stack ADT using 2 implementations of the Queue ADT. One of the queues will be used to store the elements and the other to hold themtemporarily during the *pop* and *top* methods. The *push* method would *enqueue* the given element onto the storage queue. The *top* method would transfer all but the last element fromthe storage queue onto the temporary queue, save the front element of the storage queue to be returned, transfer the last element to the temporary queue, then transfer all elements back to the storage queue. The *pop* method would do the same as top, except instead of transferring the last element onto the temporaryqueue after savingit for return, that last element would be discarded. Let Q1 and Q2 be the two queues to be used in the implementation of stack. All we have to do is to define the *push* and *pop* operations for the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.017.png)

Inthe algorithms below, we make sure that one queue is always empty.

**PushOperationAlgorithm:** Insert the element inwhichever queue is not empty.

- Check whether queue Q1 is empty or not. If Q1 is empty then Enqueue the element into Q2.
- Otherwise EnQueue the element into Q1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.018.png)

Time Complexity: O(1).

**PopOperationAlgorithm:** Transfer *n* – 1 elements to the other queue and delete last fromqueue for performingpop operation.

- If queue Q1 is not empty then transfer *n* – 1 elements from Q1 to Q2 and then, DeQueue the last element of Q1 and returnit.
- If queue Q2 is not empty then transfer *n* – 1 elements from Q2 to Q1 and then,

DeQueue the last element of Q2 and returnit.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.019.png)

Time Complexity: Running time of pop operation is O(*n*) as each time pop is called, we are transferringall the elements fromone queue to the other.

**Problem-4  Maximum sum in sliding window:** Given array A[] with sliding window of size

w which is moving from the very left of the array to the very right. Assume that we can onlysee the *w* numbers in the window. Each time the sliding window moves rightwards by one position. For example: The arrayis [1 3 -1 -3 5 3 6 7], and *w* is 3.



| Window position                                              | Max  |
| ------------------------------------------------------------ | ---- |
| [1 3 -1] -3 5 3 6 7                                          | 3    |
| 1 [3 -1 -3] 5 3 6 7                                          | 3    |
| 1 3 [-1 -3 5] 3 6 7                                          | 5    |
| 1 3 -1 [-3 5 3] 6 7                                          | 5    |
| 1 3 -1 -3 [5 3 6] 7                                          | 6    |
| 1 3 -1 -3 5 [3 6 7]                                          | 7    |
| **Input:** A long array A[], and a window width *w*. **Output:** An array B[], B[i] is the maximum value from A[i] to A[i+w-1]. **Requirement:** Find a good optimal way to get B[i] |      |

**Solution:** This problem can be solved with doubly ended queue (which supports insertion and deletionat bothends). Refer *Priority Queues* chapter for algorithms.

**Problem-5**  Given a queue Q containing *n* elements, transfer these items on to a stack S

(initially empty) so that front element of Q appears at the top of the stack and the order of all other items is preserved. Usingenqueue and dequeue operations for the queue, and push and pop operations for the stack, outline an efficient O(*n*) algorithm to accomplish the above task, usingonlya constant amount of additional storage.

**Solution:** Assume the elements of queue Q are *a*1:*a*2 *...an*. Dequeuing all elements and pushing them onto the stack will result in a stack with *an* at the top and *a*1 at the bottom. This is done in

O(*n*) time as dequeue and eachpushrequire constant time per operation. The queue is now empty. By popping all elements and pushing themon the queue we will get *a*1 at the top of the stack. This

is done againinO(*n*) time.

As in big-oh arithmetic we can ignore constant factors. The process is carried out in O(*n*) time. The amount of additional storage needed here has to be bigenoughto temporarilyhold one item.

**Problem-6**  A queue is set up in a circular array A[O..n - 1] with front and rear defined as

usual. Assume that *n* – 1 locations in the array are available for storing the elements (with the other element being used to detect full/empty condition). Give a formula for the number of elements inthe queue interms of *rear, front*, and *n*.

**Solution:** Consider the followingfigure to get a clear idea of the queue.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.020.jpeg)

- Rear of the queue is somewhere clockwise fromthe front.
- To enqueue an element, we move *rear* one position clockwise and write the element inthat position.
- To dequeue, we simplymove *front* one positionclockwise.
- Queue migrates ina clockwise directionas we enqueue and dequeue.
- Emptiness and fullness to be checked carefully.
- Analyze the possible situations (make some drawings to see where *front* and *rear* are whenthe queue is empty, and partiallyand totallyfilled). We will get this:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.021.png)

**Problem-7**  What is the most appropriate data structure to print elements of queue in reverse

order?

**Solution:** Stack.

**Problem-8**  Implement doubly ended queues. A double-ended queue is an abstract data

structure that implements a queue for which elements can only be added to or removed fromthe front (head) or back(tail). It is also oftencalled a head-tail linked list.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.022.jpeg)

**Problem-9**  Given a stack of integers, how do you check whether each successive pair of

numbers in the stack is consecutive or not. The pairs can be increasing or decreasing, and if the stack has an odd number of elements, the element at the top is left out of a pair. For example, if the stack of elements are [4, 5, -2, -3, 11, 10, 5, 6, 20], then the output should be true because each of the pairs (4, 5), (-2, -3), (11, 10), and (5, 6) consists of consecutive numbers.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.023.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-10**  Givena queue of integers, rearrange the elements byinterleavingthe first half of the list with the second half of the list. For example, suppose a queue stores the following sequence of values: [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]. Consider the two halves of

this list: first half: [11, 12, 13, 14, 15] second half: [16, 17, 18, 19, 20]. These are

combined in an alternating fashion to form a sequence of interleave pairs: the first values from each half (11 and 16), then the second values from each half (12 and 17), then the third values from each half (13 and 18), and so on. In each pair, the value from the first half appears before the value fromthe second half. Thus, after the call, the queue stores the followingvalues: [11, 16, 12, 17, 13, 18, 14, 19, 15, 20].

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.024.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-11**  Given an integer *k* and a queue of integers, how do you reverse the order of the

first *k* elements of the queue, leaving the other elements in the same relative order? For example, if *k*=4 and queue has the elements [10, 20, 30, 40, 50, 60, 70, 80, 90]; the output should be [40, 30, 20, 10, 50, 60, 70, 80, 90].

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.025.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.026.png)

1. **What is a Tree?**

A *tree* is a data structure similar to a linked list but instead of each node pointing simply to the next node in a linear fashion, each node points to a number of nodes. Tree is an example of a non- linear data structure. A*tree* structure is a wayof representingthe hierarchical nature of a structure ina graphical form.

Intrees ADT (Abstract Data Type), the order of the elements is not important. If we need ordering information, linear data structures like linked lists, stacks, queues, etc. canbe used.

2. **Glossary**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.027.jpeg)

- The *root* of a tree is the node with no parents. There can be at most one root node in a tree (*n*ode *A*inthe above example).
- An*edge* refers to the linkfromparent to child (all links inthe figure).
- Anode withno childrenis called *leaf* node (*E,J,K,H* and *I*).
- Childrenof same parent are called *siblings* (*B,C,D* are siblings of *A*, and *E,F* are the siblings of *B*).
- Anode p is an *ancestor* of node *q* if there exists a path from*root* to *q* and p appears onthe path. The node *q* is called a *descendant* of p. For example, *A,C* and *G* are the ancestors of if.
- The set of all nodes at a given depth is called the *level* of the tree (*B, C* and *D* are the same level). The root node is at level zero.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.028.jpeg)

- The *depth* of a node is the length of the path fromthe root to the node (depth of *G* is 2, *A*– *C* – *G*).
- The *height* of a node is the length of the path fromthat node to the deepest node. The height of a tree is the length of the path fromthe root to the deepest node in the tree. A (rooted) tree with only one node (the root) has a height of zero. In the previous example, the height of *B* is 2 (*B* – *F* – *J*).
- *Height of the tree* is the maximumheight amongall the nodes inthe tree and *depth of the tree* is the maximum depth among all the nodes in the tree. For a given tree, depth and height returns the same value. But for individual nodes we may get different results.
- The size of a node is the number of descendants it has including itself (the size of the subtree *C* is 3).
- If every node in a tree has only one child (except leaf nodes) then we call such trees *skew trees*. If every node has only left child then we call them *left skew trees*. Similarly, if everynode has onlyright child thenwe call them*right skew trees.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.029.png)

3. **Binary Trees**

A tree is called *binary tree* if each node has zero child, one child or two children. Empty tree is also a valid binary tree. We can visualize a binary tree as consisting of a root and two disjoint binarytrees, called the left and right subtrees of the root.

**Generic Binary Tree**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.030.png)

4. **Types of Binary Trees**

**Strict Binary Tree:** A binary tree is called *strict binary tree* if each node has exactly two childrenor no children.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.031.jpeg)

**Full Binary Tree:** A binary tree is called *full binary tree* if each node has exactly two children and all leaf nodes are at the same level.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.032.jpeg)

**Complete Binary Tree:** Before definingthe *complete binary tree*, let us assume that the height of the binary tree is *h*. In complete binary trees, if we give numbering for the nodes by starting at the root (let us say the root node has 1) then we get a complete sequence from 1 to the number of nodes in the tree. While traversing we should give numbering for NULL pointers also. A binary tree is called *complete binary tree* if all leaf nodes are at height *h* or *h* – 1 and also without any missingnumber inthe sequence.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.033.png)

5. **Properties of Binary Trees**

For the following properties, let us assume that the height of the tree is *h*. Also, assume that root node is at height zero.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.034.jpeg)

Fromthe diagramwe caninfer the followingproperties:

- The number of nodes n in a full binary tree is 2*h+*1 – 1. Since, there are *h* levels we need to add all nodes at eachlevel [20 + 21*+* 22 + ··· + 2*h* = 2*h+*1 *–* 1].
- The number of nodes *n* in a complete binary tree is between 2*h* (minimum) and 2*h+*1

– 1 (maximum). For more informationonthis, refer to *Priority Queues* chapter.

- The number of leaf nodes ina full binarytree is 2*h*.
- The number of NULLlinks (wasted pointers) in a complete binary tree of n nodes is *n* + 1.

**Structure of Binary Trees**

Now let us define structure of the binarytree. For simplicity, assume that the data of the nodes are integers. One way to represent a node (which contains data) is to have two links which point to left and right childrenalongwithdata fields as shownbelow:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.035.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.036.png)

**Note:** Intrees, the default flow is fromparent to childrenand it is not mandatoryto show directed branches. For our discussion, we assume boththe representations shownbelow are the same.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.037.png)

**Operations on Binary Trees**

**Basic Operations**

- Insertinganelement into a tree
- Deletinganelement froma tree
- Searchingfor anelement
- Traversingthe tree

**Auxiliary Operations**

- Findingthe size of the tree
- Findingthe height of the tree
- Findingthe level whichhas maximumsum
- Findingthe least commonancestor (LCA) for a givenpair of nodes, and manymore.

**Applications of Binary Trees**

Followingare the some of the applications where *binary trees* playanimportant role:

- Expressiontrees are used incompilers.
- Huffmancodingtrees that are used indata compressionalgorithms.
- Binary Search Tree (BST), which supports search, insertion and deletion on a collectionof items inO(*logn*) (average).
- Priority Queue (PQ), which supports search and deletion of minimum(or maximum) ona collectionof items inlogarithmic time (inworst case).

6. **Binary Tree Traversals**

In order to process trees, we need a mechanism for traversing them, and that forms the subject of this section. The process of visiting all nodes of a tree is called *tree traversal*. Each node is processed only once but it may be visited more than once. As we have already seen in linear data structures (like linked lists, stacks, queues, etc.), the elements are visited in sequential order. But, intree structures there are manydifferent ways.

Tree traversal is like searching the tree, except that in traversal the goal is to move through the tree in a particular order. In addition, all nodes are processed in the *traversal but searching* stops whenthe required node is found.

**TraversalPossibilities**

Starting at the root of a binary tree, there are three main steps that can be performed and the order in which they are performed defines the traversal type. These steps are: performing an action on the current node (referred to as “visiting” the node and denoted with *“D”*), traversing to the left child node (denoted with “*L*”), and traversing to the right child node (denoted with “*R*”). This process can be easily described through recursion. Based on the above definition there are 6 possibilities:

1. *LDR:* Process left subtree, process the current node data and then process right subtree
1. *LRD:* Process left subtree, process right subtree and then process the current node data
1. *DLR:* Process the current node data, process left subtree and then process right subtree
1. *DRL:* Process the current node data, process right subtree and then process left subtree
1. *RDL:* Process right subtree, process the current node data and then process left subtree
1. *RLD:* Process right subtree, process left subtree and then process the current node data

**Classifying the Traversals**

The sequence inwhichthese entities (*n*odes) are processed defines a particular traversal method. The classificationis based onthe order inwhichcurrent node is processed. That means, if we are classifying based on current node (*D*) and if *D* comes in the middle then it does not matter whether *L* is onleft side of *D* or *R* is onleft side of *D.*

Similarly, it does not matter whether *L* is onright side of *D* or *R* is on right side of *D*. Due to this, the total 6 possibilities are reduced to 3 and these are:

- Preorder (*DLR*) Traversal
- Inorder (*LDR*) Traversal
- Postorder (*LRD*) Traversal

There is another traversal method whichdoes not depend onthe above orders and it is:

- Level Order Traversal: This method is inspired from Breadth First Traversal (BFS of Graphalgorithms).

Let us use the diagrambelow for the remainingdiscussion.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.038.jpeg)

**PreOrder Traversal**

In preorder traversal, each node is processed before (pre) either of its subtrees. This is the simplest traversal to understand. However, even though each node is processed before the subtrees, it still requires that some information must be maintained while moving down the tree. In the example above, 1 is processed first, then the left subtree, and this is followed by the right subtree.

Therefore, processing must return to the right subtree after finishing the processing of the left subtree. To move to the right subtree after processing the left subtree, we must maintain the root information. The obvious ADT for such information is a stack. Because of its LIFO structure, it is possible to get the informationabout the right subtrees backinthe reverse order.

Preorder traversal is defined as follows:

- Visit the root.
- Traverse the left subtree inPreorder.
- Traverse the right subtree inPreorder.

The nodes of tree would be visited inthe order: 1 2 4 5 3 6 7

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.039.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Non-Recursive Preorder Traversal**

In the recursive version, a stack is required as we need to remember the current node so that after completing the left subtree we can go to the right subtree. To simulate the same, first we process the current node and before going to the left subtree, we store the current node on stack. After completing the left subtree processing, *pop* the element and go to its right subtree. Continue this process until stackis nonempty.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.040.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**InOrder Traversal**

In Inorder Traversal the root is visited between the subtrees. Inorder traversal is defined as follows:

- Traverse the left subtree inInorder.
- Visit the root.
- Traverse the right subtree inInorder.

The nodes of tree would be visited inthe order: 4 2 5 1 6 3 7

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.041.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Non-Recursive Inorder Traversal**

The Non-recursive version of Inorder traversal is similar to Preorder. The only change is, instead of processing the node before going to left subtree, process it after popping (which is indicated after completionof left subtree processing).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.042.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**PostOrder Traversal**

In postorder traversal, the root is visited after both subtrees. Postorder traversal is defined as follows:

- Traverse the left subtree inPostorder.
- Traverse the right subtree inPostorder.
- Visit the root.

The nodes of the tree would be visited inthe order: 4 5 2 6 7 3 1

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.043.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Non-Recursive Postorder Traversal**

In preorder and inorder traversals, after popping the stack element we do not need to visit the same vertex again. But in postorder traversal, each node is visited twice. That means, after processing the left subtree we will visit the current node and after processing the right subtree we will visit the same current node. But we should be processing the node during the second visit. Here the problem is how to differentiate whether we are returning from the left subtree or the right subtree.

We use a *previous* variable to keep trackof the earlier traversed node. Let’s assume *current* is the current node that is on top of the stack. When *previous* is *current’s* parent, we are traversing down the tree. In this case, we try to traverse to *current’s* left child if available (i.e., push left child to the stack). If it is not available, we lookat *current’s* right child. If bothleft and right child do not exist (ie, *current* is a leaf node), we print *current’s* value and pop it off the stack.

If prev is *current’s* left child, we are traversingup the tree fromthe left. We lookat *current’s* right child. If it is available, then traverse down the right child (i.e., push right child to the stack); otherwise print *current’s* value and pop it off the stack. If *previous* is *current’s* right child, we are traversingup the tree fromthe right. Inthis case, we print *current’s* value and pop it off the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.044.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**LevelOrder Traversal**

Level order traversal is defined as follows:

- Visit the root.
- While traversinglevel (, keep all the elements at level ( + 1 inqueue.
- Go to the next level and visit all the nodes at that level.
- Repeat this until all levels are completed.

The nodes of the tree are visited inthe order: 1 2 3 4 5 6 7

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.045.png)

Time Complexity: O(*n*). Space Complexity: O(*n*). Since, in the worst case, all the nodes on the entire last level could be inthe queue simultaneously.

**Binary Trees: Problems & Solutions**

**Problem-1**  Give analgorithmfor findingmaximumelement inbinarytree.

**Solution:** One simple way of solving this problem is: find the maximum element in left subtree, find the maximumelement in right sub tree, compare themwith root data and select the one which is givingthe maximumvalue. This approachcanbe easilyimplemented withrecursion.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.046.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-2**  Give an algorithm for finding the maximum element in binary tree without

recursion.

**Solution:** Usinglevel order traversal: just observe the element’s data while deleting.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.047.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-3**  Give analgorithmfor searchinganelement inbinarytree.

**Solution:** Given a binary tree, return true if a node with data is found in the tree. Recurse down the tree, choose the left or right branchbycomparingdata witheachnode’s data.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.048.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-4**  Give analgorithmfor searchinganelement inbinarytree without recursion.

**Solution:** We can use level order traversal for solving this problem. The only change required in level order traversal is, instead of printingthe data, we just need to checkwhether the root data is equal to the element we want to search.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.049.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-5**  Give analgorithmfor insertinganelement into binarytree.

**Solution:** Since the given tree is a binary tree, we can insert the element wherever we want. To insert an element, we can use the level order traversal and insert the element wherever we find the node whose left or right child is NULL.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.050.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-6**  Give analgorithmfor findingthe size of binarytree.

**Solution:** Calculate the size of left and right subtrees recursively, add 1 (current node) and return to its parent.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.051.png)

Time Complexity: O(*n*). Space Complexity: O(*n*). **Problem-7**  Canwe solve [Problem-6](#_page44_x66.91_y55.03) without recursion?

**Solution: Yes,** usinglevel order traversal.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.052.png)

**Problem-8**  Give an algorithmfor printing the level order data in reverse order. For example,

the output for the below tree should be: 4 5 6 7 2 3 1

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.053.jpeg)

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.054.png)

**Problem-9**  Give analgorithmfor deletingthe tree. **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.055.jpeg)

To delete a tree, we must traverse all the nodes of the tree and delete themone by one. So which traversal should we use: Inorder, Preorder, Postorder or Level order Traversal?

Before deleting the parent node we should delete its children nodes first. We can use postorder traversal as it does the work without storing anything. We can delete tree with other traversals also withextra space complexity. For the following, tree nodes are deleted inorder – 4,5,2,3,1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.056.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-10**  Give analgorithmfor findingthe height (or depth) of the binarytree.

**Solution:** Recursively calculate height of left and right subtrees of a node and assign height to the node as max of the heights of two children plus 1. This is similar to *PreOrder* tree traversal (and *DFS* of Graphalgorithms).


![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.057.png)

Time Complexity: O(*n*). Space Complexity: O(*n*). **Problem-11**  Canwe solve [Problem-10](#_page46_x66.91_y681.29) without recursion?

**Solution: Yes,** using level order traversal. This is similar to *BFS* of Graph algorithms. End of level is identified withNULL.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.058.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-12**  Give analgorithmfor findingthe deepest node of the binarytree. **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.059.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-13**  Give an algorithm for deleting an element (assuming data is given) from binary

tree.

**Solution:** The deletionof a node inbinarytree canbe implemented as

- Startingat root, find the node whichwe want to delete.
- Find the deepest node inthe tree.
- Replace the deepest node’s data withnode to be deleted.
- Thendelete the deepest node.

**Problem-14**  Give an algorithm for finding the number of leaves in the binary tree without

usingrecursion.

**Solution:** The set of nodes whose bothleft and right childrenare NULLare called leaf nodes.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.060.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-15**  Give an algorithmfor finding the number of full nodes in the binary tree without

usingrecursion.

**Solution:** The set of all nodes withbothleft and right childrenare called full nodes.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.061.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-16**  Give an algorithm for finding the number of half nodes (*n*odes with only one

child) inthe binarytree without usingrecursion.

**Solution:** The set of all nodes witheither left or right child (but not both) are called half nodes.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.062.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-17**  Giventwo binarytrees, returntrue if theyare structurallyidentical. **Solution:**

**Algorithm:**

- If bothtrees are NULLthenreturntrue.
- If both trees are not NULL, then compare data and recursively check left and right subtree structures.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.063.png)

Time Complexity: O(*n*). Space Complexity: O(*n*), for recursive stack.

**Problem-18**  Give an algorithm for finding the diameter of the binary tree. The diameter of a

tree (sometimes called the *width*) is the number of nodes on the longest path between two leaves inthe tree.

**Solution:** To find the diameter of a tree, first calculate the diameter of left subtree and right subtrees recursively. Among these two values, we need to send maximum value along with current level (+1).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.064.jpeg)

There is another solution and the complexity is O(*n*). The main idea of this approach is that the node stores its left child’s and right child’s maximum diameter if the node’s child is the “root”, therefore, there is no need to recursively call the height method. The drawback is we need to add two extra variables inthe node structure.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.065.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-19**  Give an algorithm for finding the level that has the maximum sum in the binary

tree.

**Solution:** The logic is very much similar to finding the number of levels. The only change is, we

need to keep trackof the sums as well.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.066.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-20**  Givena binarytree, print out all its root-to-leaf paths. **Solution:** Refer to comments infunctions.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.067.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*), for recursive stack.

**Problem-21**  Give an algorithm for checking the existence of path with given sum. That

means, givena sum, checkwhether there exists a pathfromroot to anyof the nodes.

**Solution:** For this problem, the strategy is: subtract the node value fromthe sumbefore calling its childrenrecursively, and checkto see if the sumis 0 whenwe runout of tree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.068.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-22**  Give analgorithmfor findingthe sumof all elements inbinarytree.

**Solution:** Recursively, call left subtree sum, right subtree sum and add their values to current nodes data.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.069.png)

Time Complexity: O(*n*). Space Complexity: O(*n*). **Problem-23**  Canwe solve [Problem-22](#_page59_x66.91_y658.51) without recursion?

**Solution:** We can use level order traversal with simple change. Every time after deleting an element fromqueue, add the nodes data value to *sum* variable.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.070.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-24**  Give an algorithm for converting a tree to its mirror. Mirror of a tree is another

tree with left and right children of all non-leaf nodes interchanged. The trees below are mirrors to eachother.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.071.png)

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.072.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-25**  Given two trees, give an algorithm for checking whether they are mirrors of

eachother.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.073.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-26**  Give an algorithmfor finding LCA (Least Common Ancestor) of two nodes in a

BinaryTree.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.074.png)

Time Complexity: O(*n*). Space Complexity: O(*n*) for recursion.

**Problem-27**  Give an algorithm for constructing binary tree from given Inorder and Preorder

traversals.

**Solution:** Let us consider the traversals below:

Inorder sequence: D B E AF C Preorder sequence: AB D E C F

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.075.jpeg)

In a Preorder sequence, leftmost element denotes the root of the tree. So we know *‘A’* is the root for given sequences. By searching *‘A’* in Inorder sequence we can find out all elements on the left side of *‘A’*, which come under the left subtree, and elements on the right side of *‘A’*, which come under the right subtree. So we get the structure as seenbelow.

We recursivelyfollow the above steps and get the followingtree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.076.png)

**Algorithm:** BuildTree()

1  Select an element from *Preorder*. Increment a *Preorder* index variable (*preOrderIndex* incode below) to picknext element innext recursive call.
1  Create a new tree node (*newNode*) fromheap withthe data as selected element.
1  Find the selected element’s indexinInorder. Let the indexbe *inOrderIndex.*
1  Call BuildBinaryTree for elements before *inOrderIndex* and make the built tree as left subtree of *newNode.*
1  Call BuildBinaryTree for elements after *inOrderIndex* and make the built tree as right subtree of *newNode.*
1  return*newNode.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.077.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-28**  If we are given two traversal sequences, can we construct the binary tree

uniquely?

**Solution:** It depends on what traversals are given. If one of the traversal methods is *Inorder* then the tree canbe constructed uniquely, otherwise not.

Therefore, the followingcombinations canuniquelyidentifya tree:

- Inorder and Preorder
- Inorder and Postorder
- Inorder and Level-order

The followingcombinations do not uniquelyidentifya tree.

- Postorder and Preorder
- Preorder and Level-order
- Postorder and Level-order

For example, Preorder, Level-order and Postorder traversals are the same for the above trees:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.078.png)

So, even if three of them (PreOrder, Level-Order and PostOrder) are given, the tree cannot be constructed uniquely.

**Problem-29**  Give an algorithm for printing all the ancestors of a node in a Binary tree. For

the tree below, for 7 the ancestors are 1 3 7.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.079.jpeg)

**Solution:** Apart fromthe Depth First Search of this tree, we can use the following recursive way to print the ancestors.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.080.png)

Time Complexity: O(*n*). Space Complexity: O(*n*) for recursion.

**Problem-30  Zigzag Tree Traversal:** Give an algorithm to traverse a binary tree in Zigzag

order. For example, the output for the tree below should be: 1 3 2 4 5 6 7

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.081.jpeg)

**Solution:** This problem can be solved easily using two stacks. Assume the two stacks are: *currentLevel* and *nextLevel*. We would also need a variable to keep track of the current level order (whether it is left to right or right to left).

We pop from *currentLevel* stack and print the node’s value. Whenever the current level order is from left to right, push the node’s left child, then its right child, to stack *nextLevel*. Since a stack is a Last In First Out (*LIFO*) structure, the next time that nodes are popped off nextLevel, it will be inthe reverse order.

On the other hand, when the current level order is from right to left, we would push the node’s right child first, thenits left child. Finally, don’t forget to swap those two stacks at the end of each level (*i. e.*, when*currentLevel* is empty).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.082.jpeg)

Time Complexity: O(*n*). Space Complexity: Space for two stacks = O(*n*) + O(*n*) = O(*n*).

**Problem-31**  Give analgorithmfor findingthe vertical sumof a binarytree. For example, The

tree has 5 vertical lines

Vertical-1: nodes-4 => vertical sumis 4

Vertical-2: nodes-2 => vertical sumis 2

Vertical-3: nodes-1,5,6 => vertical sumis 1 + 5 + 6 = 12 Vertical-4: nodes-3 => vertical sumis 3

Vertical-5: nodes-7 => vertical sumis 7

We need to output: 4 2 12 3 7

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.083.jpeg)

**Solution:** We can do an inorder traversal and hash the column. We call VerticalSumlnBinaryTreefroot, 0) which means the root is at column 0. While doing the traversal, hashthe columnand increase its value by*root* → *data.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.084.png)

**Problem-32**  How manydifferent binarytrees are possible withnnodes?

**Solution:** For example, consider a tree with 3 nodes (*n* = 3). It will have the maximum combinationof 5 different (i.e., 23 -3 = 5) trees.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.085.png)

Ingeneral, if there are *n* nodes, there exist 2*n* –*n* different trees.

**Problem-33**  Given a tree with a special property where leaves are represented with ‘L’ and

internal node with ‘I’. Also, assume that each node has either 0 or 2 children. Given preorder traversal of this tree, construct the tree.

**Example:** Givenpreorder string=> ILILL

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.086.jpeg)

**Solution:** First, we should see how preorder traversal is arranged. Pre-order traversal means first put root node, then pre-order traversal of left subtree and then pre-order traversal of right subtree. In a normal scenario, it’s not possible to detect where left subtree ends and right subtree starts using only pre-order traversal. Since every node has either 2 children or no child, we can surelysaythat if a node exists thenits siblingalso exists. So everytime whenwe are computinga subtree, we need to compute its siblingsubtree as well.

Secondly, whenever we get ‘L’ in the input string, that is a leaf and we can stop for a particular subtree at that point. After this ‘L’ node (left child of its parent ‘L’), its siblingstarts. If ‘L’ node is right child of its parent, thenwe need to go up inthe hierarchyto find the next subtree to compute.

Keeping the above invariant in mind, we can easily determine when a subtree ends and the next one starts. It means that we can give any start node to our method and it can easily complete the subtree it generates going outside of its nodes. We just need to take care of passing the correct start nodes to different sub-trees.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.087.png)

Time Complexity: O(*n*).

**Problem-34**  Given a binary tree with three pointers (left, right and nextSibling), give an

algorithmfor fillingthe *nextSibling* pointers assumingtheyare NULLinitially.

**Solution:** We can use simple queue (similar to the solution of [Problem-11](#_page47_x66.91_y376.99)). Let us assume that the structure of binarytree is:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.088.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-35**  Is there anyother wayof solving[Problem-34](#_page70_x66.91_y448.99)?

**Solution:** The trick is to re-use the populated *nextSibling* pointers. As mentioned earlier, we just

need one more step for it to work. Before we pass the *left* and *right* to the recursion function itself, we connect the right child’s *nextSibling* to the current node’s nextSiblingleft child. Inorder for this to work, the current node *nextSibling* pointer must be populated, which is true in this case.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.089.png)

Time Complexity: O(*n*).

7. **Generic Trees (N-ary Trees)**

In the previous section we discussed binary trees where each node can have a maximum of two children and these are represented easily with two pointers. But suppose if we have a tree with manychildrenat everynode and also if we do not know how manychildrena node canhave, how do we represent them?

For example, consider the tree shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.090.jpeg)

**How do we represent the tree?**

In the above tree, there are nodes with 6 children, with 3 children, with 2 children, with 1 child, and with zero children (leaves). To present this tree we have to consider the worst case (6 children) and allocate that many child pointers for each node. Based on this, the node representationcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.091.png)

Since we are not using all the pointers in all the cases, there is a lot of memory wastage. Another problem is that we do not know the number of children for each node in advance. In order to solve this problem we need a representation that minimizes the wastage and also accepts nodes withanynumber of children.

**Representation of Generic Trees**

Since our objective is to reachall nodes of the tree, a possible solutionto this is as follows:

- At eachnode linkchildrenof same parent (siblings) fromleft to right.
- Remove the links fromparent to all childrenexcept the first child.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.092.jpeg)

What these above statements say is if we have a link between children then we do not need extra links from parent to all children. This is because we can traverse all the elements by starting at the first child of the parent. So if we have a link between parent and first child and also links betweenall childrenof same parent thenit solves our problem.

This representation is sometimes called first child/next sibling representation. First child/next sibling representation of the generic tree is shown above. The actual representation for this tree is:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.093.jpeg)

Based onthis discussion, the tree node declarationfor general tree canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.094.png)

**Note:** Since we are able to convert any generic tree to binary representation; in practice we use binary trees. We can treat all generic trees with a first child/next sibling representation as binary trees.

**Generic Trees: Problems & Solutions**

**Problem-36**  Givena tree, give analgorithmfor findingthe sumof all the elements of the tree.

**Solution:** The solution is similar to what we have done for simple binary trees. That means, traverse the complete list and keep on adding the values. We can either use level order traversal

or simple recursion.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.095.png)

Time Complexity: O(*n*). Space Complexity: O(1) (if we do not consider stack space), otherwise O(*n*).

**Note:** All problems which we have discussed for binary trees are applicable for generic trees also. Instead of left and right pointers we just need to use firstChild and nextSibling.

**Problem-37**  For a 4-ary tree (each node can contain maximum of 4 children), what is the

maximumpossible height with100 nodes? Assume height of a single node is 0.

**Solution:** In4-arytree eachnode cancontain0 to 4 children, and to get maximumheight, we need to keep only one child for each parent. With 100 nodes, the maximum possible height we can get is 99.

If we have a restriction that at least one node has 4 children, then we keep one node with 4 children and the remaining nodes with 1 child. In this case, the maximum possible height is 96. Similarly, withnnodes the maximumpossible height is *n* – 4.

**Problem-38**  For a 4-ary tree (each node can contain maximum of 4 children), what is the

minimumpossible height with*n* nodes?

**Solution:** Similar to the above discussion, if we want to get minimumheight, then we need to fill all nodes with maximum children (in this case 4). Now let’s see the following table, which indicates the maximumnumber of nodes for a givenheight.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.096.png)

For a given height *h* the maximum possible nodes are: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.097.png). To get minimum height, take logarithmonbothsides:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.098.png)

**Problem-39**  Given a parent array P, where *P*[*i*] indicates the parent of *ith* node in the tree

(assume parent of root node is indicated with –1). Give an algorithmfor finding the height or depthof the tree.

**Solution:**

For example: if the Pis

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.099.png)

Its correspondingtree is:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.100.jpeg)

From the problem definition, the given array represents the parent array. That means, we need to consider the tree for that array and find the depth of the tree. The depth of this given tree is 4. If we carefully observe, we just need to start at every node and keep going to its parent until we reach–1 and also keep trackof the maximumdepthamongall nodes.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.101.png)

Time Complexity: O(*n*2). For skew trees we will be re-calculating the same values. Space Complexity: O(1).

**Note:** We can optimize the code by storing the previous calculated nodes’ depth in some hash table or other array. This reduces the time complexitybut uses extra space.

**Problem-40**  Given a node in the generic tree, give an algorithm for counting the number of

siblings for that node.

**Solution:** Since tree is represented with the first child/next sibling method, the tree structure can be givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.102.png)

For a givennode inthe tree, we just need to traverse all its next siblings.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.103.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-41**  Given a node in the generic tree, give an algorithm for counting the number of

childrenfor that node.

**Solution:** Since the tree is represented as first child/next sibling method, the tree structure can be givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.104.png)

For a given node in the tree, we just need to point to its first child and keep traversing all its next siblings.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.105.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-42**  Given two trees how do we check whether the trees are isomorphic to each

other or not?

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.106.png)

Two binary trees *root*1 and *root*2 are isomorphic if they have the same structure. The values of the nodes does not affect whether two trees are isomorphic or not. In the diagram below, the tree in the middle is not isomorphic to the other trees, but the tree on the right is isomorphic to the tree onthe left.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.107.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-43**  Given two trees how do we check whether they are quasi-isomorphic to each

other or not?

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.108.png)

Two trees *root*1 and *root*2 are quasi-isomorphic if *root*1 can be transformed into *root*2 by swapping the left and right children of some of the nodes of *root*1. Data in the nodes are not important in determining quasi-isomorphism; only the shape is important. The trees below are quasi-isomorphic because if the childrenof the nodes onthe left are swapped, the tree onthe right is obtained.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.109.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-44**  Afull *k* –ary tree is a tree where each node has either 0 or *k* children. Given an

array which contains the preorder traversal of full *k* –ary tree, give an algorithm for constructingthe full *k* –arytree.

**Solution:** In*k* –arytree, for a node at *ith* position its children will be at *k \* i +* 1 to *k \* i + k*. For example, the example below is for full 3-arytree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.110.jpeg)

As we have seen, in preorder traversal first left subtree is processed then followed by root node and right subtree. Because of this, to construct a full *k*-ary, we just need to keep on creating the nodes without bothering about the previous constructed nodes. We can use this trick to build the tree recursivelybyusingone global index. The declarationfor *k*-arytree canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.111.jpeg)

Time Complexity: O(*n*), where *n* is the size of the pre-order array. This is because we are moving sequentiallyand not visitingthe alreadyconstructed nodes.

8. **Threaded Binary Tree Traversals (Stack or Queue-less Traversals)**

In earlier sections we have seen that, *preorder, inorder and postorder* binary tree traversals used stacks and *level order* traversals used queues as an auxiliary data structure. In this section we will discuss new traversal algorithms which do not need both stacks and queues. Such traversal

algorithms are called *threaded binary tree traversals* or *stack/queue* – *less traversals.*

**Issues with Regular Binary Tree Traversals**

- The storage space required for the stackand queue is large.
- The majority of pointers in any binary tree are NULL. For example, a binary tree with*n* nodes has *n* + 1 NULLpointers and these were wasted.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.112.jpeg)

- It is difficult to find successor node (preorder, inorder and postorder successors) for a givennode.

**Motivation for Threaded Binary Trees**

To solve these problems, one idea is to store some useful information in NULL pointers. If we observe the previous traversals carefully, stack/ queue is required because we have to record the current position in order to move to the right subtree after processing the left subtree. If we store the useful information in NULL pointers, then we don’t have to store such information in stack/ queue.

The binarytrees whichstore suchinformationinNULLpointers are called *threaded binary trees*. Fromthe above discussion, let us assume that we want to store some useful information in NULL

pointers. The next questionis what to store?

The common convention is to put predecessor/successor information. That means, if we are dealing with preorder traversals, then for a given node, NULLleft pointer will contain preorder predecessor information and NULL right pointer will contain preorder successor information. These special pointers are called *threads.*

**Classifying Threaded Binary Trees**

The classificationis based onwhether we are storinguseful informationinbothNULLpointers or onlyinone of them.

- If we store predecessor information in NULL left pointers only, then we can call suchbinarytrees *left threaded binary trees.*
- If we store successor information in NULLright pointers only, then we can call such binarytrees *right threaded binary trees.*
- If we store predecessor information in NULLleft pointers and successor information in NULL right pointers, then we can call such binary trees *fully threaded binary trees* or simply*threaded binary trees.*

**Note:** For the remainingdiscussionwe consider only(*fully*) *threaded binary trees.*

**Types of Threaded Binary Trees**

Based onabove discussionwe get three representations for threaded binarytrees.

- *Preorder Threaded Binary Trees:* NULL left pointer will contain PreOrder predecessor information and NULL right pointer will contain PreOrder successor information.
- *Inorder Threaded Binary Trees:* NULL left pointer will contain InOrder predecessor information and NULL right pointer will contain InOrder successor information.
- *Postorder Threaded Binary Trees:* NULL left pointer will contain PostOrder predecessor information and NULL right pointer will contain PostOrder successor information.

**Note:** As the representations are similar, for the remaining discussion we will use InOrder threaded binarytrees.

**Threaded Binary Tree structure**

Any program examining the tree must be able to differentiate between a regular *left/right* pointer

and a *thread*. To do this, we use two additional fields in each node, giving us, for threaded trees, nodes of the followingform:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.113.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.114.png)

**Difference between Binary Tree and Threaded Binary Tree Structures**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.115.png)

**Note:** Similarly, we candefine preorder/postorder differences as well.

As an example, let us try representing a tree in inorder threaded binary tree form. The tree below shows what an inorder threaded binary tree will look like. The dotted arrows indicate the threads. If we observe, the left pointer of left most node (2) and right pointer of right most node (31) are hanging.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.116.jpeg)

**What shouldleftmost andrightmost pointers point to?**

In the representation of a threaded binary tree, it is convenient to use a special node *Dummy* which is always present even for an empty tree. Note that right tag of Dummy node is 1 and its right child points to itself.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.117.png)

Withthis conventionthe above tree canbe represented as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.118.jpeg)

**Finding Inorder Successor in Inorder Threaded Binary Tree**

To find inorder successor of a given node without using a stack, assume that the node for which we want to find the inorder successor is *P.*

**Strategy:** If *P* has a no right subtree, then return the right child of *P*. If *P* has right subtree, then returnthe left of the nearest node whose left subtree contains *P*.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.119.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Inorder Traversalin Inorder Threaded Binary Tree**

We can start with *dummy* node and call InorderSuccessor() to visit each node until we reach *dummy* node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.120.png)

**Alternative coding:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.121.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Finding PreOrder Successor in InOrder Threaded Binary Tree**

**Strategy:** If *P* has a left subtree, thenreturnthe left child of *P*. If *P* has no left subtree, then return the right child of the nearest node whose right subtree contains *P*.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.122.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**PreOrder Traversalof InOrder Threaded Binary Tree**

As in inorder traversal, start with *dummy* node and call PreorderSuccessorf) to visit each node until we get *dummy* node again.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.123.png)

**Alternative coding:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.124.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Note:** From the above discussion, it should be clear that inorder and preorder successor finding is easy with threaded binary trees. But finding postorder successor is very difficult if we do not use stack.

**Insertion of Nodes in InOrder Threaded Binary Trees**

For simplicity, let us assume that there are two nodes *P* and *Q* and we want to attach *Q* to right of *P*. For this we will have two cases.

- Node *P* does not have right child: In this case we just need to attach *Q* to *P* and change its left and right pointers.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.125.jpeg)

- Node *P* has right child (say, *R*): In this case we need to traverse *R’s* left subtree and find the left most node and then update the left and right pointer of that node (as shownbelow).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.126.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.127.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Threaded Binary Trees: Problems & Solutions**

**Problem-45**  For a givenbinarytree (*n*ot threaded) how do we find the preorder successor?

**Solution:** For solving this problem, we need to use an auxiliary stack *S*. On the first call, the parameter node is a pointer to the head of the tree, and thereafter its value is NULL. Since we are simplyaskingfor the successor of the node we got the last time we called the function.

It is necessary that the contents of the stack *S* and the pointer *P* to the last node “visited” are preserved fromone call of the functionto the next; theyare defined as static variables.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.128.png)

**Problem-46**  For a givenbinarytree (*n*ot threaded) how do we find the inorder successor? **Solution:** Similar to the above discussion, we canfind the inorder successor of a node as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.129.png)

9. **Expression Trees**

Atree representing an expression is called an *expression tree*. In expression trees, leaf nodes are operands and non-leaf nodes are operators. That means, an expression tree is a binary tree where internal nodes are operators and leaves are operands. An expression tree consists of binary expression. But for a u-nary operator, one subtree will be empty. The figure below shows a simple expressiontree for (A+ B \*C) / D.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.130.jpeg)

**AlgorithmforBuilding ExpressionTree fromPostfix Expression**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.131.jpeg)

**Example:** Assume that one symbol is read at a time. If the symbol is an operand, we create a tree node and push a pointer to it onto a stack. If the symbol is an operator, pop pointers to two trees *T*1 and *T*2 from the stack (*T*1 is popped first) and form a new tree whose root is the operator and

whose left and right children point to *T*2 and *T*1 respectively. A pointer to this new tree is then pushed onto the stack.

As an example, assume the input is AB C \* + D /. The first three symbols are operands, so create tree nodes and pushpointers to themonto a stackas shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.132.png)

Next, an operator ‘\*’ is read, so two pointers to trees are popped, a new tree is formed and a pointer to it is pushed onto the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.133.jpeg)

Next, an operator ‘+’ is read, so two pointers to trees are popped, a new tree is formed and a pointer to it is pushed onto the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.134.jpeg)

Next, an operand ‘D’ is read, a one-node tree is created and a pointer to the corresponding tree is pushed onto the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.135.jpeg)

Finally, the last symbol (‘/’) is read, two trees are merged and a pointer to the final tree is left on the stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.136.jpeg)

10. **XOR Trees**

This concept is similar to *memory efficient doubly linked lists* of *Linked Lists* chapter. Also, like threaded binary trees this representation does not need stacks or queues for traversing the trees. This representation is used for traversing back (to parent) and forth (to children) using ⊕ operation. To represent the same in XOR trees, for each node below are the rules used for representation:

- Eachnodes left will have the ⊕ of its parent and its left children.
- Eachnodes right will have the ⊕ of its parent and its right children.
- The root nodes parent is NULLand also leaf nodes childrenare NULLnodes.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.137.jpeg)

Based onthe above rules and discussion, the tree canbe represented as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.1ee70c77-a898-4b47-bb00-f57a37314407.138.jpeg)

The major objective of this presentation is the ability to move to parent as well to children. Now,

let us see how to use this representation for traversing the tree. For example, if we are at node B and want to move to its parent node A, then we just need to perform⊕ on its left content with its left child address (we canuse right child also for goingto parent node).

Similarly, if we want to move to its child (say, left child D) then we have to perform⊕ on its left content with its parent node address. One important point that we need to understand about this representation is: When we are at node B, how do we know the address of its children D? Since the traversal starts at node root node, we can apply ⊕ on root’s left content with NULL. As a result we get its left child, B. When we are at B, we can apply ⊕ on its left content with A address.

11. **Binary Search Trees (BSTs) Why Binary Search Trees?**

In previous sections we have discussed different tree representations and in all of them we did not impose any restriction on the nodes data. As a result, to search for an element we need to check both in left subtree and in right subtree. Due to this, the worst case complexity of search operationis O(*n*).

In this section, we will discuss another variant of binary trees: Binary Search Trees (BSTs). As the name suggests, the main use of this representation is for *searching*. In this representation we impose restriction on the kind of data a node can contain. As a result, it reduces the worst case average searchoperationto O(*logn*).

**Binary Search Tree Property**

In binary search trees, all the left subtree elements should be less than root data and all the right subtree elements should be greater than root data. This is called binary search tree property. Note that, this propertyshould be satisfied at everynode inthe tree.

- The left subtree of a node contains onlynodes withkeys less thanthe nodes key.
- The right subtree of a node contains onlynodes withkeys greater thanthe nodes key.
- Boththe left and right subtrees must also be binarysearchtrees.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.001.png)

**Example:** The left tree is a binary search tree and the right tree is not a binary search tree (at node 6 it’s not satisfyingthe binarysearchtree property).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.002.png)

**Binary Search Tree Declaration**

There is no difference between regular binary tree declaration and binary search tree declaration. The difference is onlyindata but not instructure. But for our convenience we change the structure name as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.003.png)

**Operations on Binary Search Trees**

**Mainoperations:** Followingare the mainoperations that are supported bybinarysearchtrees:

- Find/ Find Minimum/ Find Maximumelement inbinarysearchtrees
- Insertinganelement inbinarysearchtrees
- Deletinganelement frombinarysearchtrees

**Auxiliary operations:** Checkingwhether the giventree is a binarysearchtree or not

- Finding*kth*-smallest element intree
- Sortingthe elements of binarysearchtree and manymore

**Important Notes on Binary Search Trees**

- Since root data is always between left subtree data and right subtree data, performinginorder traversal onbinarysearchtree produces a sorted list.
- While solving problems on binary search trees, first we process left subtree, then root data, and finally we process right subtree. This means, depending on the problem, only the intermediate step (processing root data) changes and we do not touchthe first and third steps.
- If we are searching for an element and if the left subtree root data is less than the element we want to search, then skip it. The same is the case with the right subtree.. Because of this, binary search trees take less time for searching an element than regular binary trees. In other words, the binary search trees consider either left or right subtrees for searchinganelement but not both.
- The basic operations that can be performed on binary search tree (BST) are insertion of element, deletion of element, and searching for an element. While performing these operations on BST the height of the tree gets changed each time. Hence there exists variations in time complexities of best case, average case, and worst case.
- The basic operations on a binary search tree take time proportional to the height of the tree. For a complete binary tree with node n, such operations runs in O(lgn) worst-case time. If the tree is a linear chain of n nodes (skew-tree), however, the same operations takes O(*n*) worst-case time.

**Finding an Element in Binary Search Trees**

Find operation is straightforward in a BST. Start with the root and keep moving left or right using the BST property. If the data we are searchingis same as nodes data thenwe returncurrent node.

If the data we are searching is less than nodes data then search left subtree of current node; otherwise search right subtree of current node. If the data is not present, we end up in a NULL

link.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.004.png)

Time Complexity: O(*n*), in worst case (when BST is a skew tree). Space Complexity: O(*n*), for recursive stack.

*Non recursive* versionof the above algorithmcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.005.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Finding Minimum Element in Binary Search Trees**

In BSTs, the minimum element is the left-most node, which does not has left child. In the BST below, the minimumelement is **4**.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.006.png)

Time Complexity: O(*n*), inworst case (whenBST is a *left skew* tree). Space Complexity: O(*n*), for recursive stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.007.jpeg)

*Non recursive* versionof the above algorithmcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.008.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Finding Maximum Element in Binary Search Trees**

In BSTs, the maximumelement is the right-most node, which does not have right child. In the BST below, the maximumelement is **16**.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.009.png)

Time Complexity: O(*n*), inworst case (whenBST is a *right skew* tree). Space Complexity: O(*n*), for recursive stack.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.010.jpeg)

*Non recursive* versionof the above algorithmcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.011.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Where is Inorder Predecessor and Successor?**

Where is the inorder predecessor and successor of node *X* in a binary search tree assuming all keys are distinct?

If *X* has two children then its inorder predecessor is the maximum value in its left subtree and its inorder successor the minimumvalue inits right subtree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.012.jpeg)

If it does not have a left child, thena node’s inorder predecessor is its first left ancestor.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.013.jpeg)

**Inserting an Element from Binary Search Tree**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.014.jpeg)

To insert *data* into binary search tree, first we need to find the location for that element. We can find the location of insertion by following the same mechanism as that of *find* operation. While finding the location, if the *data* is already there then we can simply neglect and come out. Otherwise, insert *data* at the last locationonthe pathtraversed.

As an example let us consider the following tree. The dotted node indicates the element (5) to be inserted. To insert 5, traverse the tree using*find* function. At node withkey4, we need to go right, but there is no subtree, so 5 is not inthe tree, and this is the correct locationfor insertion.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.015.jpeg)

**Note:** In the above code, after inserting an element in subtrees, the tree is returned to its parent. As a result, the complete tree will get updated.

Time Complexity:O(*n*).

Space Complexity:O(*n*), for recursive stack. For iterative version, space complexityis O(1).

**Deleting an Element from Binary Search Tree**

The delete operation is more complicated than other operations. This is because the element to be deleted may not be the leaf node. In this operation also, first we need to find the location of the element whichwe want to delete.

Once we have found the node to be deleted, consider the followingcases:

- If the element to be deleted is a leaf node: return NULL to its parent. That means make the correspondingchild pointer NULL. Inthe tree below to delete 5, set NULL

to its parent node 2.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.016.jpeg)

- If the element to be deleted has one child: In this case we just need to send the current node’s child to its parent. In the tree below, to delete 4, 4 left subtree is set to its parent node 2.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.017.jpeg)

- If the element to be deleted has both children: The general strategy is to replace the key of this node with the largest element of the left subtree and recursively delete that node (which is now empty). The largest node in the left subtree cannot have a right child, so the second *delete* is an easy one. As an example, let us consider the following tree. In the tree below, to delete 8, it is the right child of the root. The key value is 8. It is replaced with the largest key in its left subtree (7), and then that node is deleted as before (second case).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.018.jpeg)

**Note:** We canreplace withminimumelement inright subtree also.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.019.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*) for recursive stack. For iterative version, space complexityis O(1).

**Binary Search Trees: Problems & Solutions**

**Note:** For ordering related problems with binary search trees and balanced binary search trees,

Inorder traversal has advantages over others as it gives the sorted order.

**Problem-47**  Given pointers to two nodes in a binary search tree, find the lowest common

ancestor (*LCA*). Assume that bothvalues alreadyexist inthe tree.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.020.png)

The main idea of the solution is: while traversing BST from root to bottom, the first node we encounter with value between *α* and *β*, i.e., *α < node* → *data < β*, is the Least Common Ancestor(LCA) of *α* and *β* (where *α < β*). So just traverse the BST in pre-order, and if we find a node with value in between *α* and *β*, then that node is the LCA. If its value is greater than both *α* and *β*, then the LCA lies on the left side of the node, and if its value is smaller than both α and β, thenthe LCAlies onthe right side.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.021.png)

Time Complexity: O(*n*). Space Complexity: O(*n*), for skew trees.

**Problem-48**  Give analgorithmfor findingthe shortest pathbetweentwo nodes ina BST. **Solution:** It’s nothingbut findingthe LCAof two nodes inBST.

**Problem-49**  Give analgorithmfor countingthe number of BSTs possible with*n* nodes. **Solution:** This is a DPproblem. Refer to chapter on*Dynamic Programming* for the algorithm.

**Problem-50**  Give analgorithmto checkwhether the givenbinarytree is a BST or not. **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.022.jpeg)

Consider the followingsimple program. For eachnode, checkif the node onits left is smaller and check if the node on its right is greater. This approach is wrong as this will return true for binary tree below. Checkingonlyat current node is not enough.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.023.png)

**Problem-51**  Canwe thinkof gettingthe correct algorithm?

**Solution:** For each node, check if max value in left subtree is smaller than the current node data and min value in right subtree greater than the node data. It is assumed that we have helper functions *FindMin*() and *FindMax*() that return the min or max integer value from a non-empty tree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.024.png)

Time Complexity: O(*n*2). Space Complexity: O(*n*).

**Problem-52**  Canwe improve the complexityof [Problem-51](#_page14_x66.91_y369.47)?

**Solution: Yes.** A better solution is to look at each node only once. The trick is to write a utility helper function IsBSTUtil(struct BinaryTreeNode\* root, int min, int max) that traverses down the tree keeping track of the narrowing min and max allowed values as it goes, looking at each node only once. The initial values for min and max should be INT\_MIN and INT\_MAX – they narrow fromthere.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.025.png)

Time Complexity: O(*n*). Space Complexity: O(*n*), for stackspace.

**Problem-53**  Canwe further improve the complexityof [Problem-51](#_page14_x66.91_y369.47)?

**Solution: Yes,** byusinginorder traversal. The idea behind this solutionis that inorder traversal of BST produces sorted lists. While traversing the BST in inorder, at each node check the condition that its key value should be greater than the key value of its previous visited node. Also, we need to initialize the prev withpossible minimuminteger value (say, INT\_MIN).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.026.png)

Time Complexity: O(*n*). Space Complexity: O(*n*), for stackspace.

**Problem-54**  Give an algorithm for converting BST to circular DLL with space complexity

O(1).

**Solution:** Convert left and right subtrees to DLLs and maintain end of those lists. Then, adjust the pointers.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.027.jpeg)

Time Complexity: O(*n*).

**Problem-55**  For [Problem-54](#_page16_x66.91_y404.57), is there anyother wayof solvingit?

**Solution: Yes.** There is an alternative solution based on the divide and conquer method which is quite neat.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.028.jpeg)

Time Complexity: O(*n*).

**Problem-56**  Given a sorted doubly linked list, give an algorithm for converting it into

balanced binarysearchtree.

**Solution:** Find the middle node and adjust the pointers.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.029.png)

Time Complexity: 2*T*(*n/*2) *+* O(*n*) [for findingthe middle node] = O(*nlogn*).

**Note:** For *FindMiddleNode* functionrefer *Linked Lists* chapter.

**Problem-57**  Givena sorted array, give analgorithmfor convertingthe arrayto BST.

**Solution:** If we have to choose an array element to be the root of a balanced BST, which element should we pick? The root of a balanced BST should be the middle element fromthe sorted array. We would pick the middle element from the sorted array in each iteration. We then create a node in the tree initialized with this element. After the element is chosen, what is left? Could you identifythe sub-problems withinthe problem?

There are two arrays left – the one on its left and the one on its right. These two arrays are the sub-problems of the original problem, since both of them are sorted. Furthermore, they are subtrees of the current node’s left and right child.

The code below creates a balanced BST from the sorted array in O(*n*) time (*n* is the number of elements in the array). Compare how similar the code is to a binary search algorithm. Both are usingthe divide and conquer methodology.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.030.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*), for stackspace.

**Problem-58**  Given a singly linked list where elements are sorted in ascending order, convert

it to a height balanced BST.

**Solution:** A naive way is to apply the [Problem-56](#_page18_x66.91_y629.71) solution directly. In each recursive call, we would have to traverse half of the list’s lengthto find the middle element. The runtime complexity is clearlyO(*nlogn*), where *n* is the total number of elements in the list. This is because each level of recursive call requires a total of *n/*2 traversal steps in the list, and there are a total of *logn* number of levels (ie, the height of the balanced tree).

**Problem-59**  For [Problem-58](#_page20_x66.91_y518.11), canwe improve the complexity?

**Solution: Hint:** How about insertingnodes followingthe list order? If we canachieve this, we no longer need to find the middle element as we are able to traverse the list while inserting nodes to the tree.

**Best Solution:** As usual, the best solution requires us to think from another perspective. In other words, we no longer create nodes in the tree using the top-down approach. Create nodes bottom- up, and assign them to their parents. The bottom-up approach enables us to access the list in its order while creatingnodes [42].

Isn’t the bottom-up approachprecise? Anytime we are stuckwiththe top-downapproach, we can give bottom-up a try. Although the bottom-up approach is not the most natural way we think, it is helpful in some cases. However, we should prefer top-down instead of bottom-up in general, since the latter is more difficult to verify.

Below is the code for converting a singly linked list to a balanced BST. Please note that the algorithmrequires the list length to be passed in as the function parameters. The list length can be found in O(*n*) time by traversing the entire list once. The recursive calls traverse the list and create tree nodes by the list order, which also takes O(*n*) time. Therefore, the overall run time complexityis still O(*n*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.031.jpeg)

**Problem-60**  Give analgorithmfor findingthe *kth* smallest element inBST.

**Solution:** The idea behind this solution is that, inorder traversal of BST produces sorted lists. While traversingthe BST ininorder, keep trackof the number of elements visited.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.032.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-61  Floorandceiling:** If a givenkeyis less thanthe keyat the root of a BST thenthe

floor of the key (the largest key in the BST less than or equal to the key) must be in the left subtree. If the keyis greater thanthe keyat the root, thenthe floor of the keycould be inthe right subtree, but only if there is a key smaller than or equal to the key in the right subtree; if not (or if the key is equal to the the key at the root) then the key at the root is the floor of the key. Finding the ceiling is similar, with interchanging right and left. For example, if the sorted withinput arrayis {1, 2, 8, 10, 10, 12, 19}, then

For *x* = 0: floor doesn’t exist inarray, ceil = 1, For *x* = 1: floor = 1, ceil = 1

For *x* = 5: floor =2, ceil = 8, For *x* = 20: floor = 19, ceil doesn’t exist inarray

**Solution:** The idea behind this solution is that, inorder traversal of BST produces sorted lists. While traversing the BST in inorder, keep track of the values being visited. If the roots data is greater than the given value then return the previous value which we have maintained during traversal. If the roots data is equal to the givendata thenreturnroot data.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.033.png)

Time Complexity: O(*n*). Space Complexity: O(*n*), for stackspace.

For ceiling, we just need to call the right subtree first, followed byleft subtree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.034.png)

Time Complexity: O(*n*). Space Complexity: O(*n*), for stackspace.

**Problem-62**  Give an algorithmfor finding the union and intersection of BSTs. Assume parent

pointers are available (say threaded binary trees). Also, assume the lengths of two BSTs are *m* and nrespectively.

**Solution:** If parent pointers are available then the problemis same as merging of two sorted lists. This is because if we call inorder successor each time we get the next highest element. It’s just a matter of whichInorderSuccessor to call.

Time Complexity: O(*m* + *n*). Space complexity: O(1).

**Problem-63**  For [Problem-62](#_page24_x66.91_y439.63), what if parent pointers are not available?

**Solution:** If parent pointers are not available, the BSTs can be converted to linked lists and then merged.

1  Convert both the BSTs into sorted doubly linked lists in O(*n* + *m*) time. This produces 2 sorted lists.
1  Merge the two double linked lists into one and also maintain the count of total elements inO(*n* + *m*) time.
1  Convert the sorted doublylinked list into height balanced tree inO(*n* + *m*) time.

**Problem-64**  For [Problem-62](#_page24_x66.91_y439.63), is there anyalternative wayof solvingthe problem?

**Solution:** Yes, byusinginorder traversal.

- Performinorder traversal onone of the BSTs.
- While performingthe traversal store themintable (hashtable).
- After completion of the traversal of first *BST*, start traversal of second *BST* and compare themwithhashtable contents.

Time Complexity: O(*m* + *n*). Space Complexity: O(*Max*(*m*,*n*)).

**Problem-65**  Given a *BST* and two numbers *K*1 and *K*2, give an algorithm for printing all the

elements *of BST* inthe range *K*1 and *K*2.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.035.png)

Time Complexity: O(*n*). Space Complexity: O(*n*), for stackspace.

**Problem-66**  For [Problem-65](#_page25_x66.91_y162.84), is there anyalternative wayof solvingthe problem?

**Solution:** We can use level order traversal: while adding the elements to queue check for the range.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.036.png)

Time Complexity: O(*n*). Space Complexity: O(*n*), for queue.

**Problem-67**  For [Problem-65](#_page25_x66.91_y162.84), canwe still thinkof analternative wayto solve the problem?

**Solution:** First locate *K*1 with normal binary search and after that use InOrder successor until we encounter *K*2. For algorithm, refer to problems sectionof threaded binarytrees.

**Problem-68**  Given root of a Binary Search tree, trimthe tree, so that all elements returned in

the new tree are betweenthe inputs *A*and *B.*

**Solution:** It’s just another wayof asking[Problem-65](#_page25_x66.91_y162.84).

**Problem-69**  Given two BSTs, check whether the elements of them are the same or not. For

example: two BSTs with data 10 5 20 15 30 and 10 20 15 30 5 should return true and the dataset with 10 5 20 15 30 and 10 15 30 20 5 should return false. **Note:** BSTs data can be inanyorder.

**Solution:** One simple way is performing an inorder traversal on first tree and storing its data in hash table. As a second step, perform inorder traversal on second tree and check whether that data is already there in hash table or not (if it exists in hash table then mark it with -1 or some unique value).

During the traversal of second tree if we find any mismatch return false. After traversal of second tree check whether it has all -1s in the hash table or not (this ensures extra data available in second tree).

Time Complexity: O(*max*(*m, n*)), where *m* and n are the number of elements in first and second BST. Space Complexity: O(*max*(*m,n*)). This depends onthe size of the first tree.

**Problem-70**  For [Problem-69](#_page26_x66.91_y608.13), canwe reduce the time complexity?

**Solution:** Instead of performing the traversals one after the other, we can perform *in* – *order* traversal of both the trees in parallel. Since the *in* – *order* traversal gives the sorted list, we can checkwhether boththe trees are generatingthe same sequence or not.

Time Complexity: O(*max*(*m,n*)). Space Complexity: O(1). This depends on the size of the first tree.

**Problem-71**  For the key values 1... *n*, how many structurally unique BSTs are possible that

store those keys.

**Solution:** Strategy: consider that each value could be the root. Recursively find the size of the left and right subtrees.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.037.png)

**Problem-72**  Given a BST of size *n*, in which each node r has an additional field *r* → *size*, the number of the keys in the sub-tree rooted at *r* (including the root node *r*). Give an O(*h*) algorithm*GreaterthanConstant*(*r,k*) to find the number of keys that are strictly greater than *k* (*h* is the height of the binarysearchtree).

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.038.png)

The suggested algorithm works well if the key is a unique value for each node. Otherwise when reaching*k=r*→*data*, we should start a process of moving to the right until reaching a node *y* with a key that is bigger then *k*, and then we should return *keysCount + y*→*size*. Time Complexity: O(*h*) where *h=*O(*n*) inthe worst case and O(*logn*) inthe average case.

12. **Balanced Binary Search Trees**

In earlier sections we have seen different trees whose worst case complexity is O(*n*), where n is the number of nodes in the tree. This happens when the trees are skew trees. In this section we will tryto reduce this worst case complexityto O(*logn*) byimposingrestrictions onthe heights.

In general, the height balanced trees are represented with *HB*(*k*), where *k* is the difference betweenleft subtree height and right subtree height. Sometimes *k* is called balance factor.

**FullBalanced Binary Search Trees**

In *HB*(*k*), if *k* = 0 (if balance factor is zero), then we call such binary search trees as *full* balanced binarysearchtrees. That means, in*HB*(0) binarysearchtree, the difference betweenleft subtree height and right subtree height should be at most zero. This ensures that the tree is a full binarytree. For example,

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.039.jpeg)

**Note:** For constructing*HB*(0) tree refer to *Problems* section.

13. **AVL(Adelson-Velskiiand Landis) Trees**

In*HB*(*k*), if *k* = 1 (if balance factor is one), such a binary search tree is called an *AVL tree*. That means an AVL tree is a binary search tree with a *balance* condition: the difference between left subtree height and right subtree height is at most 1.

**Properties of AVLTrees**

Abinarytree is said to be anAVLtree, if:

- It is a binarysearchtree, and
- For any node *X*, the height of left subtree of *X* and height of right subtree of *X* differ byat most 1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.040.png)

As an example, among the above binary search trees, the left one is not an AVLtree, whereas the right binarysearchtree is anAVLtree.

**Minimum/Maximum Number of Nodes in AVLTree**

For simplicity let us assume that the height of an AVLtree is *h* and *N*(*K*) indicates the number of nodes in AVL tree with height *h*. To get the minimum number of nodes with height *h*, we should fill the tree with the minimum number of nodes possible. That means if we fill the left subtree with height *h* – 1 then we should fill the right subtree with height *h* – 2. As a result, the minimum number of nodes withheight *h* is:

*N*(*h*) = *N*(*h* – 1) + *N*(*h* – 2) + 1

Inthe above equation:

- *N*(*h* – 1) indicates the minimumnumber of nodes withheight *h* – 1.
- *N*(*h* – 2) indicates the minimumnumber of nodes withheight *h* – 2.
- Inthe above expression, “1” indicates the current node.

We cangive *N*(*h* – 1) either for left subtree or right subtree. Solvingthe above recurrence gives:

*N*(*h*) = O(1.618*h*) ⇒ *h* = 1.44*logn* ≈ O(*logn*)

Where *n* is the number of nodes in AVL tree. Also, the above derivation says that the maximum height in AVLtrees is O(*logn*). Similarly, to get maximum number of nodes, we need to fill both left and right subtrees withheight *h* – 1. As a result, we get:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.041.png)

*N*(*h*) = *N*(*h* – 1) + *N*(*h* – 1) + 1 = 2*N*(*h* – 1) + 1

The above expressiondefines the case of full binarytree. Solvingthe recurrence we get:

*N*(*h*) = O(2*h*) ⇒ *h* = *logn* ≈ O(*logn*)

∴In both the cases, AVLtree property is ensuring that the height of an AVLtree with *n* nodes is O(*logn*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.042.png)

**AVLTree Declaration**

Since AVLtree is a BST, the declaration of AVLis similar to that of BST. But just to simplify the operations, we also include the height as part of the declaration.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.043.png)

**Finding the Height of an AVLtree**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.044.png)

Time Complexity: O(1).

**Rotations**

When the tree structure changes (e.g., with insertion or deletion), we need to modify the tree to restore the AVLtree property. This can be done using single rotations or double rotations. Since an insertion/deletion involves adding/deleting a single node, this can only increase/decrease the height of a subtree by1.

So, if the AVL tree property is violated at a node *X*, it means that the heights of left(*X*) and right(*X*) differ by exactly 2. This is because, if we balance the AVL tree every time, then at any point, the difference in heights of left(*X*) and right(*X*) differ by exactly 2. Rotations is the technique used for restoring the AVLtree property. This means, we need to apply the rotations for the node *X.*

**Observation:** One important observation is that, after an insertion, only nodes that are on the path from the insertion point to the root might have their balances altered, because only those nodes have their subtrees altered. To restore the AVL tree property, we start at the insertion point and keep goingto the root of the tree.

While moving to the root, we need to consider the first node that is not satisfying the AVL property. Fromthat node onwards, everynode onthe pathto the root will have the issue.

Also, if we fix the issue for that first node, then all other nodes on the path to the root will automatically satisfy the AVLtree property. That means we always need to care for the first node that is not satisfyingthe AVLpropertyonthe pathfromthe insertionpoint to the root and fixit.

**Types of Violations**

Let us assume the node that must be rebalanced is *X*. Since anynode has at most two children, and a height imbalance requires that *X’s* two subtree heights differ by two, we can observe that a violationmight occur infour cases:

1. Aninsertioninto the left subtree of the left child of *X.*
2. Aninsertioninto the right subtree of the left child of *X.*
3. Aninsertioninto the left subtree of the right child of *X.*
4. Aninsertioninto the right subtree of the right child of *X.*

Cases 1 and 4 are symmetric and easily solved with single rotations. Similarly, cases 2 and 3 are also symmetric and canbe solved withdouble rotations (*n*eeds two single rotations).

**Single Rotations**

**Left Left Rotation(LLRotation) [Case-1]:** In the case below, node *X* is not satisfying the AVL tree property. As discussed earlier, the rotation does not have to be done at the root of a tree. In general, we start at the node inserted and travel up the tree, updating the balance information at everynode onthe path.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.045.jpeg)

For example, in the figure above, after the insertion of 7 in the original AVLtree on the left, node 9 becomes unbalanced. So, we do a single left-left rotation at 9. As a result we get the tree on the right.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.046.png)

Time Complexity: O(1). Space Complexity: O(1).

**Right Right Rotation (RR Rotation) [Case-4]:** In this case, node *X* is not satisfying the AVL tree property.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.047.jpeg)

For example, in the figure, after the insertion of 29 in the original AVL tree on the left, node 15 becomes unbalanced. So, we do a single right-right rotation at 15. As a result we get the tree on the right.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.048.png)

Time Complexity: O(1). Space Complexity: O(1).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.049.png)

**Double Rotations**

**Left Right Rotation(LR Rotation) [Case-2]:** For case-2 and case-3 single rotation does not fix the problem. We need to performtwo rotations.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.050.jpeg)

As an example, let us consider the following tree: The insertion of 7 is creating the case-2 scenario and the right side tree is the one after the double rotation.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.051.png)

Code for left-right double rotationcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.052.png)

**Right Left Rotation (RL Rotation) [Case-3]:** Similar to case-2, we need to perform two rotations to fixthis scenario.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.053.jpeg)

As an example, let us consider the following tree: The insertion of 6 is creating the case-3 scenario and the right side tree is the one after the double rotation.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.054.png)

**Insertion into an AVLtree**

Insertion into an AVLtree is similar to a BST insertion. After inserting the element, we just need to check whether there is any height imbalance. If there is an imbalance, call the appropriate rotationfunctions.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.055.jpeg)

Time Complexity: O(*logn*). Space Complexity: O(*logn*).

**AVLTrees: Problems & Solutions**

**Problem-73**  Givena height *h*, give analgorithmfor generatingthe *HB*(0).

**Solution:** As we have discussed, *HB*(0) is nothing but generating full binary tree. In full binary tree the number of nodes with height *h* is: 2h+1 – 1 (let us assume that the height of a tree with one node is 0). As a result the nodes canbe numbered as: 1 to 2h+1 – 1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.056.png)

Time Complexity: O(*n*).

Space Complexity: O(*logn*), where *logn* indicates the maximum stack size which is equal to height of tree.

**Problem-74**  Is there anyalternative wayof solving[Problem-73](#_page42_x66.91_y27.36)?

**Solution: Yes,** we can solve it following Mergesort logic. That means, instead of working with height, we can take the range. With this approach we do not need any global counter to be maintained.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.057.png)

The initial call to the *BuildHBO* function could be: *BuildHB*0(1, 1 ≪ *h*). 1 ≪ *h* does the shift operationfor calculatingthe 2*h+*1 *–* 1.

Time Complexity: O(*n*). Space Complexity: O(*login*). Where *logn* indicates maximum stack size whichis equal to the height of the tree.

**Problem-75**  Construct minimal AVL trees of height 0,1,2,3,4, and 5. What is the number of

nodes ina minimal AVLtree of height 6?

**Solution**Let *N*(*h*) be the number of nodes ina minimal AVLtree withheight *h.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.058.jpeg)

**Problem-76**  For [Problem-73](#_page42_x66.91_y27.36), how many different shapes can there be of a minimal AVLtree

of height *h?*

**Solution:** Let *NS*(*h*) be the number of different shapes of a minimal AVLtree of height *h.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.059.jpeg)

**Problem-77**  Givena binarysearchtree, checkwhether it is anAVLtree or not?

**Solution:** Let us assume that *IsAVL* is the function which checks whether the given binary search tree is an AVLtree or not. *IsAVL* returns –1 if the tree is not an AVLtree. During the checks each node sends its height to its parent.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.060.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-78**  Given a height *h*, give an algorithm to generate an AVL tree with minimum

number of nodes.

**Solution:** To get minimumnumber of nodes, fill one level with*h* – 1 and the other with*h* – 2.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.061.png)

**Problem-79**  Given an AVLtree with *n* integer items and two integers *a* and *b*, where *a* and *b*

can be any integers with *a <= b*. Implement an algorithm to count the number of nodes in the range [*a,b*].

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.062.jpeg)

The idea is to make use of the recursive property of binary search trees. There are three cases to consider: whether the current node is in the range [*a*, *b*], on the left side of the range [*a*, *b*], or on the right side of the range [*a,b*]. Only subtrees that possibly contain the nodes will be processed under eachof the three cases.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.063.png)

The complexity is similar to *in* – *order* traversal of the tree but skipping left or right sub-trees when they do not contain any answers. So in the worst case, if the range covers all the nodes in the tree, we need to traverse all the *n* nodes to get the answer. The worst time complexity is therefore O(*n*).

If the range is small, whichonlycovers a few elements ina small subtree at the bottomof the tree, the time complexitywill be O(*h*) = O(*logn*), where *h* is the height of the tree. This is because only a single path is traversed to reach the small subtree at the bottom and many higher level subtrees

have beenpruned alongthe way. **Note:** Refer similar probleminBST.

**Problem-80**  Given a BST (applicable to AVL trees as well) where each node contains two

data elements (its data and also the number of nodes in its subtrees) as shown below. Convert the tree to another BST by replacing the second data element (*n*umber of nodes in its subtrees) with previous node data in inorder traversal. Note that each node is merged with*inorder* previous node data. Also make sure that conversionhappens in-place.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.064.png)

**Solution:** The simplest way is to use level order traversal. If the number of elements in the left subtree is greater than the number of elements in the right subtree, find the maximum element in the left subtree and replace the current node second data element with it. Similarly, if the number of elements in the left subtree is less than the number of elements in the right subtree, find the minimumelement inthe right subtree and replace the current node *second* data element withit.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.065.png)

Time Complexity: O(*nlogn*) on average since BST takes O(*logn*) on average to find the maximum or minimumelement. Space Complexity: O(*n*). Since, inthe worst case, all the nodes onthe entire last level could be inthe queue simultaneously.

**Problem-81**  Canwe reduce time complexityfor the previous problem?

**Solution:** Let us try using an approach that is similar to what we followed in [Problem-60](#_page22_x66.91_y27.36). The idea behind this solution is that inorder traversal of BST produces sorted lists. While traversing the BST ininorder, keep trackof the elements visited and merge them.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.066.png)

Time Complexity: O(*n*).

Space Complexity: O(1). Note that, we are still having recursive stack space for inorder traversal.

**Problem-82**  Givena BST and a key, find the element inthe BST whichis closest to the given

key.

**Solution:** As a simple solution, we can use level-order traversal and for every element compute the difference between the given key and the element’s value. If that difference is less than the previous maintained difference, then update the difference with this new minimum value. With this approach, at the end of the traversal we will get the element whichis closest to the givenkey.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.067.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-83**  For [Problem-82](#_page49_x66.91_y429.66), canwe solve it usingthe recursive approach?

**Solution:** The approach is similar to Problem-18. Following is a simple algorithmfor finding the closest Value inBST.

1. If the root is NULL, thenthe closest value is zero (or NULL).
1. If the root’s data matches the givenkey, thenthe closest is the root.
1. Else, consider the root as the closest and do the following:
   1. If the key is smaller than the root data, find the closest on the left side tree of the root recursivelyand call it temp.
   1. If the key is larger than the root data, find the closest on the right side tree of the root recursivelyand call it temp.
1. Returnthe root or temp dependingonwhichever is nearer to the givenkey.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.068.png)

Time Complexity: O(*n*) inworst case, and inaverage case it is O(*logn*). Space Complexity: O(*n*) inworst case, and inaverage case it is O(*logn*).

**Problem-84**  Medianinaninfinite series of integers

**Solution:** Median is the middle number in a sorted list of numbers (if we have odd number of elements). If we have evennumber of elements, medianis the average of two middle numbers ina sorted list of numbers.

For solving this problem we can use a binary search tree with additional information at each node, and the number of children on the left and right subtrees. We also keep the number of total nodes inthe tree. Usingthis additional informationwe canfind the medianinO(*logn*) time, taking the appropriate branch in the tree based on the number of children on the left and right of the current node. But, the insertion complexity is O(*n*) because a standard binary search tree can degenerate into a linked list if we happento receive the numbers insorted order.

So, let’s use a balanced binarysearchtree to avoid worst case behavior of standard binarysearch trees. For this problem, the balance factor is the number of nodes in the left subtree minus the number of nodes in the right subtree. And only the nodes with a balance factor of+ 1 or 0 are considered to be balanced.

So, the number of nodes on the left subtree is either equal to or 1 more than the number of nodes onthe right subtree, but not less.

If we ensure this balance factor oneverynode inthe tree, thenthe root of the tree is the median, if the number of elements is odd. In the number of elements is even, the median is the average of the root and its inorder successor, whichis the leftmost descendent of its right subtree.

So, the complexity of insertion maintaining a balanced condition is O(*logn*) and finding a median operation is O(1) assuming we calculate the inorder successor of the root at every insertion if the number of nodes is even.

Insertionand balancingis verysimilar to AVLtrees. Instead of updatingthe heights, we update the number of nodes information. Balanced binary search trees seem to be the most optimal solution, insertionis O(*logn*) and find medianis O(1).

**Note:** For anefficient algorithmrefer to the *[Priority Queues and Heaps*](#_page68_x28.00_y82.94)* chapter.

**Problem-85**  Givena binarytree, how do youremove all the half nodes (whichhave onlyone

child)? Note that we should not touchleaves.

**Solution:** By using post-order traversal we can solve this problem efficiently. We first process the left children, then the right children, and finally the node itself. So we form the new tree bottom up, starting from the leaves towards the root. By the time we process the current node, bothits left and right subtrees have alreadybeenprocessed.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.069.png)

Time Complexity: O(*n*).

**Problem-86**  Givena binarytree, how do youremove its leaves?

**Solution:** By using post-order traversal we can solve this problem (other traversals would also work).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.070.png)

Time Complexity: O(*n*).

**Problem-87**  Given a BST and two integers (minimumand maximumintegers) as parameters,

how do youremove (prune) elements that are not withinthat range?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.071.jpeg)

**Solution: Observation:** Since we need to check each and every element in the tree, and the subtree changes should be reflected in the parent, we can think about using post order traversal. So we process the nodes starting from the leaves towards the root. As a result, while processing the node itself, both its left and right subtrees are valid pruned BSTs. At each node we will return a pointer based on its value, which will then be assigned to its parent’s left or right child pointer, depending on whether the current node is the left or right child of the parent. If the current node’s value is between*A*and *B* (*A<= node’s data <= B*) thenno actionneeds to be taken, so we return the reference to the node itself.

If the current node’s value is less than *A*, then we return the reference to its right subtree and discard the left subtree. Because if a node’s value is less than *A*, then its left children are definitely less than A since this is a binary search tree. But its right children may or may not be less than A; we can’t be sure, so we return the reference to it. Since we’re performing bottom-up post-order traversal, its right subtree is already a trimmed valid binary search tree (possibly NULL), and its left subtree is definitely NULLbecause those nodes were surely less than A and theywere eliminated duringthe post-order traversal.

Asimilar situationoccurs whenthe node’s value is greater than*B*, so we now returnthe reference to its left subtree. Because if a node’s value is greater than *B*, then its right children are definitely greater than *B*. But its left children may or may not be greater than *B;* So we discard the right subtree and returnthe reference to the alreadyvalid left subtree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.072.png)

Time Complexity: O(*n*) inworst case and inaverage case it is O(*logn*).

**Note:** If the givenBST is anAVLtree thenO(*n*) is the average time complexity.

**Problem-88**  Given a binary tree, how do you connect all the adjacent nodes at the same

level? Assume that given binary tree has next pointer along with left and right pointers as shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.073.png)

**Solution:** One simple approach is to use level-order traversal and keep updating the next pointers. While traversing, we will link the nodes on the next level. If the node has left and right node, we will link left to right. If node has next node, then link rightmost child of current node to leftmost child of next node.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.074.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-89**  Canwe improve space complexityfor [Problem-88](#_page55_x66.91_y633.76)?

**Solution:** We can process the tree level by level, but without a queue. The logical part is that when we process the nodes of the next level, we make sure that the current level has already been linked.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.075.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*depth of tree*) for stackspace.

**Problem-90**  Assume that a set *S* of *n* numbers are stored in some form of balanced binary

search tree; i.e. the depth of the tree is O(*logn*). In addition to the key value and the pointers to children, assume that every node contains the number of nodes in its subtree. Specify a reason(s) why a balanced binary tree can be a better option than a complete binarytree for storingthe set S.

**Solution:** Implementation of a balanced binary tree requires less RAM space as we do not need to keep the complete tree inRAM (since theyuse pointers).

**Problem-91**  For the [Problem-90](#_page59_x66.91_y27.36), specify a reason (s) why a complete binary tree can be a

better optionthana balanced binarytree for storingthe set S.

**Solution:** A complete binary tree is more space efficient as we do not need any extra flags. A balanced binary tree usually takes more space since we need to store some flags. For example, in a Red-Black tree we need to store a bit for the color. Also, a complete binary tree can be stored ina RAM as anarraywithout usingpointers.

**Problem-92**  Given a binary tree, find the maximum path sum. The path may start and end at

anynode inthe tree.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.076.jpeg)

**Problem-93**  Let T be a proper binarytree withroot r. Consider the followingalgorithm.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.077.png)

What does the algorithmdo?

1. It always returns the value 1.
2. It computes the number of nodes inthe tree.
3. It computes the depthof the nodes.
4. It computes the height of the tree.
5. It computes the number of leaves inthe tree.

**Solution:** E.

14. **Other Variations on Trees**

In this section, let us enumerate the other possible representations of trees. In the earlier sections, we have looked at AVLtrees, which is a binary search tree (BST) with balancing property. Now, let us lookat a few more balanced binarysearchtrees: Red-blackTrees and SplayTrees.

1. **Red-Black Trees**

In Red-black trees each node is associated with an extra attribute: the color, which is either red or black. To get logarithmic complexitywe impose the followingrestrictions.

**Definition:** ARed-blacktree is a binarysearchtree that satisfies the followingproperties:

- Root Property: the root is black
- External Property: everyleaf is black
- Internal Property: the childrenof a red node are black
- DepthProperty: all the leaves have the same black

Similar to AVL trees, if the Red-black tree becomes imbalanced, then we perform rotations to reinforce the balancing property. With Red-black trees, we can perform the following operations inO(*logn*) inworst case, where *n* is the number of nodes inthe trees.

- Insertion, Deletion
- Findingpredecessor, successor
- Findingminimum, maximum

2. **Splay Trees**

Splay-trees are BSTs with a self-adjusting property. Another interesting property of splay-trees is: starting with an empty tree, any sequence of *K* operations with maximum of *n* nodes takes O(*Klogn*) time complexity in worst case. Splay trees are easier to programand also ensure faster access to recently accessed items. Similar to *AVL* and Red-Black trees, at any point that the splay tree becomes imbalanced, we canperformrotations to reinforce the balancingproperty.

Splay-trees cannot guarantee the O(*logn*) complexity in worst case. But it gives amortized O(*logn*) complexity. Even though individual operations can be expensive, any sequence of operations gets the complexity of logarithmic behavior. One operation may take more time (a single operation may take O(*n*) time) but the subsequent operations may not take worst case complexityand onthe average *per operation* complexityis *O*{*logn*).

3. **B-Trees**

B-Tree is like other self-balancing trees such as AVLand Red-black tree such that it maintains its balance of nodes while opertions are performed against it. B-Tree has the followingproperties:

- Minimumdegree “£” where, except root node, all other nodes must have no less than *t* – 1 keys
- Eachnode withnkeys has *n* + 1 children
- Keys ineachnode are lined up where *k*1 *< k*2 < .. *kn*
- Eachnode cannot have more than2t-l keys, thus 2t children
- Root node at least must containone key. There is no root node if the tree is empty.
- Tree grows indepthonlywhenroot node is split.

Unlike a binary-tree, each node of a b-tree may have a variable number of keys and children. The keys are stored in non-decreasing order. Each key has an associated child that is the root of a subtree containingall nodes withkeys less thanor equal to the keybut greater thanthe preceeding key. Anode also has an additional rightmost child that is the root for a subtree containing all keys greater thananykeys inthe node.

A b-tree has a minumum number of allowable children for each node known as the *minimization factor*. If *t* is this *minimization factor*, every node must have at least *t* – 1 keys. Under certain circumstances, the root node is allowed to violate this property by having fewer than *t* – 1 keys. Everynode mayhave at most 2*t* – 1 keys or, equivalently, 2*t* children.

Since eachnode tends to have a large branchingfactor (a large number of children), it is typically neccessaryto traverse relativelyfew nodes before locatingthe desired key. If access to eachnode requires a disk access, then a B-tree will minimize the number of disk accesses required. The minimzation factor is usually chosen so that the total size of each node corresponds to a multiple of the block size of the underlying storage device. This choice simplifies and optimizes disk access. Consequently, a B-tree is an ideal data structure for situations where all data cannot reside inprimarystorage and accesses to secondarystorage are comparativelyexpensive (or time consuming).

To *search* the tree, it is similar to binary tree except that the key is compared multiple times in a given node because the node contains more than 1 key. If the key is found in the node, the search terminates. Otherwise, it moves downwhere at child pointed byci where key*k < ki.*

Key*insertions* of a B-tree happens fromthe bottomfasion. This means that it walk down the tree from root to the target child node first. If the child is not full, the key is simply inserted. If it is full, the child node is split in the middle, the median key moves up to the parent, then the new key is inserted. Wheninsertingand walkingdownthe tree, if the root node is found to be full, it’s split first and we have a new root node. Thenthe normal insertionoperationis performed.

Key*deletion* is more complicated as it needs to maintain the number of keys in each node to meet the constraint. If a key is found in leaf node and deleting it still keeps the number of keys in the nodes not too low, it’s simply done right away. If it’s done to the inner node, the predecessor of the keyinthe corresondingchild node is moved to replace the keyinthe inner node. If movingthe predecessor will cause the child node to violate the node count constraint, the sibling child nodes are combined and the keyinthe inner node is deleted.

4. **Augmented Trees**

In earlier sections, we have seen various problems like finding the *Kth* – smallest - element in the tree and other similar ones. Of all the problems the worst complexity is O(*n*), where n is the number of nodes inthe tree. To performsuchoperations inO(*logn*), augmented trees are useful. In these trees, extra information is added to each node and that extra data depends on the problem we are tryingto solve.

For example, to find the *Kth* element in a binary search tree, let us see how augmented trees solve the problem. Let us assume that we are using Red-Black trees as balanced BST (or any balanced BST) and augmentingthe size informationinthe nodes data. For a givennode *X* in Red-Black tree witha field *size*(*X*) equal to the number of nodes inthe subtree and canbe calculated as:

*size*(*X*) *= size*(*X* → *left*) *+ size*(*X* → *right*)) *+* 1

*Kth -* smallest - operationcanbe defined as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.078.png)

Time Complexity: O(*logn*). Space Complexity: O(*logn*).

**Example:** Withthe extra size information, the augmented tree will looklike:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.079.jpeg)

5. **IntervalTrees [Segment Trees]**

We often face questions that involve queries made in an array based on range. For example, for a given array of integers, what is the maximum number in the range *α* to *β*, where *α* and *β* are of course within array limits. To iterate over those entries with intervals containing a particular value, we can use a simple array. But if we need more efficient access, we need a more sophisticated data structure.

An array-based storage scheme and a brute-force search through the entire array is acceptable only if a single search is to be performed, or if the number of elements is small. For example, if you know all the array values of interest in advance, you need to make only one pass through the array. However, if you can interactively specify different search operations at different times, the brute-force search becomes impractical because every element in the array must be examined duringeachsearchoperation.

If you sort the array in ascending order of the array values, you can terminate the sequential search when you reach the object whose low value is greater than the element we are searching. Unfortunately, this technique becomes increasingly ineffective as the low value increases, because fewer search operations are eliminated. That means, what if we have to answer a large number of queries like this? – is brute force still a good option?

Another example is when we need to return a sum in a given range. We can brute force this too, but the problem for a large number of queries still remains. So, what can we do? With a bit of thinking we can come up with an approach like maintaining a separate array of *n* elements, where *n* is the size of the original array, where each index stores the sum of all elements from 0 to that index. So essentially we have with a bit of preprocessing brought down the query time from a worst case O(*n*) to O(1). Now this is great as far as static arrays are concerned, but, what if we are required to performupdates onthe arraytoo?

The first approachgives us anO(*n*) querytime, but anO(1) update time. The second approach, on the other hand, gives us O(1) querytime, but anO(*n*) update time. So, whichone do we choose?

Interval trees are also binarysearchtrees and theystore interval informationinthe node structure. That means, we maintain a set of *n* intervals [*i*1, *i*2] such that one of the intervals containing a

query point *Q* (if any) can be found efficiently. Interval trees are used for performing range queries efficiently.

A segment tree is a heap-like data structure that can be used for making update/query operations upon array intervals in logarithmical time. We define the segment tree for the interval [*i,j*] in the followingrecursive manner:

- The root (first node inthe array) node will hold the informationfor the interval [*i,j*]
- If i < y the left and right children will hold the information for the intervals ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.080.png)

and ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.081.png)

Segment trees (also called *segtrees* and *interval trees*) is a cool data structure, primarily used for range queries. It is a height balanced binary tree with a static structure. The nodes of a segment tree correspond to various intervals, and can be augmented with appropriate information pertaining to those intervals. It is somewhat less powerful than a balanced binary tree because of its static structure, but due to the recursive nature of operations on the segtree, it is incredibly easyto thinkabout and code.

We canuse segment trees to solve range minimum/maximumqueryproblems. The time complexity is *T*(*nlogn*) where O(*n*) is the time required to build the tree and eachquerytakes O(*logn*) time.

**Example:** Given a set of intervals: *S*= {[2-5], [6-7], [6-10], [8-9], [12-15], [15-23], [25-30]}. A query with *Q =* 9 returns [6,10] or [8,9] (assume these are the intervals which contain 9 among all the intervals). Aquerywith*Q =* 23 returns [15, 23].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.082.png)**Construction of Interval Trees:** Let us assume that we are given a set *S* of *n* intervals (called *segments*). These *n* intervals will have 2*n* endpoints. Now, let us see how to construct the interval tree.

**Algorithm:**

Recursivelybuild tree oninterval set 5 as follows:

- Sort the 2*n* endpoints
- Let Xmid be the medianpoint

Time Complexity for building interval trees: O(*nlogn*). Since we are choosing the median, Interval Trees will be approximately balanced. This ensures that, we split the set of end points up in half each time. The depth of the tree is O(*logn*). To simplify the search process, generally *Xmid*

is stored witheachnode.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.083.png)

6. **Scapegoat Trees**

Scapegoat tree is a self-balancing binary search tree, discovered by Arne Andersson. It provides worst-case O(*logn*) searchtime, and O(*logn*) amortized (average) insertionand deletiontime.

AVL trees rebalance whenever the height of two sibling subtrees differ by more than one;

scapegoat trees rebalance whenever the size of a child exceeds a certain ratio of its parents, a ratio known as a. After inserting the element, we traverse back up the tree. If we find an imbalance where a child’s size exceeds the parent’s size times alpha, we must rebuild the subtree at the parent, the *scapegoat.*

There might be more thanone possible scapegoat, but we onlyhave to pickone. The most optimal scapegoat is actually determined by height balance. When removing it, we see if the total size of the tree is less than alpha of the largest size since the last rebuilding of the tree. If so, we rebuild the entire tree. The alpha for a scapegoat tree can be any number between 0.5 and 1.0. The value 0.5 will force perfect balance, while 1.0 will cause rebalancing to never occur, effectively turningit into a BST.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.084.png)

1. **What is a Priority Queue?**

In some situations we may need to find the minimum/maximum element among a collection of elements. We can do this with the help of Priority Queue ADT. A priority queue ADT is a data structure that supports the operations *Insert* and *DeleteMin* (which returns and removes the minimumelement) or *DeleteMax* (whichreturns and removes the maximumelement).

These operations are equivalent to *EnQueue* and *DeQueue* operations of a queue. The difference is that, in priority queues, the order in which the elements enter the queue may not be the same in which they were processed. An example application of a priority queue is job scheduling, which is prioritized instead of servinginfirst come first serve.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.085.png)

Apriority queue is called an *ascending* – *priority* queue, if the itemwith the smallest key has the highest priority (that means, delete the smallest element always). Similarly, a priority queue is said to be a *descending* –*priority* queue if the item with the largest key has the highest priority (delete the maximum element always). Since these two types are symmetric we will be concentratingonone of them: ascending-priorityqueue.

2. **Priority Queue ADT**

The followingoperations make priorityqueues anADT.

**Main Priority Queues Operations**

Apriorityqueue is a container of elements, eachhavinganassociated key.

- Insert (key, data): Inserts data with *key* to the priority queue. Elements are ordered based onkey.
- DeleteMin/DeleteMax: Remove and returnthe element withthe smallest/largest key.
- GetMinimum/GetMaximum: Return the element with the smallest/largest key without deletingit.

**Auxiliary Priority Queues Operations**

- *kth -* Smallest/*kth* – Largest: Returns the *kth* -Smallest/*kth –*Largest key in priority queue.
- Size: Returns number of elements inpriorityqueue.
- Heap Sort: Sorts the elements inthe priorityqueue based onpriority(key).

3. **Priority Queue Applications**

Priorityqueues have manyapplications - a few of themare listed below:

- Data compression: HuffmanCodingalgorithm
- Shortest pathalgorithms: Dijkstra’s algorithm
- Minimumspanningtree algorithms: Prim’s algorithm
- Event-drivensimulation: customers ina line
- Selectionproblem: Finding*kth-* smallest element

4. **Priority Queue Implementations**

Before discussingthe actual implementation, let us enumerate the possible options.

**Unordered Array Implementation**

Elements are inserted into the array without bothering about the order. Deletions (DeleteMax) are performed bysearchingthe keyand thendeleting.

Insertions complexity: O(1). DeleteMincomplexity: O(*n*).

**Unordered List Implementation**

It is verysimilar to arrayimplementation, but instead of usingarrays, linked lists are used. Insertions complexity: O(1). DeleteMincomplexity: O(*n*).

**Ordered Array Implementation**

Elements are inserted into the arrayinsorted order based onkeyfield. Deletions are performed at onlyone end.

Insertions complexity: O(*n*). DeleteMincomplexity: O(1).

**Ordered List Implementation**

Elements are inserted into the list in sorted order based on key field. Deletions are performed at onlyone end, hence preservingthe status of the priorityqueue. All other functionalities associated witha linked list ADT are performed without modification.

Insertions complexity: O(*n*). DeleteMincomplexity: O(1).

**Binary Search Trees Implementation**

Both insertions and deletions take O(*logn*) on average if insertions are random (refer to *Trees* chapter).

**Balanced Binary Search Trees Implementation**

Bothinsertions and deletiontake O(*logn*) inthe worst case (refer to *Trees* chapter).

**Binary Heap Implementation**

In subsequent sections we will discuss this in full detail. For now, assume that binary heap implementation gives O(*logn*) complexity for search, insertions and deletions and O(1) for findingthe maximumor minimumelement.

**Comparing Implementations**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.086.png)

5. **Heaps and Binary Heaps What is a Heap?**

Aheap is a tree withsome special properties. The basic requirement of a heap is that the value of a node must be ≥ (or ≤) than the values of its children. This is called *heap property*. A heap also has the additional property that all leaves should be at *h* or *h* – 1 levels (where *h* is the height of the tree) for some *h >* 0 (*complete binary trees*). That means heap should forma *complete binary tree* (as shownbelow).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.087.jpeg)

In the examples below, the left tree is a heap (each element is greater than its children) and the right tree is not a heap (since 11 is greater than2).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.088.png)

**Types of Heaps?**

Based onthe propertyof a heap we canclassifyheaps into two types:

- **Min heap:** The value of a node must be less than or equal to the values of its children

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.089.jpeg)

- **Max heap:** The value of a node must be greater than or equal to the values of its children

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.090.jpeg)

6. **Binary Heaps**

In binary heap each node may have up to two children. In practice, binary heaps are enough and we concentrate onbinaryminheaps and binarymaxheaps for the remainingdiscussion.

**Representing Heaps:** Before looking at heap operations, let us see how heaps can be represented. One possibility is using arrays. Since heaps are forming complete binary trees, there

will not be any wastage of locations. For the discussion below let us assume that elements are

stored inarrays, whichstarts at index0. The previous maxheap canbe represented as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.091.png)

**Note:** For the remainingdiscussionlet us assume that we are doingmanipulations inmaxheap.

**Declaration of Heap**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.092.png)

**Creating Heap**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.093.png)

Time Complexity: O(1).

**Parent of a Node**

For a node at *ith* location, its parent is at ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.094.png) location. In the previous example, the element 6 is at second locationand its parent is at 0*th* location.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.095.png)

Time Complexity: O(1).

**Children of a Node**

Similar to the above discussion, for a node at *ith* location, its children are at 2 \* *i* + 1 and 2 \* *i +*

2 locations. For example, in the above tree the element 6 is at second location and its children 2 and 5 are at 5 (2 \**i* + 1 = 2 \*2 + 1) and 6(2 \**i* + 2 = 2 \*2) locations.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.096.png)

**Getting the Maximum Element**

Since the maximumelement inmaxheap is always at root, it will be stored at h→array[O].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.097.png)

Time Complexity: O(1).

**Heapifying an Element**

After inserting an element into heap, it may not satisfy the heap property. In that case we need to adjust the locations of the heap to make it heap again. This process is called *heapifying*. In max- heap, to heapify an element, we have to find the maximum of its children and swap it with the current element and continue this process until the heap propertyis satisfied at everynode.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.098.jpeg)

**Observation:** One important property of heap is that, if an element is not satisfying the heap property, then all the elements from that element to the root will have the same problem. In the example below, element 1 is not satisfying the heap property and its parent 31 is also having the issue. Similarly, if we heapify an element, then all the elements fromthat element to the root will also satisfy the heap property automatically. Let us go through an example. In the above heap, the element 1 is not satisfyingthe heap property. Let us tryheapifyingthis element.

To heapify1, find the maximumof its childrenand swap withthat.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.099.jpeg)

We need to continue this process until the element satisfies the heap properties. Now, swap 1 with 8.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.100.jpeg)

Now the tree is satisfying the heap property. In the above heapifying process, since we are

moving from top to bottom, this process is sometimes called *percolate down*. Similarly, if we start heapifying from any other node to root, we can that process *percolate up* as move from bottomto top.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.101.png)

Time Complexity: O(*logn*). Heap is a complete binary tree and in the worst case we start at the root and come down to the leaf. This is equal to the height of the complete binary tree. Space Complexity: O(1).

**Deleting an Element**

To delete an element fromheap, we just need to delete the element fromthe root. This is the only operation (maximum element) supported by standard heap. After deleting the root element, copy the last element of the heap (tree) and delete that last element.

After replacing the last element, the tree may not satisfy the heap property. To make it heap again, call the *PercolateDown* function.

- Copythe first element into some variable
- Copythe last element into first element location
- *PercolateDown* the first element

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.102.png)

**Note:** Deleting an element uses *PercolateDown*, and inserting an element uses *PercolateUp*. Time Complexity: same as *Heapify* functionand it is O(*logn*).

**Inserting an Element**

Insertionof anelement is similar to the heapifyand deletionprocess.

- Increase the heap size
- Keep the new element at the end of the heap (tree)
- Heapifythe element frombottomto top (root)

Before going through code, let us look at an example. We have inserted the element 19 at the end of the heap and this is not satisfyingthe heap property.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.103.jpeg)

In order to heapify this element (19), we need to compare it with its parent and adjust them. Swapping19 and 14 gives:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.104.jpeg)

Again, swap 19 andl6:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.105.jpeg)

Now the tree is satisfying the heap property. Since we are following the bottom-up approach we sometimes call this process *percolate up.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.106.jpeg)

Time Complexity: O(*logn*). The explanationis the same as that of the *Heapify* function.

**Destroying Heap**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.107.png)

**Heapifying the Array**

One simple approach for building the heap is, take *n* input items and place them into an empty heap. This can be done with *n* successive inserts and takes O(*nlogn*) in the worst case. This is due to the fact that eachinsert operationtakes O(*logn*).

To finish our discussion of binary heaps, we will look at a method to build an entire heap froma list of keys. The first method you might think of may be like the following. Given a list of keys, youcould easilybuild a heap byinsertingeachkeyone at a time. Since youare startingwitha list of one item, the list is sorted and youcould use binarysearchto find the right positionto insert the next keyat a cost of approximatelyO(*logn*) operations.

However, remember that inserting an itemin the middle of the list may require O(*n*) operations to shift the rest of the list over to make room for the new key. Therefore, to insert *n* keys into the heap would require a total of O(*nlogn*) operations. However, if we start with an entire list then we canbuild the whole heap inO(*n*) operations.

**Observation:** Leaf nodes always satisfy the heap property and do not need to care for them. The leaf elements are always at the end and to heapify the given array it should be enough if we heapify the non-leaf nodes. Now let us concentrate on finding the first non-leaf node. The last element of the heap is at location*h* → *count* – 1, and to find the first non-leaf node it is enough to find the parent of the last element.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.108.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.109.png)

Time Complexity: The linear time bound of building heap can be shown by computing the sumof the heights of all the nodes. For a complete binary tree of height *h* containing n = 2*h+*1- 1 nodes, the sum of the heights of the nodes is *n – h -* 1 *= n* – *logn* – 1 (for proof refer to *Problems Section*). That means, building the heap operation can be done in linear time (O(*n*)) by applying a *PercolateDown* functionto the nodes inreverse level order.

7. **Heapsort**

One main application of heap ADT is sorting (heap sort). The heap sort algorithm inserts all elements (froman unsorted array) into a heap, then removes themfromthe root of a heap until the heap is empty. Note that heap sort can be done in place with the array to be sorted. Instead of deleting an element, exchange the first element (maximum) with the last element and reduce the heap size (array size). Then, we heapify the first element. Continue this process until the number of remainingelements is one.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.110.png)

Time complexity: As we remove the elements from the heap, the values become sorted (since maximum elements are always *root* only). Since the time complexity of both the insertion

algorithmand deletion algorithmis O(*logn*) (where *n* is the number of items in the heap), the time complexityof the heap sort algorithmis O(*nlogn*).

8. **Priority Queues [Heaps]: Problems & Solutions**

**Problem-1**  What are the minimumand maximumnumber of elements ina heap of height *h?*

**Solution:** Since heap is a complete binary tree (all levels contain full nodes except possibly the lowest level), it has at most 2*h+*1 – 1 elements (if it is complete). This is because, to get maximum nodes, we need to fill all the *h* levels completelyand the maximumnumber of nodes is nothingbut the sumof all nodes at all *h* levels.

To get minimum nodes, we should fill the *h* – 1 levels fully and the last level with only one element. As a result, the minimumnumber of nodes is nothing but the sumof all nodes from*h* – 1 levels plus 1 (for the last level) and we get 2*h* – 1 + 1 = 2*h* elements (if the lowest level has just 1 element and all the other levels are complete).

**Problem-2**  Is there a min-heap with seven distinct elements so that the preorder traversal of

it gives the elements insorted orde?

**Solution: Yes.** For the tree below, preorder traversal produces ascendingorder.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.111.jpeg)

**Problem-3**  Is there a max-heap with seven distinct elements so that the preorder traversal of

it gives the elements insorted order?

**Solution: Yes.** For the tree below, preorder traversal produces descendingorder.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.112.jpeg)

**Problem-4**  Is there a min-heap/max-heap with seven distinct elements so that the inorder

traversal of it gives the elements insorted order?

**Solution: No.** Since a heap must be either a min-heap or a max-heap, the root will hold the smallest element or the largest. An inorder traversal will visit the root of the tree as its second step, whichis not the appropriate place if the tree’s root contains the smallest or largest element.

**Problem-5**  Is there a min-heap/max-heap with seven distinct elements so that the postorder

traversal of it gives the elements insorted order?

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.113.png)

**Yes,** if the tree is a max-heap and we want descending order (below left), or if the tree is a min- heap and we want ascendingorder (below right).

**Problem-6**  Show that the height of a heap withnelements is *logn?*

**Solution:** Aheap is a complete binary tree. All the levels, except the lowest, are completely full. Aheap has at least 2*h* elements and at most elements 2*h* ≤ *n* ≤ 2*h+*1 – 1. This implies, *h* ≤ *logn* ≤ *h*

\+ 1. Since *h* is aninteger, *h = logn.*

**Problem-7**  Givena min-heap, give analgorithmfor findingthe maximumelement.

**Solution:** For a given min heap, the maximum element will always be at leaf only. Now, the next questionis how to find the leaf nodes inthe tree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.114.jpeg)

If we carefully observe, the next node of the last element’s parent is the first leaf node. Since the last element is always at the *h* → count – 1*th* location, the next node of its parent (parent at location![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.115.png) canbe calculated as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.116.png)

Now, the onlystep remainingis scanningthe leaf nodes and findingthe maximumamongthem.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.117.png)

Time Complexity: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.118.png).

**Problem-8**  Give analgorithmfor deletinganarbitraryelement fromminheap.

**Solution:** To delete an element, first we need to search for an element. Let us assume that we are using level order traversal for finding the element. After finding the element we need to follow the DeleteMinprocess.

Time Complexity= Time for findingthe element + Time for deletinganelement

- O(*n*) + *O* (*logn*) *≈* O(*n*). //Time for searching is dominated.

**Problem-9**  Give analgorithmfor deletingthe *ith* indexed element ina givenmin-heap. **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.119.png)

Time Complexity= O(*logn*).

**Problem-10**  Prove that, for a complete binary tree of height *h* the sum of the height of all

nodes is O(*n* – *h*).

**Solution:** A complete binary tree has 2*i* nodes on level (.Also, a node on level *i* has depth *i* and height *h* – *i*. Let us assume that *S* denotes the sum of the heights of all these nodes and *S* can be calculated as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.120.png)

Multiplyingwith2 onbothsides gives: 2*S =* 2*h +* 4(*h* – 1) + 8(*h* – 2) + ···+ 2*h* – 1(1) Now, subtract *S* from2*S*: 2*S* – *S* = *– h +* 2 *+* 4 + ··· + 2*h* ⇒ *S* = (2*h+*1 – 1) – (*h* – 1)

But, we already know that the total number of nodes *n* in a complete binary tree with height *h* is *n*

- 2*h+*1 – 1. This gives us: *h =* log(*n* + 1).

Finally, replacing2*h+*1 – 1 with*n*, gives: *S* = *n* – (*h* – 1) = O(*n* – *logn*) = O(*n* - *h*).

**Problem-11**  Give analgorithmto find all elements less thansome value of *k* ina binaryheap.

**Solution:** Start from the root of the heap. If the value of the root is smaller than *k* then print its value and call recursively once for its left child and once for its right child. If the value of a node is greater or equal than*k* thenthe functionstops without printingthat value.

The complexity of this algorithm is O(*n*), where *n* is the total number of nodes in the heap. This bound takes place in the worst case, where the value of every node in the heap will be smaller than*k*, so the functionhas to call eachnode of the heap.

**Problem-12**  Give analgorithmfor mergingtwo binarymax-heaps. Let us assume that the size

of the first heap is *m + n* and the size of the second heap is *n.*

**Solution:** One simple wayof solvingthis problemis:

- Assume that the elements of the first array (with size *m + n*) are at the beginning. That means, first *m* cells are filled and remaining*n* cells are empty.
- Without changingthe first heap, just append the second heap and heapifythe array.
- Since the total number of elements in the new array is *m + n*, each heapify operation takes O(*log*(*m + n*)).

The complexityof this algorithmis : O((*m* + *n*)*log*(*m + n*)). **Problem-13**  Canwe improve the complexityof [Problem-12](#_page91_x66.91_y261.19)?

**Solution:** Instead of heapifying all the elements of the *m + n* array, we can use the technique of “building heap with an array of elements (heapifying array)”. We can start with non-leaf nodes and heapifythem. The algorithmcanbe givenas:

- Assume that the elements of the first array (with size *m + n*) are at the beginning. That means, the first *m* cells are filled and the remaining*n* cells are empty.
- Without changingthe first heap, just append the second heap.
- Now, find the first non-leaf node and start heapifyingfromthat element.

In the theory section, we have already seen that building a heap with n elements takes O(*n*) complexity. The complexityof mergingwiththis technique is: O(*m* + *n*).

**Problem-14**  Is there an efficient algorithm for merging 2 max-heaps (stored as an array)?

Assume botharrays have *n* elements.

**Solution:** The alternative solution for this problem depends on what type of heap it is. If it’s a standard heap where everynode has up to two childrenand whichgets filled up so that the leaves are ona maximumof two different rows, we cannot get better thanO(*n*) for the merge.

There is an O(*logm* × *logn*) algorithmfor merging two binary heaps with sizes *m* and *n*. For *m = n*, this algorithm takes O(*log*2*n*) time complexity. We will be skipping it due to its difficulty and scope.

For better merging performance, we can use another variant of binary heap like a *Fibonacci- Heap* whichcanmerge inO(1) onaverage (amortized).

**Problem-15**  Give analgorithmfor findingthe *kth* smallest element inmin-heap. **Solution:** One simple solutionto this problemis: performdeletion*k* times frommin-heap.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.121.png)

Time Complexity: O(*klogn*). Since we are performing deletion operation *k* times and each deletiontakes O(*logn*).

**Problem-16**  For [Problem-15](#_page92_x66.91_y140.11), canwe improve the time complexity?

**Solution:** Assume that the original min-heap is called *HOrig* and the auxiliary min-heap is named *HAux*. Initially, the element at the top *of HOrig*, the minimumone, is inserted into *HAux*. Here we don’t do the operationof DeleteMinwith*HOrig.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.122.png)

Every while-loop iteration gives the *kth* smallest element and we need *k* loops to get the *kth* smallest elements. Because the size of the auxiliary heap is always less than *k*, every while-loop iteration the size of the auxiliary heap increases by one, and the original heap *HOrig* has no operationduringthe finding, the runningtime is O(*klogk*).

**Note:** The above algorithm is useful if the *k* value is too small compared to *n*. If the *k* value is approximately equal to *n*, then we can simply sort the array (let’s say, using *couting* sort or any

other linear sorting algorithm) and return *kth* smallest element from the sorted array. This gives O(*n*) solution.

**Problem-17**  Find *k* maxelements frommaxheap.

**Solution:** One simple solutionto this problemis: build max-heap and performdeletion*k* times.

*T*(*n*) = DeleteMinfromheap *k* times = *Θ*(*klogn*). **Problem-18**  For [Problem-17](#_page93_x66.91_y585.18), is there anyalternative solution?

**Solution:** We can use the [Problem-16](#_page92_x66.91_y393.06) solution. At the end, the auxiliary heap contains the k- largest elements. Without deletingthe elements we should keep onaddingelements to *HAux.*

**Problem-19**  How do we implement stackusingheap?

**Solution:** To implement a stack using a priority queue PQ (using min heap), let us assume that we are using one extra integer variable *c*. Also, assume that *c* is initialized equal to any known value (e.g., 0). The implementation of the stack ADT is given below. Here *c* is used as the priority while inserting/deletingthe elements fromPQ.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.123.png)

We could also increment *c* backwhenpopping.

**Observation:** We could use the negative of the current system time instead of *c* (to avoid overflow). The implementationbased onthis canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.124.png)

**Problem-20**  How do we implement Queue usingheap?

**Solution:** To implement a queue using a priority queue PQ (using min heap), as similar to stacks simulation, let us assume that we are using one extra integer variable, *c*. Also, assume that *c* is initialized equal to any known value (e.g., 0). The implementation of the queue ADT is given below. Here the *c* is used as the prioritywhile inserting/deletingthe elements fromPQ.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.125.png)

**Note:** We could also decrement *c* whenpopping.

**Observation:** We could use just the negative of the current system time instead of *c* (to avoid overflow). The implementationbased onthis canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.126.png)

**Note:** The onlychange is that we need to take a positive *c* value instead of negative.

**Problem-21**  Given a big file containing billions of numbers, how can you find the 10

maximumnumbers fromthat file?

**Solution:** Always remember that when you need to find max *n* elements, the best data structure to use is priorityqueues.

One solution for this problem is to divide the data in sets of 1000 elements (let’s say 1000) and make a heap of them, and then take 10 elements from each heap one by one. Finally heap sort all the sets of 10 elements and take the top 10 among those. But the problem in this approach is where to store 10 elements from each heap. That may require a large amount of memory as we

have billions of numbers.

Reusing the top 10 elements (from the earlier heap) in subsequent elements can solve this problem. That means take the first block of 1000 elements and subsequent blocks of 990 elements each. Initially, Heapsort the first set of 1000 numbers, take max 10 elements, and mix them with

990 elements of the 2*nd* set. Again, Heapsort these 1000 numbers (10 from the first set and 990 fromthe 2*nd* set), take 10 max elements, and mix themwith 990 elements of the 3*rd* set. Repeat till the last set of 990 (or less) elements and take max 10 elements from the final heap. These 10 elements will be your answer.

Time Complexity: O(*n*) = *n*/1000 ×(complexity of Heapsort 1000 elements) Since complexity of heap sorting1000 elements will be a constant so the O(*n*) = *n* i.e. linear complexity.

**Problem-22  Merge *k* sortedlists withtotal of *n* elements:** We are given *k* sorted lists with

total *n* inputs inall the lists. Give analgorithmto merge theminto one single sorted list.

**Solution:** Since there are *k* equal size lists witha total of *n* elements, the size of eachlist is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.127.png) One simple wayof solvingthis problemis:

- Take the first list and merge it with the second list. Since the size of each list is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.127.png), this step produces a sorted list with size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.128.png). This is similar to merge sort logic. The

time complexityof this step is: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.128.png). This is because we need to scan all the elements of boththe lists. • Then, merge the second list output withthe third list. As a result, this step produces a sorted list with size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.129.png). The time complexity of this step is: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.129.png). This is because we

need to scanall the elements of bothlists (one withsize ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.128.png) and the other withsize ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.127.png) ). • Continue this process until all the lists are merged to one list.

Total time complexity:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.130.png)

Space Complexity: O(1).

**Problem-23**  For [Problem-22](#_page96_x66.91_y241.74), canwe improve the time complexity?

**Solution:**

1  Divide the lists into pairs and merge them. That means, first take two lists at a time and merge themso that the total elements parsed for all lists is O(*n*). This operation gives *k*/2 lists.
1  Repeat step-1 until the number of lists becomes one.

Time complexity: Step-1 executes *logk* times and each operation parses all *n* elements in all the lists for making*k*/2 lists. For example, if we have 8 lists, thenthe first pass would make 4 lists by parsing all *n* elements. The second pass would make 2 lists by again parsing *n* elements and the third pass would give 1 list by again parsing n elements. As a result the total time complexity is O(*nlogn*).

Space Complexity: O(*n*).

**Problem-24**  For [Problem-23](#_page96_x66.91_y600.84), canwe improve the space complexity? **Solution:** Let us use heaps for reducingthe space complexity.

1. Build the max-heap withall the first elements fromeachlist inO(*k*).
1. In each step, extract the maximum element of the heap and add it at the end of the output.
1. Add the next element fromthe list of the one extracted. That means we need to select the next element of the list which contains the extracted element of the previous step.
1. Repeat step-2 and step-3 until all the elements are completed fromall the lists.

Time Complexity = O(*nlogk* ). At a time we have *k* elements max-heap and for all *n* elements we have to read just the heap in*logk* time, so total time = O(*nlogk*).

Space Complexity: O(*k*) [for Max-heap].

**Problem-25**  Given 2 arrays *A* and *B* each with *n* elements. Give an algorithm for finding

largest *n* pairs (*A*[*i*]*,B*[*j*]).

**Solution: Algorithm:**

- Heapify*A*and *B*. This step takes O(2*n*) ≈ O(*n*).
- Then keep on deleting the elements fromboth the heaps. Each step takes O(2*logn*) *≈* O(*logn*).

Total Time complexity: O(*nlogn*).

**Problem-26  Min-Max heap:** Give an algorithm that supports min and max in O(1) time,

insert, delete min, and delete max in O(*logn*) time. That means, design a data structure whichsupports the followingoperations:



| Operation                                                    | Complexity |
| ------------------------------------------------------------ | ---------- |
| Init                                                         | O(*n*)     |
| Insert                                                       | O(*logn*)  |
| FindMin                                                      | O(1)       |
| FindMax                                                      | O(1)       |
| Delete Min                                                   | O(*logn*)  |
|                                                              |            |
| Delete Max O(*logri*)![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.131.png)![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8c8ada64-b722-496c-87c0-2ca2a5f4f1cf.132.png) |            |

**Solution:** This problemcan be solved using two heaps. Let us say two heaps are: Minimum-Heap Hmin and Maximum-Heap Hmax. Also, assume that elements in both the arrays have mutual

pointers. That means, an element in Hmin will have a pointer to the same element in Hmax and an element inHmax will have a pointer to the same element inHmin.



| Init                                                         | Build Hmin inO(*n*) and Hmax inO(*n*)                        |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| Insert(x)                                                    | Insert xto Hmin inO(*logn*). Insert xto Hmax inO(*logn*). Update the pointers inO(1) |
| FindMin()                                                    | Returnroot(Hmin) inO(1)                                      |
| FindMax                                                      | Returnroot(Hmax) inO(1)                                      |
| Delete Min                                                   | Delete the minimumfromHmin inO(*logn*). Delete the same element from Hmax byusingthe mutual pointer inO(*logn*) |
| DeleteMax                                                    | Delete the maximumfromHmax inO(*logn*). Delete the same element from Hmin byusingthe mutual pointer inO(*logn*) |
| **Problem-27**  Dynamic median finding. Design a heap data structure that supports finding the |                                                              |

median.

**Solution:** In a set of *n* elements, median is the middle element, such that the number of elements lesser than the median is equal to the number of elements larger than the median. If *n* is odd, we can find the median by sorting the set and taking the middle element. If *n* is even, the median is usuallydefined as the average of the two middle elements. This algorithmworks even when some of the elements in the list are equal. For example, the median of the multiset {1, 1, 2, 3, 5} is 2, and the medianof the multiset {1, 1, 2, 3, 5, 8} is 2.5.

*“Median heaps”* are the variant of heaps that give access to the median element. A median heap can be implemented using two heaps, each containing half the elements. One is a max-heap, containing the smallest elements; the other is a min-heap, containing the largest elements. The size of the max-heap may be equal to the size of the min-heap, if the total number of elements is even. In this case, the median is the average of the maximumelement of the max-heap and the minimum element of the min-heap. If there is an odd number of elements, the max-heap will contain one more element than the min-heap. The median in this case is simply the maximum element of the max-heap.

**Problem-28  Maximumsuminsliding window:** Given array A[] with sliding window of size w which is moving from the very left of the array to the very right. Assume that we can onlysee the w numbers inthe window. Eachtime the slidingwindow moves rightwards by

one position. For example: The arrayis [1 3 -1 -3 5 3 6 7], and w is 3.



| Window position                                              | Max  |
| ------------------------------------------------------------ | ---- |
| [1 3 -1] -3 5 3 6 7                                          | 3    |
| 1 [3 -1 -3] 5 3 6 7                                          | 3    |
| 1 3 [-1 -3 5] 3 6 7                                          | 5    |
| 1 3 -1 [-3 5 3] 6 7                                          | 5    |
| 1 3 -1 -3 [5 3 6] 7                                          | 6    |
| 1 3 -1 -3 5 [3 6 7]                                          | 7    |
| **Input:** A long array A[], and a window width *w*. **Output:** An array B[], B[i] is the maximumvalue of fromA[i] to A[i+w-1] |      |

**Requirement:** Find a good optimal wayto get B[i]

**Solution:** Brute force solution is, every time the window is moved we can search for a total of *w* elements inthe window.

Time complexity: O(*nw*).

**Problem-29**  For [Problem-28](#_page98_x66.91_y707.68), canwe reduce the complexity?

**Solution: Yes,** we can use heap data structure. This reduces the time complexity to O(*nlogw*). Insert operation takes O(*logw*) time, where *w* is the size of the heap. However, getting the maximumvalue is cheap; it merelytakes constant time as the maximumvalue is always kept inthe

root (head) of the heap. As the window slides to the right, some elements in the heap might not be valid anymore (range is outside of the current window). How should we remove them? We would need to be somewhat careful here. Since we only remove elements that are out of the window’s range, we would need to keep trackof the elements’ indices too.

**Problem-30**  For [Problem-28](#_page98_x66.91_y707.68), canwe further reduce the complexity?

**Solution: Yes,** The double-ended queue is the perfect data structure for this problem. It supports insertion/deletion from the front and back. The trick is to find a way such that the largest element in the window would always appear in the front of the queue. How would you maintain this requirement as youpushand pop elements inand out of the queue?

Besides, you will notice that there are some redundant elements in the queue that we shouldn’t even consider. For example, if the current queue has the elements: [10 5 3], and a new element in the window has the element 11. Now, we could have emptied the queue without considering elements 10, 5, and 3, and insert onlyelement 11 into the queue.

Typically, most people try to maintain the queue size the same as the window’s size. Try to break away from this thought and think out of the box. Removing redundant elements and storing only elements that need to be considered inthe queue is the keyto achievingthe efficient O(*n*) solution below. This is because each element in the list is being inserted and removed at most once. Therefore, the total number of insert + delete operations is 2*n.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.001.png)

**Problem-31**  A priority queue is a list of items in which each item has associated with it a

priority. Items are withdrawnfroma priorityqueue inorder of their priorities startingwith the highest priority item first. If the maximum priority item is required, then a heap is constructed suchthanpriorityof everynode is greater thanthe priorityof its children.

Design such a heap where the itemwith the middle priority is withdrawn first. If there are n items in the heap, then the number of items with the priority smaller than the middle priorityis ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.002.png) if nis odd, else ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.003.png) ∓1.

Explainhow withdraw and insert operations work, calculate their complexity, and how the data structure is constructed.

**Solution:** We can use one min heap and one max heap such that root of the min heap is larger than the root of the max heap. The size of the min heap should be equal or one less than the size of the maxheap. So the middle element is always the root of the maxheap.

For the insert operation, if the new item is less than the root of max heap, then insert it into the max heap; else insert it into the min heap. After the withdraw or insert operation, if the size of heaps are not as specified above than transfer the root element of the max heap to min heap or vice-versa.

Withthis implementation, insert and withdraw operationwill be inO(*logn*) time. **Problem-32**  Giventwo heaps, how do youmerge (union) them?

**Solution:** Binary heap supports various operations quickly: Find-min, insert, decrease-key. If we have two min-heaps, H1 and H2, there is no efficient wayto combine theminto a single min-heap.

For solving this problem efficiently, we can use mergeable heaps. Mergeable heaps support efficient unionoperation. It is a data structure that supports the followingoperations:

- Create-Heap(): creates anemptyheap
- Insert(H,X,K) : insert anitemxwithkeyK into a heap H
- Find-Min(H) : returnitemwithminkey
- Delete-Min(H) : returnand remove
- Union(H1, H2) : merge heaps H1 and H2

Examples of mergeable heaps are:

- Binomial Heaps
- Fibonacci Heaps

Bothheaps also support:

- Decrease-Key(H,X,K): assignitemYwitha smaller keyK
- Delete(H,X) : remove itemX

**Binomial Heaps:** Unlike binary heap which consists of a single tree, a *binomial* heap consists of a small set of component trees and no need to rebuild everything when union is performed. Each component tree is ina special format, called a *binomial tree.*

Abinomial tree of order *k*, denoted by*Bk* is defined recursivelyas follows:

- *B*0 is a tree witha single node
- For *k* ≥ 1, *Bk* is formed by joining two *Bk*–1, such that the root of one tree becomes the leftmost child of the root of the other.

**Example:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.004.png)

**Fibonacci Heaps:** Fibonacci heap is another example of mergeable heap. It has no good worst- case guarantee for any operation (except Insert/Create-Heap). Fibonacci Heaps have excellent amortized cost to performeach operation. Like *binomial* heap, *fibonacci* heap consists of a set of min-heap ordered component trees. However, unlike binomial heap, it has

- No limit onnumber of trees (up to O(*n*)), and
- No limit onheight of a tree (up to O(*n*))

Also, *Find-Min, Delete-Min, Union, Decrease-Key, Delete* all have worst-case O(*n*) running time. However, inthe amortized sense, eachoperationperforms veryquickly.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.005.png)

**Problem-33**  Medianinaninfinite series of integers

**Solution:** Median is the middle number in a sorted list of numbers (if we have odd number of elements). If we have evennumber of elements, medianis the average of two middle numbers ina sorted list of numbers.

We cansolve this problemefficientlybyusing2 heaps: One MaxHeap and one MinHeap.

1. MaxHeap contains the smallest half of the received integers
1. MinHeap contains the largest half of the received integers

The integers in MaxHeap are always less than or equal to the integers in MinHeap. Also, the number of elements in MaxHeap is either equal to or 1 more than the number of elements in the MinHeap.

In the stream if we get 2*n* elements (at any point of time), MaxHeap and MinHeap will both contain equal number of elements (in this case, *n* elements in each heap). Otherwise, if we have received 2*n* + 1 elements, MaxHeap will contain*n* + 1 and MinHeap *n*.

Let us find the Median: If we have 2*n* + 1 elements (odd), the Median of received elements will be the largest element in the MaxHeap (nothing but the root of MaxHeap). Otherwise, the Median of received elements will be the average of largest element in the MaxHeap (nothing but the root of MaxHeap) and smallest element inthe MinHeap (nothingbut the root of MinHeap). This canbe calculated inO(1).

Inserting an element into heap can be done in O(*logn*). Note that, any heap containing *n* + 1 elements might need one delete operation(and insertionto other heap) as well.

**Example:**

Insert 1: Insert to MaxHeap. MaxHeap: {1}, MinHeap:{}

Insert 9: Insert to MinHeap. Since 9 is greater than 1 and MinHeap maintains the maximum elements.

MaxHeap: {1}, MinHeap:{9}

Insert 2: Insert MinHeap. Since 2 is less thanall elements of MinHeap. MaxHeap: {1,2}, MinHeap:{9}

Insert 0: Since MaxHeap already has more than half; we have to drop the max element from MaxHeap and insert it to MinHeap. So, we have to remove 2 and insert into MinHeap. Withthat it becomes:

MaxHeap: {1}, MinHeap:{2,9}

Now, insert 0 to MaxHeap.

Total Time Complexity: O(*logn*).

**Problem-34**  Suppose the elements 7, 2, 10 and 4 are inserted, in that order, into the valid 3-

ary max heap found in the above question, Which one of the following is the sequence of items inthe arrayrepresentingthe resultant heap?

1) 10, 7, 9, 8, 3, 1, 5, 2, 6, 4
2) 10, 9, 8, 7, 6, 5, 4, 3, 2, 1
3) 10, 9, 4, 5, 7, 6, 8, 2, 1, 3
4) 10, 8, 6, 9, 7, 2, 3, 4, 1, 5

**Solution:** The 3-arymaxheap withelements 9, 5, 6, 8, 3, 1 is:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.006.jpeg)

After Insertionof 7:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.007.jpeg)

After Insertionof 2:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.008.jpeg)

After Insertionof 10:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.009.jpeg)

After Insertionof 4:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.010.jpeg)

**Problem-35**  A complete binary min-heap is made by including each integer in [1,1023]

exactly once. The depth of a node in the heap is the length of the path from the root of the heap to that node. Thus, the root is at depth 0. The maximum depth at which integer 9 can appear is.

**Solution:** As shown in the figure below, for a given number *i*, we can fix the element *i* at *ith* level and arrange the numbers 1 to *i* – 1 to the levels above. Since the root is at depth *zero*, the

maximum depth of the *ith* element in a min-heap is *i* – 1. Hence, the maximum depth at which integer 9 canappear is 8.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.011.jpeg)

**Problem-36**  A *d*-ary heap is like a binary heap, but instead of 2 children, nodes have *d*

children. How would yourepresent a *d*-aryheap with*n* elements in an array? What are the expressions for determining the parent of a given element, *Parent*(*i*), and a *jth* child of a givenelement, *Child*(*i,j*), where 1 ≤ j ≤ d?

**Solution:** The following expressions determine the parent and *jth* child of element i (where 1 ≤ j

- d):

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.012.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.013.png)

1. **Introduction**

In this chapter, we will represent an important mathematics concept: *sets*. This means how to represent a group of elements which do not need any order. The disjoint sets ADT is the one used for this purpose. It is used for solving the equivalence problem. It is very simple to implement. A simple array can be used for the implementation and each function takes only a few lines of code. Disjoint sets ADT acts as an auxiliary data structure for many other algorithms (for example, *Kruskal’s* algorithm in graph theory). Before starting our discussion on disjoint sets ADT, let us lookat some basic properties of sets.

2. **Equivalence Relations and Equivalence Classes**

For the discussion below let us assume that 5 is a set containing the elements and a relation *R* is defined onit. That means for everypair of elements in*a,b* ∈ 5, *a R b* is either true or false. If *a R* *b* is true, then we say *a* is related to *b*, otherwise *a* is not related to *b. A* relation *R* is called an *equivalence relation* if it satisfies the followingproperties:

- *Reflexive:* For everyelement *a* ∈ *S.aR a* is true.
- *Symmetric:* For anytwo elements *a, b* ∈ *S*, if *a R b* is true then*b R a* is true.
- *Transitive:* For any three elements a, b, c ∈ S, if a R b and *b R c* are true then *a R c* is true.

As an example, relations ≤ (less than or equal to) and ≥ (greater than or equal to) on a set of integers are not equivalence relations. Theyare reflexive (since *a ≤ a*) and transitive (*a ≤ b* and *b*

- *c* implies *a ≤* c) but not symmetric (*a ≤ b* does not imply*b ≤ a*).

Similarly, *rail connectivity* is an equivalence relation. This relation is reflexive because any location is connected to itself. If there is connectivity from city *a* to city *b*, then city *b* also has connectivityto city*a*, so the relation is symmetric. Finally, if city *a* is connected to city *b* and city *b* is connected to cityc, thencity*a* is also connected to city*c.*

The *equivalence class* of an element *a* ∈ *S* is a subset of *S* that contains all the elements that are related to *a*. Equivalence classes create a *partition* of *S*. Every member of *S* appears in exactly one equivalence class. To decide if *a R b*, we just need to check whether *a* and *b* are in the same equivalence class (group) or not.

In the above example, two cities will be in same equivalence class if they have rail connectivity. If theydo not have connectivitythentheywill be part of different equivalence classes.

Since the intersection of any two equivalence classes is empty (*ϕ*), the equivalence classes are sometimes called *disjoint sets*. In the subsequent sections, we will try to see the operations that canbe performed onequivalence classes. The possible operations are:

- Creatinganequivalence class (makinga set)
- Findingthe equivalence class name (Find)
- Combiningthe equivalence classes (Union)

3. **Disjoint Sets ADT**

To manipulate the set elements we need basic operations defined on sets. In this chapter, we concentrate onthe followingset operations:

- MAKESET(*X*): Creates a new set containinga single element *X.*
- UNION(*X*, *Y*): Creates a new set containing the elements *X* and *Y* in their union and deletes the sets containingthe elements *X* and *Y.*
- FIND(*X*): Returns the name of the set containingthe element *X.*

4. **Applications**

Disjoint sets ADT have manyapplications and a few of themare:

- To represent networkconnectivity
- Image processing
- To find least commonancestor
- To define equivalence of finite state automata
- Kruskal’s minimumspanningtree algorithm(graphtheory)
- Ingame algorithms

5. **Tradeoffs in Implementing Disjoint Sets ADT**

Let us see the possibilities for implementing disjoint set operations. Initially, assume the input elements are a collection of *n* sets, each with one element. That means, initial representation assumes all relations (except reflexive relations) are false. Each set has a different element, so that *Si* ∩ *Sj=* ф. This makes the sets *disjoint.*

To add the relation *a R b* (UNION), we first need to check whether *a* and *b* are already related or not. This can be verified by performing FINDs on both *a* and *b* and checking whether they are in the same equivalence class (set) or not.

If they are not, then we apply UNION. This operation merges the two equivalence classes containing*a* and *b* into a new equivalence class by creating a new set *Sk = Si* ∪ *Sj* and deletes *Si*

and *Sj*. Basicallythere are two ways to implement the above FIND/UNION operations:

- Fast FIND implementation(also called QuickFIND)
- Fast UNION operationimplementation(also called QuickUNION)

6. **Fast FIND Implementation (Quick FIND)**

In this method, we use an array. As an example, in the representation below the array contains the set name for each element. For simplicity, let us assume that all the elements are numbered sequentiallyfrom0 to *n* – 1.

In the example below, element 0 has the set name 3, element 1 has the set name 5, and so on. With this representation FIND takes only O(1) since for any element we can find the set name by accessingits arraylocationinconstant time.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.014.png)

In this representation, to perform UNION(*a*, *b*) [assuming that *a* is in set *i* and *b* is in set *j*] we need to scanthe complete arrayand change all *i’s to j*. This takes O(*n*).

Asequence of *n* – 1 unions take O(*n*2) time in the worst case. If there are O(*n*2) FIND operations, this performance is fine, as the average time complexity is O(1) for each UNION or FIND operation. If there are fewer FINDs, this complexityis not acceptable.

7. **Fast UNION Implementation (Quick UNION)**

In this and subsequent sections, we will discuss the faster *UNION* implementations and its variants. There are different ways of implementing this approach and the following is a list of a few of them.

- Fast UNION implementations (Slow FIND)
- Fast UNION implementations (QuickFIND)
- Fast UNION implementations withpathcompression

8. **Fast UNION Implementation (Slow FIND)**

As we have discussed, FIND operation returns the same answer (set name) if and only if they are in the same set. In representing disjoint sets, our main objective is to give a different set name for each group. In general we do not care about the name of the set. One possibility for implementing the set is *tree* as eachelement has onlyone *root* and we canuse it as the set name.

**How are these represented?** One possibilityis usinganarray: for eachelement keep the *root* as its set name. But with this representation, we will have the same problem as that of FIND array implementation. To solve this problem, instead of storing the *root* we can keep the parent of the element. Therefore, usinganarraywhichstores the parent of eachelement solves our problem.

To differentiate the root node, let us assume its parent is the same as that of the element in the array. Based onthis representation, MAKESET, FIND, UNION operations canbe defined as:

- (*X*): Creates a new set containing a single element *X* and in the array update the parent of *X* as *X*. That means root (set name) of *X* is *X.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.015.png)

- UNION(X, *Y*): Replaces the two sets containing *X* and *Y* by their union and in the arrayupdates the parent of *X* as *Y.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.016.jpeg)

- FIND(X): Returns the name of the set containing the element *X*. We keep on searchingfor *X’s* set name until we come to the root of the tree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.017.jpeg)

For the elements 0 to *n* – 1 the initial representationis:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.018.png)

To performa UNION on two sets, we merge the two trees by making the root of one tree point to the root of the other.

Initial Configurationfor the elements 0 to 6

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.019.png)

After UNION(5,6)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.020.png)

After UNION( 1,2)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.021.png)

After UNION(0,2)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.022.png)

One important thing to observe here is, UNION operation is changing the root’s parent only, but not for all the elements inthe sets. Due to this, the time complexityof UNION operationis O(1).

A FIND(X) on element *X* is performed by returning the root of the tree containing *X*. The time to performthis operationis proportional to the depthof the node representing*X.*

Using this method, it is possible to create a tree of depth *n -* 1 (Skew Trees). The worst-case running time of a FIND is O(*n*) and *m* consecutive FIND operations take O(*mn*) time in the worst case.

**MAKESET**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.023.png)

**FIND**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.024.png)

**UNION**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.025.png)

9. **Fast UNION Implementations (Quick FIND)**

The main problem with the previous approach is that, in the worst case we are getting the skew trees and as a result the FIND operation is taking O(*n*) time complexity. There are two ways to improve it:

- UNION by Size (also called UNION by Weight): Make the smaller tree a subtree of the larger tree
- UNION by Height (also called UNION by Rank): Make the tree with less height a subtree of the tree withmore height

**UNION by Size**

In the earlier representation, for each element *i* we have stored *i* (in the parent array) for the root element and for other elements we have stored the parent of *i*. But in this approach we store negative of the size of the tree (that means, if the size of the tree is 3 then store –3 in the parent array for the root element). For the previous example (after UNION(0,2)), the new representation will looklike:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.026.png)

Assume that the size of one element set is 1 and store – 1. Other thanthis there is no change.

**MAKESET**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.027.png)

**FIND**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.028.png)

**UNION by Size**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.029.png)

**Note:** There is no change inFIND operationimplementation.

**UNION by Height (UNION by Rank)**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.030.png)

As in UNION by size, in this method we store negative of height of the tree (that means, if the height of the tree is 3 then we store –3 in the parent array for the root element). We assume the height of a tree with one element set is 1. For the previous example (after UNION(0,2)), the new representationwill looklike:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.031.png)

**UNION by Height**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.032.png)

**Note:** For FIND operationthere is no change inthe implementation.

**Comparing UNION by Size and UNION by Height**

With UNION by size, the depth of any node is never more than *logn*. This is because a node is initially at depth 0. When its depth increases as a result of a UNION, it is placed in a tree that is at least twice as large as before. That means its depth can be increased at most *logn* times. This means that the running time for a FIND operation is O(*logn*), and a sequence of *m* operations takes O(*m logn*).

Similarly with UNION by height, if we take the UNION of two trees of the same height, the height of the UNION is one larger than the common height, and otherwise equal to the max of the two heights. This will keep the height of tree of *n* nodes fromgrowing past O(*logn*). A sequence of *m* UNIONs and FINDs canthenstill cost O(*m logn*).

**Path Compression**

FIND operation traverses a list of nodes on the way to the root. We can make later FIND operations efficient by making each of these vertices point directly to the root. This process is called *path compression*. For example, in the FIND(*X*) operation, we travel from*X* to the root of the tree. The effect of path compression is that every node on the path from *X* to the root has its parent changed to the root.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.033.jpeg)

With path compression the only change to the FIND function is that *S*[*X*] is made equal to the value returned by FIND. That means, after the root of the set is found recursively, *X* is made to point directlyto it. This happenrecursivelyto everynode onthe pathto the root.

**FIND with path compression**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.034.png)

**Note:** Path compression is compatible with UNION by size but not with UNION by height as

there is no efficient wayto change the height of the tree.

10. **Summary**

Performing*m* union-find operations ona set of *n* objects.



| Algorithm                                  | Worst-case time  |
| ------------------------------------------ | ---------------- |
| Quick-Find                                 | *mn*             |
| Quick-Union                                | *mn*             |
| Quick-UnionbySize/Height                   | *n* + *m logn*   |
| Pathcompression                            | *n + m logn*     |
| Quick-UnionbySize/Height + PathCompression | (*m + n*) *logn* |

11. **Disjoint Sets: Problems & Solutions**

**Problem-1**  Consider a list of cities *c*1; *c*2*,...,cn*. Assume that we have a relation *R* such that,

for any *i,j, R*(*ci,cj*) is 1 if cities *ci* and *cj* are in the same state, and 0 otherwise. If *R* is stored as a table, how muchspace does it require?

**Solution:** *R* must have anentryfor everypair of cities. There are Θ(*n*2) of these.

**Problem-2**  For [Problem-1](#_page22_x66.91_y372.31), usinga Disjoint sets ADT, give analgorithmthat puts eachcityin

a set suchthat *ci* and *cj* are inthe same set if and onlyif theyare inthe same state.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.035.png)

**Problem-3**  For [Problem-1](#_page22_x66.91_y372.31), when the cities are stored in the Disjoint sets ADT, if we are

giventwo cities *ci* and *cj*, how do we checkif theyare inthe same state?

**Solution:** Cities *ci* and *cj* are inthe same state if and onlyif FIND(*ci*) = FIND(*cj*).

**Problem-4**  For [Problem-1](#_page22_x66.91_y372.31), if we use linked-lists with UNION by size to implement the

union-find ADT, how muchspace do we use to store the cities?

**Solution:** There is one node per city, so the space is Θ(*n*).

**Problem-5**  For [Problem-1](#_page22_x66.91_y372.31), if we use trees with UNION by rank, what is the worst-case

runningtime of the algorithmfrom[Problem-2](#_page22_x66.91_y465.92)?

**Solution:** Whenever we do a UNION in the algorithm from [Problem-2](#_page22_x66.91_y465.92), the second argument is a tree of size 1. Therefore, all trees have height 1, so each union takes time O(1). The worst-case runningtime is thenΘ(*n*2).

**Problem-6**  If we use trees without union-by-rank, what is the worst-case running time of the

algorithmfrom[Problem-2](#_page22_x66.91_y465.92)? Are there more worst-case scenarios than[Problem-5](#_page23_x66.91_y171.38)?

**Solution:** Because of the special case of the unions, union-by-rank does not make a difference for our algorithm. Hence, everythingis the same as in[Problem-5](#_page23_x66.91_y171.38).

**Problem-7**  With the quick-union algorithm we know that a sequence of *n* operations (*unions*

and *finds*) can take slightly more than linear time in the worst case. Explain why if all the *finds* are done before all the *unions*, a sequence of n operations is guaranteed to take O(*n*) time.

**Solution:** If the *find* operations are performed first, then the *find* operations take O(1) time each because everyitemis the root of its owntree. No itemhas a parent, so findingthe set anitemis in takes a fixed number of operations. Union operations always take O(1) time. Hence, a sequence of noperations withall the *finds* before the *unions* takes O(*n*) time.

**Problem-8**  Withreference to [Problem-7](#_page23_x66.91_y361.49), explain why if all the unions are done before all the

finds, a sequence of noperations is guaranteed to take O(*n*) time.

**Solution:** This problem requires amortized analysis. *Find* operations can be expensive, but this expensive *find* operationis balanced out bylots of cheap *union* operations.

The accounting is as follows. *Union* operations always take O(1) time, so let’s say they have an actual cost of ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)1. Assign each *union* operation an amortized cost of ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)2, so every *union* operation puts ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)1 in the account. Each *union* operation creates a new child. (Some node that was not a child of any other node before is a child now.) When all the union operations are done, there is $1 inthe account for everychild, or in other words, for everynode witha depthof one or

greater. Let’s say that a *find*(*u*) operation costs ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)1 if *u* is a root. For any other node, the *find* operation costs an additional ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)1 for each parent pointer the *find* operation traverses. So the actual cost is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png) (1 + *d*), where *d* is the depth of *u*. Assign each *find* operation an amortized cost of ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)2. This covers the case where *u* is a root or a child of a root. For each additional parent pointer traversed, ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)1 is withdrawnfromthe account to payfor it.

Fortunately, path compression changes the parent pointers of all the nodes we pay ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)1 to traverse, so these nodes become children of the root. All of the traversed nodes whose depths are 2 or greater move up, so their depths are now 1. We will never have to pay to traverse these nodes again. Saythat a node is a grandchild if its depthis 2 or greater.

Every time *find*(*u*) visits a grandchild, ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)1 is withdrawn from the account, but the grandchild is no longer a grandchild. So the maximum number of dollars that can ever be withdrawn from the account is the number of grandchildren. But we initially put $1 in the bank for every child, and every grandchild is a child, so the bank balance will never drop below zero. Therefore, the

amortization works out. *Union* and *find* operations both have amortized costs of ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.036.png)2, so any sequence of noperations where all the unions are done first takes O(*n*) time.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.037.png)

1. **Introduction**

In the real world, many problems are represented in terms of objects and connections between them. For example, in an airline route map, we might be interested in questions like: “What’s the fastest way to go from Hyderabad to New York?” *or* “What is the cheapest way to go from Hyderabad to New York?” To answer these questions we need information about connections (airline routes) between objects (towns). Graphs are data structures used for solving these kinds of problems.

2. **Glossary**

**Graph:** A graph is a pair (*V, E*), where *V* is a set of nodes, called *vertices*, and £ is a collection of pairs of vertices, called *edges.*

- *Vertices* and *edges* are positions and store elements
- Definitions that we use:
- *Directed edge:*
- ordered pair of vertices (*u, v*)
- first vertex*u* is the origin
- second vertex*v* is the destination
- Example: one-wayroad traffic

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.038.png)

- *Undirected edge:*
- unordered pair of vertices (*u, v*)
- Example: railwaylines

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.039.png)

- *Directed graph:*
- all the edges are directed
- Example: route network

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.040.png)

- *Undirected graph:*
- all the edges are undirected
- Example: flight network

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.041.png)

- When an edge connects two vertices, the vertices are said to be adjacent to each other and the edge is incident onbothvertices.
- Agraphwithno cycles is called a *tree*. Atree is anacyclic connected graph.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.042.png)

- Aself loop is anedge that connects a vertexto itself.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.043.png)

- Two edges are parallel if theyconnect the same pair of vertices.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.044.png)

- The *D*egree of a vertexis the number of edges incident onit.
- A subgraph is a subset of a graph’s edges (with associated vertices) that form a graph.
- A path in a graph is a sequence of adjacent vertices. *S*imple path is a path with no repeated vertices. Inthe graphbelow, the dotted lines represent a pathfrom*G* to *E.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.045.png)

- A cycle is a path where the first and last vertices are the same. A simple cycle is a cycle withno repeated vertices or edges (except the first and last vertices).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.046.png)

- We say that one vertex is connected to another if there is a path that contains both of them.
- Agraphis connected if there is a pathfrom*every* vertexto everyother vertex.
- If a graphis not connected thenit consists of a set of connected components.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.047.png)

- A*directed* acyclic graph[DAG] is a directed graphwithno cycles.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.048.png)

- Aforest is a disjoint set of trees.
- A spanning tree of a connected graph is a subgraph that contains all of that graph’s vertices and is a single tree. A spanning forest of a graph is the union of spanning trees of its connected components.
- Abipartite graphis a graphwhose vertices canbe divided into two sets suchthat all edges connect a vertexinone set witha vertexinthe other set.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.049.png)

- In *weighted graphs* integers (*weights*) are assigned to each edge to represent (distances or costs).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.050.jpeg)

- Graphs withall edges present are called *complete* graphs.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.051.png)

- Graphs with relatively few edges (generally if it edges < |*V*| log |*V|*) are called *sparse graphs.*
- Graphs withrelativelyfew of the possible edges missingare called *dense.*
- Directed weighted graphs are sometimes called *network.*
- We will denote the number of vertices in a given graph by *|V|*, and the number of edges by *|E|*. Note that *E* can range anywhere from 0 to |*V*|(|*V*| – l)/2 (in undirected graph). This is because eachnode canconnect to everyother node.

3. **Applications of Graphs**

- Representingrelationships betweencomponents inelectronic circuits
- Transportationnetworks: Highwaynetwork, Flight network
- Computer networks: Local area network, Internet, Web
- Databases: For representing ER (Entity Relationship) diagrams in databases, for representingdependencyof tables indatabases

4. **Graph Representation**

As inother ADTs, to manipulate graphs we need to represent theminsome useful form. Basically, there are three ways of doingthis:

- AdjacencyMatrix
- AdjacencyList
- AdjacencySet

**Adjacency Matrix**

**Graph Declaration for Adjacency Matrix**

First, let us look at the components of the graph data structure. To represent graphs, we need the number of vertices, the number of edges and also their interconnections. So, the graph can be declared as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.052.png)

**Description**

In this method, we use a matrix with size *V* × *V*. The values of matrix are boolean. Let us assume the matrixis *Adj*. The value *Adj*[*u, v*] is set to 1 if there is an edge fromvertex u to vertex v and 0 otherwise.

In the matrix, each edge is represented by two bits for undirected graphs. That means, an edge from**u**to **v** is represented by1 value inboth*Adj*[**u**,**v** ] and *Adj*[*u,v*]. To save time, we canprocess only half of this symmetric matrix. Also, we can assume that there is an “edge” from each vertex to itself. So, *Adj*[u, u] is set to 1 for all vertices.

If the graphis a directed graphthenwe need to markonlyone entryinthe adjacencymatrix. As an example, consider the directed graphbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.053.png)

The adjacencymatrixfor this graphcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.054.png)

Now, let us concentrate onthe implementation. To read a graph, one wayis to first read the vertex names and thenread pairs of vertexnames (edges). The code below reads anundirected graph.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.055.jpeg)

The adjacency matrix representation is good if the graphs are dense. The matrix requires O(V2) bits of storage and O(V2) time for initialization. If the number of edges is proportional to V2, then there is no problem because V2 steps are required to read the edges. If the graph is sparse, the initializationof the matrixdominates the runningtime of the algorithmas it takes takes O(V2).

**Adjacency List**

**Graph Declaration for Adjacency List**

In this representation all the vertices connected to a vertex *v* are listed on an adjacency list for that vertex *v*. This can be easily implemented with linked lists. That means, for each vertex *v* we use a linked list and list nodes represents the connections between*v* and other vertices to which *v* has anedge.

The total number of linked lists is equal to the number of vertices in the graph. The graph ADT canbe declared as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.056.png)

**Description**

Considering the same example as that of the adjacency matrix, the adjacency list representation canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.057.jpeg)

Since vertex A has an edge for B and D, we have added them in the adjacency list for A. The same is the case withother vertices as well.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.058.jpeg)For this representation, the order of edges in the input is *important*. This is because they determine the order of the vertices on the adjacency lists. The same graph can be represented in many different ways in an adjacency list. The order in which edges appear on the adjacency list affects the order inwhichedges are processed byalgorithms.

**Disadvantages of Adjacency Lists**

Using adjacency list representation we cannot perform some operations efficiently. As an example, consider the case of deleting a node. . In adjacency list representation, it is not enugh if we simply delete a node from the list representation, if we delete a node from the adjacency list then that is enough. For each node on the adjacency list of that node specifies another vertex. We need to search other nodes linked list also for deleting it. This problem can be solved by linking the two list nodes that correspond to a particular edge and making the adjacency lists doubly linked. But all these extra links are riskyto process.

**Adjacency Set**

It is very much similar to adjacency list but instead of using Linked lists, Disjoint Sets [Union- Find] are used. For more details refer to the *[Disjoint Sets ADT*](#_page8_x28.00_y82.94)* chapter.

**Comparison of Graph Representations**

Directed and undirected graphs are represented with the same structures. For directed graphs, everything is the same, except that each edge is represented just once. An edge from *x* to *y* is represented bya 1 value in*Agj*[*x*][*y*] inthe adjacencymatrix, or byaddingyon*x’s* adjacency list. For weighted graphs, everythingis the same, except fill the adjacencymatrixwithweights instead of booleanvalues.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.059.png)

5. **Graph Traversals**

To solve problems on graphs, we need a mechanism for traversing the graphs. Graph traversal algorithms are also called *graph search* algorithms. Like trees traversal algorithms (Inorder, Preorder, Postorder and Level-Order traversals), graph search algorithms can be thought of as startingat some source vertexina graphand “searching” the graphbygoingthroughthe edges and markingthe vertices. Now, we will discuss two suchalgorithms for traversingthe graphs.

- DepthFirst Search[DFS]
- BreadthFirst Search[BFS]

**Depth First Search [DFS]**

DFS algorithm works in a manner similar to preorder traversal of the trees. Like preorder traversal, internallythis algorithmalso uses stack.

Let us consider the following example. Suppose a person is trapped inside a maze. To come out fromthat maze, the personvisits eachpathand eachintersection(inthe worst case). Let us saythe personuses two colors of paint to markthe intersections alreadypassed. Whendiscoveringa new intersection, it is marked grey, and he continues to go deeper.

After reaching a “dead end” the person knows that there is no more unexplored path fromthe grey intersection, which now is completed, and he marks it with black. This “dead end” is either an intersection which has already been marked grey or black, or simply a path that does not lead to anintersection.

The intersections of the maze are the vertices and the paths between the intersections are the edges of the graph. The process of returning from the “dead end” is called *backtracking*. We are trying to go away from the starting vertex into the graph as deep as possible, until we have to backtrack to the preceding grey vertex. In DFS algorithm, we encounter the following types of edges.



| *Tree edge:* encounter new vertex                            |
| ------------------------------------------------------------ |
| *Back edge:* fromdescendent to ancestor                      |
| *Forward edge:* fromancestor to descendent                   |
| *Cross edge:* betweena tree or subtrees                      |
| For most algorithms boolean classification, unvisited/visited is enough (for three color implementation refer to problems section). That means, for some problems we need to use three colors, but for our discussiontwo colors are enough. |

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.060.png)

Initially all vertices are marked unvisited (false). The DFS algorithm starts at a vertex *u* in the graph. By starting at vertex *u* it considers the edges from *u* to other vertices. If the edge leads to an already visited vertex, then backtrack to current vertex *u*. If an edge leads to an unvisited vertex, then go to that vertex and start processing from that vertex. That means the new vertex becomes the current vertex. Follow this process until we reach the dead-end. At this point start *backtracking.*

The process terminates when backtracking leads back to the start vertex. The algorithm based on this mechanismis givenbelow: assume Visited[] is a global array.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.061.jpeg)

As an example, consider the following graph. We can see that sometimes an edge leads to an alreadydiscovered vertex. These edges are called *back edges*, and the other edges are called *tree edges* because deletingthe backedges fromthe graphgenerates a tree.

The final generated tree is called the DFS tree and the order in which the vertices are processed is called *DFS numbers* of the vertices. In the graph below, the gray color indicates that the vertex is visited (there is no other significance). We need to see whenthe Visited table is updated.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.062.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.063.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.064.jpeg) From the above diagrams, it can be seen that the DFS traversal creates a tree (without back edges) and we call such tree a *DFS tree*. The above algorithm works even if the given graph has connected components.

The time complexity of DFS is O(*V + E*), if we use adjacency lists for representing the graphs. This is because we are starting at a vertex and processing the adjacent nodes only if they are not visited. Similarly, if an adjacency matrix is used for a graph representation, then all edges

adjacent to a vertexcan’t be found efficiently, and this gives O(*V*2) complexity.

**Applications of DFS**

- Topological sorting
- Findingconnected components
- Findingarticulationpoints (cut vertices) of the graph
- Findingstronglyconnected components
- Solvingpuzzles suchas mazes

For algorithms refer to *Problems Section.*

**Breadth First Search [BFS]**

The BFS algorithm works similar to *level – order* traversal of the trees. Like *level – order* traversal, BFS also uses queues. In fact, *level – order* traversal got inspired from BFS. BFS works level by level. Initially, BFS starts at a given vertex, which is at level 0. In the first stage it visits all vertices at level 1 (that means, vertices whose distance is 1 from the start vertex of the graph). In the second stage, it visits all vertices at the second level. These new vertices are the ones whichare adjacent to level 1 vertices.

BFS continues this process until all the levels of the graph are completed. Generally *queue* data structure is used for storingthe vertices of a level.

As similar to DFS, assume that initially all vertices are marked *unvisited* (*false*). Vertices that have been processed and removed from the queue are marked *visited* (*true*). We use a queue to represent the visited set as it will keep the vertices in the order of when they were first visited. The implementationfor the above discussioncanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.065.jpeg)

As an example, let us consider the same graph as that of the DFS example. The BFS traversal can be shownas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.066.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.067.jpeg) Time complexity of BFS is O(*V + E*), if we use adjacency lists for representing the graphs, and O(*V*2) for adjacencymatrixrepresentation.

**Applications of BFS**

- Findingall connected components ina graph
- Findingall nodes withinone connected component
- Findingthe shortest pathbetweentwo nodes
- Testinga graphfor bipartiteness

**Comparing DFS and BFS**

Comparing BFS and DFS, the big advantage of DFS is that it has much lower memory requirements than BFS because it’s not required to store all of the child pointers at each level. Depending on the data and what we are looking for, either DFS or BFS can be advantageous. For example, in a family tree if we are looking for someone who’s still alive and if we assume that person would be at the bottom of the tree, then DFS is a better choice. BFS would take a very longtime to reachthat last level.

The DFS algorithmfinds the goal faster. Now, if we were looking for a family member who died a very long time ago, then that person would be closer to the top of the tree. In this case, BFS finds faster than DFS. So, the advantages of either vary depending on the data and what we are lookingfor.

DFS is related to preorder traversal of a tree. Like *preorder* traversal, DFS visits each node before its children. The BFS algorithmworks similar to *level – order* traversal of the trees.

If someone asks whether DFS is better or BFS is better, the answer depends on the type of the problem that we are trying to solve. BFS visits each level one at a time, and if we know the solution we are searching for is at a low depth, then BFS is good. DFS is a better choice if the solution is at maximum depth. The below table shows the differences between DFS and BFS in terms of their applications.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.068.png)

6. **TopologicalSort**

*Topological sort* is an ordering of vertices in a directed acyclic graph[DAG] in which each node comes before all nodes to which it has outgoing edges. As an example, consider the course

prerequisite structure at universities. A directed *edge* (*v,w*) indicates that course *v* must be completed before course *w*. Topological orderingfor this example is the sequence whichdoes not violate the prerequisite requirement. Every DAG may have one or more topological orderings. Topological sort is not possible if the graph has a cycle, since for two vertices *v* and w on the cycle, *v* precedes w and w precedes *v.*

Topological sort has an interesting property. All pairs of consecutive vertices in the sorted order are connected by edges; then these edges form a directed Hamiltonian path [refer to *Problems Section*] in the DAG. If a Hamiltonian path exists, the topological sort order is unique. If a topological sort does not form a Hamiltonian path, DAG can have two or more topological orderings. In the graph below: 7, 5, 3, 11, 8, 2, 9, 10 and 3, 5, 7, 8, 11, 2, 9, 10 are both topological orderings.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.069.jpeg)

Initially, *indegree* is computed for all vertices, starting with the vertices which are having indegree 0. That means consider the vertices whichdo not have anyprerequisite. To keep trackof vertices withindegree zero we canuse a queue.

All vertices of indegree 0 are placed on queue. While the queue is not empty, a vertex *v* is removed, and all edges adjacent to *v* have their indegrees decremented. A vertex is put on the queue as soon as its indegree falls to 0. The topological ordering is the order in which the vertices DeQueue.

The time complexityof this algorithmis O(|*E*|+ *|V|*) if adjacencylists are used.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.070.png)

Total runningtime of topological sort is O(*V* + *E*).

**Note:** The Topological sorting problem can be solved with DFS. Refer to the *Problems Section* for the algorithm.

**Applications of TopologicalSorting**

- Representingcourse prerequisites
- Detectingdeadlocks
- Pipeline of computingjobs
- Checkingfor symbolic linkloop
- Evaluatingformulae inspreadsheet

7. **Shortest Path Algorithms**

Let us consider the other important problem of a graph. Given a graph *G =* (*V, E*) and a distinguished vertex s, we need to find the shortest path from s to every other vertex in *G*. There are variations in the shortest path algorithms which depend on the type of the input graph and are givenbelow.

**Variations of Shortest Path Algorithms**



| Shortest pathinunweighted graph                 |
| ----------------------------------------------- |
| Shortest pathinweighted graph                   |
| Shortest pathinweighted graphwithnegative edges |
| **Applications of Shortest Path Algorithms**    |

- Findingfastest wayto go fromone place to another
- Findingcheapest wayto fly/send data fromone cityto another

**Shortest Path in Unweighted Graph**

Let *s* be the input vertex from which we want to find the shortest path to all other vertices. Unweighted graph is a special case of the weighted shortest-path problem, with all edges a weight of 1. The algorithmis similar to BFS and we need to use the followingdata structures:

- Adistance table withthree columns (eachrow corresponds to a vertex):
  - Distance fromsource vertex.
  - Path– contains the name of the vertexthroughwhichwe get the shortest distance.
- A queue is used to implement breadth-first search. It contains vertices whose distance from the source node has been computed and their adjacent vertices are to be examined.

As anexample, consider the followinggraphand its adjacencylist representation.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.071.jpeg)

The adjacencylist for this graphis:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.072.png)

Let *s* = *C*. The distance from*C* to *C* is 0. Initially, distances to all other nodes are not computed, and we initialize the second column in the distance table for all vertices (except *C*) with -1 as below.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.073.png)

**Algorithm**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.074.png)

Running time: O(|*E*| + *|V|*), if adjacency lists are used. In for loop, we are checking the outgoing edges for a given vertex and the sum of all examined edges in the while loop is equal to the number of edges whichgives O(|*E*|).

If we use matrix representation the complexity is O(|*V*|2), because we need to read an entire row inthe matrixof length*|V|* inorder to find the adjacent vertices for a givenvertex.

**Shortest path in Weighted Graph [Dijkstra’s]**

Afamous solution for the shortest path problemwas developed by *Dijkstra. Dijkstra’s* algorithm is a generalizationof the BFS algorithm. The regular BFS algorithmcannot solve the shortest path problem as it cannot guarantee that the vertex at the front of the queue is the vertex closest to source *s*.

Before going to code let us understand how the algorithm works. As in unweighted shortest path algorithm, here too we use the distance table. The algorithm works by keeping the shortest distance of vertex *v* from the source in the *Distance* table. The value *Distance*[*v*] holds the distance from s to v. The shortest distance of the source to itself is zero. The *Distance* table for all other vertices is set to –1 to indicate that those vertices are not alreadyprocessed.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.075.png)

After the algorithm finishes, the *Distance* table will have the shortest distance from source *s* to each other vertex *v*. To simplify the understanding of *Dijkstra’s* algorithm, let us assume that the given vertices are maintained in two sets. Initially the first set contains only the source element

and the second set contains all the remaining elements. After the *kth* iteration, the first set contains *k* vertices which are closest to the source. These *k* vertices are the ones for which we have alreadycomputed the shortest distances fromsource.

**Notes onDijkstra’s Algorithm**

- It uses greedymethod: Always pickthe next closest vertexto the source.
- It uses priorityqueue to store unvisited vertices bydistance froms.
- It does not workwithnegative weights.

**Difference betweenUnweightedShortest PathandDijkstra’s Algorithm**

1) To represent weights in the adjacency list, each vertex contains the weights of the edges (inadditionto their identifier).
1) Instead of ordinary queue we use priority queue [distances are the priorities] and the vertexwiththe smallest distance is selected for processing.
1) The distance to a vertex is calculated by the sum of the weights of the edges on the pathfromthe source to that vertex.
1) We update the distances in case the newly computed distance is smaller than the old distance whichwe have alreadycomputed.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.076.jpeg)

The above algorithm can be better understood through an example, which will explain each step that is taken and how *Distance* is calculated. The weighted graph below has 5 vertices from *A – E.*

The value between the two vertices is known as the edge cost between two vertices. For example, the edge cost between *A*and *C* is 1. Dijkstra’s algorithmcan be used to find the shortest pathfromsource *A*to the remainingvertices inthe graph.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.077.jpeg)

Initiallythe *Distance* table is:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.078.png)

After the first step, fromvertex *A*, we can reach *B* and *C*. So, in the *Distance* table we update the reachabilityof *B* and *C* withtheir costs and the same is shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.079.png)

Now, let us select the minimum distance among all. The minimum distance vertex is *C*. That means, we have to reach other vertices fromthese two vertices (*A*and C). For example, *B* can be reached from *A* and also from *C*. In this case we have to select the one which gives the lowest cost. Since reaching*B* through*C* is givingthe minimumcost (1 + 2), we update the *Distance* table for vertex*B* withcost 3 and the vertexfromwhichwe got this cost as *C.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.080.png)

The only vertex remaining is *E*. To reach *E*, we have to see all the paths through which we can reach *E* and select the one which gives the minimum cost. We can see that if we use *B* as the intermediate vertexthrough*C* we get the minimumcost.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.081.png)

The final minimumcost tree whichDijkstra’s algorithmgenerates is:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.082.jpeg)

**Performance**

In Dijkstra’s algorithm, the efficiency depends on the number of DeleteMins (*V* DeleteMins) and updates for priority queues (*E* updates) that are used. If a *standard binary heap* is used then the complexityis O(*ElogV*).

The term *ElogV* comes from *E* updates (each update takes *logV*) for the standard heap. If the set used is anarraythenthe complexityis O(*E* + *V*2).

**Disadvantages of Dijkstra’s Algorithm**

- As discussed above, the major disadvantage of the algorithm is that it does a blind search, therebywastingtime and necessaryresources.
- Another disadvantage is that it cannot handle negative edges. This leads to acyclic graphs and most oftencannot obtainthe right shortest path.

**Relatives of Dijkstra’s Algorithm**

- The *Bellman- Ford* algorithm computes single-source shortest paths in a weighted digraph. It uses the same concept as that of *Dijkstra’s* algorithm but can handle negative edges as well. It has more runningtime than*Dijkstra’s* algorithm.
- Prim’s algorithm finds a minimum spanning tree for a connected weighted graph. It implies that a subset of edges that forma tree where the total weight of all the edges inthe tree is minimized.

**Bellman-Ford Algorithm**

If the graph has negative edge costs, then *Dijkstra’s* algorithmdoes not work. The problemis that once a vertex*u* is declared known, it is possible that fromsome other, unknownvertex*v* there is a path back to *u* that is very negative. In such a case, taking a path from s to *v* back to *u* is better than going from s to *u* without using *v. A* combination of Dijkstra’s algorithm and unweighted algorithms will solve the problem. Initialize the queue with s. Then, at each stage, we *DeQueue* a vertex*v*. We find all vertices *W* adjacent to *v* suchthat,

*distance to v* + *weight* (*v,w*) < old distance to w

We update w old distance and path, and place *w* on a queue if it is not already there. Abit can be set for each vertex to indicate presence in the queue. We repeat the process until the queue is empty.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.083.png)

This algorithm works if there are no negative-cost cycles. Each vertex can DeQueue at most | *V*| times, so the runningtime is O(|*E*|. *|V|*) if adjacencylists are used.

**Overview of Shortest Path Algorithms**



|Shortest pathinunweighted graph[*Modified BFS*]|O(*|E| + |V|*)|
| - | - |
|Shortest pathinweighted graph[*Dijkstra’s*]|O(*|E| log |V|*)|
|Shortest pathinweighted graphwithnegative edges [*Bellman* – *Ford*]|O(*|E|.|V|*)|
|Shortest pathinweighted acyclic graph|O(*|E| + |V|*)|

8. **MinimalSpanning Tree**

The *Spanning tree* of a graph is a subgraph that contains all the vertices and is also a tree. A graph may have many spanning trees. As an example, consider a graph with 4 vertices as shown below. Let us assume that the corners of the graphare vertices.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.084.png)

For this simple graph, we canhave multiple spanningtrees as shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.085.png)

The algorithmwe will discuss now is *minimum spanning tree* in an undirected graph. We assume that the given graphs are weighted graphs. If the graphs are unweighted graphs then we can still use the weighted graph algorithms by treating all weights as equal. A *minimum spanning tree* of an undirected graph *G* is a tree formed from graph edges that connect all the vertices of *G* with minimum total cost (weights). A minimum spanning tree exists only if the graph is connected. There are two famous algorithms for this problem:

- *Prim’s* Algorithm
- *Kruskal’s* Algorithm

**Prim’s Algorithm**

Prim’s algorithmis almost the same as Dijkstra’s algorithm. As in Dijkstra’s algorithm, in Prim’s algorithm we keep the values *distance* and *paths* in the distance table. The only exception is that since the definition of *distance* is different, the updating statement also changes a little. The update statement is simpler thanbefore.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.086.jpeg)

The entire implementation of this algorithm is identical to that of Dijkstra’s algorithm. The running time is O(|*V*|2) without heaps [good for dense graphs], and O (*ElogV*) using binary heaps [good for sparse graphs].

**Kruskal’s Algorithm**

The algorithmstarts with V different trees (V is the vertices in the graph). While constructing the minimum spanning tree, every time Kruskal’s alorithm selects an edge that has minimum weight and then adds that edge if it doesn’t create a cycle. So, initially, there are | V| single-node trees in the forest. Addinganedge merges two trees into one. Whenthe algorithmis completed, there will be only one tree, and that is the minimum spanning tree. There are two ways of implementing Kruskal’s algorithm:

- ByusingDisjoint Sets: UsingUNION and FIND operations
- ByusingPriorityQueues: Maintains weights inpriorityqueue

The appropriate data structure is the UNION/FIND algorithm [for implementing forests]. Two vertices belong to the same set if and only if they are connected in the current spanning forest. Eachvertexis initiallyinits ownset. If *u* and *v* are inthe same set, the edge is rejected because it forms a cycle. Otherwise, the edge is accepted, and a UNION is performed on the two sets containing*u* and *v*. As anexample, consider the followinggraph(the edges show the weights).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.087.jpeg)

Now let us perform Kruskal’s algorithm on this graph. We always select the edge which has minimumweight.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.088.jpeg)

From the above graph, the edges which have minimum weight (cost) are: AD and BE. From these two we can select one of them and let us assume that we select AD (dotted line).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.089.jpeg)

DF is the next edge that has the lowest cost (6).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.090.jpeg)

BE now has the lowest cost and we select it (dotted lines indicate selected edges).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.091.jpeg)

Next, AC and CE have the low cost of 7 and we select AC.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.092.jpeg)

Then we select CE as its cost is 7 and it does not form a cycle.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.093.jpeg)

The next low cost edges are CB and EF. But if we select CB, then it forms a cycle. So we discard it. This is also the case with EF. So we should not select those two. And the next low cost is 9 (BD and EG). Selecting BD forms a cycle so we discard it. Adding EG will not form a cycle and therefore with this edge we complete all vertices of the graph.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.094.png)

**Note:** For implementation of UNION and FIND operations, refer to the *[Disjoint Sets ADT* ](#_page8_x28.00_y82.94)*chapter.

The worst-case running time of this algorithm is O(*ElogE*), which is dominated by the heap operations. That means, since we are constructing the heap with E edges, we need O(*ElogE*) time to do that.

9. **Graph Algorithms: Problems & Solutions**

**Problem-1**  In an undirected simple graph with *n* vertices, what is the maximum number of

edges? Self-loops are not allowed.

**Solution:** Since every node can connect to all other nodes, the first node can connect to *n* – 1 nodes. The second node can connect to *n* – 2 nodes [since one edge is already there fromthe first

node]. The total number of edges is: 1 + 2 + 3 + ··· + *n* – ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.095.png) edges.

**Problem-2**  How many different adjacency matrices does a graph with *n* vertices and *E* edges

have?

**Solution:** It’s equal to the number of permutations of *n* elements, i.e., *n*!.

**Problem-3**  How manydifferent adjacencylists does a graphwith*n* vertices have? **Solution:** It’s equal to the number of permutations of edges, i.e., *E*!.

**Problem-4**  Which undirected graph representation is most appropriate for determining

whether or not a vertexis isolated (is not connected to anyother vertex)?

**Solution: Adjacency List.** If we use the adjacency matrix, then we need to check the complete row to determine whether that vertex has edges or not. By using the adjacency list, it is very easy to check, and it can be done just by checking whether that vertex has NULLfor next pointer or not [NULLindicates that the vertexis not connected to anyother vertex].

**Problem-5**  For checking whether there is a path from source s to target *t*, which one is best

betweendisjoint sets and DFS?

**Solution:** The table below shows the comparison between disjoint sets and DFS. The entries in the table represent the case for anypair of nodes (for *s* and *t*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.096.png)

**Problem-6**  What is the maximum number of edges a directed graph with n vertices can have

and still not containa directed cycle?

**Solution:** The number is V (V – 1)/2. Any directed graph can have at most *n*2 edges. However, since the graphhas no cycles it cannot containa self loop, and for anypair *x,y* of vertices, at most

one edge from(*x*,*y*) and (*y*,*x*) canbe included. Therefore the number of edges canbe at most (V2 – V)/2 as desired. It is possible to achieve V(V – 1)/2 edges. Label *n* nodes 1,2... *n* and add an edge (x, y) if and onlyif *x < y*. This graphhas the appropriate number of edges and cannot contain a cycle (anypathvisits anincreasingsequence of nodes).

**Problem-7**  How many simple directed graphs with no parallel edges and self-loops are

possible interms of *V?*

**Solution:** (V) × (V– 1). Since, eachvertexcanconnect to V– 1 vertices without self-loops. **Problem-8**  What are the differences betweenDFS and BFS?

**Solution:**



| DFS                                                          | BFS                                                        |
| ------------------------------------------------------------ | ---------------------------------------------------------- |
| Backtrackingis possible froma dead end.                      | Backtrackingis not possible.                               |
| Vertices fromwhichexplorationis incomplete are processed ina LIFO order | The vertices to be explored are organized as a FIFO queue. |
| The searchis done inone particular direction                 | The vertices at the same level are maintained inparallel.  |
| **Problem-9**  Earlier in this chapter, we discussed minimum spanning tree algorithms. Now, |                                                            |

give analgorithmfor findingthe maximum-weight spanningtree ina graph.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.097.png)

Using the given graph, construct a new graph with the same nodes and edges. But instead of using the same weights, take the negative of their weights. That means, weight of an edge = negative of weight of the corresponding edge in the given graph. Now, we can use existing *minimum spanning tree* algorithms on this new graph. As a result, we will get the maximum-weight spanningtree inthe original one.

**Problem-10**  Give an algorithm for checking whether a given graph *G* has simple path from

source s to destination*d*. Assume the graph*G* is represented usingthe adjacent matrix.

**Solution:** Let us assume that the structure for the graphis:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.098.png)

For each vertex call *DFS* and check whether the current vertex is the same as the destination vertex or not. If they are the same, then return 1. Otherwise, call the *DFS* on its unvisited neighbors. One important thing to note here is that, we are calling the DFS algorithm on vertices whichare not yet visited.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.099.png)

Time Complexity: O(*E*). In the above algorithm, for each node, since we are not calling *DFS* on all of its neighbors (discardingthrough*if* condition), Space Complexity: O(*V*).

**Problem-11**  Count simple paths for a given graph *G* has simple path from source s to

destinationd? Assume the graphis represented usingthe adjacent matrix.

**Solution:** Similar to the discussion in [Problem-10](#_page72_x66.91_y421.44), start at one node and call DFS on that node. As a result of this call, it visits all the nodes that it can reach in the given graph. That means it visits all the nodes of the connected component of that node. If there are any nodes that have not beenvisited, thenagainstart at one of those nodes and call DFS.

Before the first DFS in each connected component, increment the connected components *count*. Continue this process until all of the graph nodes are visited. As a result, at the end we will get the total number of connected components. The implementation based on this logic is given below:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.100.png)

**Problem-12  All pairs shortest path problem:** Find the shortest graph distances between

every pair of vertices in a given graph. Let us assume that the given graph does not have negative edges.

**Solution:** The problemcanbe solved using*n* applications of *Dijkstra’s* algorithm. That means we apply*Dijkstra’s* algorithm on each vertex of the given graph. This algorithm does not work if the graphhas edges withnegative weights.

**Problem-13**  In[Problem-12](#_page74_x66.91_y358.67), how do we solve the all pairs shortest path problemif the graph

has edges withnegative weights?

**Solution:** This can be solved by using the *Floyd – Warshall algorithm*. This algorithm also works in the case of a weighted graph where the edges have negative weights. This algorithm is anexample of Dynamic Programming-refer to the *Dynamic Programming* chapter.

**Problem-14  DFS Application:** *Cut Vertex* or *Articulation Points*

**Solution:** Inanundirected graph, a *cut vertex* (or articulation point) is a vertex, and if we remove it, then the graph splits into two disconnected components. As an example, consider the following figure. Removal of the *“D”* vertex divides the graph into two connected components ({*E,F*} and {*A,B, C, G*}).

Similarly, removal of the “*C*” vertex divides the graph into ({*G*} and {*A, B,D,E,F*}). For this graph, *A*and *C* are the cut vertices.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.101.png)

**Note:** Aconnected, undirected graph is called *bi – connected* if the graph is still connected after removinganyvertex.

*DFS* provides a linear-time algorithm(O(*n*)) to find all cut vertices in a connected graph. Starting at any vertex, call a *DFS* and number the nodes as they are visited. For each vertex *v*, we call this DFS number *dfsnum*(v). The tree generated with DFS traversal is called *DFS spanning tree*. Then, for every vertex *v* in the *DFS* spanning tree, we compute the lowest-numbered vertex, which we call *low*(*v*), that is reachable from *v* by taking zero or more tree edges and then possiblyone backedge (inthat order).

Based on the above discussion, we need the following information for this algorithm: the *dfsnum* of each vertex in the *DFS* tree (once it gets visited), and for each vertex *v*, the lowest depth of neighbors of all descendants of *v* inthe *DFS* tree, called the *low.*

The *dfsnum* can be computed during DFS. The low of *v* can be computed after visiting all descendants of *v* (i.e., just before *v* gets popped off the *DFS* stack) as the minimumof the *dfsnum* of all neighbors of *v* (other than the parent of *v* in the *DFS* tree) and the *low* of all children of *v* in the *DFS* tree.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.102.jpeg)

The root vertex is a cut vertex if and only if it has at least two children. A non-root vertex u is a cut vertex if and only if there is a son *v* of *u* such that *low*(*v*) ≥ *dfsnum*(*u*). This property can be tested once the *DFS* is returned from every child of *u* (that means, just before u gets popped off the DFS stack), and if true, *u* separates the graphinto different bi-connected components. This can be represented by computing one bi-connected component out of every such *v* (a component whichcontains *v* will containthe sub-tree of *v*, plus *u*), and then erasing the sub-tree of *v* fromthe tree.

For the given graph, the *DFS* tree with *dfsnum/low* can be given as shown in the figure below. The implementationfor the above discussionis:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.103.png)

**Problem-15**  Let *G* be a connected graph of order *n*. What is the maximum number of cut-

vertices that *G* cancontain?

**Solution:** *n –* 2. As an example, consider the following graph. In the graph below, except for the vertices 1 and *n*, all the remaining vertices are cut vertices. This is because removing 1 and *n* vertices does not split the graph into two. This is a case where we can get the maximum number of cut vertices.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.104.png)

**Problem-16  DFS Application:** *Cut Bridges* or *Cut Edges*

**Solution:**

**Definition:** Let *G* be a connected graph. An edge *uv* in *G* is called a *bridge* of *G* if *G* – *uv* is disconnected.

As anexample, consider the followinggraph.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.105.png)

In the above graph, if we remove the edge *uv* then the graph splits into two components. For this graph, *uv* is a bridge. The discussion we had for cut vertices holds good for bridges also. The only change is, instead of printing the vertex, we give the edge. The main observation is that an edge (*u, v*) cannot be a bridge if it is part of a cycle. If (*u, v*) is not part of a cycle, then it is a bridge.

We can detect cycles in *DFS* by the presence of back edges, (*u, v*) is a bridge if and only if none of v or *v’s* children has a back edge to *u* or any of *u’s* ancestors. To detect whether any of *v’s* children has a back edge to *u’s* parent, we can use a similar idea as above to see what is the smallest *dfsnum* reachable fromthe subtree rooted at *v.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.106.png)

**Problem-17  DFS Application:** Discuss *Euler* Circuits

**Solution:** Before discussingthis problemlet us see the terminology:

- *Eulerian tour-* a paththat contains all edges without repetition.
- *Eulerian circuit* – a path that contains all edges without repetition and starts and ends inthe same vertex.
- *Eulerian graph* – a graphthat contains anEuleriancircuit.
- *Even vertex:* a vertexthat has anevennumber of incident edges.
- *Odd vertex:* a vertexthat has anodd number of incident edges.

*Euler* circuit: For a givengraphwe have to reconstruct the circuits usinga pen, drawingeachline exactlyonce. We should not lift the penfromthe paper while drawing. That means, we must find a path in the graph that visits every edge exactly once and this problem is called an *Euler path* (also called *Euler tour*) or *Euler circuit problem*. This puzzle has a simple solution based on DFS.

An *Euler* circuit exists if and only if the graph is connected and the number of neighbors of each vertex is even. Start with any node, select any untraversed outgoing edge, and follow it. Repeat until there are no more remaining unselected outgoing edges. For example, consider the following graph: Alegal Euler Circuit of this graphis 0 1 3 4 1 2 3 5 4 2 0.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.107.png)

If we start at vertex 0, we can select the edge to vertex 1, then select the edge to vertex 2, then select the edge to vertex0. There are now no remainingunchosenedges fromvertex0:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.108.png)

We now have a circuit 0,1,2,0 that does not traverse every edge. So, we pick some other vertex that is on that circuit, say vertex 1. We then do another depth first search of the remaining edges. Say we choose the edge to node 3, then 4, then 1. Again we are stuck. There are no more unchosen edges from node 1. We now splice this path 1,3,4,1 into the old path 0,1,2,0 to get: 0,1,3,4,1,2,0. The unchosenedges now looklike this:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.109.png)

We can pick yet another vertex to start another DFS. If we pick vertex 2, and splice the path 2,3,5,4,2, thenwe get the final circuit 0,1,3,4,1,2,3,5,4,2,0.

Asimilar problemis to find a simple cycle in an undirected graph that visits every vertex. This is known as the *Hamiltonian cycle problem*. Although it seems almost identical to the *Euler* circuit problem, no efficient algorithmfor it is known.

**Notes:**

- A connected undirected graph is *Eulerian* if and only if every graph vertex has an evendegree, or exactlytwo vertices withanodd degree.
- Adirected graphis *Eulerian* if it is stronglyconnected and everyvertexhas anequal *in* and *out* degree.

**Application:** A postman has to visit a set of streets in order to deliver mails and packages. He needs to find a path that starts and ends at the post-office, and that passes through each street (edge) exactly once. This way the postman will deliver mails and packages to all the necessary streets, and at the same time will spend minimumtime/effort onthe road.

**Problem-18  DFS Application:** FindingStronglyConnected Components.

**Solution:** This is another application of DFS. In a directed graph, two vertices *u* and *v* are strongly connected if and only if there exists a path from*u* to *v* and there exists a path from*v* to *u*. The strongconnectedness is anequivalence relation.

- Avertexis stronglyconnected withitself
- If a vertex*u* is stronglyconnected to a vertex*v*, then*v* is stronglyconnected to *u*
- If a vertex *u* is strongly connected to a vertex *v*, and *v* is strongly connected to a vertex*x*, then*u* is stronglyconnected to *x*

What this says is, for a givendirected graphwe candivide it into stronglyconnected components. This problem can be solved by performing two depth-first searches. With two DFS searches we can test whether a given directed graph is strongly connected or not. We can also produce the subsets of vertices that are stronglyconnected.

**Algorithm**

- PerformDFS ongivengraph*G.*
- Number vertices of given graph *G* according to a post-order traversal of depth-first spanningforest.
- Construct graph*Gr* byreversingall edges in*G.*
- Perform DFS on *Gr:* Always start a new DFS (initial call to Visit) at the highest-

numbered vertex.

- Each tree in the resulting depth-first spanning forest corresponds to a strongly- connected component.

**Why this algorithmworks?**

Let us consider two vertices, *v* and *w*. If they are in the same strongly connected component, then there are paths from*v* to *W* and from *w* to *v* in the original graph *G*, and hence also in *Gr*. If two

vertices *v* and w are not in the same depth-first spanning tree of *Gr*, clearly they cannot be in the same strongly connected component. As an example, consider the graph shown below on the left. Let us assume this graphis *G.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.110.jpeg)

Now, as per the algorithm, performing *DFS* on this *G* graph gives the following diagram. The dotted line from*C* to *A*indicates a backedge.

Now, performingpost order traversal onthis tree gives: *D,C,B* and *A.*



| Vertex                                                       | Post Order Number |
| ------------------------------------------------------------ | ----------------- |
| A                                                            | 4                 |
| B                                                            | 3                 |
| C                                                            | 2                 |
| D                                                            | 1                 |
| Now reverse the given graph *G* and call it *Gr* and at the same time assign postorder numbers to the vertices. The reversed graph*Gr* will looklike: |                   |

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.111.jpeg)

The last step is performing DFS on this reversed graph *Gr*. While doing *DFS*, we need to consider the vertex which has the largest DFS number. So, first we start at *A*and with *DFS* we go to *C* and then *B*. At B, we cannot move further. This says that {*A, B, C*} is a strongly connected component. Now the only remaining element is *D* and we end our second *DFS* at *D*. So the connected components are: {*A, B, C*} and {*D*}.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.112.jpeg)

The implementationbased onthis discussioncanbe shownas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.113.jpeg)

**Problem-19**  Count the number of connected components of Graph *G* which is represented in

the adjacent matrix.

**Solution:** This problemcanbe solved withone extra counter in*DFS.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.114.jpeg)

Time Complexity: Same as that of DFS and it depends on implementation. With adjacency matrix the complexityis O(|*E*|+ *|V|*) and withadjacencymatrixthe complexityis O(|*V*|2).

**Problem-20**  Canwe solve the [Problem-19](#_page84_x66.91_y546.59), usingBFS?

**Solution: Yes.** This problemcanbe solved withone extra counter inBFS.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.115.jpeg)

Time Complexity: Same as that of *BFS* and it depends on implementation. With adjacency matrix the complexityis O(|*E*|+ *|V|*) and withadjacencymatrixthe complexityis O(|*V*|2).

**Problem-21**  Let us assume that *G*(*V,E*) is anundirected graph. Give analgorithmfor findinga

spanning tree which takes O(|*E*|) time complexity (not necessarily a minimum spanning tree).

**Solution:** The test for a cycle can be done in constant time, by marking vertices that have been added to the set *S*. Anedge will introduce a cycle, if bothits vertices have alreadybeenmarked.

**Algorithm:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.116.png)

**Problem-22**  Is there anyother wayof solving0?

**Solution:** Yes. We can run *BFS* and find the *BFS* tree for the graph (level order tree of the graph). Then start at the root element and keep moving to the next levels and at the same time we have to consider the nodes in the next level only once. That means, if we have a node with multiple input edges thenwe should consider onlyone of them; otherwise theywill forma cycle.

**Problem-23**  Detectinga cycle inanundirected graph

**Solution:** An undirected graph is acyclic if and only if a *DFS* yields no back edges, edges (*u, v*) where *v* has alreadybeendiscovered and is anancestor of *u.*

- Execute *DFS* onthe graph.
- If there is a backedge – the graphhas a cycle.

If the graph does not contain a cycle, then *|E| < |V|* and *DFS* cost O(|*V*|). If the graph contains a cycle, thena backedge is discovered after 2*|V|* steps at most.

**Problem-24**  Detectinga cycle inDAG **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.117.png)

Cycle detection on a graph is different than on a tree. This is because in a graph, a node can have multiple parents. Ina tree, the algorithmfor detectinga cycle is to do a depthfirst search, marking nodes as theyare encountered. If a previouslymarked node is seenagain, thena cycle exists. This won’t work on a graph. Let us consider the graph shown in the figure below. If we use a tree cycle detection algorithm, then it will report the wrong result. That means that this graph has a cycle in it. But the given graph does not have a cycle in it. This is because node 3 will be seen twice ina *DFS* startingat node 1.

The cycle detection algorithmfor trees can easily be modified to work for graphs. The key is that in a *DFS* of an acyclic graph, a node whose descendants have all been visited can be seen again without implyinga cycle. But, if a node is seenfor the second time before all its descendants have been visited, then there must be a cycle. Can you see why this is? Suppose there is a cycle containing node A. This means that Amust be reachable fromone of its descendants. So when the *DFS* is visiting that descendant, it will see *A* again, before it has finished visiting all of *A’s* descendants. So there is a cycle. Inorder to detect cycles, we canmodifythe depthfirst search.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.118.jpeg)

Time Complexity: O(*V* + *E*).

**Problem-25**  Givena directed acyclic graph, give analgorithmfor findingits depth.

**Solution:** If it is an undirected graph, we can use the simple unweighted shortest path algorithm (check *Shortest Path Algorithms* section). We just need to return the highest number among all distances. For directed acyclic graph, we can solve by following the similar approach which we used for finding the depth in trees. In trees, we have solved this problem using level order

traversal (withone extra special symbol to indicate the end of the level).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.119.jpeg)

Total runningtime is O(*V* + *E*).

**Problem-26**  How manytopological sorts of the followingdagare there?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.120.png)

**Solution:** If we observe the above graph there are three stages with 2 vertices. In the early

discussion of this chapter, we saw that topological sort picks the elements with zero indegree at any point of time. At each of the two vertices stages, we can first process either the top vertex or the bottom vertex. As a result, at each of these stages we have two possibilities. So the total number of possibilities is the multiplication of possibilities at each stage and that is, 2 × 2 × 2 = 8.

**Problem-27  Unique topological ordering:** Design an algorithm to determine whether a

directed graphhas a unique topological ordering.

**Solution:** A directed graph has a unique topological ordering if and only if there is a directed edge between each pair of consecutive vertices in the topological order. This can also be defined as: a directed graph has a unique topological ordering if and only if it has a Hamiltonian path. If the digraph has multiple topological orderings, then a second topological order can be obtained byswappinga pair of consecutive vertices.

**Problem-28**  Let us consider the prerequisites for courses at *IIT Bombay*. Suppose that all

prerequisites are mandatory, every course is offered every semester, and there is no limit to the number of courses we cantake inone semester. We would like to know the minimum number of semesters required to complete the major. Describe the data structure we would use to represent this problem, and outline a linear time algorithmfor solvingit.

**Solution:** Use a directed acyclic graph (DAG). The vertices represent courses and the edges represent the prerequisite relation between courses at *IIT Bombay*. It is a DAG, because the prerequisite relationhas no cycles.

The number of semesters required to complete the major is one more than the longest path in the dag. This can be calculated on the DFS tree recursively in linear time. The longest path out of a vertex*x* is 0 if *x* has outdegree 0, otherwise it is 1 + *max* {*longest path out of y* |(*x*,*y*) is *an edge of G*}.

**Problem-29**  At a university let’s say *IIT Bombay*), there is a list of courses along with their

prerequisites. That means, two lists are given:

*A*– Courses list

*B* – Prerequisites: B contains couples (*x*,*y*) where *x,y* ∈ *A* indicating that course *x* can’t be takenbefore course *y*.

Let us consider a student who wants to take onlyone course ina semester. Designa schedule for this student.

**Example:** A = {C-Lang, Data Structures, OS, CO, Algorithms, Design Patterns, Programming}. B = { (C-Lang, CO), (OS, CO), (Data Structures, Algorithms), (Design Patterns, Programming) }. *One possible schedule could be*:

Semester 1: Data Structures Semester 2: Algorithms Semester 3: C-Lang

Semester 4: OS

Semester 5: CO

Semester 6: DesignPatterns Semester 7: Programming

**Solution:** The solution to this problemis exactly the same as that of topological sort. Assume that the courses names are integers in the range [1..*n*], *n* is known (*n* is not constant). The relations between the courses will be represented by a directed graph *G =* (*V,E*), where *V* are the set of courses and if course *i* is prerequisite of course *j, E* will contain the edge (*i,j*). Let us assume that the graphwill be represented as anAdjacencylist.

First, let’s observe another algorithmto topologicallysort a DAG inO(|*V*|+ *|E|*).

- Find in-degree of all the vertices - O(|*V*|+ *|E|*)
- Repeat:

Find a vertexv within-degree=0 - O(|*V*|)

Output v and remove it fromG, alongwithits edges - O(|*V*|)

Reduce the in-degree of each node u such as (*v, u*) was an edge in G and keep a list of vertices within-degree=0 – O(*degree*(*v*))

Repeat the process until all the vertices are removed

The time complexityof this algorithmis also the same as that of the topological sort and it is O(|*V*|

\+ *|E|*).

**Problem-30**  In [Problem-29](#_page90_x66.91_y491.49), a student wants to take all the courses in *A*, in the minimal

number of semesters. That means the student is ready to take any number of courses in a semester. Designa schedule for this scenario. *One possible schedule is:*

*Semester* 1: C-Lang, OS, DesignPatterns

*Semester* 2: Data Structures, CO, Programming

*Semester* 3: Algorithms

**Solution:** A variation of the above topological sort algorithm with a slight change: In each semester, instead of taking one subject, take all the subjects with zero indegree. That means, execute the algorithm on all the nodes with degree 0 (instead of dealing with one source in each stage, all the sources will be dealt and printed).

Time Complexity: O(|*V*|+ *|E|*).

**Problem-31  LCA of a DAG:** Given a DAG and two vertices *v* and *w*, find the *lowest*

*common ancestor* (LCA) of *v* and *w*. The LCA of *v* and w is an ancestor of *v* and *w* that has no descendants that are also ancestors of *v* and *w.*

**Hint:** Define the height of a vertex *v* in a DAG to be the length of the longest path from*root* to *v*. Among the vertices that are ancestors of both *v* and *w*, the one with the greatest height is an LCA

of *v* and *w.*

**Problem-32  Shortest ancestral path:** Given a DAG and two vertices *v* and *w*, find the

*shortest ancestral path* between *v* and *w*. An ancestral path between *v* and *w* is a common ancestor *x* along with a shortest path from *v* to *x* and a shortest path from *w* to *x*. The shortest ancestral pathis the ancestral pathwhose total lengthis minimized.

**Hint:** Run BFS two times. First run from *v* and second time from *w*. Find a DAG where the shortest ancestral pathgoes to a commonancestor *x* that is not anLCA.

**Problem-33**  Let us assume that we have two graphs *G*1 and *G*2. How do we check whether

theyare isomorphic or not?

**Solution:** There are many ways of representing the same graph. As an example, consider the following simple graph. It can be seen that all the representations below have the same number of vertices and the same number of edges.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.121.png)

**Definition:** Graphs G1 = {V1, E1} and G2 = {V2, E2} are isomorphic if

1) There is a one-to-one correspondence fromV1 to V2 and
1) There is a one-to-one correspondence fromE1 to E2 that map eachedge of G1 to G2.

Now, for the givengraphs how do we checkwhether theyare isomorphic or not?

In general, it is not a simple task to prove that two graphs are isomorphic. For that reason we must consider some properties of isomorphic graphs. That means those properties must be

satisfied if the graphs are isomorphic. If the given graph does not satisfy these properties then we saytheyare not isomorphic graphs.

*Property:* Two graphs are isomorphic if and only if for some ordering of their vertices their adjacencymatrices are equal.

Based on the above property we decide whether the given graphs are isomorphic or not. I order to checkthe property, we need to do some matrixtransformationoperations.

**Problem-34**  How manysimple undirected non-isomorphic graphs are there with*n* vertices?

**Solution:** We will try to answer this question in two steps. First, we count all labeled graphs. Assume all the representations below are labeled with {1,2,3} as vertices. The set of all such graphs for *n* = 3 are:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.122.png)

There are only two choices for each edge: it either exists or it does not. Therefore, since the maximum number of edges is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.123.png) (and since the maximum number of edges in an undirected

graph with *n* vertices is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.124.png), the total number of undirected labeled graphs is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.125.png).

**Problem-35  Hamiltonian path in DAGs:** Given a DAG, design a linear time algorithm to

determine whether there is a paththat visits eachvertexexactlyonce.

**Solution:** The *Hamiltonian* path problem is an NP-Complete problem (for more details ref *Complexity Classes* chapter). To solve this problem, we will try to give the approximation algorithm(whichsolves the problem, but it maynot always produce the optimal solution).

Let us consider the topological sort algorithm for solving this problem. Topological sort has an interesting property: that if all pairs of consecutive vertices in the sorted order are connected by edges, then these edges form a directed *Hamiltonian* path in the DAG. If a *Hamiltonian* path exists, the topological sort order is unique. Also, if a topological sort does not form a *Hamiltonian* path, the DAG will have two or more topological orderings.

*Approximation Algorithm:* Compute a topological sort and checkif there is anedge betweeneach consecutive pair of vertices inthe topological order.

In an unweighted graph, find a path from **s** to **t** that visits each vertex exactly once. The basic solution based on backtracking is, we start at s and try all of its neighbors recursively, making sure we never visit the same vertex twice. The algorithm based on this implementation can be givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.126.png)

Note that if we have a partial path from s to u using vertices s = v1, v2*,...*, vk = u, then we don’t care about the order in which we visited these vertices so as to figure out which vertex to visit next. All that we need to know is the set of vertices we have seen (the seenTable[] array) and

whichvertexwe are at right now (u). There are 2n possible sets of vertices and nchoices for u. In other words, there are 2n possible *seenTable*[] arrays and n different parameters to Hamiltonian\_path(). What Hamiltonian\_path() does during any particular recursive call is completelydetermined bythe *seenTable*[ ] arrayand the parameter u.

**Problem-36**  For a givengraph*G* with*n* vertices how manytrees we canconstruct?

**Solution:** There is a simple formula for this problem and it is named after Arthur Cayley. For a given graph with *n* labeled vertices the formula for finding number of trees on is *nn*–2. Below, the number of trees withdifferent *n* values is shown.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.127.png)

**Problem-37**  For a givengraphG with*n* vertices how manyspanningtrees canwe construct?

**Solution:** The solution to this problemis the same as that of [Problem-36](#_page94_x66.91_y415.15). It is just another way of asking the same question. Because the number of edges in both regular tree and spanning tree are the same.

**Problem-38**  The *Hamiltonian cycle* problem: Is it possible to traverse each of the vertices

of a graphexactlyonce, startingand endingat the same vertex?

**Solution:** Since the *Hamiltonian* path problem is an NP-Complete problem, the *Hamiltonian* cycle problem is an NP-Complete problem. A *Hamiltonian* cycle is a cycle that traverses every

vertex of a graph exactly once. There are no known conditions in which are both necessary and sufficient, but there are a few sufficient conditions.

- For a graph to have a *Hamiltonian* cycle the degree of each vertex must be two or more.
- The Petersengraphdoes not have a *Hamiltonian* cycle and the graphis givenbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.128.png)

- In general, the more edges a graph has, the more likely it is to have a *Hamiltonian* cycle.
- Let G be a simple graph with n ≥ 3 vertices. If every vertex has a degree of at least

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.129.png), thenG has a *Hamiltonian* cycle.

- The best knownalgorithmfor findinga *Hamiltonian* cycle has an exponential worst- case complexity.

**Note:** For the approximation algorithmof *Hamiltonian* path, refer to the *Dynamic Programming* chapter.

**Problem-39**  What is the difference between*Dijkstra’s* and *Prim’s* algorithm?

**Solution:** *Dijkstra’s* algorithm is almost identical to that of *Prim’s*. The algorithm begins at a specific vertex and extends outward within the graph until all vertices have been reached. The only distinction is that *Prim’s* algorithmstores a minimumcost edge whereas *Dijkstra’s* algorithm stores the total cost from a source vertex to the current vertex. More simply, *Dijkstra’s* algorithm stores a summation of minimumcost edges whereas *Prim’s* algorithmstores at most one minimum cost edge.

**Problem-40  Reversing Graph:** : Give an algorithm that returns the reverse of the directed

graph(eachedge from*v* to *w* is replaced byanedge from*w to v*).

**Solution:** In graph theory, the reverse (also called *transpose*) of a directed graph *G* is another directed graph on the same set of vertices with all the edges reversed. That means, if *G* contains anedge (*u, v*) thenthe reverse of *G* contains anedge (*v, u*) and vice versa.

**Algorithm:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.130.png)

**Problem-41  Travelling Sales Person Problem:** Find the shortest path in a graph that visits

eachvertexat least once, startingand endingat the same vertex?

**Solution:** The Traveling Salesman Problem (*TSP*) is related to finding a Hamiltonian cycle. Given a weighted graph *G*, we want to find the shortest cycle (may be non-simple) that visits all the vertices.

**Approximationalgorithm:** This algorithmdoes not solve the problembut gives a solution which is withina factor of 2 of optimal (inthe worst-case).

1) Find a Minimal SpanningTree (MST).
1) Do a DFS of the MST.

For details, refer to the chapter on*Complexity Classes.* **Problem-42**  Discuss Bipartite matchings?

**Solution:** InBipartite graphs, we divide the graphs into two disjoint sets, and eachedge connects a vertexfromone set to a vertexinanother subset (as showninfigure).

**Definition:** A simple graph *G =* (*V, E*) is called a *bipartite graph* if its vertices can be divided into two disjoint sets *V = V*1 ⋃ *V*2, such that every edge has the form*e* = (*a,b*) where *a* ∈ *V*1 and

*b* ∈ *V*2. One important conditionis that no vertices bothin*V*1 or bothin*V*2 are connected.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.131.png)

**Properties of Bipartite Graphs**

- Agraph is called bipartite if and only if the given graph does not have an odd length cycle.
- A *complete bipartite graph Km,n* is a bipartite graph that has each vertex from one

set adjacent to eachvertexfromanother set.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.132.png)

- A subset of edges *M* ⊂ *E* is a *matching* if no two edges have a common vertex. As an example, matching sets of edges are represented with dotted lines. Amatching *M* is called *maximum* if it has the largest number of possible edges. In the graphs, the dotted edges represent the alternative matchingfor the givengraph.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.133.png)

- Amatching *M* is *perfect* if it matches all vertices. We must have *V*1 *= V*2 in order to have perfect matching.
- An *alternating path* is a path whose edges alternate between matched and unmatched edges. If we find an alternating path, then we can improve the matching. This is because an alternating path consists of matched and unmatched edges. The number of unmatched edges exceeds the number of matched edges by one.

Therefore, analternatingpathalways increases the matchingbyone.

**The next question is, how do we find a perfect matching?** Based on the above theory and definition, we canfind the perfect matchingwiththe followingapproximationalgorithm.

**Matching Algorithm(Hungarianalgorithm)**

1) Start at unmatched vertex.
1) Find analternatingpath.
1) If it exists, change matching edges to no matching edges and conversely. If it does not exist, choose another unmatched vertex.
1) If the number of edges equals *V*/2, stop. Otherwise proceed to step 1 and repeat, as longas all vertices have beenexamined without findinganyalternatingpaths.

**Time Complexity of the Matching Algorithm:** The number of iterations is in O(*V*). The complexity of finding an alternating path using BFS is O(*E*). Therefore, the total time complexity is O(*V* × *E*).

**Problem-43**  Marriage and Personnel Problem?

**Marriage Problem:** There are *X* men and *Y* women who desire to get married. Participants indicate who among the opposite sex could be a potential spouse for them. Every woman can be married to at most one man, and every man to at most one woman. How can we marry everybody to someone theylike?

**Personnel Problem:** You are the boss of a company. The company has *M* workers and *N* jobs. Each worker is qualified to do some jobs, but not others. How will you assign jobs to each worker?

**Solution:** These two cases are just another way of asking about bipartite graphs, and the solution is the same as that of [Problem-42](#_page96_x66.91_y589.95).

**Problem-44**  How manyedges will be there incomplete bipartite graph*Km,n*?

**Solution:** *m* × *n*. This is because each vertex in the first set can connect all vertices in the second set.

**Problem-45**  A graph is called a regular graph if it has no loops and multiple edges where

each vertex has the same number of neighbors; i.e., every vertex has the same degree. Now, if *Km,n* is a regular graph, what is the relationbetween*m* and *n*?

**Solution:** Since eachvertexshould have the same degree, the relationshould be *m = n.*

**Problem-46**  What is the maximum number of edges in the maximum matching of a bipartite

graphwithnvertices?

**Solution:** From the definition of *matching*, we should not have edges with common vertices. So

in a bipartite graph, each vertex can connect to only one vertex. Since we divide the total vertices into two sets, we can get the maximum number of edges if we divide them in half. Finally the answer is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.129.png).

**Problem-47**  Discuss Planar Graphs. *Planar graph:* Is it possible to draw the edges of a

graphinsucha waythat the edges do not cross?

**Solution:** Agraph G is said to be planar if it can be drawn in the plane in such a way that no two edges meet each other except at a vertex to which they are incident. Any such drawing is called a plane drawingof G. As anexample consider the below graph:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.134.png)

This graphwe caneasilyconvert to a planar graphas below (without anycrossed edges).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.6d054b01-95b2-428d-b41e-1c670396c1b6.135.png)

How do we decide whether a givengraphis planar or not?

The solution to this problemis not simple, but researchers have found some interesting properties that we canuse to decide whether the givengraphis a planar graphor not.

**Properties of PlanarGraphs**

- If a graph *G* is a connected planar simple graph with *V* vertices, where *V =* 3 and *E* edges, then*E =* 3*V* – 6.
- *K*5 is non-planar. [*K*5 stands for complete graphwith5 vertices].
- If a graph *G* is a connected planar simple graph with *V* vertices and *E* edges, and no

triangles, then*E =* 2*V* – 4.

- **K3,3** is non-planar. [*K*3,3 stands for bipartite graph with 3 vertices on one side and the other 3 vertices onthe other side. *K*3,3 contains 6 vertices].
- If a graph *G* is a connected planar simple graph, then *G* contains at least one vertex of 5 degrees or less.
- Agraph is planar if and only if it does not contain a subgraph that has *K*5 and *K*3,3 as

a contraction.

- If a graph*G* contains a nonplanar graphas a subgraph, then*G* is non-planar.
- If a graph*G* is a planar graph, theneverysubgraphof *G* is planar.
- For anyconnected planar graph*G =* (*V,E*), the followingformula should hold: *V + F*
  - *E =* 2, where *F* stands for the number of faces.
- For any planar graph *G =* (*V, E*) with *K* components, the following formula holds: *V*

+ *F* – *E =* 1 *+ K.*

In order to test the planarity of a given graph, we use these properties and decide whether it is a planar graph or not. Note that all the above properties are only the necessary conditions but not sufficient.

**Problem-48**  How manyfaces does *K*2,3 have?

**Solution:** From the above discussion, we know that *V* + *F – E =* 2, and from an earlier problem we know that *E = m* × *n* = 2 × 3 = 6 and *V = m + n =* 5. ∴5 + *F* – 6 = 2 ⇒ *F* = 3.

**Problem-49**  Discuss GraphColoring

**Solution:** A*k* –coloring of a graph *G* is an assignment of one color to each vertex of *G* such that no more than k colors are used and no two adjacent vertices receive the same color. A graph is called *k* –colorable if and onlyif it has a *k* –coloring.

**Applications of Graph Coloring:** The graph coloring problem has many applications such as scheduling, register allocationincompilers, frequencyassignment inmobile radios, etc.

**Clique:** A*clique* ina graph*G* is the maximumcomplete subgraphand is denoted by*ω*(*G*).

**Chromatic number:** The chromatic number of a graph *G* is the smallest number k such that *G* is *k* –colorable, and it is denoted by*X* (*G*).

The lower bound for *X* (*G*) is *ω*(*G*), and that means *ω*(*G*) ≤ *X* (*G*).

**Properties of Chromatic number:** Let G be a graph with n vertices and G′ is its complement. Then,

- *X* (*G*) ≤ ∆ (*G*) + 1, where ∆ (G) is the maximumdegree of G.
- *X*(*G*) *ω*(*G*′) ≥ *n*
- *X*(*G*) *+ ω*(*G*′) ≤ *n* + 1
- *X*(*G*) + (*G*′) ≤ *n* + 1

**K-colorability problem:** Given a graph G = (*V,E*) and a positive integer *k* ≤ *V*. Check whether G is *k* –colorable?

This problem is NP-complete and will be discussed in detail in the chapter on *Complexity Classes.*

**Graph coloring algorithm:** As discussed earlier, this problem is *NP*-Complete. So we do not have a polynomial time algorithmto determine *X*(*G*). Let us consider the followingapproximation (no efficient) algorithm.

- Consider a graph G with two non-adjacent vertices *a* and *b*. The connection G1 is obtained by joining the two non-adjacent vertices *a* and *b* with an edge. The contraction G2 is obtained by shrinking {*a,b*} into a single vertex *c*(*a, b*) and by

joiningit to eachneighbor inG of vertex*a* and of vertex*b* (and eliminating multiple edges).

- A coloring of G in which *a* and *b* have the same color yields a coloring of *G*1. A coloringof *G* inwhich*a* and *b* have different colors yields a coloringof *G*2.
- Repeat the operations of connection and contraction in each graph generated, until the resulting graphs are all cliques. If the smallest resulting clique is a *K* –clique, then(*G*) = K.

**Important notes onGraphColoring**

- Anysimple planar graphG canbe colored with6 colors.
- Everysimple planar graphcanbe colored withless thanor equal to 5 colors.

**Problem-50**  What is the four coloringproblem?

**Solution:** A graph can be constructed from any map. The regions of the map are represented by the vertices of the graph, and two vertices are joined by an edge if the regions corresponding to the vertices are adjacent. The resulting graph is planar. That means it can be drawn in the plane without anyedges crossing.

The *Four Color Problem* is whether the vertices of a planar graph can be colored with at most four colors so that no two adjacent vertices use the same color.

**History:** The *Four Color Problem* was first given by *Francis Guthrie*. He was a student at *University College London* where he studied under *Augusts De Morgan*. After graduating from London he studied law, but some years later his brother Frederick Guthrie had become a student of *De Morgan*. One dayFrancis asked his brother to discuss this problemwith*De Morgan.*

**Problem-51**  When an adjacency-matrix representation is used, most graph algorithms require time O(*V*2). Show that determining whether a directed graph, represented in an adjacency-

matrix that contains a sink can be done in time O(*V*). A sink is a vertex with in-degree *|V|*

- 1 and out-degree 0 (Onlyone canexist ina graph).

**Solution:** Avertexi is a sinkif and onlyif *M*[*i,j*] = 0 for all j and *M*[*j, i*] = 1 for all *j* ≠ *i*. For any pair of vertices *i* and *j*:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.001.png)

**Algorithm:**

- Start at *i =* 1,*j =* 1
- If *M*[*i,j*] = 0 → *i* wins, *j + +*
- If *M*[*i*,*j*] = 1 → *j* wins, *i* + +
- Proceed withthis process until *j = n* or *i = n* + 1
- If *i* == *n* + 1, the graphdoes not containa sink
- Otherwise, checkrow *i* – it should be all zeros; and checkcolumn*i* – it should be all but *M*[*i, i*] ones; – if so, t is a sink.

Time Complexity: O(*V*), because at most 2*|V|* cells inthe matrixare examined. **Problem-52**  What is the worst – case memoryusage of DFS?

**Solution:** It occurs when the O(|*V*|), which happens if the graph is actually a list. So the algorithm is memoryefficient ongraphs withsmall diameter.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.002.png)

**Problem-53**  Does DFS find the shortest pathfromstart node to some node w ? **Solution: No.** InDFS it is not compulsoryto select the smallest weight edge.

**Problem-54**  True or False: Dijkstra’s algorithm does not compute the “all pairs” shortest

paths in a directed graph with positive edge weights because, running the algorithm a single time, starting fromsome single vertex *x*, it will compute only the min distance from *x* to *y* for all nodes yinthe graph.

**Solution:** True.

**Problem-55**  True or False: Prim’s and Kruskal’s algorithms may compute different minimum

spanningtrees whenrunonthe same graph.

**Solution:** True.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.003.png)

1. **What is Sorting?**

*Sorting* is an algorithmthat arranges the elements of a list in a certain order [either *ascending* or *descending*]. The output is a permutationor reorderingof the input.

2. **Why is Sorting Necessary?**

Sorting is one of the important categories of algorithms in computer science and a lot of research has gone into this category. Sorting can significantly reduce the complexity of a problem, and is oftenused for database algorithms and searches.

3. **Classification of Sorting Algorithms**

Sortingalgorithms are generallycategorized based onthe followingparameters.

**By Number of Comparisons**

In this method, sorting algorithms are classified based on the number of comparisons. For comparison based sorting algorithms, best case behavior is O(*nlogn*) and worst case behavior is

O(*n*2). Comparison-based sorting algorithms evaluate the elements of the list by key comparison operationand need at least O(*nlogn*) comparisons for most inputs.

Later in this chapter we will discuss a few *non – comparison* (*linear*) sorting algorithms like Counting sort, Bucket sort, Radix sort, etc. Linear Sorting algorithms impose few restrictions on the inputs to improve the complexity.

**By Number of Swaps**

In this method, sorting algorithms are categorized by the number *of swaps* (also called *inversions*).

**By Memory Usage**

Some sorting algorithms are *“in place”* and they need O(1) or O(*logn*) memory to create auxiliarylocations for sortingthe data temporarily.

**By Recursion**

Sorting algorithms are either recursive [quick sort] or non-recursive [selection sort, and insertion sort], and there are some algorithms whichuse both(merge sort).

**By Stability**

Sortingalgorithmis *stable* if for all indices *i* and *j* such that the key *A*[*i*] equals key*A*[*j*], if record *R*[*i*] precedes record *R*[*j*] in the original file, record *R*[*i*] precedes record *R*[*j*] in the sorted list. Few sorting algorithms maintain the relative order of elements with equal keys (equivalent elements retaintheir relative positions evenafter sorting).

**By Adaptability**

With a few sorting algorithms, the complexity changes based on pre-sortedness [quick sort]: pre- sortedness of the input affects the runningtime. Algorithms that take this into account are knownto be adaptive.

4. **Other Classifications**

Another method of classifyingsortingalgorithms is:

- Internal Sort
- External Sort

**InternalSort**

Sort algorithms that use main memory exclusively during the sort are called *internal* sorting algorithms. This kind of algorithmassumes high-speed randomaccess to all memory.

**ExternalSort**

Sorting algorithms that use external memory, such as tape or disk, during the sort come under this category.

5. **Bubble Sort**

Bubble sort is the simplest sorting algorithm. It works by iterating the input array from the first element to the last, comparing each pair of elements and swapping them if needed. Bubble sort continues its iterations until no more swaps are needed. The algorithmgets its name fromthe way smaller elements “bubble” to the top of the list. Generally, insertion sort has better performance than bubble sort. Some researchers suggest that we should not teach bubble sort because of its simplicityand hightime complexity.

The onlysignificant advantage that bubble sort has over other implementations is that it candetect whether the input list is alreadysorted or not.

**Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.004.png)

Algorithm takes O(*n*2) (even in best case). We can improve it by using one extra flag. No more swaps indicate the completion of sorting. If the list is already sorted, we can use this flag to skip the remainingpasses.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.005.png)

This modified versionimproves the best case of bubble sort to O(*n*).

**Performance**



| Worst case complexity: O(*n*2)                   |
| ------------------------------------------------ |
| Best case complexity(Improved version) : O(*n*)  |
|                                                  |
| Average case complexity(Basic version) : O(*n*2) |
| Worst case space complexity: O(1) auxiliary      |

6. **Selection Sort**

Selectionsort is anin-place sortingalgorithm. Selectionsort works well for small files. It is used for sorting the files with very large values and small keys. This is because selection is made based onkeys and swaps are made onlywhenrequired.

**Advantages**

- Easyto implement
- In-place sort (requires no additional storage space)

**Disadvantages**

- Doesn’t scale well: O(*n*2)

**Algorithm**

1. Find the minimumvalue inthe list
1. Swap it withthe value inthe current position
1. Repeat this process for all the elements until the entire arrayis sorted

This algorithmis called *selection sort* since it repeatedly*selects* the smallest element.

**Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.006.png)

**Performance**



| Worst case complexity: O(*n*2)              |
| ------------------------------------------- |
| Best case complexity: O(*n*2)               |
| Average case complexity: O(*n*2)            |
| Worst case space complexity: O(1) auxiliary |

7. **Insertion Sort**

Insertion sort is a simple and efficient comparison sort. In this algorithm, each iteration removes an element from the input data and inserts it into the correct position in the list being sorted. The choice of the element being removed from the input is random and this process is repeated until all input elements have gone through.

**Advantages**

- Simple implementation
- Efficient for small data
- Adaptive: If the input list is presorted [may not be completely] then insertions sort takes O(*n* + *d*), where *d* is the number of inversions
- Practically more efficient than selection and bubble sorts, even though all of them

have O(*n*2) worst case complexity

- Stable: Maintains relative order of input data if the keys are same
- In-place: It requires onlya constant amount O(1) of additional memoryspace
- Online: Insertionsort cansort the list as it receives it

**Algorithm**

Every repetition of insertion sort removes an element from the input data, and inserts it into the correct position in the already-sorted list until no input elements remain. Sorting is typically done in-place. The resulting array after *k* iterations has the property where the first *k* + 1 entries are sorted.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.007.png)

Eachelement greater than*x* is copied to the right as it is compared against *x.*

**Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.008.png)

**Example**

Givenanarray: 6 8 1 4 5 3 7 2 and the goal is to put theminascendingorder.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.009.png)

**Analysis**

**Worst case analysis**

Worst case occurs when for every *i* the inner loop has to move all elements *A*[1], . . . , *A*[*i* – 1] (whichhappens when*A*[*i*] = keyis smaller thanall of them), that takes Θ(*i* – 1) time.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.010.png)

**Average case analysis**

For the average case, the inner loop will insert *A*[*i*] in the middle of *A*[1], . . . , *A*[*i –* 1]. This takes Θ(*i*/2) time.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.011.png)

**Performance**

If every element is greater than or equal to every element to its left, the running time of insertion sort is Θ(*n*). This situation occurs if the array starts out already sorted, and so an already-sorted arrayis the best case for insertionsort.



| Worst case complexity: Θ(*n*2)                               |
| ------------------------------------------------------------ |
| Best case complexity: Θ(*n*)                                 |
| Average case complexity: Θ(*n*2)                             |
|                                                              |
| Worst case space complexity: O(*n*2) total, O(1) auxiliary![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.012.png) |

**Comparisons to Other Sorting Algorithms**

Insertion sort is one of the elementary sorting algorithms with O(*n*2) worst-case time. Insertion sort is used whenthe data is nearlysorted (due to its adaptiveness) or whenthe input size is small (due to its low overhead). For these reasons and due to its stability, insertion sort is used as the recursive base case (when the problem size is small) for higher overhead divide-and-conquer sortingalgorithms, suchas merge sort or quicksort.

**Notes:**

- Bubble sort takes ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.013.png) comparisons and ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.013.png) swaps (inversions) in both average case and inworst case.
- Selectionsort takes ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.013.png) comparisons and *n* swaps.
- Insertion sort takes ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.014.png) comparisons and ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.015.png) swaps in average case and in the worst

case theyare double.

- Insertionsort is almost linear for partiallysorted input.
- Selectionsort is best suits for elements withbigger values and small keys.

8. **ShellSort**

*Shell sort* (also called *diminishing increment sort*) was invented by *Donald Shell*. This sorting algorithm is a generalization of insertion sort. Insertion sort works efficiently on input that is already almost sorted. Shell sort is also known as n-gap insertion sort. Instead of comparing only the adjacent pair, shell sort makes several passes and uses various gaps between adjacent elements (endingwiththe gap of 1 or classical insertionsort).

In insertion sort, comparisons are made between the adjacent elements. At most 1 inversion is eliminated for each comparison done with insertion sort. The variation used in shell sort is to avoid comparing adjacent elements until the last step of the algorithm. So, the last step of shell sort is effectively the insertion sort algorithm. It improves insertion sort by allowing the comparison and exchange of elements that are far away. This is the first algorithmwhich got less thanquadratic complexityamongcomparisonsort algorithms.

Shellsort is actually a simple extension for insertion sort. The primary difference is its capability of exchanging elements that are far apart, making it considerably faster for elements to get to where they should be. For example, if the smallest element happens to be at the end of an array, with insertion sort it will require the full array of steps to put this element at the beginning of the array. However, with shell sort, this element can jump more than one step a time and reach the

proper destinationinfewer exchanges.

The basic idea in shellsort is to exchange every hth element in the array. Now this can be confusingso we’ll talkmore about this, *h* determines how far apart element exchange can happen, say for example take *h* as 13, the first element (index-0) is exchanged with the 14*th* element (index-13) if necessary (of course). The second element with the 15*th* element, and so on. Now if we take has 1, it is exactlythe same as a regular insertionsort.

Shellsort works by starting with big enough (but not larger than the array size) *h* so as to allow eligible element exchanges that are far apart. Once a sort is complete with a particular *h*, the array can be said as *h*-sorted. The next step is to reduce *h* by a certain sequence, and again performanother complete *h*-sort. Once *h* is 1 and *h-*sorted, the array is completely sorted. Notice that the last sequence for ft is 1 so the last sort is always an insertion sort, except by this time the arrayis alreadywell-formed and easier to sort.

Shell sort uses a sequence *h*1,*h*2*, ...,ht* called the *increment sequence*. Any increment sequence is fine as long as *h*1 = 1, and some choices are better than others. Shell sort makes multiple passes through the input list and sorts a number of equally sized sets using the insertion sort. Shell sort improves the efficiencyof insertionsort by*quickly* shiftingvalues to their destination.

**Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.016.png)

Note that when *h ==* 1, the algorithm makes a pass over the entire list, comparing adjacent elements, but doing very few element exchanges. For *h* == 1, shell sort works just like insertion sort, except the number of inversions that have to be eliminated is greatlyreduced bythe previous

steps of the algorithmwith*h >* 1.

**Analysis**

Shell sort is efficient for mediumsize lists. For bigger lists, the algorithmis not the best choice. It is the fastest of all O(*n*2) sortingalgorithms.

The disadvantage of Shell sort is that it is a complex algorithm and not nearly as efficient as the merge, heap, and quick sorts. Shell sort is significantly slower than the merge, heap, and quick sorts, but is a relatively simple algorithm, which makes it a good choice for sorting lists of less than 5000 items unless speed is important. It is also a good choice for repetitive sorting of smaller lists.

The best case in Shell sort is when the array is already sorted in the right order. The number of comparisons is less. The runningtime of Shell sort depends onthe choice of increment sequence.

**Performance**



| Worst case complexitydepends ongap sequence. Best known: O(*nlog*2*n*) |
| ------------------------------------------------------------ |
| Best case complexity: O(*n*)                                 |
| Average case complexitydepends ongap sequence                |
| Worst case space complexity: O(*n*)                          |

9. **Merge Sort**

Merge sort is anexample of the divide and conquer strategy.

**Important Notes**

- *Merging* is the process of combiningtwo sorted files to make one bigger sorted file.
- *Selection* is the process of dividinga file into two parts: *k* smallest elements and *n – k* largest elements.
- Selectionand mergingare opposite operations
  - selectionsplits a list into two lists
  - mergingjoins two files to make one file
- Merge sort is Quicksort’s complement
- Merge sort accesses the data ina sequential manner
- This algorithmis used for sortinga linked list
- Merge sort is insensitive to the initial order of its input
- In Quick sort most of the work is done before the recursive calls. Quick sort starts with the largest subfile and finishes with the small ones and as a result it needs stack. Moreover, this algorithm is not stable. Merge sort divides the list into two parts; then each part is conquered individually. Merge sort starts with the small subfiles and finishes with the largest one. As a result it doesn’t need stack. This algorithmis stable.

**Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.017.jpeg)

**Analysis**

In Merge sort the input list is divided into two parts and these are solved recursively. After solving the sub problems, they are merged by scanning the resultant sub problems. Let us assume *T*(*n*) is the complexity of Merge sort with *n* elements. The recurrence for the Merge Sort can be defined as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.018.png)

**Note:** For more details, refer to *Divide and Conquer* chapter.

**Performance**



| Worst case complexity: Θ(*nlogn*)             |
| --------------------------------------------- |
| Best case complexity: Θ(*nlogn*)              |
| Average case complexity: Θ(*nlogn*)           |
| Worst case space complexity: Θ(*n*) auxiliary |

10. **Heap Sort**

Heapsort is a comparison-based sorting algorithm and is part of the selection sort family. Although somewhat slower in practice on most machines than a good implementation of Quick sort, it has the advantage of a more favorable worst-case Θ(*nlogn*) runtime. Heapsort is an in- place algorithmbut is not a stable sort.

**Performance**



| Worst case performance: Θ(*nlogn*)                           |
| ------------------------------------------------------------ |
| Best case performance: Θ(*nlogn*)                            |
| Average case performance: Θ(*nlogn*)                         |
| Worst case space complexity: Θ(n) total, Θ(1) auxiliary      |
| For other details onHeapsort refer to the *Priority Queues* chapter. |

11. **Quicksort**

Quick sort is an example of a divide-and-conquer algorithmic technique. It is also called *partition exchange sort*. It uses recursive calls for sorting the elements, and it is one of the famous algorithms amongcomparison-based sortingalgorithms.

*Divide:* The array *A*[*low ...high*] is partitioned into two non-empty sub arrays *A*[*low ...q*] and *A*[*q*

+ 1... *high*], such that each element of *A*[*low ... high*] is less than or equal to each element of *A*[*q*
+ 1... *high*]. The index*q* is computed as part of this partitioningprocedure.

*Conquer:* The two sub arrays *A*[*low ...q*] and *A*[*q* + 1 *...high*] are sorted by recursive calls to Quicksort.

**Algorithm**

The recursive algorithmconsists of four steps:

1) If there are one or no elements inthe arrayto be sorted, return.
1) Pick an element in the array to serve as the *“pivot”* point. (Usually the left-most element inthe arrayis used.)
1) Split the array into two parts – one with elements larger than the pivot and the other withelements smaller thanthe pivot.
1) Recursivelyrepeat the algorithmfor bothhalves of the original array.

**Implementation**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.019.jpeg)

**Analysis**

Let us assume that *T*(n) be the complexity of Quick sort and also assume that all elements are distinct. Recurrence for *T*(*n*) depends on two subproblem sizes which depend on partition

element. If pivot is *ith* smallest element then exactly (*i* – 1) items will be in left part and (n – *i*) in right part. Let us call it as *i* –split. Since each element has equal probability of selecting it as

pivot the probabilityof selecting*ith* element is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.020.png).

**Best Case:** Eachpartitionsplits arrayinhalves and gives

*T*(*n*) = 2*T*(*n*/2) + Θ(*n*) = Θ(nlogn), [using*Divide and Conquer* master theorem] **Worst Case:** Eachpartitiongives unbalanced splits and we get

*T*(*n*) *= T*(*n* – 1) *+* Θ(*n*) = Θ(*n*2)[*using Subtraction and Conquer master theorem*] The worst-case occurs whenthe list is alreadysorted and last element chosenas pivot.

**Average Case:** In the average case of Quick sort, we do not know where the split happens. For this reason, we take all possible values of split locations, add all their complexities and divide with*n* to get the average case complexity.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.021.png)

Multiplybothsides by*n*.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.022.png)

Same formula for *n* – 1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.023.png)

Subtract the *n* – 1 formula from*n*.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.024.png)

Divide with*n*(*n +* 1).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.025.jpeg)

Time Complexity, *T*(*n*) = O(*nlogn*).

**Performance**



| Worst case Complexity: O(*n*2)      |
| ----------------------------------- |
| Best case Complexity: O(*nlogn*)    |
| Average case Complexity: O(*nlogn*) |
| Worst case space Complexity: O(1)   |
| **Randomized Quick sort**           |

In average-case behavior of Quick sort, we assume that all permutations of the input numbers are equally likely. However, we cannot always expect it to hold. We can add randomization to an algorithminorder to reduce the probabilityof gettingworst case inQuicksort.

There are two ways of adding randomization in Quick sort: either by randomly placing the input data in the array or by randomly choosing an element in the input data for pivot. The second choice is easier to analyze and implement. The change will only be done at the *partition* algorithm.

In normal Quick sort, *pivot* element was always the leftmost element in the list to be sorted. Instead of always using *A*[*low*] as *pivot*, we will use a randomly chosen element from the subarray *A*[*low..high*] in the randomized version of Quick sort. It is done by exchanging element *A*[*low*] withanelement chosenat randomfrom*A*[*low..high*]. This ensures that the *pivot* element is equallylikelyto be anyof the *high – low* + 1 elements inthe subarray.

Since the pivot element is randomly chosen, we can expect the split of the input array to be reasonably well balanced on average. This can help in preventing the worst-case behavior of quicksort whichoccurs inunbalanced partitioning. Eventhoughthe randomized versionimproves

the worst case complexity, its worst case complexity is still O(*n*2). One way to improve *Randomized – Quick sort* is to choose the pivot for partitioning more carefully than by picking a random element from the array. One common approach is to choose the pivot as the median of a set of 3 elements randomlyselected fromthe array.

12. **Tree Sort**

Tree sort uses a binary search tree. It involves scanning each element of the input and placing it into its proper positionina binarysearchtree. This has two phases:

- First phase is creatinga binarysearchtree usingthe givenarrayelements.
- Second phase is traversing the given binary search tree in inorder, thus resulting in a sorted array.

**Performance**

The average number of comparisons for this method is O(*nlogn*). But inworst case, the number of comparisons is reduced byO(*n*2), a case whicharises whenthe sort tree is skew tree.

13. **Comparison of Sorting Algorithms**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.026.png)

**Note:** *n* denotes the number of elements inthe input.

14. **Linear Sorting Algorithms**

In earlier sections, we have seen many examples of comparison-based sorting algorithms. Among them, the best comparison-based sorting has the complexity O(*nlogn*). In this section, we will discuss other types of algorithms: Linear Sorting Algorithms. To improve the time complexity of sorting these algorithms, we make some assumptions about the input. A few examples of Linear SortingAlgorithms are:

- CountingSort
- Bucket Sort
- RadixSort

15. **Counting Sort**

Counting sort is not a comparison sort algorithm and gives O(*n*) complexity for sorting. To achieve O(*n*) complexity, *counting* sort assumes that each of the elements is an integer in the range 1 to *K*, for some integer *K*. When if = O(*n*), the *counting* sort runs in O(*n*) time. The basic idea of Counting sort is to determine, for each input element *X*, the number of elements less than *X*. This information can be used to place it directly into its correct position. For example, if 10 elements are less than*X*, then*X* belongs to position11 inthe output.

Inthe code below, *A*[0 *..n* – 1] is the input arraywithlength*n*. InCountingsort we need two more arrays: let us assume array *B*[0 *..n –* 1] contains the sorted output and the array *C*[0 *..K* – 1] provides temporarystorage.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.027.png)

Total Complexity: O(*K*) + O(*n*) + O(*K*) + O(*n*) = O(*n*) if *K* =O(*n*). Space Complexity: O(*n*) if *K* =O(*n*).

**Note:** Countingworks well if *K* =O(*n*). Otherwise, the complexitywill be greater.

16. **Bucket Sort (or Bin Sort)**

Like *Counting* sort, *Bucket* sort also imposes restrictions on the input to improve the performance. In other words, Bucket sort works well if the input is drawn fromfixed set. *Bucket* sort is the generalization of *Counting* Sort. For example, assume that all the input elements from {0, 1, . . . , *K* – 1}, i.e., the set of integers in the interval [0, *K* – 1]. That means, *K* is the number

of distant elements in the input. *Bucket* sort uses *K* counters. The *ith* counter keeps track of the number of occurrences of the *ith* element. Bucket sort with two buckets is effectively a version of Quicksort withtwo buckets.

For bucket sort, the hash function that is used to partition the elements need to be very good and must produce ordered hash: if i < k then hash(i) < hash(k). Second, the elements to be sorted must be uniformlydistributed.

The aforementioned aside, bucket sort is actually very good considering that counting sort is reasonably speaking its upper bound. And counting sort is very fast. The particular distinction for bucket sort is that it uses a hash function to partition the keys of the input array, so that multiple keys may hash to the same bucket. Hence each bucket must effectively be a growable list; similar to radixsort.

Inthe below code insertionsort is used to sort eachbucket. This is to inculcate that the bucket sort algorithm does not specify which sorting technique to use on the buckets. A programmer may choose to continuously use bucket sort on each bucket until the collection is sorted (in the manner of the radixsort programbelow). Whichever sortingmethod is used onthe , bucket sort still tends toward O(*n*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.028.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

17. **Radix Sort**

Similar to *Counting* sort and *Bucket* sort, this sorting algorithm also assumes some kind of information about the input elements. Suppose that the input values to be sorted are from base *d*. That means all numbers are *d*-digit numbers.

In Radix sort, first sort the elements based on the last digit [the least significant digit]. These results are again sorted by second digit [the next to least significant digit]. Continue this process for all digits until we reach the most significant digits. Use some stable sort to sort them by last digit. Then stable sort them by the second least significant digit, then by the third, etc. If we use Countingsort as the stable sort, the total time is O(*nd*) ≈ O(*n*).

**Algorithm:**

1) Take the least significant digit of eachelement.
2) Sort the list of elements based on that digit, but keep the order of elements with the same digit (this is the definitionof a stable sort).
3) Repeat the sort witheachmore significant digit.

The speed of Radix sort depends on the inner basic operations. If the operations are not efficient enough, Radix sort can be slower than other algorithms such as Quick sort and Merge sort. These operations include the insert and delete functions of the sub-lists and the process of isolating the digit we want. If the numbers are not of equal length then a test is needed to check for additional digits that need sorting. This can be one of the slowest parts of Radix sort and also one of the hardest to make efficient.

Since Radix sort depends on the digits or letters, it is less flexible than other sorts. For every different type of data, Radix sort needs to be rewritten, and if the sorting order changes, the sort needs to be rewrittenagain. Inshort, Radixsort takes more time to write, and it is verydifficult to write a general purpose Radixsort that canhandle all kinds of data.

For many programs that need a fast sort, Radix sort is a good choice. Still, there are faster sorts, whichis one reasonwhyRadixsort is not used as muchas some other sorts.

Time Complexity: O(*nd*) ≈ O(*n*), if *d* is small.

18. **TopologicalSort**

Refer to *Graph Algorithms* Chapter.

19. **ExternalSorting**

External sorting is a generic term for a class of sorting algorithms that can handle massive amounts of data. These external sortingalgorithms are useful whenthe files are too bigand cannot fit into mainmemory.

As with internal sorting algorithms, there are a number of algorithms for external sorting. One such algorithm is External Mergesort. In practice, these external sorting algorithms are being supplemented byinternal sorts.

**Simple ExternalMergesort**

Anumber of records fromeach tape are read into main memory, sorted using an internal sort, and then output to the tape. For the sake of clarity, let us assume that 900 megabytes of data needs to be sorted usingonly100 megabytes of RAM.

1) Read 100MB of the data into main memory and sort by some conventional method

(let us sayQuicksort).

2) Write the sorted data to disk.
2) Repeat steps 1 and 2 until all of the data is sorted inchunks of 100MB. Now we need to merge theminto one single sorted output file.
2) Read the first 10MB of each sorted chunk (call them input buffers) in main memory (90MB total) and allocate the remaining10MB for output buffer.
2) Perform a 9-way Mergesort and store the result in the output buffer. If the output buffer is full, write it to the final sorted file. If any of the 9 input buffers gets empty, fill it with the next 10MB of its associated 100MB sorted chunk; or if there is no more data inthe sorted chunk, markit as exhausted and do not use it for merging.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.029.jpeg)

The above algorithmcan be generalized by assuming that the amount of data to be sorted exceeds the available memory by a factor of *K*. Then, *K* chunks of data need to be sorted and a *K* -way merge has to be completed.

If *X* is the amount of main memory available, there will be *K* input buffers and 1 output buffer of size *X/*(*K* + 1) each. Depending on various factors (how fast is the hard drive?) better performance can be achieved if the output buffer is made larger (for example, twice as large as one input buffer).

Complexity of the 2-way External Merge sort: In each pass we read + write each page in file. Let us assume that there are *n* pages in file. That means we need ⌈*logn*⌉+ 1 number of passes. The total cost is 2*n*(⌈*logn*⌉+ 1).

20. **Sorting: Problems & Solutions**

**Problem-1**  Givenanarray*A*[0*...n–* 1] of *n* numbers containingthe repetitionof some number.

Give an algorithm for checking whether there are repeated elements or not. Assume that we are not allowed to use additional space (i.e., we can use a few temporary variables, O(1) storage).

**Solution:** Since we are not allowed to use extra space, one simple way is to scan the elements one-by-one and for each element check whether that element appears in the remaining elements. If we find a matchwe returntrue.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.030.png)

Each iteration of the inner, *j*-indexed loop uses O(1) space, and for a fixed value of *i*, the *j* loop executes *n – i* times. The outer loop executes *n* – 1 times, so the entire function uses time proportional to

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.031.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-2**  Canwe improve the time complexityof [Problem-1](#_page27_x66.91_y129.94)?

**Solution: Yes,** usingsortingtechnique.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.032.png)

Heapsort function takes O(*nlogn*) time, and requires O(1) space. The scan clearly takes *n* – 1 iterations, eachiterationusingO(1) time. The overall time is O(*nlogn + n*) = O(*nlogn*).

Time Complexity: O(*nlogn*). Space Complexity: O(1).

**Note:** For variations of this problem, refer *[Searching*](#_page46_x28.00_y82.94)* chapter.

**Problem-3**  Given an array *A*[0 *...n* – 1], where each element of the array represents a vote in

the election. Assume that each vote is given as an integer representing the ID of the chosen candidate. Give analgorithmfor determiningwho wins the election.

**Solution:** This problemis nothing but finding the element which repeated the maximumnumber of times. The solutionis similar to the [Problem-1](#_page27_x66.91_y129.94) solution: keep trackof counter.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.033.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Note:** For variations of this problem, refer to *[Searching*](#_page46_x28.00_y82.94)* chapter.

**Problem-4**  Can we improve the time complexity of [Problem-3](#_page28_x66.91_y301.61)? Assume we don’t have any

extra space.

**Solution: Yes.** The approach is to sort the votes based on candidate ID, then scan the sorted array and count up which candidate so far has the most votes. We only have to remember the winner, so we don’t need a clever data structure. We canuse Heapsort as it is anin-place sortingalgorithm.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.034.jpeg)

Since Heapsort time complexity is O(*nlogn*) and in-place, it only uses an additional O(1) of storage in addition to the input array. The scan of the sorted array does a constant-time conditional *n* – 1 times, thus usingO(*n*) time. The overall time bound is O(*nlogn*).

**Problem-5**  Canwe further improve the time complexityof [Problem-3](#_page28_x66.91_y301.61)?

**Solution:** In the given problem, the number of candidates is less but the number of votes is significantlylarge. For this problemwe canuse countingsort.

Time Complexity: O(*n*), *n* is the number of votes (elements) inthe array. Space Complexity: O(*k*),

*k* is the number of candidates participatinginthe election.

**Problem-6**  Given an array *A* of *n* elements, each of which is an integer in the range [1, *n*2],

how do we sort the arrayinO(*n*) time?

**Solution:** If we subtract each number by 1 then we get the range [0, *n*2 – 1]. If we consider all numbers as 2 –digit base *n*. Eachdigit ranges from0 to *n*2 – 1. Sort this usingradixsort. This uses only two calls to counting sort. Finally, add 1 to all the numbers. Since there are 2 calls, the complexityis O(2*n*) ≈ O(*n*).

**Problem-7**  For [Problem-6](#_page30_x66.91_y55.03), what if the range is [1... *n*3]?

**Solution:** If we subtract each number by 1 then we get the range [0, *n*3 – 1]. Considering all numbers as 3-digit base n: each digit ranges from0 to *n*3 – 1. Sort this using radix sort. This uses only three calls to counting sort. Finally, add 1 to all the numbers. Since there are 3 calls, the complexityis O(3*n*) ≈ O(*n*).

**Problem-8**  Given an array with *n* integers, each of value less than *n*100, can it be sorted in

linear time?

**Solution: Yes.** The reasoningis same as inof [Problem-6](#_page30_x66.91_y55.03) and [Problem-7](#_page30_x66.91_y180.33).

**Problem-9**  Let *A* and *B* be two arrays of *n* elements each. Given a number *K*, give an O(*nlogn*) time algorithmfor determining whether there exists a ∈ Aand b ∈ B such that *a*

+ *b = K.*

**Solution:** Since we need O(*nlogn*), it gives us a pointer that we need to sort. So, we will do that.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.035.png)

**Note:** For variations of this problem, refer to *[Searching*](#_page46_x28.00_y82.94)* chapter.

**Problem-10**  Let *A,B* and *C* be three arrays of *n* elements each. Given a number *K*, give an

O(*nlogn*) time algorithmfor determiningwhether there exists *a* ∈ *A, b* ∈ *B* and *c* ∈ *C* such that *a + b + c = K.*

**Solution:** Refer to *[Searching*](#_page46_x28.00_y82.94)* chapter.

**Problem-11**  Given an array of *n* elements, can we output in sorted order the *K* elements

followingthe medianinsorted order intime O(*n* + *KlogK*).

**Solution: Yes.** Find the median and partition the median. With this we can find all the elements greater thanit. Now find the *K*th largest element in this set and partition it; and get all the elements less than it. Output the sorted list of the final set of elements. Clearly, this operation takes O(*n* + *KlogK*) time.

**Problem-12**  Consider the sorting algorithms: Bubble sort, Insertion sort, Selection sort,

Merge sort, Heap sort, and Quicksort. Whichof these are stable?

**Solution:** Let us assume that *A*is the arrayto be sorted. Also, let us say*R* and *S* have the same key and *R* appears earlier in the array than *S*. That means, *R* is at *A*[*i*] and *S* is at *A*[*j*], with *i < j*. To show anystable algorithm, inthe sorted output *R* must precede *S*.

**Bubble sort:** Yes. Elements change order only when a smaller record follows a larger. Since *S* is not smaller than*R* it cannot precede it.

**Selectionsort:** No. It divides the array into sorted and unsorted portions and iteratively finds the minimumvalues in the unsorted portion. After finding a minimum*x*, if the algorithm moves *x* into the sorted portion of the array by means of a swap, then the element swapped could be *R* which then could be moved behind *S*. This would invert the positions of *R* and *S*, so in general it is not stable. If swapping is avoided, it could be made stable but the cost in time would probably be verysignificant.

**Insertionsort:** Yes. As presented, when *S* is to be inserted into sorted subarray *A*[1*..j* – 1], only records larger than *S* are shifted. Thus *R* would not be shifted during *S’s* insertion and hence would always precede it.

**Merge sort:** Yes, In the case of records with equal keys, the record in the left subarray gets preference. Those are the records that came first in the unsorted array. As a result, they will precede later records withthe same key.

**Heapsort:** No. Suppose *i =* 1 and *R* and *S* happen to be the two records with the largest keys in the input. Then *R* will remain in location 1 after the array is heapified, and will be placed in locationninthe first iterationof Heapsort. Thus *S* will precede *R* inthe output.

**Quick sort:** No. The partitioning step can swap the location of records many times, and thus two records withequal keys could swap positioninthe final output.

**Problem-13**  Consider the same sorting algorithms as that of [Problem-12](#_page31_x66.91_y156.67). Which of them are

in-place?

**Solution:**

**Bubble sort:** Yes, because onlytwo integers are required.

**Insertionsort:** Yes, since we need to store two integers and a record.

**Selectionsort:** Yes. This algorithmwould likelyneed space for two integers and one record.

**Merge sort:** No. Arrays need to performthe merge. (If the data is in the formof a linked list, the sortingcanbe done in-place, but this is a nontrivial modification.)

**Heapsort:** Yes, since the heap and partially-sorted arrayoccupyopposite ends of the input array.

**Quicksort:** No, since it is recursive and stores O(*logn*) activation records on the stack. Modifyingit to be non-recursive is feasible but nontrivial.

**Problem-14**  Among Quick sort, Insertion sort, Selection sort, and Heap sort algorithms,

whichone needs the minimumnumber of swaps?

**Solution:** Selectionsort – it needs nswaps only(refer to theorysection).

**Problem-15**  What is the minimumnumber of comparisons required to determine if an integer

appears more than*n/*2 times ina sorted arrayof *n* integers?

**Solution:** Refer to *[Searching*](#_page46_x28.00_y82.94)* chapter.

**Problem-16  Sort an array of 0’s, 1’s and 2’s:** Given an array A[] consisting of 0’s, 1’s and

2’s, give analgorithmfor sorting*A*[]. The algorithmshould put all 0’s first, thenall 1’s and all 2’s last.

**Example:** Input = {0,1,1,0,1,2,1,2,0,0,0,1}, Output = {0,0,0,0,0,1,1,1,1,1,2,2}

**Solution:** Use Counting sort. Since there are only three elements and the maximumvalue is 2, we need a temporaryarraywith3 elements.

Time Complexity: O(*n*). Space Complexity: O(1).

**Note:** For variations of this problem, refer to *[Searching*](#_page46_x28.00_y82.94)* chapter. **Problem-17**  Is there anyother wayof solving[Problem-16](#_page32_x66.91_y392.58)?

**Solution:** Using Quick dort. Since we know that there are only 3 elements, 0,1 and 2 in the array, we can select 1 as a pivot element for Quick sort. Quick sort finds the correct place for 1 by movingall 0’s to the left of 1 and all 2’s to the right of 1. For doingthis it uses onlyone scan.

Time Complexity: O(*n*). Space Complexity: O(1).

**Note:** For efficient algorithm, refer to *[Searching*](#_page46_x28.00_y82.94)* chapter.

**Problem-18**  How do we find the number that appeared the maximum number of times in an

array?

**Solution:** One simple approach is to sort the given array and scan the sorted array. While scanning, keep trackof the elements that occur the maximumnumber of times.

**Algorithm:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.036.png)

Time Complexity = Time for Sorting + Time for Scan = O(*nlogn*) +O(*n*) = O(*nlogn*). Space Complexity: O(1).

**Note:** For variations of this problem, refer to *[Searching*](#_page46_x28.00_y82.94)* chapter. **Problem-19**  Is there anyother wayof solving[Problem-18](#_page32_x66.91_y730.01)?

**Solution: Using Binary Tree.** Create a binary tree with an extra field *count* which indicates the number of times an element appeared in the input. Let us say we have created a Binary Search Tree [BST]. Now, do the In-Order traversal of the tree. The In-Order traversal of BST produces the sorted list. While doingthe In-Order traversal keep trackof the maximumelement.

Time Complexity: O(*n*) + O(*n*) ≈ O(*n*). The first parameter is for constructing the BST and the second parameter is for Inorder Traversal. Space Complexity: O(2*n*) ≈ O(*n*), since every node in BST needs two extra pointers.

**Problem-20**  Is there yet another wayof solving[Problem-18](#_page32_x66.91_y730.01)?

**Solution: Using Hash Table.** For each element of the given array we use a counter, and for each occurrence of the element we increment the corresponding counter. At the end we can just return the element whichhas the maximumcounter.

Time Complexity: O(*n*). Space Complexity: O(*n*). For constructingthe hashtable we need O(*n*). **Note:** For the efficient algorithm, refer to the *[Searching*](#_page46_x28.00_y82.94)* chapter.

**Problem-21**  Given a 2 GB file with one string per line, which sorting algorithm would we

use to sort the file and why?

**Solution:** When we have a size limit of 2GB, it means that we cannot bring all the data into the mainmemory.

**Algorithm:** How much memory do we have available? Let’s assume we have *X* MB of memory available. Divide the file into *K* chunks, where *X* \**K* ~ 2 *GB.*

- Bringeachchunkinto memoryand sort the lines as usual (anyO(*nlogn*) algorithm).
- Save the lines backto the file.
- Now bringthe next chunkinto memoryand sort.
- Once we’re done, merge themone byone; inthe case of one set finishing, bringmore data fromthe particular chunk.

The above algorithm is also known as *external sort*. Step 3 – 4 is known as K-way merge. The idea behind going for anexternal sort is the size of data. Since the data is huge and we can’t bring it to the memory, we need to go for a disk-based sortingalgorithm.

**Problem-22  Nearly sorted:** Given an array of *n* elements, each which is at most *K* positions

fromits target position, devise analgorithmthat sorts inO(*n logK*) time.

**Solution:** Divide the elements into *n/K* groups of size *K*, and sort each piece in O(*KlogK*) time, let’s sayusingMergesort. This preserves the propertythat no element is more than*K* elements out of position. Now, merge eachblockof *K* elements withthe blockto its left.

**Problem-23**  Is there anyother wayof solving[Problem-22](#_page34_x66.91_y278.88)?

**Solution:** Insert the first *K* elements into a binary heap. Insert the next element fromthe array into the heap, and delete the minimumelement fromthe heap. Repeat.

**Problem-24  Merging Ksorted lists:** Given *K* sorted lists with a total of n elements, give an

O(*nlogK*) algorithmto produce a sorted list of all *n* elements.

**Solution:** Simple Algorithmfor merging *K* sorted lists: Consider groups each having ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.037.png) elements. Take the first list and merge it with the second list using a linear-time algorithm for merging two

sorted lists, such as the merging algorithmused in merge sort. Then, merge the resulting list of ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.038.png)

elements with the third list, and then merge the resulting list of ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.039.png) elements with the fourth list. Repeat this until we end up witha single sorted list of all *n* elements.

Time Complexity: Ineachiterationwe are merging*K* elements.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.040.png)

**Problem-25**  Canwe improve the time complexityof [Problem-24](#_page34_x66.91_y450.26)?

**Solution:** One method is to repeatedly pair up the lists and then merge each pair. This method can also be seen as a tail component of the execution merge sort, where the analysis is clear. This is called the Tournament Method. The maximum depth of the Tournament Method is *logK* and in eachiterationwe are scanningall the nelements.

Time Complexity; O(*n*logK).

**Problem-26**  Is there anyother wayof solving[Problem-24](#_page34_x66.91_y450.26)?

**Solution:** The other method is to use a *rain* priority queue for the minimum elements of each of the if lists. At each step, we output the extracted minimum of the priority queue, determine from whichof the *K* lists it came, and insert the next element fromthat list into the priorityqueue. Since we are usingpriorityqueue, that maximumdepthof priorityqueue is *logK.*

Time Complexity; O(*n*logK).

**Problem-27**  Whichsortingmethod is better for Linked Lists?

**Solution:** Merge Sort is a better choice. At first appearance, merge sort may not be a good selection since the middle node is required to subdivide the given list into two sub-lists of equal length. We can easily solve this problem by moving the nodes alternatively to two lists (refer to *Linked Lists* chapter). Then, sorting these two lists recursively and merging the results into a single list will sort the givenone.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.041.png)

**Note:** Append() appends the first argument to the tail of a singly linked list whose head and tail are defined bythe second and third arguments.

All external sorting algorithms can be used for sorting linked lists since each involved file can be considered as a linked list that canonlybe accessed sequentially. We cansort a doublylinked list using its next fields as if it was a singly linked one and reconstruct the prev fields after sorting withanadditional scan.

**Problem-28**  Canwe implement Linked Lists SortingwithQuickSort?

**Solution:** The original Quick Sort cannot be used for sorting Singly Linked Lists. This is because we cannot move backward in Singly Linked Lists. But we can modify the original Quick Sort and make it workfor SinglyLinked Lists.

Let us consider the following modified Quick Sort implementation. The first node of the input list is considered a *pivot* and is moved to *equal*. The value of each node is compared with the *pivot* and moved to *less* (respectively, *equal* or *larger*) if the nodes value is smaller than (respectively, *equal* to or *larger* than) the *pivot*. Then, *less* and *larger* are sorted recursively. Finally, joining *less, equal* and *larger* into a single list yields a sorted one.

*Append*() appends the first argument to the tail of a singly linked list whose head and tail are defined bythe second and third arguments. Onreturn, the first argument will be modified so that it points to the next node of the list. *Join*() appends the list whose head and tail are defined by the third and fourth arguments to the list whose head and tail are defined by the first and second arguments. For simplicity, the first and fourth arguments become the head and tail of the resulting list.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.042.jpeg)

**Problem-29**  Given an array of 100,000 pixel color values, each of which is an integer in the

range [0,255]. Whichsortingalgorithmis preferable for sortingthem?

**Solution:** Counting Sort. There are only 256 key values, so the auxiliary array would only be of size 256, and there would be only two passes through the data, which would be very efficient in bothtime and space.

**Problem-30**  Similar to [Problem-29](#_page37_x66.91_y638.15), if we have a telephone directorywith10 millionentries,

whichsortingalgorithmis best?

**Solution:** Bucket Sort. In Bucket Sort the buckets are defined by the last 7 digits. This requires an auxiliary array of size 10 million and has the advantage of requiring only one pass through the data on disk. Each bucket contains all telephone numbers with the same last 7 digits but with different area codes. The buckets can then be sorted by area code with selection or insertion sort; there are onlya handful of area codes.

**Problem-31**  Give analgorithmfor merging*K*-sorted lists. **Solution:** Refer to *Priority Queues* chapter.

**Problem-32**  Givena bigfile containingbillions of numbers. Find maximum10 numbers from

this file.

**Solution:** Refer to *Priority Queues* chapter.

**Problem-33**  There are two sorted arrays *A* and *B*. The first one is of size *m + n* containing

only*m* elements. Another one is of size *n* and contains *n* elements. Merge these two arrays into the first arrayof size *m + n* suchthat the output is sorted.

**Solution:** The trick for this problem is to start filling the destination array from the back with the largest elements. We will end up witha merged and sorted destinationarray.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.043.png)

Time Complexity: O(*m* + *n*). Space Complexity: O(1).

**Problem-34  Nuts and Bolts Problem:** Given a set of *n* nuts of different sizes and *n* bolts suchthat there is a one-to-one correspondence betweenthe nuts and the bolts, find for each

nut its corresponding bolt. Assume that we can only compare nuts to bolts: we cannot

compare nuts to nuts and bolts to bolts.

**Alternative way of framing the question:** We are given a box which contains bolts and nuts. Assume there are *n* nuts and *n* bolts and that each nut matches exactly one bolt (and vice versa). By trying to match a bolt and a nut we can see which one is bigger, but we cannot compare two bolts or two nuts directly. Design an efficient algorithm for matching the nuts and bolts.

**Solution: Brute Force Approach:** Start with the first bolt and compare it with each nut until we find a match. In the worst case, we require n comparisons. Repeat this for successive bolts on all remaininggives O(*n*2) complexity.

**Problem-35**  For [Problem-34](#_page38_x66.91_y713.79), canwe improve the complexity?

**Solution:** In [Problem-34](#_page38_x66.91_y713.79), we got O(*n*2) complexity in the worst case (if bolts are in ascending order and nuts are in descending order). Its analysis is the same as that of Quick Sort. The improvement is also along the same lines. To reduce the worst case complexity, instead of selecting the first bolt every time, we can select a random bolt and match it with nuts. This randomized selection reduces the probability of getting the worst case, but still the worst case is

O(*n*2).

**Problem-36**  For [Problem-34](#_page38_x66.91_y713.79), canwe further improve the complexity?

**Solution:** We can use a divide-and-conquer technique for solving this problemand the solution is very similar to randomized Quick Sort. For simplicity let us assume that bolts and nuts are represented intwo arrays *B* and *N.*

The algorithm first performs a partition operation as follows: pick a random boltB[t]. Using this bolt, rearrange the arrayof nuts into three groups of elements:

- First the nuts smaller than*B*[*i*]
- Thenthe nut that matches *B*[*i*], and
- Finally, the nuts larger than*B*[*i*].

Next, usingthe nut that matches *B*[*i*], performa similar partition on the array of bolts. This pair of partitioning operations can easily be implemented in O(*n*) time, and it leaves the bolts and nuts nicely partitioned so that the *“pivot”* bolt and nut are aligned with each other and all other bolts and nuts are on the correct side of these pivots – smaller nuts and bolts precede the pivots, and larger nuts and bolts follow the pivots. Our algorithm then completes by recursively applying itself to the subarray to the left and right of the pivot position to match these remaining bolts and nuts. We can assume by induction on *n* that these recursive calls will properly match the remainingbolts.

To analyze the running time of our algorithm, we can use the same analysis as that of randomized Quick Sort. Therefore, applying the analysis from Quick Sort, the time complexity of our algorithmis O(*nlogn*).

**Alternative Analysis:** We can solve this problemby making a small change to Quick Sort. Let us assume that we pick the last element as the pivot, say it is a nut. Compare the nut with only bolts as we walk down the array. This will partition the array for the bolts. Every bolt less than the partitionnut will be onthe left. And everybolt greater thanthe partitionnut will be onthe right.

While traversing down the list, find the matching bolt for the partition nut. Now we do the partition again using the matching bolt. As a result, all the nuts less than the matching bolt will be on the left side and all the nuts greater than the matching bolt will be on the right side. Recursivelycall onthe left and right arrays.

The time complexityis O(2nlogn) ≈ O(*nlogn*).

**Problem-37**  Given a binary tree, can we print its elements in sorted order in O(*n*) time by

performinganIn-order tree traversal?

**Solution: Yes,** if the tree is a BinarySearchTree [BST]. For more details refer to *Trees* chapter.

**Problem-38**  Given an array of elements, convert it into an array such that A< B > C < D > E

< F and so on.

**Solution:** Sort the array, thenswap everyadjacent element to get the final result.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.044.png)

The time complexityis O(*nlogn+n*) *≈* O(*nlogn*), for sortingand a scan. **Problem-39**  Canwe do [Problem-38](#_page40_x66.91_y298.33) withO(*n*) time?

**Solution:** Make sure all even positioned elements are greater than their adjacent odd elements, and we don’t need to worry about odd positioned elements. Traverse all even positioned elements of input array, and do the following:

- If the current element is smaller than the previous odd element, swap previous and

current.

- If the current element is smaller thanthe next odd element, swap next and current.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.045.png)

The time complexityis O(*n*).

**Problem-40**  Merge sort uses

1) Divide and conquer strategy
1) Backtrackingapproach
1) Heuristic search
1) Greedyapproach

**Solution: (a).** Refer theorysection.

**Problem-41**  Which of the following algorithm design techniques is used in the quicksort

algorithm?

1) Dynamic programming
1) Backtracking
1) Divide and conquer
1) Greedymethod

**Solution: (c).** Refer theorysection.

**Problem-42**  For merging two sorted lists of sizes m and n into a sorted list of size m+n, we

required comparisons of

1) O(*m*)
2) O(*n*)
3) O(*m* + *n*)
4) O(*logm + logn*)

**Solution: (c).** We canuse merge sort logic. Refer theorysection.

**Problem-43**  Quick-sort is runontwo inputs shownbelow to sort inascendingorder

1) 1,2,3 ....n
1) n, n- 1, n-2, .... 2, 1

Let C1 and C2 be the number of comparisons made for the inputs (i) and (ii) respectively. Then,

1) C1 < C2
1) C1 > C2
1) C1 = C2
1) we cannot sayanythingfor arbitrary*n*.

**Solution: (b).** Since the given problems needs the output in ascending order, Quicksort on already sorted order gives the worst case (O(*n*2)). So, (i) generates worst case and (ii) needs fewer comparisons.

**Problem-44**  Give the correct matchingfor the followingpairs:

1) O(*logn*)
2) O(*n*)
3) O(*nlogn*)
4) O(*n*2)
5) Selection
6) Insertionsort
7) Binarysearch
8) Merge sort
9) A– R B – PC – Q – D – S
10) A– R B – PC – S D – Q
11) A– PB – R C – S D – Q
12) A– PB – S C – R D – Q

**Solution: (b).** Refer theorysection.

**Problem-45**  Let s be a sorted array of n integers. Let t(n) denote the time taken for the most

efficient algorithm to determine if there are two elements with sum less than 1000 in s. whichof the followingstatements is true?

1) *t*(*n*) is O(1)
1) *n < t*(*n*) < ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.046.png)
1) ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.047.png)
1) ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.048.png)

**Solution: (a).** Since the given array is already sorted it is enough if we check the first two elements of the array.

**Problem-46**  The usual Θ(*n*2) implementation of Insertion Sort to sort an array uses linear

search to identify the position where an element is to be inserted into the already sorted part of the array. If, instead, we use binary search to identify the position, the worst case runningtime will

1) remainΘ(*n*2)
1) become Θ(*n*(*log n*)2)
1) become Θ(*nlogn*)
1) become Θ(*n*)

**Solution: (a).** If we use binary search then there will be ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.049.png) comparisons in the worst case,

which is Θ(*nlogn*). But the algorithm as a whole will still have a running time of Θ(*n*2) on average because of the series of swaps required for eachinsertion.

**Problem-47**  In quick sort, for sorting n elements, the *n/*4*th* smallest element is selected as

pivot using an O(*n*) time algorithm. What is the worst case time complexity of the quick sort?

1) Θ(*n*)
1) Θ(*nLogn*)
1) Θ(*n*2)
1) Θ(*n*2*logn*)

**Solution:** The recursionexpressionbecomes: T(n) = T(n/4) + T(3n/4) + en. Solvingthe recursion using*variant* of master theorem, we get Θ(*nLogn*).

**Problem-48**  Consider the Quicksort algorithm. Suppose there is a procedure for finding a

pivot element which splits the list into two sub-lists each of which contains at least one- fifth of the elements. Let T(*n*) be the number of comparisons required to sort n elements. Then

1) T (n) ≤ 2T (n/5) + n
1) T (n) ≤ T (n/5) + T (4n/5) + n
1) T (n) ≤ 2T (4n/5) + n
1) T (n) ≤ 2T (n/2) + n

**Solution: (C).** For the case where n/5 elements are in one subset, T(n/5) comparisons are needed for the first subset with*n*/5 elements, T(4n/5) is for the rest 4n/5 elements, and *n* is for finding the pivot. If there are more than *n*/5 elements in one set then other set will have less than 4n/5 elements and time complexitywill be less thanT(n/5) + T(4n/5) + n.

**Problem-49**  Which of the following sorting algorithms has the lowest worst-case

complexity?

1) Merge sort
1) Bubble sort
1) Quicksort
1) Selectionsort

**Solution: (A).** Refer theorysection.

**Problem-50**  Which one of the following in place sorting algorithms needs the minimum

number of swaps?

1) Quicksort
1) Insertionsort
1) Selectionsort
1) Heap sort

**Solution: (C).** Refer theorysection.

**Problem-51**  You have an array of n elements. Suppose you implement quicksort by always

choosing the central element of the array as the pivot. Then the tightest upper bound for the worst case performance is

1) O(*n*2)
1) O(*nlogn*)
1) Θ(*nlogn*)
1) O(*n*3)

**Solution:** (A). When we choose the first element as the pivot, the worst case of quick sort comes if the input is sorted- either inascendingor descendingorder.

**Problem-52**  Let P be a Quicksort Program to sort numbers in ascending order using the first

element as pivot. Let t1 and t2 be the number of comparisons made by P for the inputs {1, 2, 3, 4, 5} and {4, 1, 5, 3, 2} respectively. Whichone of the followingholds?

1) t1 = 5
1) t1 < t2
1) t1 > t2
1) t1 = t2

**Solution:** (C). Quick Sort’s worst case occurs when first (or last) element is chosen as pivot with sorted arrays.

**Problem-53**  The minimum number of comparisons required to find the minimum and the

maximumof 100 numbers is ——

**Solution:** 147 (Formula for the minimum number of comparisons required is 3n/2 – 3 with n numbers).

**Problem-54**  The number of elements that canbe sorted inT(*logn*) time usingheap sort is

1) Θ(1)
1) Θ(sqrt(logn))
1) Θ(logn/(loglogn))
1) Θ(logn)

**Solution:** (D). Sorting an array with k elements takes time Θ(k log k) as k grows. We want to choose k such that Θ(k log k) = Θ(logn). Choosing k = Θ(logn) doesn’t necessarily work, since Θ(k log k) = Θ(logn loglogn) ≠ Θ(logn). On the other hand, if you choose k = T(log n / log log n), thenthe runtime of the sort will be

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.050.png)

Notice that 1 – logloglogn / loglogn tends toward 1 as n goes to infinity, so the above expression actually is Θ(log n), as required. Therefore, if you try to sort an array of size Θ(logn / loglogn) usingheap sort, as a functionof n, the runtime is Θ(logn).

**Problem-55**  Which one of the following is the tightest upper bound that represents the

number of swaps required to sort *n* numbers usingselectionsort?

1) O(*logn*)
1) O(*n*)
1) O(*nlogn*)
1) O(*n*2)

**Solution:** (B). Selectionsort requires onlyO(*n*) swaps.

**Problem-56**  Which one of the following is the recurrence equation for the worst case time

complexity of the Quicksort algorithm for sorting n(≥ 2) numbers? In the recurrence equations giveninthe options below, c is a constant.

(A)T(n) = 2T (n/2) + cn

2) T(n) = T(n– 1) + T(0) + cn
2) T(n) = 2T (n– 2) + cn
2) T(n) = T(n/2) + cn

**Solution:** (B). Whenthe pivot is the smallest (or largest) element at partitioningona blockof size n the result yields one empty sub-block, one element (pivot) in the correct place and sub block of size *n* – 1.

**Problem-57**  True or False. Inrandomized quicksort, eachkeyis involved inthe same number

of comparisons.

**Solution:** False.

**Problem-58**  True or False: If Quicksort is written so that the partition algorithmalways uses the medianvalue of the segment as the pivot, thenthe worst-case performance is O(*nlogn*).

**Soution:** True.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.051.png)

1. **What is Searching?**

In computer science, *searching* is the process of finding an itemwith specified properties froma collection of items. The items may be stored as records in a database, simple data elements in arrays, text in files, nodes in trees, vertices and edges in graphs, or they may be elements of other searchspaces.

2. **Why do we need Searching?**

*Searching* is one of the core computer science algorithms. We know that today’s computers store a lot of information. To retrieve this information proficiently we need very efficient searching algorithms. There are certain ways of organizing the data that improves the searching process. That means, if we keep the data in proper order, it is easy to search the required element. Sorting is one of the techniques for making the elements ordered. In this chapter we will see different searchingalgorithms.

3. **Types of Searching**

Followingare the types of searches whichwe will be discussinginthis book.

- Unordered Linear Search
- Sorted/Ordered Linear Search
- BinarySearch
- Interpolationsearch
- BinarySearchTrees (operates ontrees and refer *Trees* chapter)
- Symbol Tables and Hashing
- StringSearchingAlgorithms: Tries, TernarySearchand SuffixTrees

4. **Unordered Linear Search**

Let us assume we are givenanarraywhere the order of the elements is not known. That means the elements of the array are not sorted. In this case, to search for an element we have to scan the complete arrayand see if the element is there inthe givenlist or not.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.052.png)

Time complexity: O(*n*), in the worst case we need to scan the complete array. Space complexity: O(1).

5. **Sorted/Ordered Linear Search**

If the elements of the array are already sorted, then in many cases we don’t have to scan the complete array to see if the element is there in the given array or not. In the algorithm below, it can be seen that, at any point if the value at *A*[*i*] is greater than the *data* to be searched, then we just return–1 without searchingthe remainingarray.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.053.png)

Time complexity of this algorithm is O(*n*).This is because in the worst case we need to scan the complete array. But in the average case it reduces the complexity even though the growth rate is the same.

Space complexity: O(1).

**Note:** For the above algorithm we can make further improvement by incrementing the index at a faster rate (say, 2). This will reduce the number of comparisons for searchinginthe sorted list.

6. **Binary Search**

Let us consider the problem of searching a word in a dictionary. Typically, we directly go to some approximate page [say, middle page] and start searchingfromthat point. If the *name* that we are searching is the same then the search is complete. If the page is before the selected pages then apply the same process for the first half; otherwise apply the same process to the second half. Binary search also works in the same way. The algorithm applying such a strategy is referred to as *binary search* algorithm.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.054.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.055.jpeg)

Recurrence for binary search is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.056.png). This is because we are always

considering only half of the input list and throwing out the other half. Using *Divide and Conquer* master theorem, we get, *T*(*n*) = O(*logn*).

Time Complexity: O(*logn*). Space Complexity: O(1) [for iterative algorithm].

7. **Interpolation Search**

Undoubtedly binary search is a great algorithm for searching with average running time complexity of *logn*. It always chooses the middle of the remaining search space, discarding one half or the other, again depending on the comparison between the key value found at the estimated (middle) position and the key value sought. The remaining search space is reduced to the part

before or after the estimated position.

Inthe mathematics, interpolationis a process of constructingnew data points withinthe range of a discrete set of known data points. In computer science, one often has a number of data points which represent the values of a function for a limited number of values of the independent variable. It is often required to interpolate (i.e. estimate) the value of that function for an intermediate value of the independent variable.

For example, suppose we have a table like this, which gives some values of an unknown function *f*. Interpolationprovides a means of estimatingthe functionat intermediate points, suchas *x* = 55.



| *x*                                                          | *f*(*x*) |
| ------------------------------------------------------------ | -------- |
| 1                                                            | 10       |
| 2                                                            | 20       |
| 3                                                            | 30       |
| 4                                                            | 40       |
| 5                                                            | 50       |
| 6                                                            | 60       |
| 7                                                            | 70       |
| There are many different interpolation methods, and one of the simplest methods is linear interpolation. Since 55 is midway between 50 and 60, it is reasonable to take *f*(55) midway between*f*(5) = 50 and *f*(6) = 60, whichyields 55. |          |

Linear interpolationtakes two data points, say(*x*1; *y*2) and (*x*2, *y*2), and the interpolant is givenby:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.057.png)

With above inputs, what will happen if we don’t use the constant ½, but another more accurate constant “K”, that canlead us closer to the searched item.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.058.png)

This algorithm tries to follow the way we search a name in a phone book, or a word in the dictionary. We, humans, know in advance that in case the name we’re searching starts with a “m”, like “monk” for instance, we should start searching near the middle of the phone book. Thus if we’re searching the word “career” in the dictionary, you know that it should be placed somewhere at the beginning. This is because we know the order of the letters, we know the interval (a-z), and somehow we intuitively know that the words are dispersed equally. These facts are enough to realize that the binary search can be a bad choice. Indeed the binary search algorithm divides the list in two equal sub-lists, which is useless if we know in advance that the searched item is somewhere in the beginning or the end of the list. Yes, we can use also jump search if the itemis at the beginning, but not if it is at the end, in that case this algorithmis not so effective.

The interpolation search algorithmtries to improve the binary search. The question is how to find this value? Well, we know bounds of the interval and looking closer to the image above we can define the followingformula.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.059.png)

This constant *K* is used to narrow down the search space. For binary search, this constant *K* is (*low + high*)*/*2.

Now we can be sure that we’re closer to the searched value. On average the interpolation search makes about *log* (*logn*) comparisons (if the elements are uniformly distributed), where *n* is the number of elements to be searched. In the worst case (for instance where the numerical values of the keys increase exponentially) it can make up to O(*n*) comparisons. In interpolation-sequential search, interpolation is used to find an item near the one being searched for, then linear search is used to find the exact item. For this algorithm to give best results, the dataset should be ordered and uniformlydistributed.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.060.png)

8. **Comparing Basic Searching Algorithms**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.061.png)

**Note:** For discussiononbinarysearchtrees refer *Trees* chapter.

9. **SymbolTables and Hashing**

Refer to *[Symbol Tables*](#_page52_x28.00_y289.17)* and *Hashing* chapters.

10. **String Searching Algorithms**

Refer to *String Algorithms* chapter.

11. **Searching: Problems & Solutions**

**Problem-1**  Given an array of *n* numbers, give an algorithm for checking whether there are

anyduplicate elements inthe arrayor no?

**Solution:** This is one of the simplest problems. One obvious answer to this is exhaustively searching for duplicates in the array. That means, for each input element check whether there is any element with the same value. This we can solve just by using two simple *for* loops. The code for this solutioncanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.062.png)

Time Complexity: O(*n*2), for two nested *for* loops. Space Complexity: O(1). **Problem-2**  Canwe improve the complexityof [Problem-1](#_page52_x66.91_y497.32)*’s* solution?

**Solution: Yes.** Sort the given array. After sorting, all the elements with equal values will be adjacent. Now, do another scan on this sorted array and see if there are elements with the same value and adjacent.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.063.png)

Time Complexity: O(*nlogn*), for sorting (assuming *nlogn* sorting algorithm). Space Complexity: O(1).

**Problem-3**  Is there anyalternative wayof solving*Problem-1*?

**Solution: Yes,** using hash table. Hash tables are a simple and effective method used to implement dictionaries. *Average* time to search for an element is O(1), while worst-case time is O(*n*). Refer to *Hashing* chapter for more details onhashingalgorithms. As anexample, consider the array, *A*= {3,2,1,2,2,3}.

Scan the input array and insert the elements into the hash. For each inserted element, keep the *counter* as 1 (assume initially all entires are filled with zeros). This indicates that the corresponding element has occurred already. For the given array, the hash table will look like (after insertingthe first three elements 3,2 and 1):

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.064.png)

Now if we try inserting 2, since the counter value of 2 is already 1, we can say the element has appeared twice.

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-4**  Canwe further improve the complexityof [Problem-1](#_page52_x66.91_y497.32) solution?

**Solution:** Let us assume that the array elements are positive numbers and all the elements are in the range 0 to *n* – 1. For each element *A*[*i*], go to the array element whose index is *A*[*i*]. That means select *A*[*A*[*i*]] and mark - *A*[*A*[*i*]] (negate the value at *A*[*A*[*i*]]). Continue this process until we encounter the element whose value is already negated. If one such element exists then we say duplicate elements exist inthe givenarray. As anexample, consider the array, *A*= {3,2,1,2,2,3}.

Initially,

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.065.png)

At step-1, negate A[abs(A[0])],

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.066.png)

At step-2, negate A[abs(A[l])],

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.067.png)

At step-3, negate A[abs(A[2])],

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.068.png)

At step-4, negate A[abs(A[3])],

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.069.png)

At step-4, observe that *A*[*abs*(*A*[3])] is already negative. That means we have encountered the same value twice.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.070.png)

Time Complexity: O(*n*). Since onlyone scanis required. Space Complexity: O(1). **Notes:**

- This solutiondoes not workif the givenarrayis read only.
- This solutionwill workonlyif all the arrayelements are positive.
- If the elements range is not in0 to *n* – 1 thenit maygive exceptions.

**Problem-5**  Given an array of *n* numbers. Give an algorithm for finding the element which

appears the maximumnumber of times inthe array?

**Brute Force Solution:** One simple solution to this is, for each input element check whether there is any element with the same value, and for each such occurrence, increment the counter. Each time, checkthe current counter withthe *max* counter and update it if this value is greater than *max* counter. This we cansolve just byusingtwo simple *for* loops.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.071.png)

Time Complexity: O(*n*2), for two nested *for* loops. Space Complexity: O(1). **Problem-6**  Canwe improve the complexityof [Problem-5](#_page55_x66.91_y579.57) solution?

**Solution: Yes.** Sort the given array. After sorting, all the elements with equal values come adjacent. Now, just do another scan on this sorted array and see which element is appearing the maximumnumber of times.

Time Complexity: O(*nlogn*). (for sorting). Space Complexity: O(1). **Problem-7**  Is there anyother wayof solving[Problem-5](#_page55_x66.91_y579.57)?

**Solution: Yes,** using hash table. For each element of the input, keep track of how many times that element appeared in the input. That means the counter value represents the number of occurrences for that element.

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-8**  or [Problem-5](#_page55_x66.91_y579.57), can we improve the time complexity? Assume that the elements’

range is 1 to *n*. That means all the elements are withinthis range only.

**Solution: Yes.** We can solve this problem in two scans. We *cannot* use the negation technique of [Problem-3](#_page53_x66.91_y629.64) for this problem because of the number of repetitions. In the first scan, instead of negating, add the value *n*. That means for each occurrence of an element add the array size to that element. In the second scan, check the element value by dividing it by *n* and return the element whichgives the maximumvalue. The code based onthis method is givenbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.072.png)

**Notes:**

- This solutiondoes not workif the givenarrayis read only.
- This solutionwill workonlyif the arrayelements are positive.
- If the elements range is not in1 to *n* thenit maygive exceptions.

Time Complexity: O(*n*). Since no nested *for* loops are required. Space Complexity: O(1).

**Problem-9**  Given an array of *n* numbers, give an algorithmfor finding the first element in the

array which is repeated. For example, in the array *A =* {3,2,1,2,2,3}, the first repeated number is 3 (not 2). That means, we need to return the first element among the repeated elements.

**Solution:** We canuse the brute force solutionthat we used for [Problem-1](#_page52_x66.91_y497.32). For each element, since it checks whether there is a duplicate for that element or not, whichever element duplicates first will be returned.

**Problem-10**  For [Problem-9](#_page57_x66.91_y353.04), canwe use the sortingtechnique?

**Solution:** No. For proving the failed case, let us consider the following array. For example, *A* = {3, 2, 1, 2, 2, 3}. After sorting we get *A =* {1,2,2,2,3,3}. In this sorted array the first repeated element is 2 but the actual answer is 3.

**Problem-11**  For [Problem-9](#_page57_x66.91_y353.04), canwe use hashingtechnique?

**Solution:** Yes. But the simple hashing technique which we used for [Problem-3](#_page53_x66.91_y629.64) will not work. For example, if we consider the input array as A = {3,2,1,2,3}, then the first repeated element is 3, but using our simple hashing technique we get the answer as 2. This is because 2 is coming twice before 3. Now let us change the hashing table behavior so that we get the first repeated element. Let us say, instead of storing 1 value, initially we store the position of the element in the array. As a result the hashtable will looklike (after inserting3,2 and 1):

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.073.png)

Now, if we see 2 again, we just negate the current value of 2 in the hash table. That means, we make its counter value as –2. The negative value in the hash table indicates that we have seen the same element two times. Similarly, for 3 (the next element inthe input) also, we negate the current value of the hashtable and finallythe hashtable will looklike:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.074.png)

After processing the complete input array, scan the hash table and return the highest negative indexed value fromit (i.e., –1 inour case). The highest negative value indicates that we have seen that element first (amongrepeated elements) and also repeating.

**What if the element is repeated more than twice?** In this case, just skip the element if the correspondingvalue *i* is alreadynegative.

**Problem-12**  For [Problem-9](#_page57_x66.91_y353.04), can we use the technique that we used for [Problem-3](#_page53_x66.91_y629.64) (negation

technique)?

**Solution: No.** As an example of contradiction, for the array *A =* {3,2,1,2,2,3} the first repeated element is 3. But withnegationtechnique the result is 2.

**Problem-13  Finding the Missing Number:** We are given a list of *n* – 1 integers and these

integers are in the range of 1 to *n*. There are no duplicates in the list. One of the integers is missing in the list. Given an algorithm to find the missing integer. **Example:** I/P: [1,2,4,6,3,7,8] O/P: 5

**Brute Force Solution:** One simple solution to this is, for each number in 1 to n, check whether that number is inthe givenarrayor not.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.075.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-14**  For [Problem-13](#_page58_x66.91_y528.23), canwe use sortingtechnique?

**Solution: Yes.** Sortingthe list will give the elements inincreasingorder and withanother scanwe canfind the missingnumber.

Time Complexity: O(*nlogn*), for sorting. Space Complexity: O(1). **Problem-15**  For [Problem-13](#_page58_x66.91_y528.23), canwe use hashingtechnique?

**Solution: Yes.** Scan the input array and insert elements into the hash. For inserted elements, keep *counter* as 1 (assume initially all entires are filled with zeros). This indicates that the corresponding element has occurred already. Now, scan the hash table and return the element whichhas counter value zero.

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-16**  For [Problem-13](#_page58_x66.91_y528.23), canwe improve the complexity?

**Solution: Yes.** We canuse summationformula.

1) Get the sumof numbers, *sum = n* × (*n* + l)/2.
1) Subtract all the numbers from*sum* and youwill get the missingnumber.

Time Complexity: O(*n*), for scanningthe complete array.

**Problem-17**  In [Problem-13](#_page58_x66.91_y528.23), if the sum of the numbers goes beyond the maximum allowed

integer, then there can be integer overflow and we may not get the correct answer. Can we solve this problem?

**Solution:**

1) *XOR* all the arrayelements, let the result of *XOR* be *X.*

2) *XOR* all numbers from1 to *n*, let *XOR* be Y.
3) *XOR* of *X* and *Y*gives the missingnumber.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.076.png)

Time Complexity: O(*n*), for scanningthe complete array. Space Complexity: O(1).

**Problem-18  Find the Number Occurring an Odd Number of Times:** Given an array of

positive integers, all numbers occur an even number of times except one number which occurs an odd number of times. Find the number in O(*n*) time & constant space. **Example** : I/P= [1,2,3,2,3,1,3] O/P= 3

**Solution:** Do a bitwise *XOR* of all the elements. We get the number which has odd occurrences. This is because, *AXOR A=* 0.

Time Complexity: O(n). Space Complexity: O(1).

**Problem-19  Find the two repeating elements in a given array:** Given an array with *size*,

all elements of the array are in range 1 to n and also all elements occur only once except two numbers which occur twice. Find those two repeating numbers. For example: if the array is 4,2,4,5,2,3,1 with *size* = 7 and *n* = 5. This input has *n +* 2 = 7 elements with all elements occurringonce except 2 and 4 whichoccur twice. So the output should be 4 2.

**Solution:** One simple way is to scan the complete array for each element of the input elements. That means use two loops. In the outer loop, select elements one by one and count the number of occurrences of the selected element in the inner loop. For the code below, assume that *PrintRepeatedElements* is called with*n +* 2 to indicate the size.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.077.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-20**  For [Problem-19](#_page60_x66.91_y438.42), canwe improve the time complexity?

**Solution:** Sort the array using any comparison sorting algorithmand see if there are any elements whichare contiguous withthe same value.

Time Complexity: O(*nlogn*). Space Complexity: O(1).

**Problem-21**  For [Problem-19](#_page60_x66.91_y438.42), canwe improve the time complexity?

**Solution:** Use Count Array. This solution is like using a hash table. For simplicity we can use array for storing the counts. Traverse the array once and keep track of the count of all elements in the array using a temp array *count*[] of size *n*. When we see an element whose count is already set, print it as duplicate. For the code below assume that *PrintRepeatedElements* is called with *n*

+ 2 to indicate the size.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.078.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-22**  Consider [Problem-19](#_page60_x66.91_y438.42). Let us assume that the numbers are in the range 1 to n. Is

there anyother wayof solvingthe problem?

**Solution: Yes, by using XOR Operation.** Let the repeating numbers be *X* and *Y*, if we *XOR* all the elements inthe arrayand also all integers from1 to *n*, thenthe result will be *X XOR Y*. The 1’s

inbinaryrepresentationof *X XOR Y*correspond to the different bits between*X* and *Y*. If the *kth* bit of *X XOR Y*is 1, we can *XOR* all the elements in the array and also all integers from1 to n whose

*kth* bits are 1. The result will be one of *X* and *Y.*


![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.079.jpeg)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-23**  Consider [Problem-19](#_page60_x66.91_y438.42). Let us assume that the numbers are in the range 1 to *n*. Is

there yet other wayof solvingthe problem?

**Solution:** We can solve this by creating two simple mathematical equations. Let us assume that two numbers we are going to find are *X* and *Y*. We know the sum of *n* numbers is *n*(*n* + l)/2 and the product is *n*!. Make two equations using these sum and product formulae, and get values of two unknowns using the two equations. Let the summation of all numbers in array be *S* and product be *P* and the numbers whichare beingrepeated are *X* and *Y*.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.080.png)

Using the above two equations, we can find out *X* and *Y*. There can be an addition and multiplicationoverflow problemwiththis approach.

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-24**  Similar to [Problem-19](#_page60_x66.91_y438.42), let us assume that the numbers are in the range 1 to n.

Also, *n –* 1 elements are repeating thrice and remaining element repeated twice. Find the element whichrepeated twice.

**Solution:** If we *XOR* all the elements in the array and all integers from 1 to n, then all the elements which are repeated thrice will become zero. This is because, since the element is repeating thrice and *XOR* another time from range makes that element appear four times. As a result, the output of *a XOR a XOR a XOR a =* 0. It is the same case with all elements that are repeated three times.

Withthe same logic, for the element whichrepeated twice, if we *XOR* the input elements and also the range, then the total number of appearances for that element is 3. As a result, the output *of a XOR a XOR a = a*. Finally, we get the element whichrepeated twice.

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-25**  Given an array of *n* elements. Find two elements in the array such that their sum

is equal to givenelement *K.*

**Brute Force Solution:** One simple solution to this is, for each input element, check whether there is any element whose sum is *K*. This we can solve just by using two simple for loops. The code for this solutioncanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.081.png)

Time Complexity: O(*n*2). This is because of two nested *for* loops. Space Complexity: O(1). **Problem-26**  For [Problem-25](#_page63_x66.91_y278.88), canwe improve the time complexity?

**Solution: Yes.** Let us assume that we have sorted the given array. This operation takes O(*nlogn*). On the sorted array, maintain indices *loIndex =* 0 and *hiIndex = n* – 1 and compute *A*[*loIndex*] *+ A*[*hiIndex*]. If the sum equals *K*, then we are done with the solution. If the sum is less than *K*, decrement *hiIndex*, if the sumis greater than*K*, increment *loIndex.*


![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.082.png)

Time Complexity: O(*nlogn*). If the givenarrayis alreadysorted thenthe complexityis O(*n*). Space Complexity: O(1).

**Problem-27**  Does the solutionof [Problem-25](#_page63_x66.91_y278.88) workevenif the arrayis not sorted?

**Solution: Yes.** Since we are checking all possibilities, the algorithm ensures that we get the pair of numbers if theyexist.

**Problem-28**  Is there anyother wayof solving[Problem-25](#_page63_x66.91_y278.88)?

**Solution: Yes,** usinghashtable. Since our objective is to find two indexes of the arraywhose sum is *K*. Let us say those indexes are *X* and *Y*. That means, *A*[*X*] + *A*[*Y*] *= K*. What we need is, for each element of the input array *A*[*X*], check whether *K – A*[*X*] also exists in the input array. Now, let us simplifythat searchingwithhashtable.

**Algorithm:**

- For eachelement of the input array, insert it into the hashtable. Let us saythe current element is *A*[*X*].
- Before proceeding to the next element we check whether *K* – *A*[*X*] also exists in the hashtable or not.
- Ther existence of suchnumber indicates that we are able to find the indexes.
- Otherwise proceed to the next input element.

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-29**  GivenanarrayAof *n* elements. Find three indices, *i,j* & *k* suchthat *A*[*i*]2 + *A*[*j*]2

- *A*[*k*]2?

**Solution: Algorithm:**

- Sort the givenarrayin-place.
- For eacharrayindex*i* compute *A*[*i*]2 and store inarray.
- [Search for 2 numbers in array from0 to *i* – 1 which adds to *A*\[*i*\] similar to Problem-](#_page63_x66.91_y278.88)

[25. This will give us the result in O(*n*) time. If we find such a sum, return true, ](#_page63_x66.91_y278.88)otherwise continue.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.083.png)

Time Complexity: Time for sorting+ *n* × (Time for findingthe sum) = O(*nlogn*) *+ n* × O(n)= *n*2. Space Complexity: O(1).

**Problem-30  Two elements whose sumis closest to zero.** Given an array with both positive

and negative numbers, find the two elements such that their sum is closest to zero. For the below array, algorithmshould give -80 and 85. Example: 1 60 – 10 70 – 80 85

**Brute Force Solution:** For each element, find the *sum* with every other element in the array and compare sums. Finally, returnthe minimum*sum.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.084.jpeg)

Time complexity: O(*n*2). Space Complexity: O(1).

**Problem-31**  Canwe improve the time complexityof [Problem-30](#_page65_x66.91_y432.77)? **Solution:** Use Sorting.

**Algorithm:**

1. Sort all the elements of the giveninput array.
1. Maintain two indexes, one at the beginning (*i* = 0) and the other at the ending (*j* = *n* –
   1. Also, maintain two variables to keep track of the smallest positive sum closest to zero and the smallest negative sumclosest to zero.
1. While *i < j:*
1. If the current pair sum is > zero and < *postiveClosest* then update the postiveClosest. Decrement *j.*
1. If the current pair sum is < zero and > *negativeClosest* then update the negativeClosest. Increment *i.*
1. Else, print the pair

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.085.png)

Time Complexity: O(*nlogn*), for sorting. Space Complexity: O(1).

**Problem-32**  Givenanarrayof nelements. Find three elements inthe arraysuchthat their sum

is equal to givenelement *K?*

**Brute Force Solution:** The default solution to this is, for each pair of input elements check whether there is any element whose sum is *K*. This we can solve just by using three simple for loops. The code for this solutioncanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.086.png)Time Complexity: O(*n*3), for three nested *for* loops. Space Complexity: O(1). **Problem-33**  Does the solutionof [Problem-32](#_page67_x66.91_y400.03) workevenif the arrayis not sorted?

**Solution: Yes.** Since we are checking all possibilities, the algorithm ensures that we can find three numbers whose sumis *K* if theyexist.

**Problem-34**  Canwe use sortingtechnique for solving[Problem-32](#_page67_x66.91_y400.03)? **Solution: Yes.**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.087.png)

Time Complexity: Time for sorting + Time for searching in sorted list = O(*nlogn*) + O(*n*2) ≈ O(*n*2). This is because of two nested *for* loops. Space Complexity: O(1).

**Problem-35**  Canwe use hashingtechnique for solving[Problem-32](#_page67_x66.91_y400.03)?

**Solution: Yes.** Since our objective is to find three indexes of the arraywhose sumis *K*. Let us say those indexes are *X,Y*and *Z*. That means, *A*[*X*] *+ A*[*Y*] *+ A*[*Z*] *= K.*

Let us assume that we have kept all possible sums alongwiththeir pairs inhashtable. That means the key to hash table is *K – A*[*X*] and values for *K – A*[*X*] are all possible pairs of input whose sumis if – *A*[*X*].

**Algorithm:**

- Before starting the search, insert all possible sums with pairs of elements into the hashtable.
- For each element of the input array, insert into the hash table. Let us say the current element is *A*[*X*].
- Checkwhether there exists a hashentryinthe table withkey: *K – A*[*X*].
- If such element exists then scan the element pairs of *K – A*[*X*] and return all possible pairs byincluding*A*[*X*] also.
- If no suchelement exists (with*K – A*[*X*] as key) thengo to next element.

Time Complexity: The time for storing all possible pairs in Hash table + searching = O(*n*2) + O(*n*2) *≈* O(*n*2). Space Complexity: O(*n*).

**Problem-36**  Givenanarrayof *n* integers, the 3 – *sum problem* is to find three integers whose

sumis closest to *zero.*

**Solution:** This is the same as that of [Problem-32](#_page67_x66.91_y400.03) with*K* value is zero.

**Problem-37**  Let A be an array of *n* distinct integers. Suppose A has the following property:

there exists an index 1 ≤ *k* ≤ *n* such that *A*[l],..., *A*[*k*] is an increasing sequence and *A*[*k* + 1],..., *A*[*n*] is a decreasing sequence. Design and analyze an efficient algorithm for finding *k.*

**Similar question:** Let us assume that the given array is sorted but starts with negative numbers and ends with positive numbers [such functions are called monotonically increasing functions]. In this array find the starting index of the positive numbers. Assume that we know the lengthof the input array. Designa O(*logn*) algorithm.

**Solution:** Let us use a variant of the binarysearch.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.088.jpeg)

The recursionequationis *T*(*n*) = 2*T*(*n/*2) *+ c*. Usingmaster theorem, we get O(*logn*). **Problem-38**  If we don’t know n, how do we solve the [Problem-37](#_page69_x66.91_y261.08)?

**Solution:** Repeatedly compute *A*[1],*A*[2],*A*[4],*A*[8],*A*[16] and so on, until we find a value of *n* suchthat *A*[*n*] *>* 0.

Time Complexity: O(*logn*), since we are moving at the rate of 2. Refer to *Introduction to Analysis of Algorithms* chapter for details onthis.

**Problem-39**  Given an input array of size unknown with all 1’s in the beginning and 0’s in the

end. Find the indexinthe arrayfromwhere 0’s start. Consider there are millions of 1’s and 0’s inthe array. E.g. arraycontents 1111111……..1100000……..0000000.

**Solution:** This problem is almost similar to [Problem-38](#_page70_x66.91_y474.19). Check the bits at the rate of 2*K*where *k*

- 0,1,2 *...*. Since we are movingat the rate of 2, the complexityis O(*logn*).

**Problem-40**  Given a sorted array of n integers that has been rotated an unknown number of

times, give a O(*logn*) algorithmthat finds anelement inthe array.

**Example:** Find 5 in array (15 16 19 20 25 1 3 4 5 7 10 14) **Output:** 8 (the index of 5 in the array)

**Solution:** Let us assume that the given array is *A*[]and use the solution of [Problem-37](#_page69_x66.91_y261.08) with an extension. The function below *FindPivot* returns the *k* value (let us assume that this function returns the index instead of the value). Find the pivot point, divide the array into two sub-arrays and call binarysearch.

The main idea for finding the pivot point is – for a sorted (in increasing order) and pivoted array, the pivot element is the only element for which the next element to it is smaller than it. Using the above criteria and the binarysearchmethodologywe canget pivot element inO(*logn*) time.

**Algorithm:**

1) Find out the pivot point and divide the arrayinto two sub-arrays.
1) Now call binarysearchfor one of the two sub-arrays.
   1. if the element is greater than the first element then search in left subarray.
   1. else searchinright subarray.
1) If element is found inselected sub-array, thenreturnindex*else* return–1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.089.jpeg)

Time complexity: O(*logn*).

**Problem-41**  For [Problem-40](#_page70_x66.91_y697.52), canwe solve withrecursion?

**Solution: Yes.**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.090.png)

Time complexity: O(*logn*).

**Problem-42  Bitonic search:** An array is *bitonic* if it is comprised of an increasing sequence

of integers followed immediately by a decreasing sequence of integers. Given a bitonic array A of n distinct integers, describe how to determine whether a given integer is in the arrayinO(*logn*) steps.

**Solution:** The solutionis the same as that for [Problem-37](#_page69_x66.91_y261.08).

**Problem-43**  Yet, other wayof framing[Problem-37](#_page69_x66.91_y261.08).

Let *A*[] be an array that starts out increasing, reaches a maximum, and then decreases. DesignanO(*logn*) algorithmto find the indexof the maximumvalue.

**Problem-44**  Give an O(*nlogn*) algorithm for computing the median of a sequence of *n*

integers.

**Solution:** Sort and returnelement at ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.091.png).

**Problem-45**  Given two sorted lists of size *m* and n, find median of all elements in O(*log* (*m*

+ *n*)) time.

**Solution:** Refer to *Divide and Conquer* chapter.

**Problem-46**  Given a sorted array *A* of n elements, possibly with duplicates, find the index of

the first occurrence of a number inO(*logn*) time.

**Solution:** To find the first occurrence of a number we need to check for the following condition.

Returnthe positionif anyone of the followingis true:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.092.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.093.png)

Time Complexity: O(*logn*).

**Problem-47**  Givena sorted array*A*of nelements, possiblywithduplicates. Find the indexof

the last occurrence of a number inO(*logn*) time.

**Solution:** To find the last occurrence of a number we need to check for the following condition. Returnthe positionif anyone of the followingis true:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.094.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.095.png)

Time Complexity: O(*logn*).

**Problem-48**  Givena sorted arrayof *n* elements, possiblywithduplicates. Find the number of

occurrences of a number.

**Brute Force Solution:** Do a linear search of the array and increment count as and when we find the element data inthe array.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.096.png)

Time Complexity: O(*n*).

**Problem-49**  Canwe improve the time complexityof [Problem-48](#_page75_x66.91_y55.03)?

**Solution: Yes.** We cansolve this byusingone binarysearchcall followed byanother small scan. **Algorithm:**

- Do a binarysearchfor the *data* inthe array. Let us assume its positionis *K.*
- Now traverse towards the left from K and count the number of occurrences of *data*. Let this count be *leftCount.*
- Similarly, traverse towards right and count the number of occurrences of *data*. Let this count be *rightCount.*
- Total number of occurrences = *leftCount* + 1 + *rightCount*

Time Complexity– O(*logn + S*) where 5 is the number of occurrences of *data.* **Problem-50**  Is there anyalternative wayof solving[Problem-48](#_page75_x66.91_y55.03)? **Solution:**

**Algorithm:**

- Find first occurrence of *data* and call its index as *firstOccurrence* (for algorithm refer to [Problem-46](#_page73_x66.91_y692.70))
- Find last occurrence of *data* and call its index as *lastOccurrence* (for algorithm refer to [Problem-47](#_page74_x66.91_y383.69))
- Return*lastOccurrence* – *firstOccurrence* + 1

Time Complexity= O(*logn* + *logn*) *= O*(*logn*).

**Problem-51**  What is the next number inthe sequence 1,11,21 and why? **Solution:** Read the givennumber loudly. This is just a funproblem.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.097.png)

So the answer is: the next number is the representation of the previous number by reading it loudly.

**Problem-52**  Findingsecond smallest number efficiently.

**Solution:** We can construct a heap of the given elements using up just less than *n* comparisons (Refer to the *Priority Queues* chapter for the algorithm). Then we find the second smallest using *logn* comparisons for the GetMax() operation. Overall, we get *n* + *logn + constant.*

**Problem-53**  Is there anyother solutionfor [Problem-52](#_page76_x66.91_y195.36)?

**Solution:** Alternatively, split the *n* numbers into groups of 2, perform *n/*2 comparisons successively to find the largest, using a tournament-like method. The first round will yield the maximum in *n* – 1 comparisons. The second round will be performed on the winners of the first round and the ones that the maximumpopped. This will yield *logn* – 1 comparison for a total of *n*

+ *logn –* 2. The above solutionis called the *tournament problem.*

**Problem-54**  An element is a majority if it appears more than *n*/2 times. Give an algorithm

takes anarrayof nelement as argument and identifies a majority(if it exists).

**Solution:** The basic solution is to have two loops and keep track of the maximum count for all different elements. If the maximumcount becomes greater than*n*/2, thenbreakthe loops and return the element having maximum count. If maximum count doesn’t become more than *n*/2, then the majorityelement doesn’t exist.

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-55**  Canwe improve [Problem-54](#_page76_x66.91_y399.86) time complexityto O(*nlogn*)*?*

**Solution:** Using binary search we can achieve this. Node of the Binary Search Tree (used in this approach) will be as follows.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.098.png)Insert elements in BST one by one and if an element is already present then increment the count of the node. At any stage, if the count of a node becomes more than *n*/2, then return. This method works well for the cases where *n*/2 +1 occurrences of the majorityelement are present at the start of the array, for example {1,1,1,1,1,2,3, and 4}.

Time Complexity: If a binary search tree is used then worst time complexity will be O(*n*2). If a balanced-binary-searchtree is used thenO(*nlogn*). Space Complexity: O(*n*).

**Problem-56**  Is there anyother of achievingO(*nlogn*) complexityfor [Problem-54](#_page76_x66.91_y399.86)? **Solution:** Sort the input arrayand scanthe sorted arrayto find the majorityelement.

Time Complexity: O(*nlogn*). Space Complexity: O(1). **Problem-57**  Canwe improve the complexityfor [Problem-54](#_page76_x66.91_y399.86)?

**Solution:** If an element occurs more than *n*/2 times in *A* then it must be the median of *A*. But, the reverse is not true, so once the medianis found, we must checkto see how manytimes it occurs in [*A*. We can use linear selection which takes O(*n*) time (for algorithm, refer to *Selection Algorithms* chapter).](#_page89_x28.00_y82.94)

int CheckMajority(int A[], inn) {

1) Use linear selectionto find the median*m* of *A.*
1) Do one more pass through*A*and count the number of occurrences of *m.*

1. If *m* occurs more than*n*/2 times thenreturntrue;
1. Otherwise returnfalse.

}

**Problem-58**  Is there anyother wayof solving[Problem-54](#_page76_x66.91_y399.86)?

**Solution:** Since only one element is repeating, we can use a simple scan of the input array by keeping track of the count for the elements. If the count is 0, then we can assume that the element visited for the first time otherwise that the resultant element.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.099.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-59**  Given an array of 2*n* elements of which n elements are the same and the

remainingnelements are all different. Find the majorityelement.

**Solution:** The repeated elements will occupy half the array. No matter what arrangement it is, onlyone of the below will be true:

- All duplicate elements will be at a relative distance of 2 fromeach other. Ex:**n**, *1*, **n**, *100*, **n**, *54*, **n**...
- At least two duplicate elements will be next to eachother.

Ex: *n,n*, 1,100, *n*, 54, *n*,....

*n*, 1,*n*,*n*,*n*,54,100...

1,100,54, *n.n.n.n....*

Inworst case, we will need two passes over the array:

- First Pass: compare *A*[*i*] and *A*[*i* + 1]
- Second Pass: compare *A*[*i*] and *A*[*i* + 2]

Somethingwill matchand that’s your element. This will cost O(*n*) intime and O(1) inspace.

**Problem-60**  Given an array with 2*n* + 1 integer elements, n elements appear twice in arbitrary places in the array and a single integer appears only once somewhere inside.

Find the lonelyinteger withO(*n*) operations and O(1) extra memory.

**Solution:** Except for one element, all elements are repeated. We know that *A XOR A* = 0. Based onthis if we *XOR* all the input elements thenwe get the remainingelement.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.100.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-61  Throwing eggs fromann-story building:** Suppose we have an *n* story building

and a number of eggs. Also assume that aneggbreaks if it is thrownfromfloor *F* or higher, and will not break otherwise. Devise a strategy to determine floor *F*, while breaking O(*logn*) eggs.

**Solution:** Refer to *Divide and Conquer* chapter.

**Problem-62  Local minimum of an array:** Given an array *A* of n distinct integers, design an

O(*logn*) algorithmto find a *local minimum:* anindex*i* suchthat *A*[*i* – 1] < *A*[*i*] *< A*[*i* + 1].

**Solution:** Check the middle value *A*[*n/*2], and two neighbors *A*[*n/*2 – 1] and *A*[*n/*2 + 1]. If *A*[*n/*2] is local minimum, stop; otherwise searchinhalf withsmaller neighbor.

**Problem-63**  Give an *n* × *n* array of elements such that each row is in ascending order and

each column is in ascending order, devise an O(*n*) algorithm to determine if a given element *x* is inthe array. Youmayassume all elements inthe *n* × *n* arrayare distinct.

**Solution:** Let us assume that the given matrix is *A*[*n*][*n*]. Start with the last row, first column [or first row, last column]. If the element we are searching for is greater than the element at *A*[1][*n*], then the first column can be eliminated. If the search element is less than the element at *A*[1][*n*], then the last row can be completely eliminated. Once the first column or the last row is eliminated, start the process again with the left-bottom end of the remaining array. In this algorithm, there would be maximum*n* elements that the searchelement would be compared with.

Time Complexity: O(*n*). This is because we will traverse at most 2n points. Space Complexity: O(1).

**Problem-64**  Given an *n* × *n* array a of *n*2 numbers, give an O(*n*) algorithm to find a pair of

indices *i* and *j* suchthat *A*[*i*][*j*] *< A*[*i +* 1][*j*]*.A*[*i*][*j*] *< A*[*i*][*j +* 1]*,A*[*i*][*j*] *< A*[*i* – 1][*j*], and *A*[*i*][*j*] *< A*[*i*][*j* – 1].

**Solution:** This problemis the same as [Problem-63](#_page79_x66.91_y443.78).

**Problem-65**  Given *n* × *n* matrix, and in each row all 1’s are followed by 0’s. Find the row

withthe maximumnumber of 0’s.

**Solution:** Start withfirst row, last column. If the element is 0 thenmove to the previous columnin the same row and at the same time increase the counter to indicate the maximumnumber of 0’s. If the element is 1 then move to the next row in the the same column. Repeat this process until your reachlast row, first column.

Time Complexity: O(2*n*) *≈* O(*n*) (similar to [Problem-63](#_page79_x66.91_y443.78)).

**Problem-66**  Given an input array of size unknown, with all numbers in the beginning and

special symbols in the end. Find the index in the array from where the special symbols start.

**Solution:** Refer to *Divide and Conquer* chapter.

**Problem-67  Separate even and odd numbers:** Given an array *A*[], write a function that

segregates evenand odd numbers. The functions should put all evennumbers first, and then odd numbers. **Example:** Input = {12,34,45,9,8,90,3} Output = {12,34,90,8,9,45,3}

**Note:** Inthe output, the order of numbers canbe changed, i.e., inthe above example 34 can come before 12, and 3 cancome before 9.

**Solution:** The problemis verysimilar to *Separate* 0’s *and* 1’*s* (Problem-68) in an array, and both problems are variations of the famous *Dutch national flag problem.*

**Algorithm:** The logic is similar to Quicksort.

1) Initialize two indexvariables left and right: *left =* 0, *right = n* – 1
1) Keep incrementingthe left indexuntil yousee anodd number.
1) Keep decrementingthe right indexuntil youe see anevennumber.
1) If *left* < *right* thenswap *A*[*left*] and *A*[*right*]

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.101.png)

Time Complexity: O(*n*).

**Problem-68**  The following is another way of structuring [Problem-67](#_page80_x66.91_y265.10), but with a slight

difference.

**Separate 0’s and 1’s in an array:** We are given an array of 0’s and 1’s in random order. Separate 0’s on the left side and 1’s on the right side of the array. Traverse the array only once.

**Input array =** [0,1,0,1,0,0,1,1,1,0] **Output array =** [0,0,0,0,0,1,1,1,1,1]

**Solution:** Counting0’s or 1’s

1. Count the number of 0’s. Let the count be *C.*
1. Once we have the count, put *C* 0’s at the beginning and 1’s at the remaining *n- C* positions inthe array.

Time Complexity: O(*n*). This solutionscans the arraytwo times. **Problem-69**  Canwe solve [Problem-68](#_page81_x66.91_y382.75) inone scan?

**Solution: Yes.** Use two indexes to traverse: Maintain two indexes. Initialize the first index left as 0 and the second indexright as *n* – 1. Do the followingwhile *left < right:*

1) Keep the incrementingindexleft while there are Os init
1) Keep the decrementingindexright while there are Is init
1) If left < right thenexchange *A*[*left*] and *A*[*right*]

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.102.jpeg)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-70  Sort an array of 0’s, 1’s and 2’s [or R’s, G’s and B’s]:** Given an array A[]

consistingof 0’s, 1’s and 2’s, give analgorithmfor sorting*A*[].The algorithmshould put all 0’s first, then all 1’s and finally all 2’s at the end. **Example Input** = {0,1,1,0,1,2,1,2,0,0,0,1}, **Output =** {0,0,0,0,0,1,1,1,1,1,2,2}

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.103.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-71  Maximum difference between two elements:** Given an array *A*[] of integers,

find out the difference between any two elements such that the larger element appears after the smaller number in*A*[].

**Examples:** If arrayis [2,3,10,6,4,8,1] thenreturned value should be 8 (Difference between 10 and 2). If array is [ 7,9,5,6,3,2 ] then the returned value should be 2 (Difference between7 and 9)

**Solution:** Refer to *Divide and Conquer* chapter.

**Problem-72**  Given an array of 101 elements. Out of 101 elements, 25 elements are repeated

twice, 12 elements are repeated 4 times, and one element is repeated 3 times. Find the element whichrepeated 3 times inO(1).

**Solution:** Before solving this problem, let us consider the following *XOR* operation property: *a XOR a* = 0. That means, if we applythe *XOR* onthe same elements thenthe result is 0.

**Algorithm:**

- *XOR* all the elements of the givenarrayand assume the result is *A.*
- After this operation, 2 occurrences of the number whichappeared 3 times becomes 0 and one occurrence remains the same.
- The 12 elements that are appearing4 times become 0.
- The 25 elements that are appearing2 times become 0.
- So just *XOR’ing* all the elements gives the result.

Time Complexity: O(*n*), because we are doingonlyone scan. Space Complexity: O(1).

**Problem-73**  Given a number n, give an algorithm for finding the number of trailing zeros in

*n*!.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.104.png)

Time Complexity: O(*logn*).

**Problem-74**  Given an array of 2*n* integers in the following format *a*1 *a*2 *a*3 *...an b*1 *b*2 *b*3

*...bn*. Shuffle the arrayto *a*1 *b*1 *a*2 *b*2 *a*3 *b*3 *... an bn* without anyextra memory.

**Solution:** A brute force solution involves two nested loops to rotate the elements in the second half of the array to the left. The first loop runs n times to cover all elements in the second half of the array. The second loop rotates the elements to the left. Note that the start index in the second loop depends onwhichelement we are rotatingand the end indexdepends onhow manypositions we need to move to the left.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.105.png)

Time Complexity: O(*n*2).

**Problem-75**  Canwe improve [Problem-74](#_page84_x66.91_y335.46) solution?

**Solution:** Refer to the *Divide and Conquer* chapter. A better solution of time complexity O(*nlogn*) canbe achieved usingthe *Divide and Concur* technique. Let us lookat anexample

1. Start withthe array: *a*1 *a*2 *a*3 *a*4 *b*1 *b*2 *b*3 *b*4
1. Split the arrayinto two halves: *a*1 *a*2 *a*3 *a*4 : *b*1 *b*2 *b*3 *b*4
1. Exchange elements around the center: exchange *a*3 *a*4 with *b*1 *b*2 and you get: *a*1 *a.*2 *b*1 *b*2 *a*3 *a*4 *b*3 *b*4
1. Split *a*1 *a*2 *b*1 *b*2 into *a*1 *a*2 : *b*1 *b*2. Thensplit *a*3 *a*4 *b*3 *b*4 into *a*3 *a*4 : *b*3 *b*4
1. Exchange elements around the center for each subarray you get: *a*1 *b*1 *a*2 *b*2 and *a*3 *b*3 *a*4 *b*4

Note that this solution only handles the case when *n* = 2*i* where *i* = 0,1,2,3, etc. In our example *n*

- 22 = 4 which makes it easy to recursively split the array into two halves. The basic idea behind swapping elements around the center before calling the recursive function is to produce smaller size problems. A solution with linear time complexity may be achieved if the elements are of a specific nature. For example, if you can calculate the new position of the element using the value of the element itself. This is nothingbut a hashingtechnique.

**Problem-76**  Given an array A[], find the maximum j – i such that A[j] > A[i]. For example,

Input: {34, 8, 10, 3, 2, 80, 30, 33, 1} and Output: 6 (j = 7, i = 1).

**Solution: Brute Force Approach:** Run two loops. In the outer loop, pick elements one by one from the left. In the inner loop, compare the picked element with the elements starting from the right side. Stop the inner loop when you see an element greater than the picked element and keep updatingthe maximumj – i so far.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.106.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-77**  Canwe improve the complexityof [Problem-76](#_page85_x66.91_y341.10)?

**Solution:** To solve this problem, we need to get two optimum indexes of A[]: left index *i* and

right index *j*. For an element A[i], we do not need to consider A[i] for the left index if there is an element smaller than A[i] on the left side of A[i]. Similarly, if there is a greater element on the right side of A[j] thenwe do not need to consider this j for the right index.

So we construct two auxiliary Arrays LeftMins[] and RightMaxs[] such that LeftMins[i] holds the smallest element on the left side of A[i] including A[i], and RightMaxs[j] holds the greatest element on the right side of A[j] including A[j]. After constructing these two auxiliary arrays, we traverse boththese arrays fromleft to right.

While traversing LeftMins[] and RightMaxs[], if we see that LeftMins[i] is greater than RightMaxs[j], thenwe must move ahead inLeftMins[] (or do i++) because all elements onthe left of LeftMins[i] are greater than or equal to LeftMins[i]. Otherwise we must move ahead in RightMaxs[j] to lookfor a greater y– *i* value.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.107.jpeg)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-78**  Given an array of elements, how do you check whether the list is pairwise

sorted or not? Alist is considered pairwise sorted if each successive pair of numbers is in sorted (non-decreasing) order.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.108.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-79**  Given an array of *n* elements, how do you print the frequencies of elements

without usingextra space. Assume all elements are positive, editable and less than*n.*

**Solution:** Use *negation* technique.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.109.jpeg)

Array should have numbers in the range [1, *n*] (where n is the size of the array). The if condition

(A[pos] > 0 && *A*[*expectedPos*] *>* 0) means that both the numbers at indices *pos* and *expectedPos* are actual numbers in the array but not their frequencies. So we will swap them so that the number at the index *pos* will go to the position where it should have been if the numbers 1, 2, 3, ...., *n* are kept in0, 1, 2, ..., *n* – 1 indices. Inthe above example input array, initially*pos =* 0, so 10 at index 0 will go to index 9 after the swap. As this is the first occurrence of 10, make it to -1. Note that we are storing the frequencies as negative numbers to differentiate between actual numbers and frequencies.

The else if condition (*A*[*pos*] > 0) means *A*[*pos*] is a number and *A*[*expectedPos*] is its frequency without including the occurrence of *A*[*pos*]. So increment the frequency by 1 (that is decrement by 1 in terms of negative numbers). As we count its occurrence we need to move to next pos, so *pos*

+ *+*, but before moving to that next position we should make the frequency of the number *pos* + 1 whichcorresponds to index*pos* of zero, since sucha number has not yet occurred.

The final else part means the current index pos already has the frequency of the number *pos* + 1, so move to the next *pos*, hence *pos + +.*

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-80**  Which is faster and by how much, a linear search of only 1000 elements on a 5-

GHz computer or a binary search of 1 million elements on a 1-GHz computer. Assume that the execution of each instruction on the 5-GHz computer is five times faster than on the 1- GHz computer and that eachiterationof the linear searchalgorithmis twice as fast as each iterationof the binarysearchalgorithm.

**Solution:** A binary search of 1 million elements would require ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.110.png) or about 20

iterations at most (i.e., worst case). A linear search of 1000 elements would require 500 iretations on the average (i.e., going halfway through the array). Therefore, binary search would

be ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.111.png) faster (in terms of iterations) than linear search. However, since linear search iterations are twice as fast, binary search would be ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.112.png) or about 12 times faster than linear search

overall, on the same machine. Since we run them on different machines, where an instruction on the 5-GhZ machine is 5 times faster than an instruction on a 1-GHz machine, binary search would

be ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.113.png) or about 2 times faster than linear search! The key idea is that software improvements can make analgorithmrunmuchfaster without havingto use more powerful software.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.114.png)

1. **What are Selection Algorithms?**

*Selection algorithm* is an algorithm for finding the *kth* smallest/largest number in a list (also called as *kth* order statistic). This includes finding the minimum, maximum, and median elements. For finding the *kth* order statistic, there are multiple solutions which provide different complexities, and inthis chapter we will enumerate those possibilities.

2. **Selection by Sorting**

Aselection problemcan be converted to a sorting problem. In this method, we first sort the input elements and thenget the desired element. It is efficient if we want to performmanyselections.

For example, let us say we want to get the minimum element. After sorting the input elements we can simply return the first element (assuming the array is sorted in ascending order). Now, if we want to find the second smallest element, we cansimplyreturnthe second element fromthe sorted list.

That means, for the second smallest element we are not performing the sorting again. The same is also the case with subsequent queries. Even if we want to get *kth* smallest element, just one scan of the sorted list is enough to find the element (or we can return the *kth*-indexed value if the elements are inthe array).

From the above discussion what we can say is, with the initial sorting we can answer any query in one scan, O(*n*). In general, this method requires O(*nlogn*) time (for *sorting*), where n is the length of the input list. Suppose we are performing *n* queries, then the average cost per operation

is just ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.115.png). This kind of analysis is called *amortized* analysis.

3. **Partition-based Selection Algorithm**

For the algorithmcheck[Problem-6](#_page93_x66.91_y703.29). This algorithmis similar to Quicksort.

4. **Linear Selection Algorithm - Median of Medians Algorithm**



| Worst-case performance                          | O(*n*)         |
| ----------------------------------------------- | -------------- |
| Best-case performance                           | O(*n*)         |
| Worst-case space complexity                     | O(1) auxiliary |
| Refer to [Problem-11](#_page96_x66.91_y538.99). |                |

5. **Finding the K Smallest Elements in Sorted Order**

For the algorithmcheck[Problem-6](#_page93_x66.91_y703.29). This algorithmis similar to Quicksort.

6. **Selection Algorithms: Problems & Solutions**

**Problem-1**  Find the largest element inanarrayAof size *n.* **Solution:** Scanthe complete arrayand returnthe largest element.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.116.png)

Time Complexity- O(*n*). Space Complexity- O(1).

**Note:** Any deterministic algorithmthat can find the largest of *n* keys by comparison of keys takes at least *n* -**1** comparisons.

**Problem-2**  Find the smallest and largest elements inanarray*A*of size *n.* **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.117.png)

Time Complexity- O(*n*). Space Complexity- O(1). The worst-case number of comparisons is 2(*n*

- 1).

**Problem-3**  Canwe improve the previous algorithms? **Solution: Yes.** We cando this bycomparinginpairs.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.118.png)

Time Complexity- O(*n*). Space Complexity- O(1). Number of comparisons: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.119.png)

**Summary:**



| Straightforward comparison– 2(*n* – 1) comparisons           |
| ------------------------------------------------------------ |
| Compare for minonlyif comparisonfor maxfails                 |
| Best case: increasingorder – *n* – 1 comparisons             |
| Worst case: decreasingorder – 2(*n* – 1) comparisons         |
| Average case: 3*n*/2 – 1 comparisons                         |
| **Note:** For divide and conquer techniques refer to *Divide and Conquer* chapter. |

**Problem-4**  Give an algorithm for finding the second largest element in the given input list of

elements.

**Solution: Brute Force Method**

**Algorithm:**

- Find largest element: needs *n* – 1 comparisons
- Delete (discard) the largest element
- Againfind largest element: needs *n –* 2 comparisons

Total number of comparisons: *n –* 1 *+ n –* 2 = 2*n –* 3

**Problem-5**  Canwe reduce the number of comparisons in[Problem-4](#_page92_x66.91_y695.68) solution?

**Solution: The Tournament method:** For simplicity, assume that the numbers are distinct and that n is a power of 2. We pair the keys and compare the pairs in rounds until only one round remains. If the input has eight keys, there are four comparisons in the first round, two in the second, and one in the last. The winner of the last round is the largest key. The figure below shows the method.

The tournament method directly applies only when n is a power of 2. When this is not the case, we can add enough items to the end of the array to make the array size a power of 2. If the tree is complete thenthe maximumheight of the tree is *logn*. If we construct the complete binary tree, we need *n* – 1 comparisons to find the largest. The second largest key has to be among the ones that were lost in a comparison with the largest one. That means, the second largest element should be one of the opponents of the largest element. The number of keys that are lost to the largest key is the height of the tree, i.e. *logn* [if the tree is a complete binary tree]. Then using the selection algorithm to find the largest among them, take *logn* – 1 comparisons. Thus the total number of comparisons to find the largest and second largest keys is *n* + *logn –* 2.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.120.jpeg)

**Problem-6**  Find the *k*-smallest elements in an array *S* of *n* elements using partitioning

method.

**Solution: Brute Force Approach:** Scan through the numbers *k* times to have the desired element. This method is the one used in bubble sort (and selection sort), every time we find out the smallest element in the whole sequence by comparing every element. In this method, the sequence has to be traversed *k* times. So the complexityis O(*n* × *k*).

**Problem-7**  Canwe use the sortingtechnique for solving[Problem-6](#_page93_x66.91_y703.29)? **Solution: Yes.** Sort and take the first *k* elements.

1. Sort the numbers.
1. Pickthe first *k* elements.

The time complexity calculation is trivial. Sorting of n numbers is of O(*nlogn*) and picking *k* elements is of O(*k*). The total complexityis O(*nlogn* + *k*) = O(*nlogn*).

**Problem-8**  Canwe use the *tree sorting* technique for solving[Problem-6](#_page93_x66.91_y703.29)? **Solution: Yes.**

1. Insert all the elements ina binarysearchtree.
1. Do an InOrder traversal and print *k* elements which will be the smallest ones. So, we have the *k* smallest elements.

The cost of creation of a binary search tree with n elements is O(*nlogn*) and the traversal up to *k* elements is O(*k*). Hence the complexityis O(*nlogn* + *k*) = O(*nlogn*).

**Disadvantage:** If the numbers are sorted in descending order, we will be getting a tree which will be skewed towards the left. In that case, the construction of the tree will be 0 + l + 2 + ... +

(*n*– 1) ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.121.png) whichis O(*n*2). To escape fromthis, we can keep the tree balanced, so that the cost of constructingthe tree will be only*nlogn.*

**Problem-9**  Canwe improve the *tree sorting* technique for solving[Problem-6](#_page93_x66.91_y703.29)?

**Solution: Yes.** Use a smaller tree to give the same result.

1. Take the first *k* elements of the sequence to create a balanced tree of *k* nodes (this will cost *klogk*).
1. Take the remainingnumbers one byone, and
1. If the number is larger thanthe largest element of the tree, return.
1. If the number is smaller than the largest element of the tree, remove the largest element of the tree and add the new element. This step is to make sure that a smaller element replaces a larger element from the tree. And of course the cost of this operation is *logk* since the tree is a balanced tree of *k* elements.

Once Step 2 is over, the balanced tree with*k* elements will have the smallest *k* elements. The only

remainingtaskis to print out the largest element of the tree. Time Complexity:

1. For the first *k* elements, we make the tree. Hence the cost is *klogk.*
1. For the rest *n – k* elements, the complexityis O(*logk*).

Step 2 has a complexity of (*n* – *k*) *logk*. The total cost is *klogk* + (*n* – *k*) *logk = nlogk* which is O(*nlogk*). This bound is actuallybetter thanthe ones provided earlier.

**Problem-10**  Canwe use the partitioningtechnique for solving[Problem-6](#_page93_x66.91_y703.29)? **Solution: Yes.**

**Algorithm**

1. Choose a pivot fromthe array.
1. Partition the array so that: *A*[*low...pivotpoint* – 1] <= *pivotpoint <= A*[*pivotpoint +* 1.*.high*].
1. if *k* < *pivotpoint* then it must be on the left of the pivot, so do the same method recursivelyonthe left part.
1. if *k* = *pivotpoint* then it must be the pivot and print all the elements from *low* to *pivotpoint.*
1. if *k* > *pivotpoint* then it must be on the right of pivot, so do the same method recursivelyonthe right part.

The top-level call would be kthSmallest = Selection(1, n, k).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.122.jpeg)

Time Complexity: O(*n*2) in worst case as similar to Quicksort. Although the worst case is the same as that of Quicksort, this performs muchbetter onthe average [O(*nlogk*) – Average case].

**Problem-11**  Find the *kth*-smallest element inanarray*S* of *n* elements inbest possible way.

**Solution:** This problemis similar to [Problem-6](#_page93_x66.91_y703.29) and all the solutions discussed for [Problem-6](#_page93_x66.91_y703.29) are valid for this problem. The only difference is that instead of printing all the *k* elements, we print

only the *kth* element. We can improve the solution by using the *median of medians* algorithm. Median is a special case of the selection algorithm. The algorithm Selection(A, *k*) to find the *kth* smallest element fromset *A*of nelements is as follows:

**Algorithm:** *Selection*(*A*, k)

1. Partition *A* into ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.123.png) groups, with each group having five items (the last group mayhave fewer items).
2. Sort eachgroup separately(e.g., insertionsort).
3. Find the medianof eachof the ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.124.png) groups and store theminsome array(let us say*A*′).
4. Use *Selection* recursively to find the median of *A*′ (median of medians). Let us asay the medianof medians is *m.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.125.png)

5. Let *q = #* elements of *A*smaller than*m*;
5. If(*k* == *q* + 1)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.126.png)

7. Else partition*A*into *X* and *Y*

- *X =* {items smaller than*m*)
- *Y=* {items larger than*m*}

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.127.png)

8. If(*k* < *q* + 1)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.128.png)

9. Else

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.129.png)

Before developing recurrence, let us consider the representation of the input below. In the figure, each circle is an element and each column is grouped with 5 elements. The black circles indicate the median in each group of 5 elements. As discussed, sort each column using constant time insertionsort.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.130.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.131.png)

In the figure above the gray circled item is the median of medians (let us call this m). It can be seen that at least 1/2 of 5 element group medians *≤m*. Also, these 1/2 of 5 element groups contribute 3 elements that are ≤ *m* except 2 groups [last group which may contain fewer than 5 elements, and other group which contains *m*]. Similarly, at least 1/2 of 5 element groups contribute 3 elements that are ≥ *m* as shownabove. 1/2 of 5 element groups contribute 3 elements,

except 2 groups gives: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.132.png). The remaining are ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.133.png). Since ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.134.png) is greater than ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.135.png) we need to consider ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.136.png) for worst.

**Components inrecurrence:**

- Inour selectionalgorithm, we choose *m*, whichis the medianof medians, to be a pivot, and partition A into two sets *X* and *Y*. We need to select the set which gives maximum size (to get the worst case).
- The time in function *Selection* when called from procedure *partition*. The number of keys inthe input to this call to *Selection* is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.124.png).
- The number of comparisons required to partition the array. This number is *length*(*S*), let us say*n*.

We have established the following recurrence:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.8262e98f-d78c-42f3-a2b7-4d7bd6863969.137.png)

From the above discussion we have seen that, if we select median of medians m as pivot, the partitionsizes are: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.001.png) and ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.002.png). If we select the maximumof these, thenwe get:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.003.png)

**Problem-12**  In Problem-11, we divided the input array into groups of 5 elements. The

constant 5 play an important part in the analysis. Can we divide in groups of 3 which work inlinear time?

**Solution:** In this case the modification causes the routine to take more than linear time. In the worst case, at least half of the ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.004.png) medians found in the grouping step are greater than the

median of medians m, but two of those groups contribute less than two elements larger than *m*. So as anupper bound, the number of elements larger thanthe pivotpoint is at least:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.005.png)

Likewise this is a lower bound. Thus up to ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.006.png) elements are fed into the recursive call to *Select*. The recursive step that finds the median of medians runs on a problemof

size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.004.png), and consequentlythe time recurrence is:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.007.png)

Assuming that *T*(*n*) is monotonically increasing, we may conclude that ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.008.png), and we can say the upper bound for this as

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.009.png), which is O(*nlogn*). Therefore, we cannot select 3 as the group size.

**Problem-13**  As in[Problem-12](#_page0_x66.91_y195.35), canwe use groups of size 7?

**Solution:** Followinga similar reasoning, we once more modifythe routine, now usinggroups of 7 instead of 5. In the worst case, at least half the ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.010.png) medians found in the grouping step are

greater than the median of medians *m*, but two of those groups contribute less than four elements larger than*m*. So as anupper bound, the number of elements larger thanthe pivotpoint is at least:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.011.png)

Likewise this is a lower bound. Thus up to ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.012.png) elements are fed into the recursive call to Select. The recursive step that finds the median of medians runs on a problemof

size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.010.png), and consequentlythe time recurrence is

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.013.png)

This is bounded above by(*a + c*) *n* provided that ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.014.png). Therefore, we can select 7 as the group size.

**Problem-14**  Given two arrays each containing n sorted elements, give an O(*logn*)*-time*

algorithmto find the medianof all 2*n* elements.

**Solution:** The simple solution to this problem is to merge the two lists and then take the average of the middle two elements (*n*ote the union always contains an even number of values). But, the merge would be Θ(*n*), so that doesn’t satisfy the problem statement. To get *logn* complexity, let *medianA* and *medianB* be the medians of the respective lists (which can be easily found since bothlists are sorted). If *medianA*== *medianB*, then that is the overall median of the union and we are done. Otherwise, the median of the union must be between *medianA* and *medianB*. Suppose that *medianA < medianB* (the opposite case is entirely similar). Then we need to find the median of the unionof the followingtwo sets:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.015.png)

So, we cando this recursivelybyresettingthe *boundaries* of the two arrays. The algorithmtracks both arrays (which are sorted) using two indices. These indices are used to access and compare the medianof botharrays to find where the overall medianlies.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.016.png)

Time Complexity: O(*logn*), since we are reducingthe problemsize byhalf everytime.

**Problem-15**  Let *A* and *B* be two sorted arrays of *n* elements each. We can easily find the *kth*

smallest element in*A*in O(1) time by just outputting *A*[*k*]. Similarly, we can easily find the *kth* smallest element in *B*. Give an O(*logk*) time algorithm to find the *kth* smallest element overall {*i.e.*, the *kth* smallest inthe unionof *A*and *B.*

**Solution:** It’s just another wayof asking[Problem-14](#_page1_x66.91_y320.94).

**Problem-16  Findthe** *k* **smallest elements insortedorder:** Given a set of *n* elements froma

totally-ordered domain, find the *k* smallest elements, and list themin sorted order. Analyze the worst-case runningtime of the best implementationof the approach.

**Solution:** Sort the numbers, and list the *k* smallest.

*T*(*n*) = Time complexityof sort + listing*k* smallest elements = Θ(*nlogn*) + Θ(*n*) = Θ(*nlogn*). **Problem-17**  For [Problem-16](#_page2_x66.91_y405.80), if we follow the approachbelow, thenwhat is the complexity?

**Solution:** Using the priority queue data structure from heap sort, construct a min-heap over the set, and perform extract-min *k* times. Refer to the *Priority Queues* (*Heaps*) chapter for more details.

**Problem-18**  For [Problem-16](#_page2_x66.91_y405.80), if we follow the approachbelow thenwhat is the complexity? Find the *kth*-smallest element of the set, partitionaround this pivot element, and sort the *k* smallest

elements.

**Solution:**

*T* (*n*) = *Time complexity of kth* – *smallest* + *Finding pivot* + *Sorting prefix*

- Θ(*n*) + Θ(*n*) + Θ(*klogk*) = Θ(*n* + *klogk*)

Since, *k* ≤ *n*, this approachis better than[Problem-16](#_page2_x66.91_y405.80) and [Problem-17](#_page2_x66.91_y524.72).

**Problem-19**  Find *k* nearest neighbors to the medianof *n* distinct numbers inO(*n*) time.

**Solution:** Let us assume that the arrayelements are sorted. Now find the medianof *n* numbers and call its index as *X* (since array is sorted, median will be at ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.017.png) location). All we need to do is

select *k* elements with the smallest absolute differences fromthe median, moving from*X –* 1 to 0, and *X* + 1 to *n –* 1 whenthe medianis at index*m.*

Time Complexity: Eachstep takes Θ(*n*). So the total time complexityof the algorithmis Θ(*n*). **Problem-20**  Is there anyother wayof solving[Problem-19](#_page3_x66.91_y55.03)?

**Solution:** Assume for simplicity that n is odd and k is even. If set Ais in sorted order, the median is in position *n/*2 and the *k* numbers in A that are closest to the median are in positions (*n* – *k*)/2 through(*n* + *k*)/2.

We first use linear time selection to find the (*n* – *k*)/2, *n*/2, and (*n* + *k*)/2 elements and then pass through set A to find the numbers less than the (*n* + *k*)/2 element, greater than the (*n* – *k*)/2 element, and not equal to the *n/* 2 element. The algorithm takes O(*n*) time as we use linear time selectionexactlythree times and traverse the nnumbers in*A*once.

**Problem-21**  Given (*x*,*y*) coordinates of *n* houses, where should you build a road parallel to

x-axis to minimize the constructioncost of buildingdriveways?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.018.jpeg)

**Solution:** The road costs nothing to build. It is the driveways that cost money. The driveway cost is proportional to its distance from the road. Obviously, they will be perpendicular. The solution is to put the street at the medianof the ycoordinates.

**Problem-22**  Given a big file containing billions of numbers, find the maximum 10 numbers

fromthat file.

**Solution:** Refer to the *Priority Queues* chapter.

**Problem-23**  Suppose there is a milk company. The company collects milk every day fromall

its agents. The agents are located at different places. To collect the milk, what is the best place to start so that the least amount of total distance is travelled?

**Solution:** Starting at the median reduces the total distance travelled because it is the place which is at the center of all the places.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.019.png)

1. **Introduction**

Since childhood, we all have used a dictionary, and many of us have a word processor (say, Microsoft Word) which comes with a spell checker. The spell checker is also a dictionary but limited inscope. There are manyreal time examples for dictionaries and a few of themare:

- Spell checker
- The data dictionaryfound indatabase management applications
- Symbol tables generated byloaders, assemblers, and compilers
- Routingtables innetworkingcomponents (DNS lookup)

In computer science, we generally use the term ‘symbol table’ rather than ‘dictionary’ when referringto the abstract data type (ADT).

2. **What are SymbolTables?**

We can define the *symbol table* as a data structure that associates a *value* with a *key*. It supports the followingoperations:

- Searchwhether a particular name is inthe table
- Get the attributes of that name
- Modifythe attributes of that name
- Insert a new name and its attributes
- Delete a name and its attributes

There are onlythree basic operations onsymbol tables: searching, inserting, and deleting.

**Example:** DNS lookup. Let us assume that the key in this case is the URLand the value is an IP address.

- Insert URLwithspecified IPaddress
- GivenURL, find correspondingIPaddress



| Key[Website]                                      | Value [IPAddress] |
| ------------------------------------------------- | ----------------- |
| [www.CareerMonks.com](http://www.CareerMonks.com) | 128.112.136.11    |
| [www.AuthorsInn.com](http://www.AuthorsInn.com)   | 128.112.128.15    |
| www.AuthInn.com                                   | 130.132.143.21    |
| [www.klm.com](http://www.klm.com)                 | 128.103.060.55    |
| [www.CareerMonk.com](http://www.CareerMonk.com)   | 209.052.165.60    |

3. **SymbolTable Implementations**

Before implementingsymbol tables, let us enumerate the possible implementations. Symbol tables canbe implemented inmanyways and some of themare listed below.

**Unordered Array Implementation**

With this method, just maintaining an array is enough. It needs O(*n*) time for searching, insertion and deletioninthe worst case.

**Ordered [Sorted] Array Implementation**

Inthis we maintaina sorted arrayof keys and values.

- Store insorted order bykey
- keys[i] = *ith* largest key
- values[i] = value associated with*ith* largest key

Since the elements are sorted and stored in arrays, we can use a simple binary search for finding an element. It takes O(*logn*) time for searching and O(*n*) time for insertion and deletion in the worst case.

**Unordered Linked List Implementation**

Just maintaining a linked list with two data values is enough for this method. It needs O(*n*) time for searching, insertionand deletioninthe worst case.

**Ordered Linked List Implementation**

In this method, while inserting the keys, maintain the order of keys in the linked list. Even if the list is sorted, inthe worst case it needs O(*n*) time for searching, insertionand deletion.

**Binary Search Trees Implementation**

Refer to *Trees* chapter. The advantages of this method are: it does not need muchcode and it has a fast search[O(*logn*) onaverage].

**Balanced Binary Search Trees Implementation**

Refer to *Trees* chapter. It is an extension of binary search trees implementation and takes O(*logn*) inworst case for search, insert and delete operations.

**Ternary Search Implementation**

Refer to *String Algorithms* chapter. This is one of the important methods used for implementing dictionaries.

**Hashing Implementation**

This method is important. For a complete discussion, refer to the *[Hashing*](#_page9_x28.00_y82.94)* chapter.

4. **Comparison Table of Symbols for Implementations**

Let us consider the followingcomparisontable for all the implementations.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.020.png)

**Notes:**

- Inthe above table, nis the input size.
- Table indicates the possible implementations discussed inthis book. But, there could be other implementations.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.021.png)

1. **What is Hashing?**

Hashing is a technique used for storing and retrieving information as quickly as possible. It is used to performoptimal searches and is useful inimplementingsymbol tables.

2. **Why Hashing?**

In the *Trees* chapter we saw that balanced binary search trees support operations such as *insert, delete* and *search* in O(*logn*) time. In applications, if we need these operations in O(1), then hashing provides a way. Remember that worst case complexity of hashing is still O(*n*), but it gives O(1) onthe average.

3. **HashTable ADT**

The commonoperations for hashtable are:

- CreatHashTable: Creates a new hashtable
- HashSearch: Searches the keyinhashtable
- Hashlnsert: Inserts a new keyinto hashtable
- HashDelete: Deletes a keyfromhashtable
- DeleteHashTable: Deletes the hashtable

4. **Understanding Hashing**

Insimple terms we cantreat *array* as a hash table. For understanding the use of hash tables, let us consider the following example: Give an algorithm for printing the first repeated character if there are duplicated elements in it. Let us think about the possible solutions. The simple and brute force wayof solvingis: givena string, for eachcharacter checkwhether that character is repeated

or not. The time complexityof this approachis O(*n*2) withO(1) space complexity.

Now, let us find a better solution for this problem. Since our objective is to find the first repeated character, what if we remember the previous characters insome array?

We know that the number of possible characters is 256 (for simplicity assume *ASCII* characters only). Create an array of size 256 and initialize it with all zeros. For each of the input characters go to the corresponding position and increment its count. Since we are using arrays, it takes constant time for reaching any location. While scanning the input, if we get a character whose counter is already 1 then we can say that the character is the one which is repeating for the first time.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.022.png)

**Why not Arrays?**

In the previous problem, we have used an array of size 256 because we know the number of different possible characters [256] in advance. Now, let us consider a slight variant of the same problem. Suppose the given array has numbers instead of characters, then how do we solve the problem?

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.023.jpeg)

In this case the set of possible values is infinity (or at least very big). Creating a huge array and storing the counters is not possible. That means there are a set of universal keys and limited locations in the memory. If we want to solve this problem we need to somehow map all these possible keys to the possible memory locations. Fromthe above discussion and diagramit can be seen that we need a mapping of possible keys to one of the available locations. As a result using simple arrays is not the correct choice for solving the problems where the possible keys are very big. The process of mappingthe keys to locations is called *hashing.*

**Note:** For now, do not worry about how the keys are mapped to locations. That depends on the functionused for conversions. One suchsimple functionis *key* % *table size.*

5. **Components of Hashing**

Hashinghas four keycomponents:

1) HashTable
1) HashFunctions
1) Collisions
1) CollisionResolutionTechniques

6. **Hash Table**

Hash table is a generalization of array. With an array, we store the element whose key is *k* at a position *k* of the array. That means, given a key *k*, we find the element whose key is *k* by just lookinginthe *kth* positionof the array. This is called *direct addressing.*

Direct addressing is applicable when we can afford to allocate an array with one position for every possible key. But if we do not have enough space to allocate a location for each possible key, then we need a mechanismto handle this case. Another way of defining the scenario is: if we have less locations and more possible keys, thensimple arrayimplementationis not enough.

In these cases one option is to use hash tables. Hash table or hash map is a data structure that stores the keys and their associated values, and hash table uses a hash function to map keys to their associated values. The general convention is that we use a hash table when the number of keys actuallystored is small relative to the number of possible keys.

7. **Hash Function**

The hashfunctionis used to transformthe keyinto the index. Ideally, the hashfunctionshould map eachpossible keyto a unique slot index, but it is difficult to achieve inpractice.

Given a collection of elements, a hash function that maps each item into a unique slot is referred to as a *perfect hash function*. If we know the elements and the collection will never change, then it is possible to construct a perfect hash function. Unfortunately, given an arbitrary collection of elements, there is no systematic way to construct a perfect hash function. Luckily, we do not need the hashfunctionto be perfect to still gainperformance efficiency.

One way to always have a perfect hash function is to increase the size of the hash table so that eachpossible value inthe element range canbe accommodated. This guarantees that eachelement will have a unique slot. Although this is practical for small numbers of elements, it is not feasible when the number of possible elements is large. For example, if the elements were nine-digit Social Security numbers, this method would require almost one billion slots. If we only want to store data for a class of 25 students, we will be wastinganenormous amount of memory.

Our goal is to create a hash function that minimizes the number of collisions, is easy to compute, and evenly distributes the elements in the hash table. There are a number of common ways to extend the simple remainder method. We will consider a few of themhere.

The *folding method* for constructing hash functions begins by dividing the elements into equal- size pieces (the last piece may not be of equal size). These pieces are then added together to give the resulting hash value. For example, if our element was the phone number 436-555-4601, we would take the digits and divide them into groups of 2 (43,65,55,46,01). After the addition, 43+65+55+46+01, we get 210. If we assume our hash table has 11 slots, then we need to perform the extra step of dividing by 11 and keeping the remainder. In this case 210 % 11 is 1, so the phone number 436-555-4601 hashes to slot 1. Some folding methods go one step further and reverse every other piece before the addition. For the above example, we get 43+56+55+64+01=219 whichgives 219 % 11 = 10.

**How to Choose Hash Function?**

The basic problems associated withthe creationof hashtables are:

- An efficient hash function should be designed so that it distributes the index values of inserted objects uniformlyacross the table.
- An efficient collision resolution algorithmshould be designed so that it computes an alternative index for a key whose hash index corresponds to a location previously inserted inthe hashtable.
- We must choose a hash function which can be calculated quickly, returns values withinthe range of locations inour table, and minimizes collisionsns.

**Characteristics of Good Hash Functions**

Agood hashfunctionshould have the followingcharacteristics:

- Minimize collision
- Be easyand quickto compute
- Distribute keyvalues evenlyinthe hashtable
- Use all the informationprovided inthe key
- Have a highload factor for a givenset of keys

8. **Load Factor**

The load factor of a non-emptyhashtable is the number of items stored inthe table divided bythe size of the table. This is the decision parameter used when we want to rehash *or* expand the existinghashtable entries. This also helps us indeterminingthe efficiencyof the hashingfunction. That means, it tells whether the hashfunctionis distributingthe keys uniformlyor not.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.024.png)

9. **Collisions**

Hash functions are used to map each key to a different address space, but practically it is not possible to create such a hash function and the problem is called *collision*. Collision is the conditionwhere two records are stored inthe same location.

10. **Collision Resolution Techniques**

The process of finding an alternate location is called *collision resolution*. Even though hash tables have collision problems, they are more efficient in many cases compared to all other data structures, like search trees. There are a number of collision resolution techniques, and the most popular are direct chainingand openaddressing.

- **Direct Chaining:** Anarrayof linked list application
  - Separate chaining
- **OpenAddressing:** Array-based implementation
- Linear probing(linear search)
- Quadratic probing(*n*onlinear search)
- Double hashing(use two hashfunctions)

11. **Separate Chaining**

Collision resolution by chaining combines linked representation with hash table. When two or more records hash to the same location, these records are constituted into a singly-linked list called a *chain.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.025.jpeg)

12. **Open Addressing**

In open addressing all keys are stored in the hash table itself. This approach is also known as *closed hashing*. This procedure is based onprobing. Acollisionis resolved byprobing.

**Linear Probing**

The interval betweenprobes is fixed at 1. Inlinear probing, we searchthe hashtable sequentially, starting from the original hash location. If a location is occupied, we check the next location. We wrap around from the last table location to the first table location if necessary. The function for rehashingis the following:

*rehash*(*key*) = (*n* + 1)% *tablesize*

One of the problems with linear probing is that table items tend to cluster together in the hash table. This means that the table contains groups of consecutively occupied locations that are

called *clustering.*

Clusters can get close to one another, and merge into a larger cluster. Thus, the one part of the table might be quite dense, even though another part has relatively few items. Clustering causes longprobe searches and therefore decreases the overall efficiency.

The next location to be probed is determined by the step-size, where other step-sizes (more than one) are possible. The step-size should be relatively prime to the table size, i.e. their greatest common divisor should be equal to 1. If we choose the table size to be a prime number, then any step-size is relativelyprime to the table size. Clusteringcannot be avoided bylarger step-sizes.

**Quadratic Probing**

The interval between probes increases proportionally to the hash value (the interval thus increasing linearly, and the indices are described by a quadratic function). The problem of Clusteringcanbe eliminated if we use the quadratic probingmethod.

In quadratic probing, we start from the original hash location *i*. If a location is occupied, we check the locations *i* + 12 , *i +*22*, i* + 32, *i* + 42... We wrap around from the last table location to the first table locationif necessary. The functionfor rehashingis the following:

*rehash*(*key*) = (*n* + *k*2)% *tablesize Example:* Let us assume that the table size is 11 (0..10) **HashFunction:** h(key) = keymod 11

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.026.png)

Insert keys

31 *mod* 11 = 9 19 *mod* 11 = 8 2 *mod* 11 = 2

13 *mod* 11 = 2 → 2 + 12 = 3 25 *mod* 11 = 3 → 3 + 12=4

24 *mod* 11 = 2 → 2 + 12, 2 + 22 = 6

21 *mod* 11 = 10

9 *mod* 11 = 9 → 9 + 12, 9 + 22 *mod* 11, 9 + 32 *mod* 11=7

Even though clustering is avoided by quadratic probing, still there are chances of clustering. Clustering is caused by multiple search keys mapped to the same hash key. Thus, the probing sequence for such search keys is prolonged by repeated conflicts along the probing sequence. Bothlinear and quadratic probinguse a probingsequence that is independent of the searchkey.

**Double Hashing**

The interval between probes is computed by another hash function. Double hashing reduces clustering in a better way. The increments for the probing sequence are computed by using a second hashfunction. The second hashfunction*h*2 should be:

*h*2(*key*) ≠ 0 and *h*2 ≠ *h*1

We first probe the location *h*1(*key*). If the location is occupied, we probe the location *h*1(*key*) + *h*2(*key*)*, h*1(*key*) + 2 \**h*2(*key*)*, ...*

*Example:*

Table size is 11 (0..10)

HashFunction: assume *h*1(*key*) *= key mod* 11 and *h*2(*key*) = 7- (*key mod* 7)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.027.png)

*Insert keys:*

58 *mod* 11 = 3

14 *mod* 11 = 3 → 3 + 7 = 10

91 *mod* 11 = 3 → 3*+* 7,3*+* 2*\** 7 *mod* 11 = 6 25 *mod* 11 = 3 → 3 + 3,3 + 2\*3 = 9

13. **Comparison of Collision Resolution Techniques Comparisons: Linear Probing vs. Double Hashing**

The choice between linear probing and double hashing depends on the cost of computing the hash functionand onthe load factor [number of elements per slot] of the table. Bothuse few probes but double hashingtake more time because it hashes to compare two hashfunctions for longkeys.

**Comparisons: Open Addressing vs. Separate Chaining**

It is somewhat complicated because we have to account for the memory usage. Separate chaining uses extra memory for links. Open addressing needs extra memory implicitly within the table to terminate the probe sequence. Open-addressed hash tables cannot be used if the data does not have unique keys. Analternative is to use separate chained hashtables.

**Comparisons: Open Addressing methods**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.028.png)

14. **How Hashing Gets O(1) Complexity**

From the previous discussion, one doubts how hashing gets O(1) if multiple elements map to the same location...

The answer to this problemis simple. By using the load factor we make sure that each block (for example, linked list in separate chaining approach) on the average stores the maximumnumber of elements less thanthe *load factor*. Also, in practice this load factor is a constant (generally, 10 or 20). As a result, searchingin20 elements or 10 elements becomes constant.

If the average number of elements in a block is greater than the load factor, we rehash the elements with a bigger hash table size. One thing we should remember is that we consider average occupancy (total number of elements in the hash table divided by table size) when decidingthe rehash.

The access time of the table depends on the load factor which in turn depends on the hash function. This is because hash function distributes the elements to the hash table. For this reason, we say hash table gives O(1) complexity on average. Also, we generally use hash tables in cases

where searches are more thaninsertionand deletionoperations.

15. **Hashing Techniques**

There are two types of hashingtechniques: static hashingand dynamic hashing

**Static Hashing**

If the data is fixed then static hashing is useful. In static hashing, the set of keys is kept fixed and giveninadvance, and the number of primarypages inthe directoryare kept fixed.

**Dynamic Hashing**

If the data is not fixed, static hashing can give bad performance, in which case dynamic hashing is the alternative, inwhichcase the set of keys canchange dynamically.

16. **Problems for which Hash Tables are not suitable**

- Problems for whichdata orderingis required
- Problems havingmultidimensional data
- Prefixsearching, especiallyif the keys are longand of variable-lengths
- Problems that have dynamic data
- Problems inwhichthe data does not have unique keys.

17. **Bloom Filters**

A Bloom filter is a probabilistic data structure which was designed to check whether an element is present in a set with memory and time efficiency. It tells us that the element either definitely is *not* in the set or *may* be in the set. The base data structure of a Bloom filter is a *Bit Vector*. The algorithmwas invented in 1970 by Burton Bloomand it relies on the use of a number of different hashfunctions.

**How it works?**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.029.jpeg)

Now that the bits in the bit vector have been set for *Element*1 and *Element*2; we canquerythe bloomfilter to tell us if somethinghas beenseenbefore.

The element is hashed but instead of setting the bits, this time a check is done and if the bits that would have been set are already set the bloom filter will returntrue that the element has beenseenbefore.

A Bloom filter starts off with a bit array initialized to zero. To store a data value, we simply apply*k* different hash functions and treat the resulting *k* values as indices in the array, and we set eachof the *k* arrayelements to 1. We repeat this for everyelement that we encounter.

Now suppose an element turns up and we want to know if we have seen it before. What we do is applythe *k* hashfunctions and lookup the indicated arrayelements. If anyof themare 0 we canbe 100% sure that we have never encountered the element before - if we had, the bit would have been set to 1. However, even if all of themare one, we still can’t conclude that we have seen the element before because all of the bits could have been set by the *k* hash functions applied to multiple other elements. All we can conclude is that it is *likely* that we have encountered the

element before.

Note that it is not possible to remove an element from a Bloom filter. The reason is simply that we can’t unset a bit that appears to belong to an element because it might also be set by another element.

If the bit array is mostly empty, i.e., set to zero, and the *k* hash functions are independent of one another, then the probability of a false positive (i.e., concluding that we have seen a data item when we actually haven’t) is low. For example, if there are only *k* bits set, we can conclude that the probability of a false positive is very close to zero as the only possibility of error is that we entered a data item that produced the same *k* hash values - which is unlikely as long as the ‘has’ functions are independent.

As the bit array fills up, the probability of a false positive slowly increases. Of course when the bit arrayis full, everyelement queried is identified as havingbeenseenbefore. So clearlywe can trade space for accuracyas well as for time.

One-time removal of an element froma Bloomfilter can be simulated by having a second Bloom filter that contains elements that have been removed. However, false positives in the second filter become false negatives in the composite filter, which may be undesirable. In this approach, re- adding a previously removed item is not possible, as one would have to remove it from the *removed* filter.

**Selecting hash functions**

The requirement of designing *k* different independent hash functions can be prohibitive for large *k*. For a good hash function with a wide output, there should be little if any correlation between different bit-fields of such a hash, so this type of hash can be used to generate multiple *different* hash functions by slicing its output into multiple bit fields. Alternatively, one can pass *k* different initial values (such as 0, 1, ..., *k* - 1) to a hash function that takes an initial value – or add (or append) these values to the key. For larger *m* and/or *k*, independence among the hash functions canbe relaxed withnegligible increase inthe false positive rate.

**Selecting size of bit vector**

A Bloom filter with 1% error and an optimal value of k, in contrast, requires only about 9.6 bits per element – regardless of the size of the elements. This advantage comes partly from its compactness, inherited from arrays, and partly from its probabilistic nature. The 1% false- positive rate canbe reduced bya factor of tenbyaddingonlyabout 4.8 bits per element.

**Space Advantages**

While risking false positives, Bloom filters have a strong space advantage over other data structures for representing sets, such as self-balancing binary search trees, tries, hash tables, or simple arrays or linked lists of the entries. Most of these require storing at least the data items themselves, which can require anywhere from a small number of bits, for small integers, to an arbitrary number of bits, such as for strings (tries are an exception, since they can share storage between elements with equal prefixes). Linked structures incur an additional linear space overhead for pointers.

However, if the number of potential values is small and many of themcan be in the set, the Bloom filter is easily surpassed by the deterministic bit array, which requires only one bit for each potential element.

**Time Advantages**

Bloom filters also have the unusual property that the time needed either to add items or to check whether an item is in the set is a fixed constant, O(*k*), completely independent of the number of items already in the set. No other constant-space set data structure has this property, but the average access time of sparse hash tables can make them faster in practice than some Bloom filters. In a hardware implementation, however, the Bloomfilter shines because its k lookups are independent and canbe parallelized.

**Implementation**

Refer to *Problems Section.*

18. **Hashing: Problems & Solutions**

**Problem-1**  Implement a separate chaining collision resolution technique. Also, discuss time

complexities of eachfunction.

**Solution:** To create a hashtable of given size, say n, we allocate an array of *n/L* (whose value is usually between 5 and 20) pointers to list, initialized to NULL. To perform *Search/Insert/Delete* operations, we first compute the index of the table from the given key by using *hashfunction* and then do the corresponding operation in the linear list maintained at that location. To get uniform distributionof keys over a hashtable, maintaintable size as the prime number.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.030.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.031.jpeg) CreatHashTable – O(*n*). HashSearch - O(1) average. Hashlnsert - O(1) average. HashDelete - O(1) average.

**Problem-2**  Givenanarrayof characters, give analgorithmfor removingthe duplicates.

**Solution:** Start with the first character and check whether it appears in the remaining part of the string using a simple linear search. If it repeats, bring the last character to that position and decrement the size of the string by one. Continue this process for each distinct character of the givenstring.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.032.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-3**  Can we find any other idea to solve this problem in better time than O(*n*2)?

Observe that the order of characters insolutions do not matter.

**Solution:** Use sorting to bring the repeated characters together. Finally scan through the array to remove duplicates inconsecutive positions.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.033.png)

Time Complexity: Θ(*nlogn*). Space Complexity: O(1).

**Problem-4**  Canwe solve this problemina single pass over givenarray?

**Solution:** We can use hash table to check whether a character is repeating in the given string or not. If the current character is not available in hash table, then insert it into hash table and keep that character in the given string also. If the current character exists in the hash table then skip that character.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.034.png)

Time Complexity: Θ(*n*) onaverage. Space Complexity: O(*n*).

**Problem-5**  Giventwo arrays of unordered numbers, checkwhether botharrays have the same

set of numbers?

**Solution:** Let us assume that two given arrays are A and B. A simple solution to the given

problem is: for each element of A, check whether that element is in B or not. A problem arises withthis approachif there are duplicates. For example consider the followinginputs:

*A*= {2,5,6,8,10,2,2} *B* = {2,5,5,8,10,5,6}

The above algorithm gives the wrong result because for each element of A there is an element in B also. But if we look at the number of occurrences, they are not the same. This problem we can solve bymovingthe elements whichare alreadycompared to the end of the list. That means, if we find an element in B, then we move that element to the end of B, and in the next searching we will not find those elements. But the disadvantage of this is it needs extra swaps. Time Complexity of

this approachis O(*n*2), since for eachelement of Awe have to scanB. **Problem-6**  Canwe improve the time complexityof [Problem-5](#_page28_x66.91_y699.06)?

**Solution: Yes.** To improve the time complexity, let us assume that we have sorted both the lists. Since the sizes of both arrays are n, we need O(*n log n*) time for sorting them. After sorting, we just need to scan both the arrays with two pointers and see whether they point to the same element everytime, and keep movingthe pointers until we reachthe end of the arrays.

Time Complexity of this approach is O(*n log n*). This is because we need O(*n log n*) for sorting the arrays. After sorting, we need O(*n*) time for scanningbut it is less compared to O(*n log n*).

**Problem-7**  Canwe further improve the time complexityof [Problem-5](#_page28_x66.91_y699.06)? **Solution: Yes,** byusinga hashtable. For this, consider the followingalgorithm. **Algorithm:**

- Construct the hashtable witharray*A*elements as keys.
- While inserting the elements, keep track of the number frequency for each number. That means, if there are duplicates, then increment the counter of that corresponding key.
- After constructingthe hashtable for *A’s* elements, now scanthe array*B.*
- For eachoccurrence of *B’s* elements reduce the correspondingcounter values.
- At the end, checkwhether all counters are zero or not.
- If all counters are zero, then both arrays are the same otherwise the arrays are different.

Time Complexity; O(*n*) for scanningthe arrays. Space Complexity; O(*n*) for hashtable.

**Problem-8**  Givena list of number pairs; if *pair*(*i,j*) exists, and *pair*(*j,i*) exists, report all such

![image-20220829202623131](C:/Users/20252/AppData/Roaming/Typora/typora-user-images/image-20220829202623131.png)

**Solution:** By using hashing, we can solve this problem in just one scan. Consider the following algorithm.

**Algorithm:**

- Read the pairs of elements one by one and insert them into the hash table. For each pair, consider the first element as keyand the second element as value.
- While inserting the elements, check if the hashing of the second element of the current pair is the same as the first number of the current pair.
- If theyare the same, thenthat indicates a symmetric pair exits and output that pair.
- Otherwise, insert that element into that. That means, use the first number of the current pair as key and the second number as value and insert them into the hash table.
- By the time we complete the scanning of all pairs, we have output all the symmetric pairs.

Time Complexity; O(*n*) for scanning the arrays. Note that we are doing a scan only of the input. Space Complexity; O(*n*) for hashtable.

**Problem-9**  Givena singlylinked list, checkwhether it has a loop init or not. **Solution: Using HashTables**

**Algorithm:**

- Traverse the linked list nodes one byone.
- Checkif the node’s address is there inthe hashtable or not.
- If it is already there in the hash table, that indicates we are visiting a node which was alreadyvisited. This is possible onlyif the givenlinked list has a loop init.
- If the address of the node is not there inthe hashtable, theninsert that node’s address into the hashtable.
- Continue this process until we reachthe end of the linked list or we find the loop.

Time Complexity; O(*n*) for scanning the linked list. Note that we are doing a scan only of the input. Space Complexity; O(*n*) for hashtable.

**Note:** for anefficient solution, refer to the *Linked Lists* chapter.

**Problem-10**  Given an array of 101 elements. Out of them 50 elements are distinct, 24

elements are repeated 2 times, and one element is repeated 3 times. Find the element that is repeated 3 times inO(1).

**Solution: Using HashTables Algorithm:**

- Scanthe input arrayone byone.
- Checkif the element is alreadythere inthe hashtable or not.
- If it is already there in the hash table, increment its counter value [this indicates the number of occurrences of the element].
- If the element is not there in the hash table, insert that node into the hash table with counter value 1.
- Continue this process until reachingthe end of the array.

Time Complexity: O(*n*), because we are doing two scans. Space Complexity: O(*n*), for hash table.

**Note:** For anefficient solutionrefer to the *Searching* chapter.

**Problem-11**  Given *m* sets of integers that have *n* elements in them, provide an algorithm to

find anelement whichappeared inthe maximumnumber of sets?

**Solution: Using HashTables Algorithm:**

- Scanthe input sets one byone.
- For each element keep track of the counter. The counter indicates the frequency of occurrences inall the sets.
- After completing the scan of all the sets, select the one which has the maximum counter value.

Time Complexity: O(*mn*), because we need to scan all the sets. Space Complexity: O(*mn*), for hashtable. Because, inthe worst case all the elements maybe different.

**Problem-12**  Given two sets *A* and *B*, and a number *K*, Give an algorithm for finding whether

there exists a pair of elements, one from*A*and one from*B*, that add up to *K.*

**Solution:** For simplicity, let us assume that the size of *A*is *m* and the size of *B* is *n*. **Algorithm:**

- Select the set whichhas minimumelements.
- For the selected set create a hashtable. We canuse bothkeyand value as the same.
- Now scan the second array and check whether (*K-selected element*) exists in the hashtable or not.
- If it exists thenreturnthe pair of elements.
- Otherwise continue until we reachthe end of the set.

Time Complexity: O(*Max*(*m*,*n*)), because we are doing two scans. Space Complexity: O(*Min*(*m*,*n*)), for hashtable. We canselect the small set for creatingthe hashtable.

**Problem-13**  Give an algorithm to remove the specified characters from a given string which

are giveninanother string?

**Solution:** For simplicity, let us assume that the maximum number of different characters is 256. First we create anauxiliaryarrayinitialized to 0. Scanthe characters to be removed, and for each of those characters we set the value to 1, whichindicates that we need to remove that character.

After initialization, scan the input string, and for each of the characters, we check whether that character needs to be deleted or not. If the flag is set then we simply skip to the next character, otherwise we keep the character in the input string. Continue this process until we reach the end of the input string. All these operations we cando in-place as givenbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.035.png)

Time Complexity: Time for scanning the characters to be removed + Time for scanning the input array= O(*n*) +O(*m*) ≈ O(*n*). Where *m* is the length of the characters to be removed and n is the lengthof the input string.

Space Complexity: O(*m*), length of the characters to be removed. But since we are assuming the maximum number of different characters is 256, we can treat this as a constant. But we should keep in mind that when we are dealing with multi-byte characters, the total number of different characters is muchmore than256.

**Problem-14**  Give an algorithm for finding the first non-repeated character in a string. For

example, the first non-repeated character inthe string*“abzddab”* is ‘*z*’.

**Solution:** The solution to this problem is trivial. For each character in the given string, we can scan the remaining string if that character appears in it. If it does not appears then we are done withthe solutionand we returnthat character. If the character appears inthe remainingstring, then go to the next character.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.036.png)

Time Complexity: O(*n*2), for two for loops. Space Complexity: O(1). **Problem-15**  Canwe improve the time complexityof [Problem-13](#_page32_x66.91_y27.36)?

**Solution: Yes.** By using hash tables we can reduce the time complexity. Create a hash table by reading all the characters in the input string and keeping count of the number of times each character appears. After creating the hash table, we can read the hash table entries to see which element has a count equal to 1. This approach takes O(*n*) space but reduces the time complexity also to O(*n*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.037.png)

Time Complexity; We have O(*n*) to create the hash table and another O(*n*) to read the entries of hash table. So the total time is O(*n*) + O(*n*) = O(2*n*) ≈ O(*n*). Space Complexity: O(*n*) for keeping the count values.

**Problem-16**  Givena string, give analgorithmfor findingthe first repeatingletter ina string?

**Solution:** The solution to this problem is somewhat similar to [Problem-13](#_page32_x66.91_y27.36) and [Problem-15](#_page33_x66.91_y449.82). The only difference is, instead of scanning the hash table twice we can give the answer in just one scan. This is because while inserting into the hash table we can see whether that element already exists or not. If it alreadyexists thenwe just need to returnthat character.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.038.png)

Time Complexity: We have O(*n*) for scanning and creating the hash table. Note that we need only one scanfor this problem. So the total time is O(*n*). Space Complexity: O(*n*) for keepingthe count values.

**Problem-17**  Given an array of *n* numbers, create an algorithm which displays all pairs

whose sumis *S*.

**Solution:** This problem is similar to [Problem-12](#_page31_x66.91_y489.05). But instead of using two sets we use only one set.

**Algorithm:**

- Scan the elements of the input array one by one and create a hash table. Both key and value canbe the same.
- After creating the hash table, again scan the input array and check whether (*S* – *selected element*) exits inthe hashtable *or* not.
- If it exits thenreturnthe pair of elements.
- Otherwise continue and read all the elements of the array.

Time Complexity; We have O(*n*) to create the hash table and another O(*n*) to read the entries of the hash table. So the total time is O(*n*) + O(*n*) = O(2*n*) ≈ O(*n*). Space Complexity: O(*n*) for keepingthe count values.

**Problem-18**  Is there anyother wayof solving[Problem-17](#_page35_x66.91_y397.15)?

**Solution: Yes.** The alternative solution to this probleminvolves sorting. First sort the input array. After sorting, use two pointers, one at the starting and another at the ending. Each time add the values of both the indexes and see if their sum is equal to *S*. If they are equal then print that pair. Otherwise increase the left pointer if the sum is less than S and decrease the right pointer if the sumis greater than*S*.

Time Complexity: Time for sorting+ Time for scanning= O(*nlogn*) + O(*n*) *≈* O(*nlogn*). Space Complexity: O(1).

**Problem-19**  We have a file with millions of lines of data. Only two lines are identical; the

rest are unique. Eachline is so longthat it maynot evenfit inthe memory. What is the most efficient solutionfor findingthe identical lines?

**Solution:** Since a complete line may not fit into the main memory, read the line partially and compute the hash from that partial line. Then read the next part of the line and compute the hash. This time use the previous hash also while computing the new hash value. Continue this process until we find the hashfor the complete line. Do this for eachline and store all the hashvalues in a file [or maintain a hash table of these hashes]. If at any point you get same hash value, read the correspondinglines part bypart and compare.

**Note:** Refer to *Searching* chapter for related problems.

**Problem-20**  If *h* is the hashingfunctionand is used to hashnkeys into a table of size s, where

n<= s, the expected number of collisions involvinga particular key*X* is :

1) less than1.
1) less than*n*.
1) less than*s*.
1) less than![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.017.png).

**Solution:** A.

**Problem-21**  Implement BloomFilters

**Solution:** A Bloom Filter is a data structure designed to tell, rapidly and memory-efficiently, whether an element is present in a set. It is based on a probabilistic mechanism where false positive retrieval results are possible, but false negatives are not. At the end we will see how to tune the parameters inorder to minimize the number of false positive results.

Let’s begin with a little bit of theory. The idea behind the Bloom filter is to allocate a bit vector of length*m*, initially all set to 0, and then choose *k* independent hash functions, *h*1, *h*2, ..., *hk*, each

with range [1..*m*]. When an element a is added to the set then the bits at positions *h*1(*a*), *h*2(a), ..., *hk*(a) in the bit vector are set to 1. Given a query element *q* we can test whether it is in the set using the bits at positions *h*1(q), *h*2(q), ..., *hk*(q) in the vector. If any of these bits is 0 we report

that *q* is not in the set otherwise we report that *q* is. The thing we have to care about is that in the first case there remains some probability that *q* is not in the set which could lead us to a false positive response.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.039.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.040.jpeg)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.041.png)

1. **Introduction**

To understand the importance of string algorithms let us consider the case of entering the URL (UniformTo understand the importance of stringalgorithms let us consider the case of enteringthe URL (Uniform Resource Locator) in any browser (say, Internet Explorer, Firefox, or Google Chrome). You will observe that after typing the prefix of the URL, a list of all possible URLs is displayed. That means, the browsers are doing some internal processing and giving us the list of matchingURLs. This technique is sometimes called *auto – completion.*

Similarly, consider the case of entering the directory name in the command line interface (in both *Windows* and *UNIX*). After typing the prefix of the directory name, if we press the *tab* button, we get a list of all matched directorynames available. This is another example of auto completion.

Inorder to support these kinds of operations, we need a data structure whichstores the stringdata efficiently. In this chapter, we will look at the data structures that are useful for implementing stringalgorithms.

We start our discussion with the basic problem of strings: given a string, how do we search a

substring (pattern)? This is called a *string matching* problem. After discussing various string matchingalgorithms, we will lookat different data structures for storingstrings.

2. **String Matching Algorithms**

In this section, we concentrate on checking whether a pattern *P* is a substring of another string *T* (*T* stands for text) or not. Since we are trying to check a fixed string *P*, sometimes these algorithms are called *exact string matching* algorithms. To simplify our discussion, let us assume that the length of given text *T* is n and the length of the pattern *P* which we are trying to match has the length *m*. That means, *T* has the characters from 0 to *n* – 1 (*T*[0 *...n –* 1]) and *P* has the characters from0 to *m* – 1 (*T*[0 *...m –* 1]). This algorithmis implemented in*C* + + as *strstr*().

In the subsequent sections, we start with the brute force method and gradually move towards better algorithms.

- Brute Force Method
- Rabin-Karp StringMatchingAlgorithm
- StringMatchingwithFinite Automata
- KMPAlgorithm
- Boyer-Moore Algorithm
- SuffixTrees

3. **Brute Force Method**

In this method, for each possible position in the text *T* we check whether the pattern *P* matches or not. Since the length of *T* is n, we have *n – m +* 1 possible choices for comparisons. This is because we do not need to check the last *m –* 1 locations of *T* as the pattern length is *m*. The followingalgorithmsearches for the first occurrence of a patternstring*P* ina text string*T.*

**Algorithm**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.042.png)

Time Complexity: O((*n* – *m* + 1) × *m*) *≈* O(*n* × *m*). Space Complexity: O(1).

4. **Rabin-Karp String Matching Algorithm**

In this method, we will use the hashing technique and instead of checking for each possible positionin*T*, we checkonlyif the hashingof *P* and the hashingof *m* characters of *T* give the same result.

Initially, apply the hash function to the first *m* characters of *T* and check whether this result and *P*’s hashingresult is the same or not. If theyare not the same, thengo to the next character of *T* and again apply the hash function to *m* characters (by starting at the second character). If they are the same thenwe compare those *m* characters of *T* with*P*.

**Selecting Hash Function**

At each step, since we are finding the hash of *m* characters of *T*, we need an efficient hash function. If the hashfunctiontakes O(*m*) complexity in every step, then the total complexity is O(*n* × *m*). This is worse than the brute force method because first we are applying the hash function and also comparing.

Our objective is to select a hash function which takes O(1) complexity for finding the hash of *m* characters of *T* every time. Only then can we reduce the total complexity of the algorithm. If the hash function is not good (worst case), the complexity of the Rabin-Karp algorithm is O(*n* – *m* + 1) × *m*) ≈ O(*n* × *m*). If we select a good hash function, the complexity of the Rabin-Karp algorithm complexity is O(*m* + *n*). Now let us see how to select a hash function which can compute the hashof *m* characters of *T* at eachstep inO(1).

For simplicity, let’s assume that the characters used in string *T* are only integers. That means, all characters in *T* ∈ {0,1,2,...,9 }. Since all of them are integers, we can view a string of *m* consecutive characters as decimal numbers. For example, string ′61815′ corresponds to the number 61815. With the above assumption, the pattern *P* is also a decimal value, and let us assume that the decimal value of *P* is *p*. For the given text *T*[0*..n* – 1], let *t*(*i*) denote the decimal value of length–*m* substring *T*[*i.. i + m* – 1] for *i =* 0,1, *...,n – m–* 1. So, *t*(*i*) *== p* if and only if *T*[*i..i + m* – 1] **==** *P*[0..*m* – 1].

We cancompute p inO(*m*) time usingHorner’s Rule as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.043.png)

The code for the above assumptionis:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.044.png)

We can compute all *t*(*i*), for *i =* 0,1,..., *n* – *m* – 1 values in a total of O(*n*) time. The value of *t*(0) can be similarly computed from*T*[0.. *m* – 1] in O(*m*) time. To compute the remaining values *t*(0), *t*(1),..., *t*(*n – m –* 1), understand that *t*(*i +* 1) canbe computed from*t*(*i*) inconstant time.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.045.png)

For example, if *T =* ″123456″ and *m =* 3

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.046.png)

**Stepby Stepexplanation**

First : remove the first digit : 123 – 100 \*1 = 23

Second: Multiplyby10 to shift it : 23 \*10 = 230 Third: Add last digit : 230 + 4 = 234

The algorithmruns by comparing, *t*(*i*) with *p*. When *t*(*i*) == *p*, then we have found the substring *P* in*T*, startingfromposition*i*.

5. **String Matching with Finite Automata**

In this method we use the finite automata which is the concept of the Theory of Computation (ToC). Before lookingat the algorithm, first let us lookat the definitionof finite automata.

**Finite Automata**

Afinite automatonF is a 5-tuple (*Q*,*q*0*,A,*∑*,δ*), where

- *Q* is a finite set of states
- q0 ∈ *Q* is the start state
- *A*⊆ *Q* is a set of acceptingstates
- ∑ is a finite input alphabet
- *δ* is the transitionfunctionthat gives the next state for a givencurrent state and input

**How does Finite Automata Work?**

- The finite automaton*F* begins instate *q*0
- Reads characters from∑ one at a time
- If *F* is instate *q* and reads input character *a, F* moves to state *δ*(*q,d*)
- At the end, if its state is in*A*, thenwe say, *F* accepted the input stringread so far
- If the input stringis not accepted it is called the rejected string

**Example:** Let us assume that *Q =* {0,1{*,q*0 = 0*,A =* {1},*∑* = {*a, b*}*. δ*(*q,d*) as shown in the transition table/diagram. This accepts strings that end in an odd number of *a’s;* e.g., *abbaaa* is accepted, *aa* is rejected.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.047.png)

**Important Notes for Constructing the Finite Automata**

For building the automata, first we start with the initial state. The FA will be in state *k* if *k* characters of the pattern have been matched. If the next text character is equal to the pattern character *c*, we have matched *k* + 1 characters and the FA enters state *k* + 1. If the next text character is not equal to the pattern character, then the FAgo to a state 0,1,2*,....or k*, depending on how manyinitial patterncharacters matchthe text characters endingwith*c.*

**Matching Algorithm**

Now, let us concentrate onthe matchingalgorithm.

- For a givenpattern*P*[0*.. m –* 1], first we need to build a finite automaton*F*
- The state set is *Q =* {0,1,2, *...,m*}
- The start state is 0
- The onlyacceptingstate is *m*
- Time to build *F* canbe large if ∑ is large
- Scanthe text string*T*[0.. *n –* 1] to find all occurrences of the pattern*P*[0*.. m –* 1]
- Stringmatchingis efficient: Θ(*n*)
- Eachcharacter is examined exactlyonce
- Constant time for eachcharacter
- But the time to compute *δ* (transition function) is O(*m*|∑|). This is because *δ* has O(*m*|∑|) entries. If we assume |∑| is constant then the complexitybecomes O(*m*).

**Algorithm:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.048.png)

Time Complexity: O(*m*).

6. **KMP Algorithm**

As before, let us assume that *T* is the stringto be searched and *P* is the patternto be matched. This algorithmwas presented byKnuth, Morris and Pratt. It takes O(*n*) time complexity for searchinga pattern. To get O(*n*) time complexity, it avoids the comparisons with elements of *T* that were previouslyinvolved incomparisonwithsome element of the pattern*P.*

The algorithm uses a table and in general we call it *prefix function* or *prefix table* or *fail function* F. First we will see how to fill this table and later how to search for a pattern using this table. The prefix function F for a pattern stores the knowledge about how the pattern matches against shifts of itself. This information can be used to avoid useless shifts of the pattern *P*. It means that this table canbe used for avoidingbacktrackingonthe string*T.*

**Prefix Table**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.049.png)

As an example, assume that *P = a b a b a c a*. For this pattern, let us follow the step-by-step instructions for fillingthe prefixtable F. Initially: *m* = *length*[*P*] = 7*,F*[0] = 0 and *F*[1] = 0.

**Step1:** *i* = 1,*j* = 0,F[1] =0

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.050.png)

**Step2:** *i* = 2*,j* = 0,F[2] = 1

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.051.png)

**Step3:** *i =* 3*,j =* 1,F[3] =2

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.052.png)

**Step4:** *i =* 4,*j* = 2,F[4] =3

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.053.png)

**Step5:** *i =* 5*,j* = 3,F[5] = 1

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.054.png)

**Step6:** *i =* 6*,j =* 1,F[6] =1

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.055.png)

At this step the fillingof the prefixtable is complete.

**Matching Algorithm**

The KMPalgorithmtakes pattern *P*, string*T* and prefix function *F* as input, and finds a match of *P* in*T.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.056.png)

Time Complexity: O(*m* + *n*), where *m* is the length of the pattern and *n* is the length of the text to be searched. Space Complexity: O(*m*).

Now, to understand the process let us go through an example. Assume that *T = b a c b a b a b a b a c a c a* & *P = a b a b a c a*. Since we have already filled the prefix table, let us use it and go to the matchingalgorithm. Initially: *n = size of T =* 15; *m = size of P =* 7.

**Step1:** *i =* 0, *j* = 0, comparing *P*[0] with *T*[0]. *P*[0] does not match with *T*[0]*. P* will be shifted one positionto the right.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.057.png)

**Step2** :*i =* 1*, j =* 0, comparing *P*[0] with*T*[1]*. P*[0] matches with *T*[1]. Since there is a match, *P* is not shifted.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.058.png)

**Step3:** *i* = 2, *j* = 1, comparing*P*[1] with*T*[2]*. P*[1] does not match with *T*[2]. Backtracking on *P*,

comparing*P*[0] and *T*[2].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.059.png)

**Step4:** *i* = 3, *j* = 0, comparing*P*[0] with*T*[3]. *P*[0] does not matchwith*T*[3].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.060.png)

**Step5:** *i* = 4, *j* = 0, comparing*P*[0] with*T*[4]. *P*[0] matches with*T*[4].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.061.png)

**Step6:** *i* = 5, *j* = 1, comparing*P*[1] with*T*[5]. *P*[1] matches with*T*[5].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.062.png)

**Step7:** *i =* 6*, j =* 2, comparing*P*[2] with*T*[6]*. P*[2] matches with*T*[6].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.062.png)

**Step8:** *i =* 7, *j* = 3, comparing*P*[3] with*T*[7]. *P*[3] matches with*T*[7].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.063.png)

**Step9:** *i =* 8, *j* = 4, comparing*P*[4] with*T*[8]. *P*[4] matches with*T*[8].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.064.png)**Step10:** *i =* 9*, j* = 5, comparing *P*[5] with *T*[9]. *P*[5] does not match with *T*[9]. Backtracking on *P*, comparing*P*[4] with*T*[9] because after mismatch; = *F*[4] = 3.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.065.png)

Comparing*P*[3] with*T*[9].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.066.png)

**Step11:** *i* = 10, *j* = 4, comparing*P*[4] with*T*[10]. *P*[4] matches with*T*[10].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.067.png)

**Step12:** *i* = 11, *j* = 5, comparing*P*[5] with*T*[11]. *P*[5] matches with*T*[11].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.068.png)

**Step13:** *i =* 12, *j* = 6, comparing*P*[6] with*T*[12]*. P*[6] matches with*T*[12].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.069.png)

Pattern*P* has beenfound to completelyoccur instring*T*. The total number of shifts that tookplace for the matchto be found are: *i* – *m*= 13 – 7 = 6 shifts.

**Notes:**

- KMPperforms the comparisons fromleft to right
- KMP algorithmneeds a preprocessing (prefix function) which takes O(*m*) space and time complexity
- Searchingtakes O(*n* + *m*) time complexity(does not depend onalphabet size)

7. **Boyer-Moore Algorithm**

Like the KMP algorithm, this also does some pre-processing and we call it *last function*. The algorithm scans the characters of the pattern from right to left beginning with the rightmost character. During the testing of a possible placement of pattern *P* in *T*, a mismatch is handled as follows: Let us assume that the current character being matched is *T*[*i*] *= c* and the corresponding pattern character is *P*[*j*]. If *c* is not contained anywhere in *P*, then shift the pattern *P* completely past *T*[*i*]. Otherwise, shift *P* until an occurrence of character *c* in *P* gets aligned with *T*[*i*]. This technique avoids needless comparisons byshiftingthe patternrelative to the text.

The *last* function takes O(*m* + |∑|) time and the actual search takes O(*nm*) time. Therefore the worst case running time of the Boyer-Moore algorithm is O(*nm* + |∑|). This indicates that the worst-case runningtime is quadratic, inthe case of *n* == *m*, the same as the brute force algorithm.

- The Boyer-Moore algorithm is very fast on the large alphabet (relative to the length of the pattern).
- For the small alphabet, Boyer-Moore is not preferable.
- For binarystrings, the KMPalgorithmis recommended.
- For the veryshortest patterns, the brute force algorithmis better.

8. **Data Structures for Storing Strings**

If we have a set of strings (for example, all the words in the dictionary) and a word which we want to search in that set, in order to perform the search operation faster, we need an efficient wayof storingthe strings. To store sets of strings we canuse anyof the followingdata structures.

- HashingTables
- BinarySearchTrees
- Tries
- TernarySearchTrees

9. **Hash Tables for Strings**

As seen in the *Hashing* chapter, we can use hash tables for storing the integers or strings. In this case, the keys are nothing but the strings. The problem with hash table implementation is that we lose the ordering information – after applying the hash function, we do not know where it will map to. As a result, some queries take more time. For example, to find all the words starting with the letter *“K”*, with hash table representation we need to scan the complete hash table. This is because the hash function takes the complete key, performs hash on it, and we do not know the locationof eachword.

10. **Binary Search Trees for Strings**

In this representation, every node is used for sorting the strings alphabetically. This is possible because the strings have a natural ordering: *A*comes before *B*, which comes before *C*, and so on. This is because words can be ordered and we can use a Binary Search Tree (BST) to store and retrieve them. For example, let us assume that we want to store the followingstrings usingBSTs:

*this is a career monk string*

For the given string there are many ways of representing them in BST. One such possibility is showninthe tree below.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.070.png)

**Issues with Binary Search Tree Representation**

This method is good in terms of storage efficiency. But the disadvantage of this representation is that, at every node, the search operation performs the complete match of the given key with the node data, and as a result the time complexity of the search operation increases. So, fromthis we cansaythat BST representationof strings is good interms of storage but not interms of time.

11. **Tries**

Now, let us see the alternative representation that reduces the time complexity of the search operation. The name *trie* is takenfromthe word re”trie”.

**What is a Trie?**

A *trie* is a tree and each node in it contains the number of pointers equal to the number of characters of the alphabet. For example, if we assume that all the strings are formed with English alphabet characters *“a”* to *“z”* then each node of the trie contains 26 pointers. A trie data structure canbe declared as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.071.png)

Suppose we want to store the strings *“a”,”all”,”als”*, and *“as”“: trie* for these strings will look like:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.072.jpeg)

**Why Tries?**

The tries caninsert and find strings inO(*L*) time (where *L* represents the length of a single word). This is muchfaster thanhashtable and binarysearchtree representations.

**Trie Declaration**

The structure of the TrieNode has data (char), is\_End\_Of\_String (boolean), and has a collection of child nodes (Collection of TrieNodes). It also has one more method called subNode(char). This method takes a character as argument and will return the child node of that character type if that is present. The basic element - TrieNode of a TRIE data structure looks like this:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.073.png)

Now that we have defined our TrieNode, let’s go ahead and look at the other operations of TRIE. Fortunately, the TRIE data structure is simple to implement since it has two major methods: insert() and search(). Let’s lookat the elementaryimplementationof boththese methods.

**Inserting a String in Trie**

To insert a string, we just need to start at the root node and follow the corresponding path (path fromroot indicates the prefix of the given string). Once we reach the NULLpointer, we just need to create a skew of tail nodes for the remainingcharacters of the givenstring.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.074.png)

Time Complexity: O(*L*), where *L* is the lengthof the stringto be inserted.

**Note:** For real dictionary implementation, we may need a few more checks such as checking whether the givenstringis alreadythere inthe dictionaryor not.

**Searching a String in Trie**

The same is the case with the search operation: we just need to start at the root and follow the pointers. The time complexity of the search operation is equal to the length of the given string that want to search.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.075.png)

Time Complexity: O(*L*), where *L* is the lengthof the stringto be searched.

**Issues with Tries Representation**

The main disadvantage of tries is that they need lot of memory for storing the strings. As we have seen above, for each node we have too many node pointers. In many cases, the occupancy of each node is less. The final conclusion regarding tries data structure is that they are faster but require huge memoryfor storingthe strings.

**Note:** There are some improved tries representations called *trie compression techniques*. But, even with those techniques we can reduce the memory only at the leaves and not at the internal nodes.

12. **Ternary Search Trees**

This representation was initially provided by Jon Bentley and Sedgewick. A ternary search tree takes the advantages of binary search trees and tries. That means it combines the memory

efficiencyof BSTs and the time efficiencyof tries. **Ternary SearchTrees Declaration**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.076.png)

The TernarySearchTree (TST) uses three pointers:

- The *left* pointer points to the TST containing all the strings which are alphabetically less than*data.*
- The *right* pointer points to the TST containing all the strings which are alphabeticallygreater than*data.*
- The *eq* pointer points to the TST containing all the strings which are alphabetically equal to *data*. That means, if we want to search for a string, and if the current character of the input string and the *data* of current node in TST are the same, then we need to proceed to the next character in the input string and search it in the subtree whichis pointed by*eq.*

**Inserting strings inTernary SearchTree**

For simplicity let us assume that we want to store the following words in TST (also assume the same order): *boats, boat, bat* and *bats*. Initially, let us start withthe *boats* string.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.077.jpeg)

Now if we want to insert the string *boat*, then the TST becomes [the only change is setting the *is\_End\_Of\_String* flagof *“t”* node to 1]:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.078.jpeg)

Now, let us insert the next string: *bat*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.079.jpeg)

Now, let us insert the final word: *bats.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.080.jpeg)

Based on these examples, we can write the insertion algorithm as below. We will combine the insertionoperationof BST and tries.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.081.png)

Time Complexity: O(*L*), where *L* is the lengthof the stringto be inserted.

**Searching in Ternary Search Tree**

If after inserting the words we want to search for them, then we have to follow the same rules as that of binary search. The only difference is, in case of match we should check for the remaining characters (in *eq* subtree) instead of return. Also, like BSTs we will see both recursive and non- recursive versions of the searchmethod.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.082.jpeg)

Time Complexity: O(*L*), where *L* is the lengthof the stringto be searched.

**Displaying AllWords of Ternary Search Tree**

If we want to print all the strings of TST we can use the following algorithm. If we want to print theminsorted order, we need to follow the inorder traversal of TST.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.083.png)

**Finding the Length of the Largest Word in TST**

This is similar to findingthe height of the BST and canbe found as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.084.png)

13. **Comparing BSTs, Tries and TSTs**

- Hash table and BST implementation stores complete the string at each node. As a result theytake more time for searching. But theyare memoryefficient.
- TSTs can grow and shrink dynamically but hash tables resize only based on load factor.
- TSTs allow partial searchwhereas BSTs and hashtables do not support it.
- TSTs can display the words in sorted order, but in hash tables we cannot get the sorted order.
- Tries perform search operations very fast but they take huge memory for storing the string.
- TSTs combine the advantages of BSTs and Tries. That means they combine the memoryefficiencyof BSTs and the time efficiencyof tries

14. **Suffix Trees**

Suffixtrees are animportant data structure for strings. Withsuffixtrees we cananswer the queries very fast. But this requires some preprocessing and construction of a suffix tree. Even though the construction of a suffix tree is complicated, it solves many other string-related problems in linear time.

**Note:** Suffix trees use a tree (suffix tree) for one string, whereas Hash tables, BSTs, Tries and TSTs store a set of strings. That means, a suffixtree answers the queries related to one string.

Let us see the terminologywe use for this representation. **Prefix andSuffix**

Givena string*T = T*1*T*2 … *Tn*, the *prefix* of *T* is a string *T*1 *...Ti* where *i* can take values from1 to *n*. For example, if *T = banana*, thenthe prefixes of *T* are: *b, ba, ban, bana, banan, banana.*

Similarly, given a string *T = T*1*T*2 *… Tn*, the *suffix* of *T* is a string *Ti ...Tn* where *i* can take values from n to 1. For example, if *T = banana*, then the suffixes of *T* are: *a, na, ana, nana, anana, banana.*

**Observation**

From the above example, we can easily see that for a given text *T* and pattern *P*, the exact string matchingproblemcanalso be defined as:

- Find a suffixof *T* suchthat *P* is a prefixof this suffix*or*
- Find a prefixof *T* suchthat *P* is a suffixof this prefix.

**Example:** Let the text to be searched be *T = acebkkbac* and the pattern be *P = kkb*. For this example, *P* is a prefixof the suffix*kkbac* and also a suffixof the prefix*acebkkb.*

**What is a Suffix Tree?**

Insimple terms, the suffixtree for text *T* is a Trie-like data structure that represents the suffixes of *T*. The definition of suffix trees can be given as: Asuffix tree for a n character string *T*[1 *...n*] is a rooted tree withthe followingproperties.

- Asuffixtree will containnleaves whichare numbered from1 to *n*
- Eachinternal node (except root) should have at least 2 children
- Eachedge ina tree is labeled bya nonemptysubstringof *T*
- No two edges of a node (childrenedges) beginwiththe same character
- The paths fromthe root to the leaves represent all the suffixes of *T*

**The Construction of Suffix Trees**

**Algorithm**

1. Let *S* be the set of all suffixes of *T*. Append $ to eachof the suffixes.
1. Sort the suffixes inS based ontheir first character.
1. For eachgroup Sc (*c* ∈ ∑):

1) If Sc group has onlyone element, thencreate a leaf node.
1) Otherwise, find the longest common prefix of the suffixes in Sc group, create an internal node, and recursively continue with Step 2, S being the set of remaining suffixes from Sc after splitting off the longest

commonprefix.

For better understanding, let us go through an example. Let the given text be *T = tatat*. For this string, give a number to eachof the suffixes.



| Index                                                    | Suffix   |
| -------------------------------------------------------- | -------- |
| 1                                                        | $        |
| 2                                                        | *t$*     |
| 3                                                        | *at$*    |
| 4                                                        | *tat$*   |
| 5                                                        | *atat$*  |
| 6                                                        | *tatat$* |
| Now, sort the suffixes based ontheir initial characters. |          |

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.085.png)

In the three groups, the first group has only one element. So, as per the algorithm, create a leaf

node for it, as shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.086.png)

Now, for *S*2 and *S*3 (as they have more than one element), let us find the longest prefix in the group, and the result is shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.087.png)

For *S*2 and *S*3, create internal nodes, and the edge contains the longest common prefix of those groups.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.088.png)

Now we have to remove the longest commonprefixfromthe *S*2 and *S*3 group elements.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.089.png)

Out next step is solving *S*2 and *S*3 recursively. First let us take *S*2. In this group, if we sort them based on their first character, it is easy to see that the first group contains only one element $, and the second group also contains only one element, *at*$. Since both groups have only one element, we candirectlycreate leaf nodes for them.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.090.jpeg)

At this step, both *S*1 and *S*2 elements are done and the only remaining group is *S*3. As similar to earlier steps, in the *S*3 group, if we sort them based on their first character, it is easy to see that there is only one element in the first group and it is $. For *S*3 remaining elements, remove the longest commonprefix.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.091.png)

In the *S*3 second group, there are two elements: $ and *at*$. We can directly add the leaf nodes for the first group element $. Let us add *S*3 subtree as shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.092.jpeg)

Now, *S*3 contains two elements. If we sort thembased on their first character, it is easy to see that there are only two elements and among them one is $ and other is *at*$. We can directly add the leaf nodes for them. Let us add *S*3 subtree as shownbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.093.jpeg)

Since there are no more elements, this is the completion of the construction of the suffix tree for string*T = tatat*. The time-complexityof the constructionof a suffixtree usingthe above algorithm

is O(*n*2) where *n* is the length of the input string because there are *n* distinct suffixes. The longest has length*n*, the second longest has length*n* – 1, and so on.

**Note:**

- There are O(*n*) algorithms for constructingsuffixtrees.
- To improve the complexity, we canuse indices instead of stringfor branches.

**Applications of Suffix Trees**

All the problems below (but not limited to these) on strings can be solved with suffix trees very efficiently(for algorithms refer to *Problems* section).

- **Exact String Matching:** Givena text *T* and a pattern*P*, how do we checkwhether *P* appears in*T* or not?
- **Longest RepeatedSubstring:** Given a text *T* how do we find the substring of *T* that is the maximumrepeated substring?
- **Longest Palindrome:** Given a text *T* how do we find the substring of *T* that is the longest palindrome of *T?*
- **Longest Common Substring:** Given two strings, how do we find the longest commonsubstring?
- **Longest Common Prefix:** Given two strings *X*[*i ...n*] and *Y*[*j* ...*m*],how do we find the longest commonprefix?
- How do we searchfor a regular expressioningiventext *T?*
- Givena text *T* and a pattern*P*, how do we find the first occurrence of *P* in*T?*

15. **String Algorithms: Problems & Solutions**

**Problem-1**  Given a paragraph of words, give an algorithm for finding the word which

appears the maximum number of times. If the paragraph is scrolled down (some words disappear from the first frame, some words still appear, and some are new words), give the maximumoccurringword. Thus, it should be dynamic.

**Solution:** For this problem we can use a combination of priority queues and tries. We start by creating a trie in which we insert a word as it appears, and at every leaf of trie. Its node contains that word along with a pointer that points to the node in the heap [priority queue] which we also create. This heap contains nodes whose structure contains a *counter*. This is its frequency and also a pointer to that leaf of trie, which contains that word so that there is no need to store the word twice.

Whenever a new word comes up, we find it in trie. If it is already there, we increase the frequencyof that node inthe heap correspondingto that word, and we call it heapify. This is done so that at any point of time we can get the word of maximum frequency. While scrolling, when a word goes out of scope, we decrement the counter in heap. If the new frequency is still greater thanzero, heapifythe heap to incorporate the modification. If the new frequencyis zero, delete the node fromheap and delete it fromtrie.

**Problem-2**  Giventwo strings, how canwe find the longest commonsubstring?

**Solution:** Let us assume that the given two strings are *T*1 and *T*2. The longest common substring of two strings, *T*1 and *T*2, can be found by building a generalized suffix tree for *T*1 and *T*2. That

means we need to build a single suffix tree for both the strings. Each node is marked to indicate if it represents a suffix of *T*1 or *T*2 or both. This indicates that we need to use different marker

symbols for both the strings (for example, we can use $ for the first string and # for the second symbol). After constructing the common suffix tree, the deepest node marked for both *T*1 and *T*2

represents the longest commonsubstring.

**Another way of doing this is:** We can build a suffix tree for the string *T*1$*T*2#. This is equivalent to buildinga commonsuffixtree for boththe strings.

Time Complexity: O(*m* + *n*), where *m* and *n* are the lengths of input strings *T*1 and *T*2.

**Problem-3  Longest Palindrome:** Given a text *T* how do we find the substring of *T* which is

the longest palindrome of *T?*

**Solution:** The longest palindrome of *T*[1..*n*] can be found in O(*n*) time. The algorithm is: first build a suffix tree for *T*$*reverse*(*T*)# or build a generalized suffix tree for *T* and *reverse*(*T*). After building the suffix tree, find the deepest node marked with both $ and #. Basically it means find the longest commonsubstring.

**Problem-4**  Given a string (word), give an algorithm for finding the next word in the

dictionary.

**Solution:** Let us assume that we are using Trie for storing the dictionary words. To find the next

word in Tries we can follow a simple approach as shown below. Starting from the rightmost character, increment the characters one by one. Once we reach *Z*, move to the next character on the left side.

Whenever we increment, check if the word with the incremented character exists in the dictionary or not. If it exists, then return the word, otherwise increment again. If we use *TST*, then we can find the inorder successor for the current word.

**Problem-5**  Give analgorithmfor reversinga string. **Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.094.png)

Time Complexity: O(*n*), where *n* is the lengthof the givenstring. Space Complexity: O(*n*).

**Problem-6**  If the string is not editable, how do we create a string that is the reverse of the

givenstring?

**Solution:** If the string is not editable, then we need to create an array and return the pointer of that.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.095.png)

Time Complexity: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.096.png), where *n* is the length of the given string. Space Complexity: O(1).

**Problem-7**  Canwe reverse the stringwithout usinganytemporaryvariable?

**Solution: Yes,** we canuse XOR logic for swappingthe variables.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.097.png)

Time Complexity: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.096.png), where *n* is the length of the given string. Space Complexity: O(1).

**Problem-8**  Given a text and a pattern, give an algorithm for matching the pattern in the text.

Assume ? (single character matcher) and \* (multi character matcher) are the wild card characters.

**Solution: Brute Force Method.** For efficient method, refer to the theorysection.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.098.png)

Time Complexity: O(*mn*), where *m* is the lengthof the text and *n* is the lengthof the pattern. Space Complexity: O(1).

**Problem-9**  Give analgorithmfor reversingwords ina sentence.

**Example:** Input: “This is a Career MonkString”, Output: “StringMonkCareer a is This”

**Solution:** Start from the beginning and keep on reversing the words. The below implementation assumes that ‘ ‘ (space) is the delimiter for words ingivensentence.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.099.jpeg)

Time Complexity: O(2*n*) ≈ O(*n*), where *n* is the lengthof the string. Space Complexity: O(1).

**Problem-10  Permutations of a string [anagrams]:** Give an algorithm for printing all

possible permutations of the characters in a string. Unlike combinations, two permutations are considered distinct if they contain the same characters but in a different order. For simplicity assume that each occurrence of a repeated character is a distinct character. That is, if the input is “aaa”, the output should be sixrepetitions of “aaa”. The permutations may be output inanyorder.

**Solution:** The solution is reached by generating n! strings, each of length n, where n is the length of the input string.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.100.png)

**Problem-11  Combinations Combinations of a String:** Unlike permutations, two

combinations are considered to be the same if they contain the same characters, but may be in a different order. Give an algorithm that prints all possible combinations of the characters in a string. For example, *“ac”* and *“ab”* are different combinations from the input string*“abc”*, but *“ab”* is the same as *“ba”.*

**Solution:** The solution is achieved by generating *n*!*/r*! (*n – r*)! strings, each of length between 1 and *n* where *n* is the lengthof the giveninput string.

**Algorithm:**

For eachof the input characters

1. Put the current character inoutput stringand print it.
1. If there are any remaining characters, generate combinations with those remainingcharacters.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.101.png)

**Problem-12**  Given a string “ABCCBCBA”, give an algorithm for recursively removing the

adjacent characters if they are the same. For example, ABCCBCBA nnnnnn> ABBCBA- >ACBA

**Solution:** First we need to checkif we have a character pair; if yes, thencancel it. Now checkfor next character and previous element. Keep canceling the characters until we either reach the start of the array, reachthe end of the array, or don’t find a pair.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.102.png)

**Problem-13**  Given a set of characters *CHARS* and a input string *INPUT*, find the minimum

window in *str* which will contain all the characters in *CHARS* in complexity O(*n*). For example, *INPUT = ABBACBAA*and *CHARS = AAB* has the minimumwindow *BAA.*

**Solution:** This algorithm is based on the sliding window approach. In this approach, we start fromthe beginningof the arrayand move to the right. As soonas we have a window whichhas all the required elements, try sliding the window as far right as possible with all the required elements. If the current window length is less than the minimumlength found until now, update the minimum length. For example, if the input array is *ABBACBAA* and the minimum window should cover characters *AAB*, thenthe slidingwindow will move like this:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.103.png)

**Algorithm:** The input is the givenarrayand chars is the arrayof characters that need to be found.

1  Make an integer array shouldfind[] of len 256. The *ith* element of this array will have the count of how manytimes we need to find the element of ASCII value *i.*
1  Make another array hasfound of 256 elements, which will have the count of the required elements found until now.
1  Count <= 0
1  While input[i]

1. If input[i] element is not to be found→ continue
1. If input[i] element is required => increase count by1.
1. If count is length of chars[] array, slide the window as much right as possible.
1. If current window length is less than min length found until now, update minlength.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.104.jpeg)

Complexity: If we walkthroughthe code, *i* and *j* cantraverse at most *n* steps (where *n* is the input

size) inthe worst case, addingto a total of 2*n* times. Therefore, time complexityis O(*n*).

**Problem-14**  We are givena 2D arrayof characters and a character pattern. Give analgorithm

to find if the pattern is present in the 2D array. The pattern can be in any order (all 8 neighbors to be considered) but we can’t use the same character twice while matching. Return 1 if match is found, 0 if not. For example: Find “MICROSOFT” in the below matrix.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.105.png)

**Solution:** Manually finding the solution of this problem is relatively intuitive; we just need to describe analgorithmfor it. Ironically, describingthe algorithmis not the easypart.

**How do we do it manually?** First we match the first element, and when it is matched we match the second element in the 8 neighbors of the first match. We do this process recursively, and when the last character of the input patternmatches, returntrue.

During the above process, take care not to use any cell in the 2D array twice. For this purpose, you mark every visited cell with some sign. If your pattern matching fails at some point, start matching from the beginning (of the pattern) in the remaining cells. When returning, you unmark the visited cells.

Let’s convert the above intuitive method into an algorithm. Since we are doing similar checks for pattern matching every time, a recursive solution is what we need. In a recursive solution, we need to check if the substring passed is matched in the given matrix or not. The condition is not to use the alreadyused cell, and to find the alreadyused cell, we need to add another 2D arrayto the function (or we can use an unused bit in the input array itself.) Also, we need the current position of the input matrixfromwhere we need to start. Since we need to pass a lot more informationthan is actually given, we should be having a wrapper function to initialize the extra information to be passed.

**Algorithm:**

If we are past the last character inthe pattern

Returntrue

If we get a used cell again

Returnfalse if we got past the 2D matrix

Returnfalse

If searchingfor first element and cell doesn’t match

FindMatchwithnext cell inrow-first order (or column-first order)

Otherwise if character matches

markthis cell as used

res = FindMatchwithnext positionof patternin8 neighbors markthis cell as unused

Returnres

Otherwise

Returnfalse

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.106.jpeg)

**Problem-15**  Given two strings str1 and *str*2, write a function that prints all interleavings of the given two strings. We may assume that all characters in both strings are different. Example: Input: *str*1 = “AB”, *str*2 = “CD” and Output: ABCD ACBD ACDB CABD

CADB CDAB. Aninterleaved stringof giventwo strings preserves the order of characters in individual strings. For example, in all the interleavings of above first example, ‘A’ comes before ‘B’ and ‘C comes before ‘D’.

**Solution:** Let the length of *str*1 be *m* and the length of *str*2 be *n*. Let us assume that all characters in*str*1 and *str*2 are different. Let Count(*m,n*) be the count of all interleaved strings insuchstrings. The value of Count(*m,n*) canbe writtenas following.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.107.png)

To print all interleavings, we can first fix the first character of strl[0..m-1] in output string, and recursively call for str1[1..m-1] and str2[0..n-1]. And then we can fix the first character of str2[0..n-1] and recursivelycall for str1[0..m-1] and str2[1..n-1].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.108.jpeg)

**Problem-16**  Given a matrix with size *n* × *n* containing random integers. Give an algorithm

which checks whether rows match with a column(s) or not. For example, if *ith* row matches with *jth* column, and *ith* row contains the elements - [2,6,5,8,9]. Then;’’1 column would also containthe elements - [2,6,5,8,9].

**Solution:** We can build a trie for the data in the columns (rows would also work). Then we can compare the rows with the trie. This would allow us to exit as soon as the beginning of a row does not matchanycolumn(backtracking). Also this would let us checka row against all columns inone pass.

If we do not want to waste memoryfor emptypointers thenwe canfurther improve the solutionby constructinga suffixtree.

**Problem-17**  Write a method to replace all spaces in a string with ‘%20’. Assume string has

sufficient space at end of stringto hold additional characters.

**Solution:** Find the number of spaces. Then, starting fromend (assuming string has enough space), replace the characters. Startingfromend reduces the overwrites.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.109.jpeg)

Time Complexity: O(*n*). Space Complexity: O(1). Here, we do not have to worry about the space needed for extra characters.

**Problem-18  Running length encoding:** Write an algorithm to compress the given string by

using the count of repeated characters and if new corn-pressed string length is not smaller thanthe original stringthenreturnthe original string.

**Solution:**

*With extra space of* O(2):

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.110.jpeg)

Time Complexity: O(*n*). Space Complexity: O(1), but it uses a temporaryarrayof size two. *Without extra space* (*inplace*):

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.111.png)

Time Complexity: O(*n*). Space Complexity: O(1).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.112.png)

1. **Introduction**

In the previous chapters, we have seen many algorithms for solving different kinds of problems. Before solving a new problem, the general tendency is to look for the similarity of the current problem to other problems for which we have solutions. This helps us in getting the solution easily.

In this chapter, we will see different ways of classifying the algorithms and in subsequent chapters we will focus ona few of them(Greedy, Divide and Conquer, Dynamic Programming).

2. **Classification**

There are manyways of classifyingalgorithms and a few of themare shownbelow:

- ImplementationMethod
- DesignMethod
- Other Classifications

3. **Classification by Implementation Method Recursion or Iteration**

A *recursive* algorithm is one that calls itself repeatedly until a base condition is satisfied. It is a commonmethod used infunctional programminglanguages like *C,C* + +, etc.

*Iterative* algorithms use constructs like loops and sometimes other data structures like stacks and queues to solve the problems.

Some problems are suited for recursive and others are suited for iterative. For example, the *Towers of Hanoi* problemcan be easily understood in recursive implementation. Every recursive versionhas aniterative version, and vice versa.

**Proceduralor Declarative (*n*on-Procedural)**

In*declarative* programming languages, we say what we want without having to say how to do it. With *procedural* programming, we have to specify the exact steps to get the result. For example, SQLis more declarative than procedural, because the queries don’t specify the steps to produce the result. Examples of procedural languages include: C, PHP, and PERL.

**Serialor Parallelor Distributed**

In general, while discussing the algorithms we assume that computers execute one instruction at a time. These are called *serial* algorithms.

*Parallel* algorithms take advantage of computer architectures to process several instructions at a time. They divide the probleminto subproblems and serve themto several processors or threads. Iterative algorithms are generallyparallelizable.

If the parallel algorithms are distributed on to different machines then we call such algorithms *distributed* algorithms.

**Deterministic or Non-Deterministic**

*Deterministic* algorithms solve the problem with a predefined process, whereas *non – deterministic* algorithms guess the best solutionat eachstep throughthe use of heuristics.

**Exact or Approximate**

As we have seen, for many problems we are not able to find the optimal solutions. That means, the algorithms for which we are able to find the optimal solutions are called *exact* algorithms. In computer science, if we do not have the optimal solution, we give approximationalgorithms.

Approximation algorithms are generally associated with NP-hard problems (refer to the *Complexity Classes* chapter for more details).

4. **Classification by Design Method**

Another wayof classifyingalgorithms is bytheir designmethod.

**Greedy Method**

*Greedy* algorithms work in stages. In each stage, a decision is made that is good at that point, without bothering about the future consequences. Generally, this means that some *local best* is chosen. It assumes that the local best selectionalso makes for the *global* optimal solution.

**Divide and Conquer**

The D & C strategysolves a problemby:

1) Divide: Breaking the problem into sub problems that are themselves smaller instances of the same type of problem.
1) Recursion: Recursivelysolvingthese sub problems.
1) Conquer: Appropriatelycombiningtheir answers.

Examples: merge sort and binarysearchalgorithms.

**Dynamic Programming**

Dynamic programming (DP) and memoization work together. The difference between DP and divide and conquer is that inthe case of the latter there is no dependencyamongthe sub problems, whereas in DP there will be an overlap of sub-problems. By using memoization [maintaining a table for already solved sub problems], DP reduces the exponential complexity to polynomial

complexity(O(*n*2), O(*n*3), etc.) for manyproblems.

The difference between dynamic programming and recursion is in the memoization of recursive calls. When sub problems are independent and if there is no repetition, memoization does not help, hence dynamic programmingis not a solutionfor all problems.

By using memoization [maintaining a table of sub problems already solved], dynamic

programmingreduces the complexityfromexponential to polynomial.

**Linear Programming**

In linear programming, there are inequalities in terms of inputs and *maximizing* (or *minimizing*) some linear function of the inputs. Many problems (example: maximum flow for directed graphs) canbe discussed usinglinear programming.

**Reduction [Transform and Conquer]**

Inthis method we solve a difficult problembytransformingit into a knownproblemfor whichwe have asymptotically optimal algorithms. In this method, the goal is to find a reducing algorithm whose complexity is not dominated by the resulting reduced algorithms. For example, the selection algorithm for finding the median in a list involves first sorting the list and then finding out the middle element inthe sorted list. These techniques are also called *transform and conquer.*

5. **Other Classifications Classification by Research Area**

In computer science each field has its own problems and needs efficient algorithms. Examples: search algorithms, sorting algorithms, merge algorithms, numerical algorithms, graph algorithms, string algorithms, geometric algorithms, combinatorial algorithms, machine learning, cryptography, parallel algorithms, data compressionalgorithms, parsingtechniques, and more.

**Classification by Complexity**

In this classification, algorithms are classified by the time they take to find a solution based on their input size. Some algorithms take linear time complexity (O(*n*)) and others take exponential time, and some never halt. Note that some problems may have multiple algorithms with different complexities.

**Randomized Algorithms**

A few algorithms make choices randomly. For some problems, the fastest solutions must involve randomness. Example: QuickSort.

**Branch and Bound Enumeration and Backtracking**

These were used in Artificial Intelligence and we do not need to explore these fully. For the Backtrackingmethod refer to the *Recusion and Backtracking* chapter.

**Note:** In the next few chapters we discuss the Greedy, Divide and Conquer, and Dynamic Programming] design methods. These methods are emphasized because they are used more often thanother methods to solve problems.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.113.png)

1. **Introduction**

Let us start our discussion with simple theory that will give us an understanding of the Greedy technique. In the game *of Chess*, every time we make a decision about a move, we have to also think about the future consequences. Whereas, in the game of *Tennis* (or *Volleyball*), our action is based onthe immediate situation.

This means that in some cases making a decision that looks right at that moment gives the best solution(*Greedy*), but in other cases it doesn’t. The Greedy technique is best suited for looking at the immediate situation.

2. **Greedy Strategy**

Greedy algorithms work in stages. In each stage, a decision is made that is good at that point, without bothering about the future. This means that some *local best* is chosen. It assumes that a local good selectionmakes for a global optimal solution.

3. **Elements of Greedy Algorithms**

The two basic properties of optimal Greedyalgorithms are:

1) Greedychoice property
1) Optimal substructure

**Greedy choice property**

This property says that the globally optimal solution can be obtained by making a locally optimal solution(Greedy). The choice made bya Greedy algorithmmay depend on earlier choices but not on the future. It iteratively makes one Greedy choice after another and reduces the given problem to a smaller one.

**Optimalsubstructure**

A problem exhibits optimal substructure if an optimal solution to the problem contains optimal solutions to the subproblems. That means we can solve subproblems and build up the solutions to solve larger problems.

4. **Does Greedy Always Work?**

Makinglocallyoptimal choices does not always work. Hence, Greedyalgorithms will not always give the best solutions. We will see particular examples in the *Problems* section and in the *Dynamic Programming* chapter.

5. **Advantages and Disadvantages of Greedy Method**

The main advantage of the Greedy method is that it is straightforward, easy to understand and easy to code. In Greedy algorithms, once we make a decision, we do not have to spend time re- examining the already computed values. Its main disadvantage is that for many problems there is no greedy algorithm. That means, in many cases there is no guarantee that making locally optimal improvements ina locallyoptimal solutiongives the optimal global solution.

6. **Greedy Applications**

- Sorting: Selectionsort, Topological sort
- PriorityQueues: Heap sort
- Huffmancodingcompressionalgorithm
- Prim’s and Kruskal’s algorithms
- Shortest pathinWeighted Graph[Dijkstra’s]
- Coinchange problem
- Fractional Knapsackproblem
- Disjoint sets-UNION bysize and UNION byheight (or rank)
- Job schedulingalgorithm
- Greedytechniques canbe used as anapproximationalgorithmfor complexproblems

7. **Understanding Greedy Technique**

For better understandinglet us go throughanexample.

**Huffman Coding Algorithm** Definition

Given a set of *n* characters from the alphabet A [each character c ∈ A*]* and their associated frequency *freq*(c), find a binary code for each character c ∈ *A*, such that ∑c ∈ A

freq(c)|binarycode(c)| is minimum, where /binarycode*(c)*/represents the length of binary code of character c. That means the sumof the lengths of all character codes should be minimum[the sum of eachcharacter’s frequencymultiplied bythe number of bits inthe representation].

The basic idea behind the Huffman coding algorithm is to use fewer bits for more frequently occurring characters. The Huffman coding algorithm compresses the storage of data using variable length codes. We know that each character takes 8 bits for representation. But in general, we do not use all of them. Also, we use some characters more frequently than others. When reading a file, the system generally reads 8 bits at a time to read a single character. But this coding scheme is inefficient. The reason for this is that some characters are more frequently used than other characters. Let’s say that the character ′e′ is used 10 times more frequently than the character ′*q*′. It would then be advantageous for us to instead use a 7 bit code for e and a 9 bit code for *q* because that could reduce our overall message length.

On average, using Huffman coding on standard files can reduce themanywhere from10% to 30% depending on the character frequencies. The idea behind the character coding is to give longer binary codes for less frequent characters and groups of characters. Also, the character coding is constructed insucha waythat no two character codes are prefixes of eachother.

**An Example**

Let’s assume that after scanninga file we find the followingcharacter frequencies:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.114.png)![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.115.png)

| Character                                                    | Frequency |
| ------------------------------------------------------------ | --------- |
| *a*                                                          | 12        |
| *b*                                                          | 2         |
| *c*                                                          | 7         |
| *d*                                                          | 13        |
| *e*                                                          | 14        |
| *f*                                                          | 85        |
| Given this, create a binary tree for each character that also stores the frequency with which it occurs (as shownbelow). |           |

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.116.png)

The algorithm works as follows: In the list, find the two binary trees that store minimum frequencies at their nodes.

Connect these two nodes at a newly created common node that will store no character but will store the sum of the frequencies of all the nodes connected below it. So our picture looks like this:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.117.png)

Repeat this process until onlyone tree is left:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.118.jpeg)Once the tree is built, each leaf node corresponds to a letter with a code. To determine the code for a particular node, traverse fromthe root to the leaf node. For eachmove to the left, append a 0 to the code, and for each move to the right, append a 1. As a result, for the above generated tree, we get the followingcodes:



| Letter                     | Code |
| -------------------------- | ---- |
| a                          | 001  |
| b                          | 0000 |
| c                          | 0001 |
| d                          | 010  |
| e                          | 011  |
| f                          | 1    |
| **Calculating Bits Saved** |      |

Now, let us see how manybits that Huffmancodingalgorithmis saving. All we need to do for this calculation is see how many bits are originally used to store the data and subtract from that the number of bits that are used to store the data using the Huffman code. In the above example, since we have six characters, let’s assume each character is stored with a three bit code. Since there are 133 such characters (multiply total frequencies by 3), the total number of bits used is 3 \* 133

- 399. Usingthe Huffmancodingfrequencies we cancalculate the new total number of bits used:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.119.jpeg)

Thus, we saved 399 – 238 = 161 bits, or nearly40% of the storage space.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.120.png)

Time Complexity: O(*nlogn*), since there will be *one* build\_heap, 2*n –* 2 delete\_mins, and *n –* 2 inserts, on a priority queue that never has more than n elements. Refer to the *Priority Queues* chapter for details.

8. **Greedy Algorithms: Problems & Solutions**

**Problem-1**  Givenanarray*F* withsize n. Assume the arraycontent *F*[*i*] indicates the lengthof

the *ith* file and we want to merge all these files into one single file. Check whether the followingalgorithmgives the best solutionfor this problemor not?

**Algorithm:** Merge the files contiguously. That means select the first two files and merge them. Then select the output of the previous merge and merge with the third file, and keep going...

**Note:** Giventwo files *A*and *B* withsizes *m* and n, the complexityof mergingis O(*m* + *n*).

**Solution:** This algorithm will not produce the optimal solution. For a counter example, let us consider the followingfile sizes array.

*F =* {10,5,100,50,20,15}

As per the above algorithm, we need to merge the first two files (10 and 5 size files), and as a result we get the following list of files. In the list below, 15 indicates the cost of merging two files withsizes 10 and 5.

{15,100,50,20,15}

Similarly, merging 15 with the next file 100 produces: {115,50,20,15}. For the subsequent steps

the list becomes

{165,20,15}, {185,15} Finally,

{200}

The total cost of merging= Cost of all mergingoperations = 15 + 115 + 165 + 185 + 200 = 680.

To see whether the above result is optimal or not, consider the order: {5,10,15,20,50,100}. For this example, following the same approach, the total cost of merging = 15 + 30 + 50 + 100 + 200

- 395. So, the givenalgorithmis not givingthe best (optimal) solution.

**Problem-2**  Similar to [Problem-1](#_page95_x66.91_y415.17), does the followingalgorithmgive the optimal solution?

**Algorithm:** Merge the files in pairs. That means after the first step, the algorithmproduces the *n*/2 intermediate files. For the next step, we need to consider these intermediate files and merge theminpairs and keep going.

**Note:** Sometimes this algorithm is called 2-way merging. Instead of two files at a time, if we merge *K* files at a time thenwe call it *K*-waymerging.

**Solution:** This algorithmwill not produce the optimal solutionand consider the previous example for a counter example. As per the above algorithm, we need to merge the first pair of files (10 and 5 size files), the second pair of files (100 and 50) and the third pair of files (20 and 15). As a result we get the followinglist of files.

{15,150,35}

Similarly, merge the output inpairs and this step produces [below, the third element does not have a pair element, so keep it the same]:

{165,35} Finally,

{185}

The total cost of merging = Cost of all merging operations = 15 + 150 + 35 + 165 + 185 = 550. This is much more than 395 (of the previous problem). So, the given algorithm is not giving the best (optimal) solution.

**Problem-3**  In[Problem-1](#_page95_x66.91_y415.17), what is the best wayto merge *all the files* into a single file?

**Solution:** Usingthe Greedyalgorithmwe canreduce the total time for mergingthe givenfiles. Let us consider the followingalgorithm.

**Algorithm:**

1. Store file sizes ina priorityqueue. The keyof elements are file lengths.
1. Repeat the followinguntil there is onlyone file:
1. Extract two smallest elements *X* and *Y.*
1. Merge *X* and *Y*and insert this new file inthe priorityqueue.

**Variant of same algorithm:**

1. Sort the file sizes inascendingorder.
1. Repeat the followinguntil there is onlyone file:
1. Take the first two elements (smallest) *X* and *Y.*
1. Merge *X* and *Y*and insert this new file inthe sorted list.

To checkthe above algorithm, let us trace it withthe previous example. The givenarrayis:

*F =* {10,5,100,50,20,15}

As per the above algorithm, after sorting the list it becomes: {5,10,15,20,50,100}. We need to merge the two smallest files (5 and 10 size files) and as a result we get the following list of files. Inthe list below, 15 indicates the cost of mergingtwo files withsizes 10 and 5.

{15,15,20,50,100}

Similarly, merging the two smallest elements (15 and 15) produces: {20,30,50,100}. For the subsequent steps the list becomes

{50,50,100} // merging20 and 30 {100,100} // merging20 and 30

Finally,

{200}

The total cost of merging= Cost of all mergingoperations = 15 + 30 + 50 + 100 + 200 = 395. So, this algorithmis producingthe optimal solutionfor this mergingproblem.

Time Complexity: O(*nlogn*) time using heaps to find best merging pattern plus the optimal cost of mergingthe files.

**Problem-4  Interval Scheduling Algorithm:** Given a set of *n* intervals S = {(starti, endj)|1 ≤ i

≤ *n*}. Let us assume that we want to find a maximum subset *S*′ of *S* such that no pair of intervals in*S*′ overlaps. Checkwhether the followingalgorithmworks or not.

**Algorithm:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.121.png)

**Solution:** This algorithm does not solve the problem of finding a maximum subset of non- overlapping intervals. Consider the following intervals. The optimal solution is {*M,O,N,K*}. However, the interval that overlaps with the fewest others is *C*, and the given algorithm will select *C* first.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.122.png)

**Problem-5**  In [Problem-4](#_page97_x66.91_y630.20), if we select the interval that starts earliest (also not overlapping

withalreadychosenintervals), does it give the optimal solution?

**Solution: No.** It will not give the optimal solution. Let us consider the example below. It can be seenthat the optimal solutionis 4 whereas the givenalgorithmgives 1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.123.png)

**Problem-6**  In [Problem-4](#_page97_x66.91_y630.20), if we select the shortest interval (but it is not overlapping the

alreadychosenintervals), does it give the optimal solution?

**Solution:** This also will not give the optimal solution. Let us consider the example below. It can be seenthat the optimal solutionis 2 whereas the algorithmgives 1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.124.png)

**Problem-7**  For [Problem-4](#_page97_x66.91_y630.20), what is the optimal solution? **Solution:** Now, let us concentrate onthe optimal greedysolution.

**Algorithm:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.125.png)

Time complexity= Time for sorting+ Time for scanning= O(*nlogn* + *n*) = O(*nlogn*).

**Problem-8**  Consider the followingproblem.

Input: S = {(starti,endi)|1 ≤ i ≤ *n*} of intervals. The interval (starti,endi) we can treat as a

request for a roomfor a class withtime start; to time endi.

Output: Find anassignment of classes to rooms that uses the fewest number of rooms. Consider the following iterative algorithm. Assign as many classes as possible to the first room, then assign as many classes as possible to the second room, then assign as many classes as possible to the third room, etc. Does this algorithmgive the best solution?

**Note:** In fact, this problem is similar to the interval scheduling algorithm. The only difference is the application.

**Solution:** This algorithm does not solve the interval-coloring problem. Consider the following intervals:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.01fe3f42-6301-4580-84c7-2beeb918f794.126.png)

Maximizingthe number of classes inthe first roomresults inhaving{*B, C, F, G*} inone room, and classes *A, D*, and *E* each in their own rooms, for a total of 4. The optimal solution is to put *A* in one room, { *B, C, D* } inanother, and {*E,F, G*} inanother, for a total of 3 rooms.

**Problem-9**  For Problem-8, consider the following algorithm. Process the classes in

increasingorder of start times. Assume that we are processingclass *C*. If there is a room*R* such that *R* has been assigned to an earlier class, and *C* can be assigned to *R* without overlapping previously assigned classes, then assign *C* to *R*. Otherwise, put *C* in a new room. Does this algorithmsolve the problem?

**Solution:** This algorithm solves the interval-coloring problem. Note that if the greedy algorithm creates a new room for the current class *ci*, then because it examines classes in order of start

times, *ci* start point must intersect withthe last class inall of the current rooms. Thus whengreedy

creates the last room, *n*, it is because the start time of the current class intersects with *n* – 1 other classes. But we know that for any single point in any class it can only intersect with at most s other class, so it must then be that *n* ≤ *S*. As s is a lower bound on the total number needed, and greedyis feasible, it is thus also optimal.

**Note:** For optimal solutionrefer to Problem-7 and for code refer to [Problem-10](#_page0_x66.91_y345.32).

**Problem-10**  Suppose we are given two arrays *Start*[1 *..n*] and *Finish*[1 *..n*] listing the start

and finish times of each class. Our task is to choose the largest possible subset *X* ∈ {1,2,...,*n*} so that for anypair *i,j* ∈ *X*, either *Start* [*i*] *> Finish*[*j*] or *Start* [*j*] > *Finish* [*i*]

**Solution:** Our aim is to finish the first class as early as possible, because that leaves us with the most remaining classes. We scan through the classes in order of finish time, and whenever we encounter a class that doesn’t conflict withthe latest class so far, thenwe take that class.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.001.png)

This algorithmclearlyruns inO(*nlogn*) time due to sorting.

**Problem-11**  Consider the making change problem in the country of India. The input to this

problem is an integer *M*. The output should be the minimum number of coins to make *M* rupees of change. In India, assume the available coins are 1,5,10,20,25,50 rupees. Assume that we have anunlimited number of coins of eachtype.

**For this problem, does the following algorithm produce the optimal solution or not?** Take as many coins as possible from the highest denominations. So for example, to make change for 234 rupees the greedy algorithm would take four 50 rupee coins, one 25 rupee coin, one 5 rupee coin, and four 1 rupee coins.

**Solution:** The greedy algorithm is not optimal for the problem of making change with the minimum number of coins when the denominations are 1,5,10,20,25, and 50. In order to make 40 rupees, the greedy algorithm would use three coins of 25,10, and 5 rupees. The optimal solution is to use two 20-shillingcoins.

**Note:** For the optimal solution, refer to the *[Dynamic Programming*](#_page33_x28.00_y82.94)* chapter.

**Problem-12**  Let us assume that we are going for a long drive between cities A and B. In

preparation for our trip, we have downloaded a map that contains the distances in miles betweenall the petrol stations onour route. Assume that our car’s tanks canhold petrol for n miles. Assume that the value n is given. Suppose we stop at every point. Does it give the best solution?

**Solution:** Here the algorithm does not produce optimal solution. Obvious Reason: filling at each petrol stationdoes not produce optimal solution.

**Problem-13**  For problem [Problem-12](#_page1_x66.91_y289.88), stop if and only if you don’t have enough petrol to

make it to the next gas station, and if you stop, fill the tank up all the way. Prove or disprove that this algorithmcorrectlysolves the problem.

**Solution:** The greedy approach works: We start our trip from *A* with a full tank. We check our map to determine the farthest petrol station on our route within *n* miles. We stop at that petrol station, fill up our tank and check our map again to determine the farthest petrol station on our route withinnmiles fromthis stop. Repeat the process until we get to *B.*

**Note:** For code, refer to *[Dynamic Programming*](#_page33_x28.00_y82.94)* chapter.

**Problem-14  Fractional Knapsack problem:** Given items *t*1:*t*2*, ...,tn* (items we might want to

carry in our backpack) with associated weights s1; s2, ... , *sn* and benefit values *vx, v*2*, …, vn*, how can we maximize the total benefit considering that we are subject to an absolute weight limit *C*?

**Solution: Algorithm:**

1) Compute value per size densityfor eachitem![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.002.png).
1) Sort eachitembyits value density.
1) Take as muchas possible of the densityitemnot alreadyinthe bag

Time Complexity: O(*nlogn*) for sortingand O(*n*) for greedyselections.

**Note:** The items can be entered into a priority queue and retrieved one by one until either the bag is full or all items have been selected. This actually has a better runtime of O(*n* + *clogn*) where *c* is the number of items that actuallyget selected inthe solution. There is a savings inruntime if *c* = O(*n*), but otherwise there is no change inthe complexity.

**Problem-15  Number of railway-platforms:** At a railway station, we have a time-table with

the trains’ arrivals and departures. We need to find the minimum number of platforms so that all the trains canbe accommodated as per their schedule.

**Example:** The timetable is as given below, the answer is 3. Otherwise, the railway station will not be able to accommodate all the trains.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.003.png)

**Solution:** Let’s take the same example as described above. Calculating the number of platforms is done bydeterminingthe maximumnumber of trains at the railwaystationat anytime.

First, sort all the arrival(*A*) and departure(*D*) times in an array. Then, save the corresponding arrivals anddepartures inthe arrayalso. After sorting, our arraywill looklike this:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.004.png)

Now modifythe arraybyplacing1 for *A*and -1 for *D*. The new arraywill looklike this:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.005.png)

Finallymake a cumulative arrayout of this:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.006.png)

Our solutionwill be the maximumvalue inthis array. Here it is 3.

**Note:** If we have a train arriving and another departing at the same time, then put the departure time first inthe sorted array.

**Problem-16**  Consider a country with very long roads and houses along the road. Assume that

the residents of all houses use cell phones. We want to place cell phone towers along the road, and each cell phone tower covers a range of 7 kilometers. Create an efficient algorithmthat allow for the fewest cell phone towers.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.007.png)

The algorithmto locate the least number of cell phone towers:

1) Start fromthe beginningof the road
1) Find the first uncovered house onthe road
1) If there is no suchhouse, terminate this algorithm. Otherwise, go to next step
1) Locate a cell phone tower 7 miles awayafter we find this house alongthe road
1) Go to step 2

**Problem-17  Preparing Songs Cassette:** Suppose we have a set of *n* songs and want to store these on a tape. In the future, users will want to read those songs from the tape. Reading a

song from a tape is not like reading from a disk; first we have to fast-forward past all the other songs, and that takes a significant amount of time. Let *A*[1 .. *n*] be an array listing the lengths of each song, specifically, song *i* has length *A*[*i*]. If the songs are stored in order

from1 to n, thenthe cost of accessingthe *kth* songis:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.008.png)

The cost reflects the fact that before we read song *k* we must first scan past all the earlier songs on the tape. If we change the order of the songs on the tape, we change the cost of accessing the songs, with the result that some songs become more expensive to read, but others become cheaper. Different song orders are likely to result in different expected costs. If we assume that each song is equally likely to be accessed, which order should we use if we want the expected cost to be as small as possible?

**Solution:** The answer is simple. We should store the songs in the order from shortest to longest. Storingthe short songs at the beginningreduces the forwardingtimes for the remainingjobs.

**Problem-18**  Let us consider a set of events at *HITEX* (*Hyderabad Convention Center*).

Assume that there are n events where each takes one unit of time. Event *i* will provide a profit of **P** [**i** ] rupees (**P** [**i** ] > 0) if started at or before time *T*[*i*], where *T*[*i*] is anarbitrary number. If an event is not started by *T*[*i*] then there is no benefit in scheduling it at all. All events can start as early as time 0. Give the efficient algorithm to find a schedule that maximizes the profit.

**Solution: Algorithm:**

- Sort the jobs accordingto floor(*T*[*i*]) (sorted fromlargest to smallest).
- Let time *t* be the current time beingconsidered (where initially*t =* floor(*T*[*i*])).
- All jobs *i* where floor(*T*[*i*]) = *t* are inserted into a priority queue with the profit g, used as the key.
- A*DeleteMax* is performed to select the job to runat time *t.*
- Then*t* is decremented and the process is continued.

Clearly the time complexity is O(*nlogn*). The sort takes O(*nlogn*) and there are at most n insert and DeleteMaxoperations performed onthe priorityqueue, eachof whichtakes O(*logn*) time.

**Problem-19**  Let us consider a customer-care server (say, mobile customer-care) with n customers to be served in the queue. For simplicity assume that the service time required

by each customer is known in advance and it is *wt* minutes for customer *i*. So if, for

example, the customers are served in order of increasing *i*, then the *ith* customer has to wait: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.009.png) *minutes*. The total waiting time of all customers can be given as

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.010.png). What is the best way to serve the customers so that the total waiting

time canbe reduced?

**Solution:** This problem can be easily solved using greedy technique. Since our objective is to reduce the total waiting time, what we can do is, select the customer whose service time is less. That means, if we process the customers in the increasing order of service time then we can reduce the total waitingtime.

Time Complexity: O(*nlogn*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.011.png)

1. **Introduction**

Inthe *Greedy* chapter, we have seen that for many problems the Greedy strategy failed to provide optimal solutions. Among those problems, there are some that can be easily solved by using the *Divide and Conquer* (D & *C*) technique. Divide and Conquer is an important algorithm design technique based onrecursion.

The *D* & *C* algorithm works by recursively breaking down a problem into two or more sub problems of the same type, until they become simple enough to be solved directly. The solutions to the sub problems are thencombined to give a solutionto the original problem.

2. **What is Divide and Conquer Strategy?**

The D & C strategysolves a problemby:

1) *Divide:* Breaking the problem into sub problems that are themselves smaller instances of the same type of problem.
2) *Recursion:* Recursivelysolvingthese sub problems.
3) *Conquer:* Appropriatelycombiningtheir answers.

3. **Does Divide and Conquer Always Work?**

It’s not possible to solve all the problems with the Divide & Conquer technique. As per the definition of D & C, the recursion solves the subproblems which are of the same type. For all problems it is not possible to find the subproblems which are the same size and *D* & C is not a choice for all problems.

4. **Divide and Conquer Visualization**

For better understanding, consider the following visualization. Assume that *n* is the size of the original problem. As described above, we can see that the problemis divided into sub problems with each of size *n/b* (for some constant *b*). We solve the sub problems recursively and combine their solutions to get the solutionfor the original problem.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.012.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.013.png)

5. **Understanding Divide and Conquer**

For a clear understandingof D & *C*, let us consider a story. There was anold manwho was a rich farmer and had seven sons. He was afraid that when he died, his land and his possessions would be divided amonghis sevensons, and that theywould quarrel withone another.

So he gathered themtogether and showed themsevensticks that he had tied together and told them that anyone who could break the bundle would inherit everything. They all tried, but no one could break the bundle. Then the old man untied the bundle and broke the sticks one by one. The brothers decided that theyshould staytogether and worktogether and succeed together. The moral for problemsolvers is different. If we can’t solve the problem, divide it into parts, and solve one part at a time.

In earlier chapters we have already solved many problems based on *D* & *C* strategy: like Binary Search, Merge Sort, Quick Sort, etc.... Refer to those topics to get an idea of how *D* & *C* works. Below are a few other real-time problems which can easily be solved with *D* & *C* strategy. For all these problems we canfind the subproblems whichare similar to the original problem.

- Looking for a name in a phone book: We have a phone book with names in alphabetical order. Given a name, how do we find whether that name is there in the phone bookor not?
- Breakinga stone into dust: We want to convert a stone into dust (verysmall stones).
- Finding the exit in a hotel: We are at the end of a very long hotel lobby with a long series of doors, with one door next to us. We are looking for the door that leads to the exit.
- Findingour car ina parkinglot.

6. **Advantages of Divide and Conquer**

**Solving difficult problems:** *D* & *C* is a powerful method for solving difficult problems. As an example, consider the Tower of Hanoi problem. This requires breaking the problem into subproblems, solving the trivial cases and combining the subproblems to solve the original problem. Dividing the probleminto subproblems so that subproblems can be combined again is a major difficulty in designing a new algorithm. For many such problems D & C provides a simple solution.

**Parallelism:** Since *D* & *C* allows us to solve the subproblems independently, this allows for execution in multiprocessor machines, especially shared-memory systems where the communication of data between processors does not need to be planned in advance, because different subproblems canbe executed ondifferent processors.

**Memory access:** *D* & *C* algorithms naturallytend to make efficient use of memorycaches. This is because once a subproblemis small, all its subproblems can be solved within the cache, without

accessingthe slower mainmemory.

7. **Disadvantages of Divide and Conquer**

One disadvantage of the *D* & *C* approach is that recursion is slow. This is because of the overhead of the repeated subproblemcalls. Also, the *D* & *C* approach needs stack for storing the calls (the state at each point in the recursion). Actually this depends upon the implementation style. With large enough recursive base cases, the overhead of recursion can become negligible for manyproblems.

Another problem with *D* & *C* is that, for some problems, it may be more complicated than an iterative approach. For example, to add *n* numbers, a simple loop to add them up in sequence is much easier than a *D* & *C* approach that breaks the set of numbers into two halves, adds them recursively, and thenadds the sums.

8. **Master Theorem**

As stated above, in the *D* & *C* method, we solve the sub problems recursively. All problems are generally defined in terms of recursive definitions. These recursive problems can easily be solved usingMaster theorem. For details onMaster theorem, refer to the *Introduction to Analysis of Algorithms* chapter. Just for continuity, let us reconsider the Master theorem.

If the recurrence is of the form![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.014.png), where *a* ≥ 1, *b >* 1, *k* ≥ 0 and p is a real number, thenthe complexitycanbe directlygivenas:

1) If *a > bk*, then![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.015.png)
1) If *a* = *bk*

1. If *p* > –1, then![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.016.png)
1. If *p* = –1, then![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.017.png)
1. If *p* < –1, then![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.018.png)

3) If *a* < *bk*

1. If *p* > 0, then*T*(*n*) = Θ(*nklogpn*)
2. If *p* < 0, then*T*(*n*) = O(*nk*)
3. **Divide and Conquer Applications**

- BinarySearch
- Merge Sort and QuickSort
- MedianFinding
- Minand MaxFinding
- MatrixMultiplication
- Closest Pair problem

10. **Divide and Conquer: Problems & Solutions**

**Problem-1**  Let us consider an algorithm*A* which solves problems by dividing theminto five

subproblems of half the size, recursively solving each subproblem, and then combining the solutions inlinear time. What is the complexityof this algorithm?

**Solution:** Let us assume that the input size is *n* and *T*(*n*) defines the solution to the given problem. As per the description, the algorithmdivides the probleminto 5 sub problems witheachof size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.019.png)

- So we need to solve ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.020.png) subproblems. After solving these sub problems, the given array (linear time) is scanned to combine these solutions. The total recurrence algorithm for this

problemcan be given as: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.021.png). Using the Master theorem(of D & C), we

get the complexity![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.022.png).

**Problem-2**  Similar to [Problem-1](#_page9_x66.91_y163.06), an algorithm *B* solves problems of size n by recursively

solving two subproblems of size *n* – 1 and then combining the solutions in constant time. What is the complexityof this algorithm?

**Solution:** Let us assume that the input size is n and *T*(*n*) defines the solution to the given problem. As per the description of algorithm we divide the problem into 2 sub problems with each of size *n* – 1. So we have to solve 2T(*n* – 1) sub problems. After solving these sub problems, the algorithmtakes onlya constant time to combine these solutions. The total recurrence algorithmfor this problemcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.023.png)

Using Master theorem (of *Subtract and Conquer*), we get the complexity as ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.024.png). (Refer to *Introduction* chapter for more details).

**Problem-3**  Again similar to [Problem-1](#_page9_x66.91_y163.06), another algorithm *C* solves problems of size *n* by dividing them into nine subproblems of size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.025.png), recursively solving each subproblem, and

thencombiningthe solutions inO(*n*2) time. What is the complexityof this algorithm?

**Solution:** Let us assume that input size is n and *T*(*n*) defines the solution to the given problem. As per the description of algorithm we divide the problem into 9 sub problems with each of size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.025.png).

So we need to solve ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.026.png) sub problems. After solving the sub problems, the algorithm takes quadratic time to combine these solutions. The total recurrence algorithmfor this problemcan be given as: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.027.png). Using *D* & *C* Master theorem, we get the complexity

as O(*n*2*logn*).

**Problem-4**  Write a recurrence and solve it.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.028.png)

**Solution:** Let us assume that input size is *n* and *T*(*n*) defines the solution to the given problem. As per the given code, after printing the character and dividing the probleminto 2 subproblems with

each of size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.019.png) and solving them. So we need to solve ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.029.png) subproblems. After solving these

subproblems, the algorithmis not doing anything for combining the solutions. The total recurrence algorithmfor this problemcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.030.png)

UsingMaster theorem(of D & C), we get the complexityas ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.031.png).

**Problem-5**  Givenanarray, give analgorithmfor findingthe maximumand minimum. **Solution:** Refer *Selection Algorithms* chapter.

**Problem-6**  Discuss BinarySearchand its complexity. **Solution:** Refer *Searching* chapter for discussiononBinarySearch.

**Analysis:** Let us assume that input size is n and *T*(*n*) defines the solution to the given problem. The elements are in sorted order. In binary search we take the middle element and check whether the element to be searched is equal to that element or not. If it is equal thenwe returnthat element.

If the element to be searched is greater than the middle element then we consider the right sub- array for finding the element and discard the left sub-array. Similarly, if the element to be searched is less than the middle element then we consider the left sub-array for finding the element and discard the right sub-array.

What this means is, in both the cases we are discarding half of the sub-array and considering the

remaininghalf only. Also, at everyiterationwe are dividingthe elements into two equal halves.

As per the above discussion every time we divide the problem into 2 sub problems with each of size ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.019.png) and solve one ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.032.png) sub problem. The total recurrence algorithm for this problem can be

givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.033.png)

UsingMaster theorem(of D & C), we get the complexityas O(*logn*).

**Problem-7**  Consider the modified version of binary search. Let us assume that the array is

divided into 3 equal parts (ternary search) instead of 2 equal parts. Write the recurrence for this ternarysearchand find its complexity.

**Solution:** From the discussion on [Problem-5](#_page10_x66.91_y476.28), binary search has the recurrence relation: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.034.png). Similar to the [Problem-5](#_page10_x66.91_y476.28) discussion, instead of 2 in the recurrence

relation we use “3”. That indicates that we are dividing the array into 3 sub-arrays with equal size and consideringonlyone of them. So, the recurrence for the ternarysearchcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.035.png)

UsingMaster theorem(of *D* & *C*), we get the complexity as ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.036.png) *≈* O(*logn*) (we don’t have to worryabout the base of *log* as theyare constants).

**Problem-8**  In [Problem-5](#_page10_x66.91_y476.28), what if we divide the array into two sets of sizes approximately

one-third and two-thirds.

**Solution:** We now consider a slightly modified version of ternary search in which only one comparison is made, which creates two partitions, one of roughly ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.025.png) elements and the other of ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.037.png).

Here the worst case comes when the recursive call is on the larger ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.037.png) element part. So the recurrence correspondingto this worst case is:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.038.png)

Using Master theorem (of D & C), we get the complexity as O(*logn*). It is interesting to note that we will get the same results for general *k*-ary search (as long as *k* is a fixed constant which does not depend on*n*) as *n* approaches infinity.

**Problem-9**  Discuss Merge Sort and its complexity.

**Solution:** Refer to *Sorting* chapter for discussion on Merge Sort. In Merge Sort, if the number of elements are greater than 1, then divide them into two equal subsets, the algorithm is recursively invoked on the subsets, and the returned sorted subsets are merged to provide a sorted list of the original set. The recurrence equationof the Merge Sort algorithmis:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.039.png)

If we solve this recurrence usingD & C Master theoremit gives O(nlogn) complexity. **Problem-10**  Discuss QuickSort and its complexity.

**Solution:** Refer to *Sorting* chapter for discussion on Quick Sort. For Quick Sort we have different complexities for best case and worst case.

**Best Case:** In *Quick Sort*, if the number of elements is greater than 1 then they are divided into two equal subsets, and the algorithm is recursively invoked on the subsets. After solving the sub problems we don’t need to combine them. This is because in *Quick Sort* they are already in sorted order. But, we need to scanthe complete elements to partitionthe elements. The recurrence equation*of Quick Sort* best case is

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.040.png)

If we solve this recurrence usingMaster theoremof D & C gives O(*nlogn*) complexity.

**Worst Case:** In the worst case, Quick Sort divides the input elements into two sets and one of them contains only one element. That means other set has *n* – 1 elements to be sorted. Let us assume that the input size is *n* and *T*(*n*) defines the solution to the given problem. So we need to solve *T*(*n –* 1), *T*(1) subproblems. But to divide the input into two sets Quick Sort needs one scan of the input elements (this takes O(*n*)).

After solving these sub problems the algorithm takes only a constant time to combine these solutions. The total recurrence algorithmfor this problemcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.041.png)

This is clearlya summationrecurrence equation. So, ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.042.png). **Note:** For the average case analysis, refer to *Sorting* chapter.

**Problem-11**  Given an infinite array in which the first *n* cells contain integers in sorted order

and the rest of the cells are filled with some special symbol (say, $). Assume we do not know the n value. Give an algorithmthat takes an integer *K* as input and finds a position in the arraycontaining*K*, if sucha positionexists, inO(*logn*) time.

**Solution:** Since we need an O(*logn*) algorithm, we should not search for all the elements of the given list (which gives O(*n*) complexity). To get O(*logn*) complexity one possibility is to use binary search. But in the given scenario we cannot use binary search as we do not know the end of the list. Our first problem is to find the end of the list. To do that, we can start at the first element and keep searching with doubled index. That means we first search at index 1 then, 2,4,8 ...

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.043.png)

It is clear that, once we have identified a possible interval *A*[*i*,...,2*i*] in which *K* might be, its length is at most n (since we have only n numbers in the array *A*), so searching for *K* using binary searchtakes O(*logn*) time.

**Problem-12**  Givena sorted arrayof non-repeated integers *A*[1.. *n*], check whether there is an

index*i* for which*A*[*i*] *= i*. Give a divide-and-conquer algorithmthat runs intime O(*logn*).

**Solution:** We can’t use binarysearchonthe arrayas it is. If we want to keep the O(*logn*) property of the solution we have to implement our own binary search. If we modify the array (in place or ina copy) and subtract *i* fromA[i], we can then use binary search. The complexity for doing so is O(*n*).

**Problem-13**  We are giventwo sorted lists of size *n*. Give analgorithmfor findingthe median

element inthe unionof the two lists.

**Solution:** We use the Merge Sort process. Use *merge* procedure of merge sort (refer to *Sorting* chapter). Keep track of the count while comparing elements of two arrays. If the count becomes *n* (since there are 2*n* elements), we have reached the median. Take the average of the elements at indexes *n* – 1 and *n* inthe merged array.

Time Complexity: O(*n*).

**Problem-14**  Canwe give the algorithmif the size of the two lists are not the same?

**Solution:** The solution is similar to the previous problem. Let us assume that the lengths of two lists are mand *n*. Inthis case we need to stop whenthe counter reaches (*m* + *n*)/2.

Time Complexity: O((*m* + *n*)/2).

**Problem-15**  Canwe improve the time complexityof [Problem-13](#_page13_x66.91_y577.99) to O(*logn*)?

**Solution: Yes,** usingthe D & C approach. Let us assume that the giventwo lists are *L*1 and *L*2.

**Algorithm:**

1. Find the medians of the given sorted input arrays *L*1[] and *L*2[]. Assume that those medians are *m*1 and *m*2.
1. If *m*1 and *m*2 are equal thenreturn*m*1 (or *m*2).
1. If *m*1 is greater than*m*2, thenthe final medianwill be below two sub arrays.
1. Fromfirst element of *L*1 to *m*1.
1. From*m*2 to last element of *L*2.
1. If *m*2 is greater than*m*1, thenmedianis present inone of the two sub arrays below.
1. From*m*1 to last element of *L*1.
1. Fromfirst element of *L*2 to *m*2.
1. Repeat the above process until the size of boththe sub arrays becomes 2.
1. If size of the two arrays is 2, thenuse the formula below to get the median.
1. Median= (*max*(*L*1[0],*L*2[0]) + *min*(*L*1[1],*L*2[1])/2

Time Complexity: O(*logn*) since we are considering only half of the input and throwing the remaininghalf.

**Problem-16**  Given an input array *A*. Let us assume that there can be duplicates in the list.

Now search for an element in the list in such a way that we get the highest index if there are duplicates.

**Solution:** Refer to *Searching* chapter.

**Problem-17**  Discuss Strassen’s Matrix Multiplication Algorithm using Divide and Conquer.

That means, giventwo *n* × *n* matrices, *A*and *B*, compute the *n* × *n* matrix*C = A*× *B*, where the elements of *C* are givenby

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.044.png)

**Solution:** Before Strassen’s algorithm, first let us see the basic divide and conquer algorithm. The general approach we follow for solving this problem is given below. To determine, *C*[*i,j*] we

need to multiplythe *ith* row of *A*with*jth* columnof *B.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.045.png)

The matrix multiplication problemcan be solved with the D & C technique. To implement a D & C algorithm we need to break the given problem into several subproblems that are similar to the original one. Inthis instance we view eachof the *n* × *n* matrices as a 2 × 2 matrix, the elements of

whichare ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.046.png) submatrices. So, the original matrixmultiplication, *C = A*× *B* canbe writtenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.047.png)

Fromthe givendefinitiono f *Ci*,*j*, we get that the result sub matrices canbe computed as follows:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.048.png)

Here the symbols + and × are taken to mean addition and multiplication (respectively) of ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.046.png) matrices.

In order to compute the original *n* × *n* matrix multiplication we must compute eight ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.046.png) matrix products (*divide*) followed by four ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.046.png) matrix sums (*conquer*). Since matrix addition is an O(*n*2) operation, the total runningtime for the multiplicationoperationis givenbythe recurrence:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.049.png)

Usingmaster theorem, we get *T*(*n*) = O(*n*3).

Fortunately, it turns out that one of the eight matrix multiplications is redundant (found by Strassen). Consider the followingseries of seven![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.046.png) matrices:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.050.png)

Each equation above has only one multiplication. Ten additions and seven multiplications are required to compute *M*0 through *M*6. Given *M*0 through *M*6, we can compute the elements of the

product matrix*C* as follows:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.051.png)

This approach requires seven ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.046.png) matrix multiplications and 18 ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.046.png) additions. Therefore, the worst-case runningtime is givenbythe followingrecurrence:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.052.png)

Usingmaster theorem, we get, ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.053.png).

**Problem-18  Stock Pricing Problem:** Consider the stock price of *[CareerMonk.com*](http://CareerMonk.com)* in *n*

consecutive days. That means the input consists of an array with stock prices of the company. We know that the stock price will not be the same on all the days. In the input stock prices there may be dates where the stock is high when we can sell the current holdings, and there may be days when we can buy the stock. Now our problem is to find the day on which we can buy the stock and the day on which we can sell the stock so that we canmake maximumprofit.

**Solution:** As given in the problem, let us assume that the input is an array with stock prices [integers]. Let us say the given array is *A*[1],...,*A*[*n*]. From this array we have to find two days [one for buy and one for sel1] in such a way that we can make maximum profit. Also, another point to make is that the buy date should be before sell date. One simple approachis to look at all possible buyand sell dates.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.054.png)

The two nested loops take *n*(*n* + l)/2 computations, so this takes time Θ(*n*2). **Problem-19**  For [Problem-18](#_page16_x66.91_y502.72), canwe improve the time complexity?

**Solution: Yes,** by opting for the Divide-and-Conquer Θ(*nlogn*) solution. Divide the input list into two parts and recursivelyfind the solutioninboththe parts. Here, we get three cases:

- *buyDatelndex* and *sellDatelndex* bothare inthe earlier time period.
- *buyDatelndex* and *sellDatelndex* bothare inthe later time period.
- *buyDatelndex* is in the earlier part and *sellDatelndex* is in the later part of the time period.

The first two cases can be solved with recursion. The third case needs care. This is because *buyDatelndex* is one side and *sellDatelndex* is on other side. In this case we need to find the minimumand maximumprices inthe two sub-parts and this we cansolve inlinear-time.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.055.png)

Algorithm*StockStrategy* is used recursively on two problems of half the size of the input, and in addition Θ(*n*) time is spent searching for the maximum and minimum prices. So the time complexity is characterized by the recurrence *T*(*n*) = 2*T*(*n/*2) *+* Θ(*n*) and by the Master theorem we get O(*n*logn).

**Problem-20**  We are testing “unbreakable” laptops and our goal is to find out how

unbreakable they really are. In particular, we work in an n-story building and want to find out the lowest floor from which we can drop the laptop without breaking it (call this “the ceiling”). Suppose we are given two laptops and want to find the highest ceiling possible. Give an algorithmthat minimizes the number of tries we need to make *f*(*n*) (hopefully, *f*(*n*) is sub-linear, as a linear *f*(*n*) yields a trivial solution).

**Solution:** For the given problem, we cannot use binary search as we cannot divide the problem and solve it recursively. Let us take an example for understanding the scenario. Let us say 14 is the answer. That means we need 14 drops to find the answer. First we drop fromheight 14, and if it breaks we try all floors from 1 to 13. If it doesn’t break then we are left 13 drops, so we will

drop it from14 + 13 + 1 = 28*th* floor. The reason being if it breaks at the 28*th* floor we can try all the floors from 15 to 27 in 12 drops (total of 14 drops). If it did not break, then we are left with 11 drops and we cantryto figure out the floor in14 drops.

From the above example, it can be seen that we first tried with a gap of 14 floors, and then followed by 13 floors, then 12 and so on. So if the answer is *k* then we are trying the intervals at *k, k* – 1, *k –* 2 ....1. Given that the number of floors is *n*, we have to relate these two. Since the maximumfloor fromwhichwe cantryis *n*, the total skips should be less thann. This gives:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.056.png)

Complexityof this process is ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.057.png).

**Problem-21**  Givennnumbers, checkif anytwo are equal.

**Solution:** Refer to *Searching* chapter.

**Problem-22**  Give analgorithmto find out if aninteger is a square? E.g. 16 is, 15 isn’t.

**Solution:** Initially let us say *i =* 2. Compute the value *i* × *i* and see if it is equal to the given number. If it is equal then we are done; otherwise increment the **i** vlaue. Continue this process until we reach*i* × *i* greater thanor equal to the givennumber.

Time Complexity: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.057.png). Space Complexity: O(1).

**Problem-23**  Given an array of 2*n* integers in the following format *a*1 *a*2 *a*3 *...an b*1 *b*2 *b*3

*...bn*. Shuffle the arrayto *a*1 *b*1 *a*2 *b*2 *a*3 *b*3 *... an bn* without anyextra memory[MA].

**Solution:** Let us take anexample (for brute force solutionrefer to *Searching* chapter)

1. Start withthe array: *a*1 *a*2 *a*3 *a*4 *b*1 *b*2 *b*3 *b*4
1. Split the arrayinto two halves: *a*1 *a*2 *a*3 *a*4 : *b*1 *b*2 *b*3 *b*4
1. Exchange elements around the center: exchange *a*3 *a*4 with *b*1 *b*2 you get: *a*1 *a*2 *b*1 *b*2 *a*3 *a*4 *b*3 *b*4
1. Split *a*1 *a*2 *b*1 *b*2 into *a*1 *a*2 : *b*1 *b*2 thensplit *a*3 *a*4 *b*3 *b*4 into *a*3 *a*4 : *b*3 *b*4
1. Exchange elements around the center for each subarray you get: *a*1 *b*1 *a*2 *b*2 and *a*3 *b*3 *a*4 *b*4

Please note that this solution only handles the case when *n =* 2*i* where *i =* 0,1,2,3, etc. In our example *n* = 22 = 4 which makes it easy to recursively split the array into two halves. The basic idea behind swapping elements around the center before calling the recursive function is to produce smaller size problems. A solution with linear time complexity may be achieved if the elements are of a specific nature. For example you can calculate the new position of the element usingthe value of the element itself. This is a hashingtechnique.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.058.png)

Time Complexity: O(*nlogn*).

**Problem-24  Nuts and Bolts Problem:** Given a set of *n* nuts of different sizes and *n* bolts

suchthat there is a one-to-one correspondence betweenthe nuts and the bolts, find for each nut its correspondingbolt. Assume that we canonlycompare nuts to bolts (cannot compare nuts to nuts and bolts to bolts).

**Solution:** Refer to *Sorting* chapter.

**Problem-25  Maximum Value Contiguous Subsequence:** Given a sequence of *n* numbers

*A*(1) *...A*(*n*), give an algorithm for finding a contiguous subsequence *A*(*i*) *...A*(*j*) for which the sum of elements in the subsequence is maximum. **Example** : {-2, **11, -4, 13**, -5, 2} → 20 and {1, -3, **4, -2, -1, 6** } → 7.

**Solution:** Divide this input into two halves. The maximumcontiguous subsequence sumcan occur inone of 3 ways:

- Case 1: It canbe completelyinthe first half
- Case 2: It canbe completelyinthe second half
- Case 3: It begins inthe first half and ends inthe second half

We begin by looking at case 3. To avoid the nested loop that results from considering all *n*/2 starting points and *n*/2 ending points independently, replace two nested loops with two consecutive loops. The consecutive loops, each of size *n*/2, combine to require only linear work. Any contiguous subsequence that begins in the first half and ends in the second half must include both the last element of the first half and the first element of the second half. What we can do in cases 1 and 2 is apply the same strategy of dividing into more halves. In summary, we do the following:

1. Recursivelycompute the maximumcontiguous subsequence that resides entirelyinthe first half.
1. Recursivelycompute the maximumcontiguous subsequence that resides entirelyinthe

second half.

3. Compute, via two consecutive loops, the maximum contiguous subsequence sum that begins inthe first half but ends inthe second half.
3. Choose the largest of the three sums.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.059.jpeg)

The base case cost is 1. The programperforms two recursive calls plus the linear work involved incomputingthe maximumsumfor case 3. The recurrence relationis:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.060.png)

Using*D* & *C* Master theorem, we get the time complexityas *T*(*n*) = O(*nlogn*). **Note:** For anefficient solutionrefer to the *[Dynamic Programming*](#_page5_x28.00_y82.94)* chapter.

**Problem-26  Closest-Pairof Points:** Givena set of npoints, *S* = {p1,p2,p3*,…,*pn}, where pi =

(xi,yi). Find the pair of points having the smallest distance among all pairs (assume that all points are inone dimension).

**Solution:** Let us assume that we have sorted the points. Since the points are in one dimension, all the points are in a line after we sort them (either on *X*-axis or *Y*-axis). The complexity of sorting is O(*nlogn*). After sorting we can go through them to find the consecutive points with the least difference. So the problem in one dimension is solved in O(*nlogn*) time which is mainly dominated bysortingtime.

Time Complexity: O(*nlogn*).

**Problem-27**  For [Problem-26](#_page21_x66.91_y689.92), how do we solve it if the points are intwo-dimensional space? **Solution:** Before goingto the algorithm, let us consider the followingmathematical equation:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.061.png)

The above equationcalculates the distance betweentwo points *p*1 = (*x*1,*y*1) and *p*2 = (*x*2,*y*2).

**Brute Force Solution:**

- Calculate the distances between all the pairs of points. From *n* points there are ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.062.png) ways of selecting2 points. ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.063.png).
- After finding distances for all *n*2 possibilities, we select the one which is giving the minimumdistance and this takes O(*n*2).

The overall time complexityis O(*n*2).

**Problem-28**  Give O(*nlogn*) solutionfor *closest pair* problem(Problem-27)?

**Solution:** To find O(*nlogn*) solution, we can use the D & C technique. Before starting the divide- and-conquer process let us assume that the points are sorted by increasing *x*-coordinate. Divide the points into two equal halves based on median of *x-*coordinates. That means the problem is divided into that of finding the closest pair in each of the two halves. For simplicity let us consider the followingalgorithmto understand the process.

**Algorithm:**

1) Sort the given points in *S* (given set of points) based on their *x* –coordinates. Partition *S* into two subsets, *S*1 and *S*2, about the line *l* through median of *S*. This

step is the *Divide* part of the *D* & *C* technique.

2) Find the closest-pairs in*S*1 andS2 and call them*L* and *R* recursively.
2) Now, steps 4 to 8 formthe Combiningcomponent of the *D* & *C* technique.
2) Let us assume that *δ = min* (*L,R*).
2) Eliminate points that are farther than*δ* apart from*l.*
2) Consider the remainingpoints and sort based ontheir *y*-coordinates.
2) Scan the remaining points in the *y* order and compute the distances of each point to all its neighbors that are distanced no more than 2 × *δ* (that’s the reason for sorting

accordingto *y*).

8) If anyof these distances is less than*δ* thenupdate *δ.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.064.jpeg)

**Combining the results inlineartime**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.065.jpeg)

Let *δ = min*(*L,R*), where Lis the solution to first sub problemand R is the solution to second sub problem. The possible candidates for closest-pair, which are across the dividing line, are those whichare less thanδ distance fromthe line. So we need onlythe points whichare inside the 2 × *δ* area across the dividing line as shown in the figure. Now, to check all points within distance δ fromthe line, consider the followingfigure.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.066.jpeg)

Fromthe above diagramwe can see that a maximumof 12 points can be placed inside the square with a distance not less than *δ*. That means, we need to check only the distances which are within 11 positions in the sorted list. This is similar to the one above, but with the difference that in the above combining of subproblems, there are no vertical bounds. So we can apply the 12-point box tactic over all the possible boxes in the 2 × *δ* area with the dividing line as the middle line. As there can be a maximum of *n* such boxes in the area, the total time for finding the closest pair in the corridor is O(*n*).

**Analysis:**

1) Step-1 and Step-2 take O(*nlogn*) for sortingand recursivelyfindingthe minimum.
1) Step-4 takes O(1).
1) Step-5 takes O(*n*) for scanningand eliminating.
1) Step-6 takes O(*nlogn*) for sorting.
1) Step-7 takes O(*n*) for scanning.

The total complexity: *T*(*n*) = O(*nlogn*) + O(1) + O(*n*) + O(*n*) + O(*n*) *≈* O(*nlogn*). **Problem-29**  To calculate *kn*, give algorithmand discuss its complexity.

**Solution:** The naive algorithm to compute *kn* is: start with 1 and multiply by *k* until reaching *kn*. For this approach; there are *n* – 1 multiplications and each takes constant time giving a Θ(*n*) algorithm.

But there is a faster wayto compute *kn*. For example,

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.067.png)

Note that takingthe square of a number needs onlyone multiplication; this way, to compute 924 we need only5 multiplications instead of 23.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.068.png)

Let T(*n*) be the number of multiplications required to compute *kn*. For simplicity, assume *k =* 2*i* for some *i* ≥ 1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.069.png)

Usingmaster theoremwe get T(*n*) = O(*logn*).

**Problem-30  The Skyline Problem:** Given the exact locations and shapes of *n* rectangular buildings in a 2-dimensional city. There is no particular order for these rectangular buildings. Assume that the bottom of all buildings lie on a fixed horizontal line (bottom

edges are collinear). The input is a list of triples; one per building. A building *Bi* is

represented by the triple (*li, hi, ri*) where *li* denote the *x*-position of the left edge and *ri* denote the *x*-position of the right edge, and *hi* denotes the building’s height. Give an

algorithm that computes the skyline (in 2 dimensions) of these buildings, eliminating hidden lines. In the diagram below there are 8 buildings, represented from left to right by the triplets (1, 14, 7), (3, 9, 10), (5, 17, 12), (14, 11, 18), (15, 6, 27), (20, 19, 22), (23, 15, 30) and (26, 14, 29).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.070.jpeg)

The output is a collection of points which describe the path of the skyline. In some versions of the problemthis collection of points is represented by a sequence of numbers *p*1; *p*2, ..., *pn*, such that

the point *pi* represents a horizontal line drawn at height *pi* if *i* is even, and it represents a vertical line drawn at position *pi* if *i* is odd. In our case the collection of points will be a sequence of *p*1*, p*2, ..., *pn* pairs of (*xi, hi*) where *pi*(*xi, hi*) represents the *hi* height of the skyline at position*xi*. In the

diagramabove the skyline is drawn with a thick line around the buildings and it is represented by the sequence of position-height pairs (1, 14), (5, 17), (12, 0), (14, 11), (18, 6), (20, 19), (22, 6), (23, 15) and (30, 0). Also, assume that *Ri* of the right most building can be maximum of 1000.

That means, the *Li* co-ordinate of left building can be minimum of 1 and *Ri* of the right most buildingcanbe maximumof 1000.

**Solution:** The most important piece of information is that we know that the left and right coordinates of each and every building are non-negative integers less than 1000. Now why is this important? Because we can assign a height-value to every distinct *xi* coordinate where *i* is

between0 and 9,999.

**Algorithm:**

- Allocate an array for 1000 elements and initialize all of the elements to 0. Let’s call this array*auxHeights.*
- Iterate over all of the buildings and for every *Bi* building iterate on the range of [*li*.. *ri*) where *li* is the left, *ri* is the right coordinate of the building*Bi.*
- For every*xj* element of this range checkif *hi>auxHeights*[xj], that is if building*Bi* is taller than the current height-value at position *xj*. If so, replace *auxHeights*[*xj*] with *hi.*

Once we checked all the buildings, the *auxHeights* array stores the heights of the tallest buildings at every position. There is one more thing to do: convert the *auxHeights* array to the expected output format, that is to a sequence of position-height pairs. It’s also easy: just map each and every*i* indexto an(i, *auxHeights*[i]) pair.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.071.jpeg)

Let’s have a look at the time complexity of this algorithm. Assume that, *n* indicates the number of buildings in the input sequence and *m* indicates the maximum coordinate (right most building *ri*).

Fromthe above code, it is clear that for every new input building, we are traversing from*left* (*li*) to *right* (*ri*) to update the heights. In the worst case, with *n* equal-size buildings, each having *l* = 0 left and *r* = *m* – 1 right coordinates, that is every building spans over the whole [0.. *m*) interval.

Thus the running time of setting the height of every position is O(*n* × *m*). The overall time- complexityis O(*n* × *m*), whichis a lot larger thanO(*n*2) if *m* > *n*.

**Problem-31**  Canwe improve the solutionof the [Problem-30](#_page26_x66.91_y481.01)?

**Solution:** It would be a huge speed-up if somehow we could determine the skyline by calculating the height for those coordinates only where it matters, wouldn’t it? Intuition tells us that if we can insert a building into an *existing skyline* then instead of all the coordinates the building spans over we only need to check the height at the left and right coordinates of the building plus those coordinates of the skyline the buildingoverlaps withand maymodify.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.072.jpeg)

Is merging two skylines substantially different from merging a building with a skyline? The answer is, of course, No. This suggests that we use divide-and-conquer. Divide the input of n buildings into two equal sets. Compute (recursively) the skyline for each set then merge the two skylines. Inserting the buildings one after the other is not the fastest way to solve this problem as we’ve seen it above. If, however, we first merge pairs of buildings into skylines, then we merge pairs of these skylines into bigger skylines (and not two sets of buildings), and then merge pairs of these bigger skylines into even bigger ones, then - since the problem size is halved in every step -after *logn* steps we cancompute the final skyline.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.073.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.074.jpeg) For example, given two skylines A=(*a*1, h*a*1, *a*2, h*a*2, ..., *an*, 0) and B=(*b*1, h*b*1, *b*2, h*b*2, ..., *bm*, 0), we merge these lists as the new list: (*c*1, h*c*1, *c*2, h*c*2*, ..., cn+m*, 0). Clearly, we merge the list of *a’s*

and *b’s* just like inthe standard Merge algorithm. But, inadditionto that, we have to decide onthe correct height in between these boundary values. We use two variables *currentHeight*1 and *currentHeight*2 (*n*ote that these are the heights prior to encounteringthe heads of the lists) to store the current height of the first and the second skyline, respectively. When comparing the head entries (*currentHeight*1*, currentHeight*2) of the two skylines, we introduce a new strip (and append to the output skyline) whose x-coordinate is the minimumof the entries’ x-coordinates and whose height is the maximum of *currentHeight*1 and *currentHeight*2. This algorithm has a structure similar to Mergesort. So the overall running time of the divide and conquer approach will be O(*nlogn*).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.075.png)

1. **Introduction**

In this chapter we will try to solve the problems for which we failed to get the optimal solutions using other techniques (say, *Divide* & *Conquer* and *Greedy* methods). Dynamic Programming (DP) is a simple technique but it canbe difficult to master. One easywayto identifyand solve DP problems is by solving as many problems as possible. The term *Programming* is not related to codingbut it is fromliterature, and means fillingtables (similar to *Linear Programming*).

2. **What is Dynamic Programming Strategy?**

Dynamic programming and memoization work together. The main difference between dynamic programming and divide and conquer is that in the case of the latter, sub problems are independent, whereas in DP there can be an overlap of sub problems. By using memoization [maintaining a table of sub problems already solved], dynamic programming reduces the

exponential complexity to polynomial complexity (O(*n*2), O(*n*3), etc.) for many problems. The major components of DPare:

- Recursion: Solves sub problems recursively.
- Memoization: Stores already computed values in table (*Memoization* means caching).

*Dynamic Programming = Recursion + Memoization*

3. **Properties of Dynamic Programming Strategy**

The two dynamic programming properties which can tell whether it can solve the given problem or not are:

- *Optimal substructure:* an optimal solution to a problem contains optimal solutions to sub problems.
- *Overlapping sub problems:* a recursive solution contains a small number of distinct sub problems repeated manytimes.

4. **Can Dynamic Programming Solve AllProblems?**

Like Greedy and Divide and Conquer techniques, DP cannot solve every problem. There are problems which cannot be solved by any algorithmic technique [Greedy, Divide and Conquer and Dynamic Programming].

The difference between Dynamic Programming and straightforward recursion is in memoization of recursive calls. If the sub problems are independent and there is no repetitionthenmemoization does not help, so dynamic programmingis not a solutionfor all problems.

5. **Dynamic Programming Approaches**

Basicallythere are two approaches for solvingDPproblems:

- Bottom-up dynamic programming
- Top-downdynamic programming

**Bottom-up Dynamic Programming**

In this method, we evaluate the function starting with the smallest possible input argument value and then we step through possible values, slowly increasing the input argument value. While computing the values we store all computed values in a table (memory). As larger arguments are evaluated, pre-computed values for smaller arguments canbe used.

**Top-down Dynamic Programming**

In this method, the problem is broken into sub problems; each of these sub problems is solved; and the solutions remembered, in case they need to be solved. Also, we save each computed value as the final actionof the recursive function, and as the first actionwe checkif pre-computed value exists.

**Bottom-up versus Top-down Programming**

In bottom-up programming, the programmer has to select values to calculate and decide the order of calculation. In this case, all sub problems that might be needed are solved in advance and then used to build up solutions to larger problems. In top-down programming, the recursive structure of the original code is preserved, but unnecessary recalculation is avoided. The problem is broken into sub problems, these sub problems are solved and the solutions remembered, in case theyneed to be solved again.

**Note:** Some problems can be solved with both the techniques and we will see examples in the next section.

6. **Examples of Dynamic Programming Algorithms**

- Many string algorithms including longest common subsequence, longest increasing subsequence, longest commonsubstring, edit distance.
- Algorithms on graphs can be solved efficiently: Bellman-Ford algorithm for finding the shortest distance ina graph, Floyd’s All-Pairs shortest pathalgorithm, etc.
- Chainmatrixmultiplication
- Subset Sum
- 0/1 Knapsack
- Travellingsalesmanproblem, and manymore

7. **Understanding Dynamic Programming**

Before goingto problems, let us understand how DPworks throughexamples.

**FibonacciSeries**

In Fibonacci series, the current number is the sumof previous two numbers. The Fibonacci series is defined as follows:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.076.png)

The recursive implementationcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.077.png)

Solvingthe above recurrence gives:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.078.png)

**Note:** For proof, refer to *Introduction* chapter.

**How does Memoizationhelp?**

Calling*fib*(5) produces a call tree that calls the functiononthe same value manytimes:

*fib*(5)

*fib*(4) *+ fib*(3)

(*fib*(3) *+ fib*(2)) *+* (*fib*(2) *+ fib*(1))

((*fib*(2) *+ fib*(1)) *+* (*fib*(1) *+ fib*(0))) *+* ((*fib*(1) *+ fib*(0)) *+ fib*(1))

(((*fib*(1) + *fib*(0)) *+ fib*(1)) *+* (*fib*(1) *+ fib*(0))) *+* ((*fib*(1) *+ fib*(0)) + *fib*(1))

In the above example, *fib*(2) was calculated three times (overlapping of subproblems). If n is big, thenmany more values of *fib* (sub problems) are recalculated, which leads to an exponential time algorithm. Instead of solving the same sub problems again and again we can store the previous calculated values and reduce the complexity.

*Memoization* works like this: Start with a recursive function and add a table that maps the function’s parameter values to the results computed by the function. Then if this function is called twice withthe same parameters, we simplylookup the answer inthe table.

**Improving:** Now, we see how DP reduces this problem complexity from exponential to polynomial. As discussed earlier, there are two ways of doing this. One approach is bottom-up: these methods start withlower values of input and keep buildingthe solutions for higher values.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.079.png)

The other approach is top-down. In this method, we preserve the recursive calls and use the values if theyare alreadycomputed. The implementationfor this is givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.080.png)

**Note:** For all problems, it maynot be possible to find bothtop-downand bottom-up programming solutions.

Both versions of the Fibonacci series implementations clearly reduce the problem complexity to O(*n*). This is because if a value is already computed then we are not calling the subproblems again. Instead, we are directlytakingits value fromthe table.

Time Complexity: O(*n*). Space Complexity: O(*n*), for table.

**FurtherImproving:** One more observation from the Fibonacci series is: The current value is the sum of the previous two calculations only. This indicates that we don’t have to store all the previous values. Instead, if we store just the last two values, we can calculate the current value. The implementationfor this is givenbelow:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.081.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Note:** This method maynot be applicable (available) for all problems.

**Observations**

While solvingthe problems usingDP, tryto figure out the following:

- See how the problems are defined interms of subproblems recursively.
- See if we canuse some table [memoization] to avoid the repeated calculations.

**Factorialof a Number**

As another example, consider the factorial problem: *n*! is the product of all integers between *n* and 1. The definitionof recursive factorial canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.082.png)

This definition can easily be converted to implementation. Here the problem is finding the value of *n*!, and the sub-problemis finding the value of (*n* – *l*)!. In the recursive case, when *n* is greater than 1, the function calls itself to find the value of (*n* – *l*)! and multiplies that with *n*. In the base case, whennis 0 or 1, the functionsimplyreturns 1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.083.png)The recurrence for the above implementationcanbe givenas: *T*(*n*) *= n* × *T*(*n* – 1) *≈* O(*n*) Time Complexity: O(*n*). Space Complexity: O(*n*), recursive calls need a stackof size *n*.

In the above recurrence relation and implementation, for any *n* value, there are no repetitive calculations (*n*o overlappingof sub problems) and the factorial functionis not gettinganybenefits withdynamic programming. Now, let us saywe want to compute a series of *m*! for some arbitrary value *m*. Using the above algorithm, for each such call we can compute it in O(*m*). For example, to find both *n*! and *m*! we can use the above approach, wherein the total complexity for finding *n*! and *m*! is O(*m* + *n*).

Time Complexity: O(*n* + *m*).

Space Complexity: O(max(*m,n*)), recursive calls need a stack of size equal to the maximum of *m* and *n.*

**Improving:** Now let us see how DP reduces the complexity. From the above recursive definition it can be seen that *fact*(*n*) is calculated from *fact*(*n* -1) and n and nothing else. Instead of calling *fact*(*n*) every time, we can store the previous calculated values in a table and use these values to calculate a new value. This implementationcanbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.084.png)

For simplicity, let us assume that we have already calculated *n*! and want to find *m*!. For finding *m*!, we just need to see the table and use the existingentries if theyare alreadycomputed. If *m < n* then we do not have to recalculate *m*!. If *m > n* then we can use *n*! and call the factorial on the remainingnumbers only.

The above implementation clearly reduces the complexity to O(*max*(*m,n*)). This is because if the *fact*(n) is already there, then we are not recalculating the value again. If we fill these newly computed values, thenthe subsequent calls further reduce the complexity.

Time Complexity: O(*max*(*m,n*)). Space Complexity: O(*max*(*m,n*)) for table.

8. **Longest Common Subsequence**

Given two strings: string *X* of length *m* [*X*(1..*m*)], and string *Y* of length *n* [*Y*(1..*n*)], find the longest common subsequence: the longest sequence of characters that appear left-to-right (but not necessarily in a contiguous block) in both strings. For example, if *X =* “ABCBDAB” and *Y =* “BDCABA”, the *LCS*(*X, Y*) = {“BCBA”, “BDAB”, “BCAB”}. We can see there are several optimal solutions.

**Brute Force Approach:** One simple idea is to check every subsequence of *X*[1.. *m*] (*m* is the length of sequence *X*) to see if it is also a subsequence of *Y*[1..*n*] (*n* is the length of sequence *Y*). Checking takes O(*n*) time, and there are 2*m* subsequences of *X*. The running time thus is exponential O(*n*. 2*m*) and is not good for large sequences.

**Recursive Solution:** Before going to DP solution, let us form the recursive solution for this and later we canadd memoizationto reduce the complexity. Let’s start withsome simple observations about the LCS problem. If we have two strings, say “ABCBDAB” and “BDCABA”, and if we draw lines from the letters in the first string to the corresponding letters in the second, no two lines cross:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.085.png)

From the above observation, we can see that the current characters of *X* and *Y* may or may not match. That means, suppose that the two first characters differ. Then it is not possible for both of them to be part of a common subsequence - one or the other (or maybe both) will have to be removed. Finally, observe that once we have decided what to do with the first characters of the strings, the remaining sub problemis again a *LCS* problem, on two shorter strings. Therefore we cansolve it recursively.

The solution to *LCS* should find two sequences in *X* and *Y* and let us say the starting index of sequence in *X* is *i* and the starting index of sequence in *Y* is *j*. Also, assume that *X*[*i ...m*] is a substringof *X* starting at character *i* and going until the end of *X*, and that *Y*[*j ...n*] is a substring of *Y*startingat character *j* and goinguntil the end of *Y.*

Based onthe above discussion, here we get the possibilities as described below:

1) If *X*[*i*] *== Y*[*j*] : 1 + *LCS*(*i +* 1*,j* + 1)
1) If *X*[*i*] ≠ *Y*[*j*]*. LCS*(*i,j +* 1) // skipping*jth* character of *Y*
1) If *X*[*i*] ≠ *Y*[*j*]*. LCS*(*i* + 1,*j*) // skipping*ith* character of *X*

In the first case, if *X*[*i*] is equal to *Y*[*j*], we get a matching pair and can count it towards the total length of the *LCS*. Otherwise, we need to skip either *ith* character of *X* or *jth* character of *Y* and find the longest commonsubsequence. Now, *LCS*(*i,j*) canbe defined as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.086.png)

LCS has many applications. In web searching, if we find the smallest number of changes that are needed to change one word into another. A*change* here is aninsertion, deletionor replacement of a single character.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.087.png)

This is a correct solution but it is very time consuming. For example, if the two strings have no matchingcharacters, the last line always gets executed whichgives (if *m* == *n*) close to O(2n).

**DP Solution: Adding Memoization:** The problem with the recursive solution is that the same subproblems get called many different times. Asubproblemconsists of a call to LCS\_length, with the arguments being two suffixes of *X* and *Y*, so there are exactly (*i* + 1)(*j* + 1) possible

subproblems (a relatively small number). If there are nearly **2n** recursive calls, some of these subproblems must be beingsolved over and over.

The DP solution is to check, whenever we want to solve a sub problem, whether we’ve already done it before. So we look up the solution instead of solving it again. Implemented in the most direct way, we just add some code to our recursive solution. To do this, look up the code. This canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.088.jpeg)

First, take care of the base cases. We have created an *LCS* table with one row and one column larger than the lengths of the two strings. Then run the iterative DP loops to fill each cell in the table. This is like doingrecursionbackwards, or bottomup.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.089.png)

The value of *LCS*[*i*][*j*] depends on 3 other values (*LCS*[*i* + 1][*j* + 1], *LCS*[*i*][*j* + 1] and *LCS*[*i* + 1][*j*]), all of which have larger values of *i or j*. They go through the table in the order of decreasing*i* and *j* values. This will guarantee that when we need to fill in the value of LCS[i][*j*], we alreadyknow the values of all the cells onwhichit depends.

Time Complexity: O(*mn*), since *i* takes values from1 to *m* and and *j* takes values from1 to *n.*

Space Complexity: O(*mn*).

**Note:** In the above discussion, we have assumed *LCS*(*i,j*) is the length of the *LCS* with *X*[*i ...m*] and *Y*[*j ...n*]. We can solve the problem by changing the definition as *LCS*(*i,j*) is the length of the *LCS* with*X*[1 ..*.i*] and *Y*[1...*j*].

**Printing the subsequence:** The above algorithm can find the length of the longest common subsequence but cannot give the actual longest subsequence. To get the sequence, we trace it through the table. Start at cell (0,0). We know that the value of LC5[0][0] was the maximum of 3 values of the neighboring cells. So we simply recompute LC5[0][0] and note which cell gave the maximumvalue. Then we move to that cell (it will be one of (1,1), (0,1) or (1,0)) and repeat this until we hit the boundary of the table. Every time we pass through a cell (*i*,*j*’) where *X*[*i*] == *Y*[*j*], we have a matching pair and print *X*[*i*]. At the end, we will have printed the longest common subsequence inO(*mn*) time.

Analternative wayof gettingpathis to keep a separate table for eachcell. This will tell us which direction we came from when computing the value of that cell. At the end, we again start at cell (0,0) and follow these directions until the opposite corner of the table.

From the above examples, I hope you understood the idea behind DP. Now let us see more problems whichcanbe easilysolved usingthe DPtechnique.

**Note:** As we have seen above, in DPthe main component is recursion. If we know the recurrence then converting that to code is a minimal task. For the problems below, we concentrate on getting the recurrence.

9. **Dynamic Programming: Problems & Solutions**

**Problem-1**  Convert the followingrecurrence to code.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.090.png)

**Solution:** The code for the givenrecursive formula canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.091.png)

**Problem-2**  Canwe improve the solutionto [Problem-1](#_page43_x66.91_y511.38) usingmemoizationof DP? **Solution: Yes.** Before findinga solution, let us see how the values are calculated.

*T*(0) = *T*(1) = 2

*T*(2) = 2 \**T*(1) \**T*(0)

*T*(3) = 2 \**T*(1) \**T*(0) + 2 \**T*(2) \**T*(1)

*T*(4) = 2 \**T*(1) \**T*(0) + 2 \**T*(2) \**T*(1) + 2 \**T*(3) \**T*(2)

From the above calculations it is clear that there are lots of repeated calculations with the same input values. Let us use a table for avoiding these repeated calculations, and the implementation canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.092.png)

Time Complexity: O(*n*2), two *for* loops. Space Complexity: O(*n*), for table. **Problem-3**  Canwe further improve the complexityof [Problem-2](#_page44_x66.91_y208.91)?

**Solution: Yes,** since all sub problem calculations are dependent only on previous calculations, code canbe modified as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.093.png)

Time Complexity: O(*n*), since onlyone *for* loop. Space Complexity: O(*n*).

**Problem-4  Maximum Value Contiguous Subsequence:** Given an array of *n* numbers, give

an algorithm for finding a contiguous subsequence *A*(*i*)*... A*(*j*) for which the sum of elements is maximum. **Example:** {-2, **11, -4, 13,** -5, 2} → 20 and {1, -3, **4, -2, -1,** 6} → 7

**Solution:**

**Input:** Array. *A*(1) ... *A*(*n*) of *n* numbers.

**Goal:** If there are no negative numbers, then the solution is just the sum of all elements in the given array. If negative numbers are there, then our aim is to maximize the sum [there can be a negative number inthe contiguous sum].

One simple and brute force approach is to see all possible sums and select the one which has maximumvalue.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.094.png)

Time Complexity: O(*n*3). Space Complexity: O(1).

**Problem-5**  Canwe improve the complexityof [Problem-4](#_page45_x66.91_y199.87)?

**Solution: Yes.** One important observation is that, if we have already calculated the sum for the subsequence *i,...,j –* 1, then we need only one more addition to get the sum for the subsequence *i,...,j*. But, the [Problem-4](#_page45_x66.91_y199.87) algorithm ignores this information. If we use this fact, we can get an

improved algorithmwiththe runningtime O(*n*2).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.095.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-6**  Canwe solve [Problem-4](#_page45_x66.91_y199.87) usingDynamic Programming?

**Solution: Yes.** For simplicity, let us say, *M*(*i*) indicates maximumsumover all windows endingat *i.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.096.png)

To find maximumsumwe have to do one of the followingand select maximumamongthem.

- Either extend the old sumbyadding*A*[*i*]
- or start new window startingwithone element *A*[*i*]

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.097.png)

Where, *M*(*i* – 1) *+ A*[*i*] indicates the case of extending the previous sum by adding *A*[*i*] and 0 indicates the new window startingat *A*[*i*].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.098.png)

Time Complexity: O(*n*). Space Complexity: O(*n*), for table. **Problem-7**  Is there anyother wayof solving[Problem-4](#_page45_x66.91_y199.87)?

**Solution: Yes.** We can solve this problem without DP too (without memory). The algorithm is a little tricky. One simple way is to look for all positive contiguous segments of the array (*sumEndingHere*) and keep track of the maximum sum contiguous segment among all positive segments (*sumSoFar*). Each time we get a positive sum compare it (*sumEndingHere*) with *sumSoFar* and update *sumSoFar* if it is greater than *sumSoFar*. Let us consider the following code for the above observation.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.099.png)**Note:** The algorithm doesn’t work if the input contains all negative numbers. It returns 0 if all numbers are negative. To overcome this, we can add an extra check before the actual implementation. The phase will look if all numbers are negative, and if they are it will return maximumof them(or smallest interms of absolute value).

Time Complexity: O(*n*), because we are doingonlyone scan. Space Complexity: O(1), for table.

**Problem-8**  In [Problem-7](#_page47_x66.91_y346.03) solution, we have assumed that *M*(*i*) indicates maximum sum over

all windows ending at *i*. Can we assume *M*(*i*) indicates maximum sum over all windows startingat *i* and endingat *n*?

**Solution:** Yes. For simplicity, let us say, *M*(*i*) indicates maximum sum over all windows starting at *i.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.100.png)

To find maximumwindow we have to do one of the followingand select maximumamongthem.

- Either extend the old sumbyadding*A*[*i*]
- Or start new window startingwithone element *A*[*i*]

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.101.png)

Where, *M*(*i* + 1) + *A*[*t*] indicates the case of extending the previous sum by adding *A*[*i*], and 0 indicates the new window startingat *A*[*i*].

Time Complexity: O(*n*). Space Complexity: O(*n*), for table.

**Note:** For O(*nlogn*) solution, refer to the *[Divide and Conquer*](#_page5_x28.00_y82.94)* chapter.

**Problem-9**  Given a sequence of n numbers *A*(1) *...A*(*n*), give an algorithm for finding a

contiguous subsequence *A*(*i*) *...A*(*j*) for which the sum of elements in the subsequence is maximum. Here the conditionis we should not select *two* contiguous numbers.

**Solution:** Let us see how DP solves this problem. Assume that *M*(*i*) represents the maximumsum from 1 to *i* numbers without selecting two contiguous numbers. While computing *M*(*i*), the

decision we have to make is, whether to select the *ith* element or not. This gives us two possibilities and based onthis we canwrite the recursive formula as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.102.png)

- The first case indicates whether we are selecting the *ith* element or not. If we don’t select the *ith* element then we have to maximize the sum using the elements 1 to *i* –

\1. If *ith* element is selected then we should not select *i –* 1*th* element and need to maximize the sumusing1 to *i –* 2 elements.

- Inthe above representation, the last two cases indicate the base cases.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.103.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.104.png)

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-10**  In [Problem-9](#_page48_x66.91_y601.29), we assumed that *M*(*i*) represents the maximum sum from 1 to *i*

numbers without selecting two contiguous numbers. Can we solve the same problem by changing the definition as: *M*(*i*) represents the maximum sum from *i* to *n* numbers without selectingtwo contiguous numbers?

**Solution: Yes.** Let us assume that *M*(*i*) represents the maximum sum from *i* to n numbers without selectingtwo contiguous numbers:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.105.png)

As similar to [Problem-9](#_page48_x66.91_y601.29) solution, we canwrite the recursive formula as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.106.png)

- The first case indicates whether we are selecting the *ith* element or not. If we don’t select the *ith* element then we have to maximize the sum using the elements *i* + 1 to

n. If *ith* element is selected then we should not select *i* + 1*th* element need to maximize the sumusing*i* + 2 to nelements.

- Inthe above representation, the last two cases indicate the base cases.

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-11**  Given a sequence of *n* numbers *A*(1) *...A*(*n*), give an algorithm for finding a

contiguous subsequence *A*(*i*) *...A*(*j*) for which the sum of elements in the subsequence is maximum. Here the conditionis we should not select *three* continuous numbers.

**Solution:** Input: Array*A*(1) *...A*(*n*) of *n* numbers.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.107.png)

Assume that *M*(*i*) represents the maximum sum from 1 to *i* numbers without selecting three contiguous numbers. While computing*M*(*i*), the decision we have to make is, whether to select *ith* element or not. This gives us the followingpossibilities:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.108.png)

- In the given problemthe restriction is not to select three continuous numbers, but we can select two elements continuously and skip the third one. That is what the first case says inthe above recursive formula. That means we are skipping*A*[*i –* 2].
- The other possibility is, selecting *ith* element and skipping second *i –* 1*th* element. This is the second case (skipping*A*[*i* – 1]).
- The third termdefines the case of not selecting *ith* element and as a result we should solve the problemwith*i* – 1 elements.

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-12**  In [Problem-11](#_page50_x66.91_y268.49), we assumed that *M*(*i)* represents the maximum sum from 1 to *i*

numbers without selecting three contiguous numbers. Can we solve the same problem by changing the definition as: *M*(*i*) represents the maximum sum from *i* to n numbers without selectingthree contiguous numbers?

**Solution: Yes.** The reasoning is very much similar. Let us see how DP solves this problem. Assume that *M*(*i*) represents the maximum sum from *i* to n numbers without selecting three contiguous numbers.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.109.png)

While computing*M*(*i*), the decision we have to make is, whether to select *ith* element or not. This gives us the followingpossibilities:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.110.png)

- In the given problemthe restriction is to not select three continuous numbers, but we can select two elements continuously and skip the third one. That is what the first case says inthe above recursive formula. That means we are skipping*A*[*i +* 2].
- The other possibility is, selecting *ith* element and skipping second *i –* 1*th* element. This is the second case (skipping*A*[*i* + 1]).
- And the third case is not selecting *ith* element and as a result we should solve the problemwith*i +* 1 elements.

Time Complexity: O(*n*). Space Complexity: O(*n*).

**Problem-13  CatalanNumbers:** How manybinarysearchtrees are there with*n* vertices?

**Solution:** Binary Search Tree (BST) is a tree where the left subtree elements are less than the root element, and the right subtree elements are greater than the root element. This property should be satisfied at every node in the tree. The number of BSTs with n nodes is called *Catalan Number* and is denoted by *Cn*. For example, there are 2 BSTs with 2 nodes (2 choices for the

root) and 5 BSTs with3 nodes.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.111.jpeg)

Let us assume that the nodes of the tree are numbered from 1 to *n*. Among the nodes, we have to select some node as root, and then divide the nodes which are less than root node into left sub tree, and elements greater than root node into right sub tree. Since we have already numbered the

vertices, let us assume that the root element we selected is *ith* element.

If we select *ith* element as root then we get *i* – 1 elements on left sub-tree and n – *i* elements on right sub tree. Since *Cn* is the Catalan number for n elements, *Ci–*1 represents the Catalan number for left sub tree elements (*i* – 1 elements) and *Cn–i* represents the Catalan number for right sub tree elements. The two sub trees are independent of each other, so we simply multiply the two numbers. That means, the Catalannumber for a fixed *i* value is *Ci*–1 × C*n*–*i*.

Since there are *n* nodes, for *i* we will get *n* choices. The total Catalan number with *n* nodes can be givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.112.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.113.png)

Time Complexity: O(4*n*). For proof, refer *Introduction* chapter.

**Problem-14**  Canwe improve the time complexityof [Problem-13](#_page51_x66.91_y609.71) usingDP?

**Solution:** The recursive call *Cn* depends only on the numbers *C*0 to *Cn*–1 and for any value of *i*, there are a lot of recalculations. We will keep a table of previously computed values of *Ci*. If the function*CatalanNumber*() is called with parameter **i**, and if it has already been computed before, thenwe cansimplyavoid recalculatingthe same subproblem.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.114.png)

The time complexity of this implementation O(*n*2), because to compute *CatalanNumber*(*n*), we need to compute all of the *CatalanNumber*(*i*) values between 0 and *n* – 1, and each one will be computed exactlyonce, inlinear time.

Inmathematics, CatalanNumber canbe represented bydirect equationas: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.115.png)

**Problem-15  Matrix Product Parenthesizations:** Given a series of matrices: *A*1 × *A*2 × *A*3 ×

- . . × *An* with their dimensions, what is the best way to parenthesize them so that it

produces the minimum number of total multiplications. Assume that we are using standard matrixand not Strassen’s matrixmultiplicationalgorithm.

**Solution:** Input: Sequence of matrices A1 × A2 × A3 × . . . × *An*, where *Ai* is a *Pi*–1 × *Pi*. The dimensions are giveninanarrayP.

**Goal:** Parenthesize the given matrices in such a way that it produces the optimal number of multiplications needed to compute A1 × A2 × A3 × . . . × *An.*

For the matrix multiplication problem, there are many possibilities. This is because matrix multiplication is associative. It does not matter how we parenthesize the product, the result will be the same. As anexample, for four matrices A, B, C, and D, the possibilities could be:

(*ABC*)*D =* (*AB*)(*CD*) *= A*(*BCD*) *= A*(*BC*)*D =..*

Multiplying (*p* × *q*) matrix with (*q* × *r*) matrix requires *pqr* multiplications. Each of the above possibilities produces a different number of products during multiplication. To select the best

one, we can go through each possible parenthesization (brute force), but this requires O(2*n*) time and is very slow. Now let us use DP to improve this time complexity. Assume that, *M*[*i,j*] represents the least number of multiplications needed to multiply*Ai … Aj.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.116.png)

The above recursive formula says that we have to find point *k* such that it produces the minimum number of multiplications. After computingall possible values for *k*, we have to select the *k* value which gives minimum value. We can use one more table (say, *S*[*i,j*]) to reconstruct the optimal parenthesizations. Compute the *M*[*i,j*] and *S*[*i,j*] ina bottom-up fashion.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.117.jpeg)

**How many sub problems are there?** In the above formula, *i* can range from 1 *to n* and *j* can range from 1 to *n*. So there are a total of *n*2 subproblems, and also we are doing *n* – 1 such operations [since the total number of operations we need for A1 × A2 ×A3 ×. . . × *An* ise *n* – 1]. So

the time complexityis O(*n*3). Space Complexity: O(*n*2).

**Problem-16**  For the [Problem-15](#_page53_x66.91_y626.46), canwe use greedymethod?

**Solution:** *Greedy* method is not an optimal way of solving this problem. Let us go through some counter example for this. As we have seenalready, *greedy* method makes the decisionthat is good locally and it does not consider the future optimal solutions. In this case, if we use *Greedy*, then we always do the cheapest multiplication first. Sometimes it returns a parenthesization that is not optimal.

**Example:** Consider A1 × A2 × A3 with dimentions 3 × 100, 100 × 2 and 2 × 2. Based on *greedy* we parenthesize themas: A1 × (A2 ×A3) with100 · 2 · 2 + 3 · 100 · 2 = 1000 multiplications. But the optimal solution to this problem is: (A1 × A2) × A3 with 3 · 100 · 2 + 3 · 2 · 2 = 612

multiplications. ∴we cannot use *greedy* for solvingthis problem.

**Problem-17  Integer Knapsack Problem [Duplicate Items Permitted]:** Given *n* types of items, where the *ith* item type has an integer size *si* and a value *v*. We need to fill a

*i*

knapsack of total capacity *C* with items of maximum value. We can add multiple items of the same type to the knapsack.

**Note:** For Fractional Knapsackproblemrefer to *Greedy Algorithms* chapter.

**Solution:** Input: *n* types of items where *ith* type item has the size *s* and value *v*. Also, assume

*i i*

infinite number of items for eachitemtype.

**Goal:** Fill the knapsackwithcapacity*C* byusing*n* types of items and withmaximumvalue.

One important note is that it’s not compulsory to fill the knapsack completely. That means, filling the knapsack completely [of size *C*] if we get a value *V* and without filling the knapsack completely [1et us say *C* – 1] with value U and if V < U then we consider the second one. In this case, we are basically filling the knapsack of size *C* – 1. If we get the same situation for *C* – 1 also, thenwe tryto fill the knapsackwith*C –* 2 size and get the maximumvalue.

Let us say M(j) denotes the maximum value we can pack into a *j* size knapsack. We can express M(j) recursivelyinterms of solutions to sub problems as follows:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.118.png)

For this problem the decision depends on whether we select a particular *ith* item or not for a knapsackof size *j.*

- If we select *ith* item, thenwe add its value *vi* to the optimal solution and decrease the size of the knapsackto be solved to *j – si.*
- If we do not select the item then check whether we can get a better solution for the knapsackof size *j –* 1.

The value of *M*(*C*) will contain the value of the optimal solution. We can find the list of items in the optimal solutionbymaintainingand following“backpointers”.

Time Complexity: Finding each *M*(*j*) value will require Θ(*n*) time, and we need to sequentially compute *C* suchvalues. Therefore, total runningtime is Θ(*nC*).

Space Complexity: Θ(*C*).

**Problem-18  0-1 Knapsack Problem:** For [Problem-17](#_page56_x66.91_y55.03), how do we solve it if the items are

not duplicated (*n*ot having an infinite number of items for each type, and each item is allowed to be used for 0 or 1 time)?

**Real-time example:** Suppose we are going by flight, and we know that there is a limitation on the luggage weight. Also, the items which we are carrying can be of different types (like laptops, etc.). In this case, our objective is to select the items with maximum value. That means, we need to tell the customs officer to select the items which have more weight and less value (profit).

**Solution:** Input is a set of *n* items with sizes *si* and values *vi* and a Knapsack of size *C* which we need to fill with a subset of items from the given set. Let us try to find the recursive formula for this problemusing DP. Let *M*(*i*,*j*) represent the optimal value we can get for filling up a knapsack of size *j* withitems 1... *i*. The recursive formula canbe givenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.119.png)

Time Complexity: O(*nC*), since there are *nC* subproblems to be solved and each of them takes O(1) to compute. Space Complexity: O(*nC*), where as Integer Knapsacktakes onlyO(*C*).

Now let us consider the following diagram which helps us in reconstructing the optimal solution and also gives further understanding. Size of below matrixis *M.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.120.png)

Since *i* takes values from1 ...*n* and *j* takes values from1... *C*, there are a total of *nC* subproblems. Now let us see what the above formula says:

- *M*(*i* – 1,*j*): Indicates the case of not selecting the *ith* item. In this case, since we are not adding any size to the knapsack we have to use the same knapsack size for subproblems but excludingthe *ith* item. The remainingitems are *i* – 1.
- *M*(*i* – 1,*j* – *si*) *+ vi* indicates the case where we have selected the *ith* item. If we add

the *ith* itemthen we have to reduce the subproblemknapsack size to *j* – *si* and at the same time we need to add the value **vi** to the optimal solution. The remaining items are *i* – 1.

Now, after finding all *M*(*i,j*) values, the optimal objective value can be obtained as: *Maxj*{*M*(*n,j*)}

This is because we do not know what amount of capacitygives the best solution.

Inorder to compute some value *M*(*i*,*j*), we take the maximumof *M*(*i* – 1,*j*) and *M*(*i* – 1,*j* – *si*) + *vi*. These two values (*M*(*i*,*j*) and *M*(*i* – 1,*j* – *si*)) appear in the previous row and also in some

previous columns. So, *M*(*i,j*) can be computed just by looking at two values in the previous row inthe table.

**Problem-19 Making Change:** Given *n* types of coin denominations of values *v*1 *< v*2 <...< *vn* (integers). Assume *v*1 = 1, so that we can always make change for any amount of money *C*.

Give an algorithm which makes change for an amount of money *C* with as few coins as possible.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.121.png)

This problem is identical to the Integer Knapsack problem. In our problem, we have coin denominations, each of value *vi*. We can construct an instance of a Knapsack problem for each

item that has a sizes *si*, which is equal to the value of *vi* coin denomination. In the Knapsack we cangive the value of everyitemas –1.

Now it is easy to understand an optimal way to make money *C* with the fewest coins is completely equivalent to the optimal way to fill the Knapsack of size *C*. This is because since every value has a value of –1, and the Knapsack algorithm uses as few items as possible which correspond to as few coins as possible.

Let us try formulating the recurrence. Let *M*(*j*) indicate the minimum number of coins required to make change for the amount of moneyequal to *j.*

*M*(*j*) = *Mini*{*M*(*j* – *vj*)} + 1

What this says is, if coin denomination *i* was the last denomination coin added to the solution, then the optimal way to finish the solution with that one is to optimally make change for the amount of moneyj – viand thenadd one extra coinof value *vi*.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.122.png)

Time Complexity: O(*nC*). Since we are solving *C* sub-problems and each of them requires minimizationof *n* terms. Space Complexity: O(*nC*).

**Problem-20  Longest Increasing Subsequence:** Given a sequence of *n* numbers *A*1 *. . . An*,

determine a subsequence (*n*ot necessarily contiguous) of maximum length in which the values inthe subsequence forma strictlyincreasingsequence.

**Solution:**

**Input:** Sequence of *n* numbers *A*1 *. . . An.*

**Goal:** To find a subsequence that is just a subset of elements and does not happen to be contiguous. But the elements in the subsequence should forma strictly increasing sequence and at the same time the subsequence should containas manyelements as possible.

For example, if the sequence is (5,6,2,3,4,1.9,9,8,9,5), then (5,6), (3,5), (1,8,9) are all increasing sub-sequences. The longest one of themis (2,3,4,8,9), and we want analgorithmfor findingit.

First, let us concentrate on the algorithm for finding the longest subsequence. Later, we can try printing the sequence itself by tracing the table. Our first step is finding the recursive formula. First, let us create the base conditions. If there is only one element in the input sequence then we don’t have to solve the problemand we just need to return that element. For any sequence we can start with the first element (*A*[1]). Since we know the first number in the LIS, let’s find the second number (*A*[2]). If *A*[2] is larger than*A*[1] theninclude *A*[2] also. Otherwise, we are done - the LIS is the one element sequence(*A*[1]).

Now, let us generalize the discussion and decide about *ith* element. Let *L*(*i*) represent the optimal subsequence which is starting at position *A*[1] and ending at *A*[*i*]. The optimal way to obtain a strictly increasing subsequence ending at position *i* is to extend some subsequence starting at some earlier position*j*. For this the recursive formula canbe writtenas:

*L*(*i*) = *Maxj* < *i and A* [*j*] < *A* [*i*]{*L*(*j*)} + 1

The above recurrence says that we have to select some earlier position *j* which gives the maximumsequence. The 1 inthe recursive formula indicates the additionof *ith* element.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.123.png)

Now after finding the maximum sequence for all positions we have to select the one among all positions whichgives the maximumsequence and it is defined as:

*Maxi*{*L*(*i*)}

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.124.png)

Time Complexity: O(*n*2), since two *for* loops. Space Complexity: O(*n*), for table.

**Problem-21  Longest Increasing Subsequence:** In [Problem-20](#_page59_x66.91_y475.45), we assumed that *L*(*i*)

represents the optimal subsequence which is starting at position *A*[1] and ending at *A*[*i*]. Now, let us change the definitionof *L*(*i*) as: *L*(*i*) represents the optimal subsequence which is starting at position *A*[*i*] and ending at *A*[*n*]. With this approach can we solve the problem?

**Solution: Yes.**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.125.png)

Let *L*(*i*) represent the optimal subsequence which is starting at position *A*[*i*] and ending at *A*[*n*]. The optimal way to obtain a strictly increasing subsequence starting at position *i* is going to be to extend some subsequence starting at some later position *j*. For this the recursive formula can be writtenas:

*L*(*i*) = *Maxj* < *i and A* [*j*] < *A* [*i*]{*L*(*j*)} + 1

We have to select some later position*j* whichgives the maximumsequence. The 1 inthe recursive formula is the addition of *ith* element. After finding the maximumsequence for all positions select

the one amongall positions whichgives the maximumsequence and it is defined as:

*Maxi*{*L*(*i*)}

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.126.png)

Time Complexity: O(*n*2) since two nested *for* loops. Space Complexity: O(*n*), for table. **Problem-22**  Is there analternative wayof solving*Problem-21?*

**Solution: Yes.** The other method is to sort the given sequence and save it into another array and then take out the “Longest Common Subsequence” (LCS) of the two arrays. This method has a

complexityof O(*n*2). For LCS problemrefer *theory section* of this chapter.

**Problem-23  Box Stacking:** Assume that we are givena set of *n* rectangular 3 – D boxes. The

dimensions of *ith* box are height *hi*, width *wi* and depth *di*. Now we want to create a stack of boxes which is as tall as possible, but we can only stack a box on top of another box if

the dimensions of the 2 –D base of the lower boxare eachstrictlylarger thanthose of the 2 –D base of the higher box. We can rotate a box so that any side functions as its base. It is possible to use multiple instances of the same type of box.

**Solution:** Boxstackingproblemcanbe reduced to LIS [*Problem-21.*

**Input:** *n* boxes where *ith* with height *h*, width *wi* and depth *d*. For all *n* boxes we have to

*i i*

consider all the orientations with respect to rotation. That is, if we have, in the original set, a box withdimensions 1 × 2 × 3, thenwe consider 3 boxes,

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.127.png)

This simplification allows us to forget about the rotations of the boxes and we just focus on the stacking of **n** boxes with each height as *hi* and a base area of (*w*i x *di*). Also assume that *wi* ≤ *di*.

Now what we do is, make a stack of boxes that is as tall as possible and has maximumheight. We allow a box *i* on top of box *j* only if box *i* is smaller than box *j* in both the dimensions. That means, if *wi < wj* && *di < dj*. Now let us solve this using DP. First select the boxes in the order

of decreasingbase area.

Now, let us say*H*(*j*) represents the tallest stack of boxes with box *j* on top. This is very similar to the LIS problembecause the stack of n boxes with ending box *j* is equal to finding a subsequence with the first *j* boxes due to the sorting by decreasing base area. The order of the boxes on the stackis goingto be equal to the order of the sequence.

Now we can write *H*(*j*) recursively. In order to form a stack which ends on box *j*, we need to extend a previous stack ending at *i*. That means, we need to put *j* box at the top of the stack [*i* box is the current top of the stack]. To put *j* box at the top of the stack we should satisfy the condition *wi > wj and di > dj* [this ensures that the low level box has more base than the boxes above it].

Based onthis logic, we canwrite the recursive formula as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.128.png)

Similar to the LIS problem, at the end we have to select the best *j* over all potential values. This is because we are not sure whichboxmight end up ontop.

*Maxj*{*H*(*j*)}

Time Complexity: O(*n*2).

**Problem-24  Building Bridges in India:** Consider a very long, straight river which moves fromnorth to south. Assume there are n cities on both sides of the river: n cities on the left

of the river and n cities on the right side of the river. Also, assume that these cities are numbered from 1 to n but the order is not known. Now we want to connect as many left- right pairs of cities as possible with bridges such that no two bridges cross. When connectingcities, we canonlyconnect cityi onthe left side to city*i* onthe right side.

**Solution:**

**Input:** Two pairs of sets witheachnumbered from1 to *n*.

**Goal:** Construct as many bridges as possible without any crosses between left side cities to right side cities of the river.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.129.jpeg)

To understand better let us consider the diagram below. In the diagram it can be seen that there are n cities on the left side of river and n cities on the right side of river. Also, note that we are connecting the cities which have the same number [a requirement in the problem]. Our goal is to connect the maximumcities on the left side of river to cities on the right side of the river, without anycross edges. Just to make it simple, let us sort the cities onone side of the river.

If we observe carefully, since the cities on the left side are already sorted, the problem can be simplified to finding the maximum increasing sequence. That means we have to use the LIS solutionfor findingthe maximumincreasingsequence onthe right side cities of the river.

Time Complexity: O(*n*2), (same as LIS).

**Problem-25  Subset Sum:** Given a sequence of *n* positive numbers *A*1 *. . . An*, give an

algorithmwhichchecks whether there exists a subset of *A*whose sumof all numbers is *T?*

**Solution:** This is a variation of the Knapsack problem. As an example, consider the following array:

*A*= [3,2,4,19,3,7,13,10,6,11]

Suppose we want to check whether there is any subset whose sum is 17. The answer is yes, because the sumof 4 + 13 = 17 and therefore {4,13} is sucha subset.

Let us try solving this problem using DP. We will define *n* × *T* matrix, where *n* is the number of elements inour input arrayand *T* is the sumwe want to check.

Let, *M*[*i,j*] = 1 if it is possible to find a subset of the numbers 1 through *i* that produce sum/ and *M*[*i,j*] = 0 otherwise.

*M*[*i*, *j*] = *Max*(*M*[*i* – 1,*j*], *M*[*i* – 1, *j* – *Ai*])

According to the above recursive formula similar to the Knapsack problem, we check if we can get the sum*j* by not including the element *i* in our subset, and we check if we can get the sum*j* by

including *i* and checking if the sum *j* – *Ai* exists without the *ith* element. This is identical to Knapsack, except that we are storing 0/1’s instead of values. In the below implementation we can

use binaryOR operationto get the maximumamong*M*[*i –* 1*,j*] and *M*[*i –* 1*,j – Ai*].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.130.png)

**How many subproblems are there?** Inthe above formula, *i* canrange from1 to *n* and *j* can range froml *to T*. There are a total of *nT* subproblems and each one takes O(1). So the time complexity is O(*nT*) and this is not polynomial as the running time depends on two variables [*n* and *T*], and we cansee that theyare anexponential functionof the other.

Space Complexity: O(*nT*).

**Problem-26**  Givena set of nintegers and the sumof all numbers is at most if. Find the subset

of these nelements whose sumis exactlyhalf of the total sumof *n* numbers.

**Solution:** Assume that the numbers are *A*1 *. . . An*. Let us use DP to solve this problem. We will

create a boolean array *T* with size equal to *K +* 1. Assume that *T*[*x*] is 1 if there exists a subset of given*n* elements whose sum is *x*. That means, after the algorithm finishes, *T*[*K*] will be 1, if and only if there is a subset of the numbers that has sum*K*. Once we have that value then we just need to return*T*[*K/*2]. If it is 1, thenthere is a subset that adds up to half the total sum.

Initiallywe set all values of *T* to 0. Thenwe set *T*[0] to 1. This is because we can always build 0 bytakinganemptyset. If we have no numbers in*A*, thenwe are done! Otherwise, we pickthe first number, *A*[0]. We can either throw it away or take it into our subset. This means that the new *T*[] should have *T*[0] and *T*[*A*[0]] set to 1. This creates the base case. We continue by taking the next element of *A.*

Suppose that we have already taken care of the first i – 1 elements of A. Now we take A[i] and look at our table T[]. After processing i – 1 elements, the array T has a 1 in every location that corresponds to a sum that we can make from the numbers we have already processed. Now we add the new number, A[i]. What should the table look like? First of all, we can simply ignore A[i]. That means, no one should disappear from T[] - we can still make all those sums. Now consider some location of T[j] that has a 1 in it. It corresponds to some subset of the previous numbers that add up to j. If we add A[i] to that subset, we will get a new subset withtotal sumj + A[i]. So we should set T[j + A[i]] to 1 as well. That’s all. Based onthe above discussion, we can write the algorithmas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.131.png)

Inthe above code, *j* loop moves fromright to left. This reduces the double countingproblem. That means, if we move fromleft to right, thenwe maydo the repeated calculations.

Time Complexity: O(*nK*), for the two *for* loops. Space Complexity: O(*K*), for the booleantable *T.* **Problem-27**  Canwe improve the performance of [Problem-26](#_page65_x66.91_y695.50)?

**Solution: Yes.** In the above code what we are doing is, the inner *j* loop is starting from *K* and movingleft. That means, it is unnecessarilyscanningthe whole table everytime.

What we actually want is to find all the 1 entries. At the beginning, only the 0th entry is 1. If we keep the locationof the rightmost 1 entryina variable, we canalways start at that spot and go left instead of startingat the right end of the table.

To take full advantage of this, we can sort *A*[] first. That way, the rightmost 1 entry will move to the right as slowly as possible. Finally, we don’t really care about what happens in the right half of the table (after *T*[*K/*2]) because if *T*[*x*] is 1, then *T*[*Kx*] must also be 1 eventually – it corresponds to the complement of the subset that gave us *x*. The code based on above discussion is givenbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.132.png)

After the improvements, the time complexity is still O(*nK*), but we have removed some useless steps.

**Problem-28**  Partition partition problem is to determine whether a given set can be partitioned into two subsets such that the sum of elements in both subsets is the same [the

same as the previous problem but a different way of asking]. For example, if A[] = {1, 5, 11, 5}, the array can be partitioned as {1, 5, 5} and {11}. Similarly, if A[] = {1, 5, 3}, the arraycannot be partitioned into equal sumsets.

**Solution:** Let us try solving this problemanother way. Following are the two main steps to solve this problem:

1. Calculate the sum of the array. If the sum is odd, there cannot be two subsets with an equal sum, so returnfalse.
1. If the sumof the arrayelements is even, calculate *sum/*2 and find a subset of the array witha sumequal to *sum/*2.

The first step is simple. The second step is crucial, and it can be solved either using recursion or Dynamic Programming.

**Recursive Solution:** Following is the recursive property of the second step mentioned above. Let subsetSum(A, n, sum/2) be the function that returns true if there is a subset of A[0..n-1] with sum equal to *sum/*2. The isSubsetSumproblemcanbe divided into two sub problems:

1) isSubsetSum() without consideringlast element (reducing*n* to *n* – 1)
1) isSubsetSumconsideringthe last element (reducingsum/2 byA[n-1] and *n* to *n* – 1)

If anyof the above sub problems returntrue, thenreturntrue.

*subsetSum* (*A,n,sum/*2) *= isSubsetSum* (*A,n* – 1,*sum/*2) *\\ subsetSum* (*A,n* – 1,*sum/*2 *– A*[*n* – 1])

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.133.jpeg)

Time Complexity: O(2*n*) In worst case, this solution tries two possibilities (whether to include or exclude) for everyelement.

**Dynamic Programming Solution:** The problem can be solved using dynamic programming when the sumof the elements is not too big. We can create a 2D array part[][] of size (*sum/*2)*\**(*n* + 1). And we can construct the solution in a bottom-up manner such that every filled entry has a followingproperty

*part* [*i*][*j*] = *true if a subset of* {*A*[0]*,A*[1]*,..A*[*j* – 1]} *has sum equal to sum/*2*, otherwise false*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.134.jpeg)

Time Complexity: O(*sum* × *n*). Space Complexity: O(*sum* × *n*). Please note that this solution will not be feasible for arrays witha bigsum.

**Problem-29  Counting Boolean Parenthesizations:** Let us assume that we are given a

boolean expression consisting of symbols *‘true’, ‘false’, ‘and’, ‘or’, and ‘xor’*. Find the number of ways to parenthesize the expression such that it will evaluate to *true*. For example, there is only 1 way to parenthesize *‘true and false xor true’* such that it evaluates to *true.*

**Solution:** Let the number of symbols be n and between symbols there are boolean operators like and, or, xor, etc. For example, if n = 4, *T or F and T xor F*. Our goal is to count the numbers of ways to parenthesize the expression with boolean operators so that it evaluates to *true*. In the above case, if we use *T or* ( (*F and T*) *xor F*) thenit evaluates to true.

*T or*{ (*F and T*)*xor F*) = *True*

Now let us see how DP solves this problem. Let *T*(*i,j*) represent the number of ways to parenthesize the sub expression with symbols *i ...j* [symbols means only *T* and *F* and not the operators] with boolean operators so that it evaluates to *true*. Also, *i and j* take the values from1 to *n*. For example, in the above case, *T*(2,4) = 0 because there is no way to parenthesize the expression*F and T xor F* to make it *true.*

Just for simplicity and similarity, let *F*(*i,j*) represent the number of ways to parenthesize the sub expression with symbols *i ...j* with boolean operators so that it evaluates to *false*. The base cases are *T*(*i,i*) and *F*(*i,i*).

Now we are going to compute *T*(*i, i* + 1) and *F*(*i, i* + 1) for all values of *i*. Similarly, *T*(*i, i* + 2) and *F*(*i, i* + 2) for all values of *i* and so on. Now let’s generalize the solution.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.135.png)

What this above recursive formula says is, *T*(*i,j*) indicates the number of ways to parenthesize the expression. Let us assume that we have some sub problems which are ending at *k*. Then the total number of ways to parenthesize from *i to j* is the sum of counts of parenthesizing from *i to k* and from *k +* 1 *to j*. To parenthesize between *k* and *k* + 1 there are three ways: *“and”, “or”* and *“xor”.*

- If we use *“and”* between *k* and *k* + 1, then the final expression becomes *true* only whenbothare *true*. If bothare *true* thenwe caninclude themto get the final count.
- If we use *“or”*, then if at least one of them is *true*, the result becomes *true*. Instead of includingall three possibilities for *“or”*, we are givingone alternative where we are subtractingthe “false” cases fromtotal possibilities.
- The same is the case with*“xor”*. The conversationis as inthe above two cases.

After finding all the values we have to select the value of *k*, which produces the maximum count, and for *k* there are *i to j –* 1 possibilities.

**How many subproblems are there?** In the above formula, *i* can range from 1 *to n*, and *j* can range from1 *to n*. So there are a total of *n*2 subproblems, and also we are doingsummationfor all suchvalues. So the time complexityis O(*n*3).

**Problem-30  Optimal Binary Search Trees:** Given a set of *n* (sorted) keys *A*[1*..n*], build the

best binary search tree for the elements of *A*. Also assume that each element is associated with*frequency* whichindicates the number of times that a particular itemis searched inthe binary search trees. That means we need to construct a binary search tree so that the total searchtime will be reduced.

**Solution:** Before solving the problem let us understand the problem with an example. Let us assume that the given array is A = [3,12,21,32,35]. There are many ways to represent these elements, two of whichare listed below.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.136.jpeg)

**Of the two, which representation is better?** The search time for an element depends on the depth of the node. The average number of comparisons for the first tree is: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.137.png) and

for the second tree, the average number of comparisons is: ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.138.png). Of the two, the first tree gives better results.

If frequencies are not given and if we want to search all elements, then the above simple calculation is enough for deciding the best tree. If the frequencies are given, then the selection depends on the frequencies of the elements and also the depth of the elements. For simplicity let us assume that the givenarrayis *A*and the correspondingfrequencies are inarray*F. F*[*i*] indicates

the frequency of *ith* element *A*[*i*]. With this, the total search time S(root) of the tree with *root* can be defined as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.139.png)

In the above expression, *depth*(*root, i*) + 1 indicates the number of comparisons for searching the *ith* element. Since we are trying to create a binary search tree, the left subtree elements are less than root element and the right subtree elements are greater than root element. If we separate the left subtree time and right subtree time, thenthe above expressioncanbe writtenas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.140.png)

If we replace the left subtree and right subtree times withtheir correspondingrecursive calls, then the expressionbecomes:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.141.png)

**Binary SearchTree node declaration**

Refer to *Trees* chapter.

**Implementation:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.142.png)

**Problem-31  Edit Distance:** Given two strings *A* of length *m* and *B* of length *n*, transform *A*

into *B* with a minimum number of operations of the following types: delete a character from *A*, insert a character into *A*, or change some character in *A* into a new character. The minimal number of such operations required to transform *A* into *B* is called the *edit distance* between*A*and *B.*

**Solution:**

**Input:** Two text strings *A*of length*m* and *B* of length*n.*

**Goal:** Convert string*A*into *B* withminimal conversions.

Before goingto a solution, let us consider the possible operations for convertingstring*A*into *B.*

- If *m > n*, we need to remove some characters of *A*
- If *m == n*, we mayneed to convert some characters of *A*
- If *m < n*, we need to remove some characters from*A*

So the operations we need are the insertion of a character, the replacement of a character and the deletionof a character, and their correspondingcost codes are defined below.

**Costs of operations:**



| Insertionof a character                                      | <p>*c*</p><p>*i*</p> |
| ------------------------------------------------------------ | -------------------- |
| Replacement of a character                                   | <p>*c*</p><p>*r*</p> |
|                                                              |                      |
| Deletionof a character                                       | <p>*c*</p><p>*d*</p> |
| Now let us concentrate on the recursive formulation of the problem. Let, *T*(*i,j*) represents the minimum cost required to transform first *i* characters of *A* to first; characters of *B*. That means, *A*[1*... i*] to *B*[1...*j*]. |                      |

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.143.png)

Based onthe above discussionwe have the followingcases.

- If we delete *ith* character from*A*, then we have to convert remaining *i –* 1 characters of *A*to *j* characters of *B*
- If we insert *ith* character in *A*, then convert these *i* characters of *A to j –* 1 characters of *B*
- If *A*[*i*] == *B*[*j*], then we have to convert the remaining *i –* 1 characters of *A to j –* 1 characters of *B*
- If *A*[*i*] ≠ *B*[*j*], then we have to replace *ith* character of *A* to *jth* character of B and convert remaining*i –* 1 characters of *A*to *j –* 1 characters of *B*

After calculatingall the possibilities we have to select the one whichgives the lowest cost.

**How many subproblems are there?** Inthe above formula, *i* canrange froml *to m* and *j* can range from 1 *to n*. This gives *mn* subproblems and each one takes O(1) and the time complexity is O(*mn*). Space Complexity: O(*mn*) where *m* is number of rows and *n* is number of columns in the givenmatrix.

**Problem-32  All Pairs Shortest Path Problem: Floyd’s Algorithm:** Given a weighted directed graph*G =* (*V,E*), where *V =* {1,2*,...,n*}. Find the shortest pathbetweenanypair of

nodes in the graph. Assume the weights are represented in the matrix *C*[*V*][*V*], where *C*[*i*] [*j*] indicates the weight (or cost) between the nodes *i* and *j*. Also, *C*[*i*][*j*] = ∞ or -1 if there is no pathfromnode *i* to node *j*.

**Solution:** Let us try to find the DP solution (Floyd’s algorithm) for this problem. The Floyd’s algorithm for all pairs shortest path problem uses matrix *A*[1*. .n*][1*..n*] to compute the lengths of the shortest paths. Initially,

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.144.png)

From the definition, *C*[*i,j*] = ∞ if there is no path from *i* to *j*. The algorithm makes n passes over A. Let A0,A1, ...,An be the values of *A*onthe npasses, withA0 beingthe initial value.

Just after the *k*– 1th iteration, Ak–1[*i,j*] = smallest length of any path from vertex *i* to vertex *j* that does not pass through the vertices {*k* + 1, *k* + 2,.... *n*}. That means, it passes through the vertices

possiblythrough{1,2,3,..., *k –* 1}.

Ineachiteration, the value *A*[*i*][*j*] is updated withminimumof Ak–1[*i*,*j*] and Ak–1[*i*, *k*] + Ak–1[*k*,*j*].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.145.png)

The *kth* pass explores whether the vertex*k* lies on an optimal path from*i* to *j*, for all *i,j*. The same is showninthe diagrambelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.146.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.147.png)

Time Complexity: O(*n*3).

**Problem-33  Optimal Strategy for a Game:** Consider a row of *n* coins of values *v*1 *... vn*,

where *n* is even [since it’s a two player game]. We play this game with the opponent. In each turn, a player selects either the first or last coin from the row, removes it from the row permanently, and receives the value of the coin. Determine the maximum possible amount of moneywe candefinitelywinif we move first.

**Alternative way of framing the question:** Given n pots, each with some number of gold coins, are arranged in a line. You are playing a game against another player. You take turns

picking a pot of gold. You may pick a pot from either end of the line, remove the pot, and keep the gold pieces. The player withthe most gold at the end wins. Develop a strategyfor playingthis game.

**Solution:** Let us solve the problem using our DP technique. For each turn either we *or* our opponent selects the coinonlyfromthe ends of the row. Let us define the subproblems as:

*V*(*i,j*): denotes the maximum possible value we can definitely win if it is our turn and the only coins remainingare *vi* ... *vj*.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.148.png)

Base Cases: *V*(*i,i*)*,V*(*i, i* + 1) for all values of *i*.

From these values, we can compute *V*(*i, i +* 2)*,V*(*i,i* + 3) and so on. Now let us define *V*(*i,j*) for eachsub problemas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.149.png)

Inthe recursive call we have to focus onith cointo *jth* coin(*v... v* ). Since it is our turn to pick the

*i j*

coin, we have two possibilities: either we canpick*vi* or *vj*. The first termindicates the case if we

select *ith* coin (*vi*) and the second termindicates the case if we select *jth* coin (*vj*). The outer *Max* indicates that we have to select the coin which gives maximum value. Now let us focus on the

terms:

- Selecting*ith* coin: If we select the *ith* coin then the remaining range is from*i* + 1 *to j*. Since we selected the *ith* coin we get the value *vi* for that. Fromthe remaining range

*i* + 1 *to j*, the opponents can select either *i* + 1*th* coin or *jth* coin. But the opoonents selection should be minimized as much as possible [the *Min* term]. The same is described inthe below figure.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.150.png)

- Selecting the *jth* coin: Here also the argument is the same as above. If we select the *jth* coin, thenthe remainingrange is fromitoj-1. Since we selected the *jth* coinwe get the value *vj* for that. From the remaining range i to j - 1, the opponent can select

either the *ith* coin or the *j* – 1*th* coin. But the opponent’s selection should be minimized as muchas possible [the *Min* term].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.151.png)

**How many subproblems are there?** Inthe above formula, *i* canrange from1 *to n* and *j* can range from1 *to n*. There are a total of *n*2 subproblems and eachtakes O(1) and the total time complexity is O(*n*2).

**Problem-34  Tiling:** Assume that we use dominoes measuring 2 × 1 to tile an infinite strip of

height 2. How manyways canone tile a 2 × *n* strip of square cells with1x2 dominoes?

**Solution:** Notice that we can place tiles either vertically or horizontally. For placing vertical tiles, we need a gap of at least 2 × 2. For placing horizontal tiles, we need a gap of 2 × 1. In this manner, the problem is reduced to finding the number of ways to partition *n* using the numbers 1 and 2 withorder considered relevant [1]. For example: 11 = 1 + 2 + 2+1+2 + 2 + 1.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.152.png)

If we have to find such arrangements for 12, we can either place a 1 at the end or we can add 2 in the arrangements possible with 10. Similarly, let us say we have *Fn* possible arrangements for n.

Thenfor (*n* + 1), we caneither place just 1 at the end *or* we canfind possible arrangements for (*n*

– 1) and put a 2 at the end. Goingbythe above theory:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.153.png)

Let’s verifythe above theoryfor our original problem:

- Inhow manyways canwe fill a 2 × 1 strip: 1 → Onlyone vertical tile.
- In how many ways can we fill a 2 × 2 strip: 2 → Either 2 horizontal or 2 vertical tiles.
- In how many ways can we fill a 2 × 3 strip: 3 → Either put a vertical tile in the 2 solutions possible for a 2 × 2 strip, or put 2 horizontal tiles in the only solution possible for a 2 × 1 strip. (2 + 1 = 3).
- Similarly, inhow manyways canwe fill a 2 × *n* strip: Either put a vertical tile inthe solutions possible for 2 *X* (*n* – 1) strip or put 2 horizontal tiles in the solution possible for a 2 × (*n* – 2) strip. (*Fn–*1 *+ Fn–*2).
- That’s how we verified that our final solution is: *Fn = Fn–*1 + *Fn*–2 with *F*1 = 1 and *F*2 = 2.

**Problem-35  Longest Palindrome Subsequence:** A sequence is a palindrome if it reads the

same whether we read it left to right or right to left. For example *A, C, G, G, G, G,C,A*. Given a sequence of length *n*, devise an algorithm to output the length of the longest palindrome subsequence. For example, the string *A,G,C,T,C,B,M,A,A,C,T,G,G,A,M* has manypalindromes as subsequences, for instance: *A,G,T,C,M,C,T,G,A*has length9.

**Solution:** Let us use DP to solve this problem. If we look at the sub-string A[i,..,j] of the string *A*, then we can find a palindrome sequence of length at least 2 if A[i] == A[j]. If they are not the same, then we have to find the maximum length palindrome in subsequences A[i + 1,..., j] and A[i,..., j – 1].

Also, every character *A*[*i*] is a palindrome of length 1. Therefore the base cases are given by *A*[*i,*

*i*] = 1. Let us define the maximumlengthpalindrome for the substringA[i,...,j] as L(i,j).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.154.png)

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.155.jpeg)

Time Complexity: First ‘for’ loop takes O(*n*) time while the second ‘for’ loop takes O(*n* – *k*) whichis also O(*n*). Therefore, the total runningtime of the algorithmis givenbyO(*n*2).

**Problem-36  Longest Palindrome Substring:** Given a string *A*, we need to find the longest

sub-stringof *A*suchthat the reverse of it is exactlythe same.

**Solution:** The basic difference between the longest palindrome substring and the longest palindrome subsequence is that, in the case of the longest palindrome substring, the output string should be the contiguous characters, which gives the maximumpalindrome; and in the case of the longest palindrome subsequence, the output is the sequence of characters where the characters might not be contiguous but they should be in an increasing sequence with respect to their positions inthe givenstring.

Brute-force solution exhaustively checks all *n* (*n* + 1) / 2 possible substrings of the given n-length string, tests each one if it’s a palindrome, and keeps track of the longest one seen so far. This has

worst-case complexity O(*n*3), but we can easily do better by realizing that a palindrome is centered on either a letter (for odd-length palindromes) or a space between letters (for even- length palindromes). Therefore we can examine all *n* + 1 possible centers and find the longest palindrome for that center, keeping track of the overall longest palindrome. This has worst-case

complexityO(*n*2).

Let us use DPto solve this problem. It is worthnotingthat there are no more thanO(*n*2) substrings in a string of length *n* (while there are exactly 2*n* subsequences). Therefore, we could scan each substring, check for a palindrome, and update the length of the longest palindrome substring discovered so far. Since the palindrome test takes time linear in the length of the substring, this

idea takes O(*n*3) algorithm. We canuse DPto improve this. For 1 ≤ *i* ≤ *j* ≤ *n*, define

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.156.png)

Also, for stringof lengthat least 3,

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.157.png)

Note that inorder to obtaina well-defined recurrence, we need to explicitlyinitialize two distinct diagonals of the boolean array *L*[*i,j*], since the recurrence for entry [*i,j*] uses the value [*i –* 1*,j* – 1], which is two diagonals away from [*i,j*] (that means, for a substring of length *k*, we need to know the status of a substringof length*k* – 2).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.158.jpeg)

Time Complexity: First for loop takes O(*n*) time while the second for loop takes O(*n* – *k*) which is also O(*n*). Therefore the total runningtime of the algorithmis givenbyO(*n*2).

**Problem-37**  Given two strings *S* and *T*, give an algorithm to find the number of times *S*

appears in *T*. It’s not compulsory that all characters of S should appear contiguous to *T*. For example, if *S* = *ab* and *T = abadcb* then the solution is 4, because *ab* is appearing 4 times in*abadcb.*

**Solution:**

**Input:** Giventwo strings *S*[1.. *m*] and *T*[1 *...m*]. **Goal:** Count the number of times that *S* appears in*T.*

Assume *L*(*i,j*) represents the count of how many times *i* characters of *S* are appearing in *j* characters of *T.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.159.png)

If we concentrate onthe components of the above recursive formula,

- If *j* = 0, thensince *T* is emptythe count becomes 0.
- If *i* = 0, then we can treat empty string *S* also appearing in *T* and we can give the count as 1.
- If S[i] == T[i], it means *ith* character of *S* and *jth* character of *T* are the same. In this case we have to check the subproblems with *i* – 1 characters of S and *j* – 1 characters of *T* and also we have to count the result of *i* characters of *S* withy – 1 characters of *T*. This is because even all *i* characters of *S* might be appearing in *j* – 1 characters of *T.*
- If S[i] ≠ T[i], then we have to get the result of subproblemwith *i* – 1 characters of *S* and *j* characters of *T.*

After computingall the values, we have to select the one whichgives the maximumcount.

**How many subproblems are there?** In the above formula, *i* can range from 1 to m and *j* can range from 1 to *n*. There are a total of *ran* subproblems and each one takes O(1). Time Complexityis O(*mn*).

Space Complexity: O(*mn*) where *m* is number of rows and *n* is number of columns in the given matrix.

**Problem-38**  Given a matrix with *n* rows and *m* columns (*n* × *m*). In each cell there are a

number of apples. We start from the upper-left corner of the matrix. We can go down or right one cell. Finally, we need to arrive at the bottom-right corner. Find the maximum number of apples that we can collect. When we pass through a cell, we collect all the apples left there.

**Solution:** Let us assume that the given matrix is *A*[*n*][*m*]. The first thing that must be observed is that there are at most 2 ways we can come to a cell - from the left (if it’s not situated on the first column) and fromthe top (if it’s not situated onthe most upper row).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.160.png)To find the best solution for that cell, we have to have already found the best solutions for all of the cells from which we can arrive to the current cell. From above, a recurrent relation can be easilyobtained as:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.161.png)

*S*(*i,j*) must be calculated by going first from left to right in each row and process the rows from top to bottom, or by going first from top to bottom in each column and process the columns from left to right.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.162.png)

**How many suchsubproblems are there?** In the above formula, *i* can range from1 *to n* and *j* can range from 1 *to m*. There are a total of *run* subproblems and each one takes O(1). Time Complexity is O(*nm*). Space Complexity: O(*nm*), where *m* is number of rows and n is number of columns inthe givenmatrix.

**Problem-39**  Similar to [Problem-38](#_page83_x66.91_y454.67), assume that we can go down, right one cell, or even in a

diagonal direction. We need to arrive at the bottom-right corner. Give DP solution to find the maximumnumber of apples we cancollect.

**Solution: Yes.** The discussion is very similar to [Problem-38](#_page83_x66.91_y454.67). Let us assume that the given matrix is A[*n*][*m*]. The first thingthat must be observed is that there are at most 3 ways we cancome to a cell - from the left, from the top (if it’s not situated on the uppermost row) or from the top diagonal. To find the best solution for that cell, we have to have already found the best solutions for all of the cells fromwhich we can arrive to the current cell. Fromabove, a recurrent relation canbe easilyobtained:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.163.png)

*S*(*i,j*) must be calculated by going first from left to right in each row and process the rows from top to bottom, or by going first from top to bottom in each column and process the columns from left to right.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.164.png)

**How many suchsubproblems are there?** In the above formula, *i* can range from1 *to n* and *j* can range from 1 *to m*. There are a total of *mn* subproblems and and each one takes O(1). Time Complexityis O(*nm*).

Space Complexity: O(*nm*) where *m* is number of rows and n is number of columns in the given matrix.

**Problem-40  Maximum size square sub-matrix with all 1’s:** Given a matrix with 0’s and

1’s, give an algorithm for finding the maximum size square sub-matrix with all Is. For example, consider the binarymatrixbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.165.png)

The maximumsquare sub-matrixwithall set bits is

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.166.png)

**Solution:** Let us try solving this problem using DP. Let the given binary matrix be B[*m*][*m*]. The idea of the algorithm is to construct a temporary matrix *L*[][] in which each entry L[*i*][*j*] represents size of the square sub-matrix with all 1’s including *B*[*i*][*j*] and *B*[*i*][*j*] is the rightmost

and bottom-most entryinthe sub-matrix.

**Algorithm:**

1) Construct a summatrix*L*[*m*][*n*] for the givenmatrix*B*[*m*][*n*].

1. Copyfirst row and first columns as is from*B*[ ][ ] to *L*[ ][ ].
1. For other entries, use the followingexpressions to construct *L*[ ][ ]

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.167.png)

2) Find the maximumentryin*L*[*m*][*n*].
2) Usingthe value and coordinates of maximumentryin*L*[*i*], print sub-matrixof *B*[][].

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.168.jpeg)

**How many subproblems are there?** Inthe above formula, *i* canrange from1 to *n* and *j* can range from 1 to *m*. There are a total *of nm* subproblems and each one takes O(1). Time Complexity is O(*nm*). Space Complexity is O(*nm*), where *n* is number of rows and *m* is number of columns in the givenmatrix.

**Problem-41  Maximum size sub-matrix with all 1’s:** Given a matrix with 0’s and 1’s, give an algorithm for finding the maximum size sub-matrix with all Is. For example, consider

the binarymatrixbelow.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.169.png)

The maximumsub-matrixwithall set bits is

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.170.png)

**Solution:** If we draw a histogram of all 1’s cells in the above rows for a particular row, then maximum all 1’s sub-matrix ending in that row will be equal to maximum area rectangle in that histogram. Below is anexample for 3*rd*row inthe above discussed matrix[1]:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.171.png)

If we calculate this area for all the rows, maximum area will be our answer. We can extend our solution very easily to find start and end co-ordinates. For this, we need to generate an auxiliary matrix *S*[][] where each element represents the number of Is above and including it, up until the first 0. *S*[][] for the above matrixwill be as shownbelow:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.172.png)

Now we can simply call our maximum rectangle in histogram on every row in *S*[][] and update the maximum area every time. Also we don’t need any extra space for saving *S*. We can update original matrix(*A*) to *S* and after calculation, we canconvert *S* backto *A.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.173.jpeg)

**Problem-42  Maximum sum sub-matrix:** Given an *n* × *n* matrix *M* of positive and negative

integers, give analgorithmto find the sub-matrixwiththe largest possible sum.

**Solution:** Let *Aux*[*r, c*] represent the sum of rectangular subarray of *M* with one corner at entry [1,1] and the other at [*r,c*]. Since there are n2 such possibilities, we can compute them in O(*n*2) time. After computing all possible sums, the sum of any rectangular subarray of *M* can be

computed in constant time. This gives an O(*n*4) algorithm: we simply guess the lower-left and the upper-right corner of the rectangular subarrayand use the *Aux* table to compute its sum.

**Problem-43**  Canwe improve the complexityof [Problem-42](#_page89_x66.91_y483.23)?

**Solution:** We can use the [Problem-4](#_page45_x66.91_y199.87) solution with little variation, as we have seen that the maximum sum array of a 1 – D array algorithm scans the array one entry at a time and keeps a running total of the entries. At any point, if this total becomes negative, then set it to 0. This algorithm is called *Kadane’s* algorithm. We use this as an auxiliary function to solve a two- dimensional probleminthe followingway.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.174.jpeg)

Time Complexity: O(*n*3).

**Problem-44**  Given a number *n*, find the minimumnumber of squares required to suma given

number *n.*

*Examples:* min[1] = 1 = 12, min[2] = 2 = 12 + 12, min[4] = 1 = 22, min[13] = 2 = 32 + 22.

**Solution:** This problem can be reduced to a coin change problem. The denominations are 1 to ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.175.png). Now, we just need to make change for *n* witha minimumnumber of denominations.

**Problem-45  Finding Optimal Number of Jumps To Reach Last Element:** Given an array, start from the first element and reach the last by jumping. The jump length can be at most

the value at the current positioninthe array. The optimumresult is whenyoureachthe goal in the minimum number of jumps. **Example:** Given array A = {2,3,1,1,4}. Possible ways to reachthe end (indexlist) are:

- 0,2,3,4 (jump 2 to index 2, and then jump 1 to index 3, and then jump 1 to index4)
- 0,1,4 (jump 1 to index1, and thenjump 3 to index4)

Since second solutionhas only2 jumps it is the optimumresult.

**Solution:** This problemis a classic example of Dynamic Programming. Though we can solve this by brute-force, it would be complex. We can use the LIS problem approach for solving this. As soon as we traverse the array, we should find the minimum number of jumps for reaching that position (index) and update our result array. Once we reach the end, we have the optimum solutionat last indexinresult array.

**How canwe findthe optimumnumberof jumps forevery position(index)?** For first index, the optimum number of jumps will be zero. Please note that if value at first index is zero, we can’t

jump to any element and return infinite. For *n +* 1*th* element, initialize result[*n* + 1] as infinite. Then we should go through a loop from0 ... *n*, and at every index *i*, we should see if we are able to jump to *n* + 1 fromi or not. If possible, then see if total number of jumps (result[i] + 1) is less thanresult[*n* + 1], thenupdate result[*n* + 1], else just continue to next index.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.176.jpeg)

The above code will return optimum number of jumps. To find the jump indexes as well, we can veryeasilymodifythe code as per requirement.

Time Complexity: Since we are running 2 loops here and iterating from 0 to *i* in every loop then total time takes will be 1 + 2 + 3 + 4 + ... + *n* – 1. So time efficiency O(*n*) = O(*n* \* (*n* – 1)/2) =

O(*n*2).

Space Complexity: O(*n*) space for result array.

**Problem-46**  Explain what would happen if a dynamic programming algorithm is designed to

solve a problemthat does not have overlappingsub-problems.

**Solution:** It will be just a waste of memory, because the answers of sub-problems will never be used again. And the runningtime will be the same as usingthe Divide & Conquer algorithm.

**Problem-47**  Christmas is approaching. You’re helping Santa Claus to distribute gifts to children. For ease of delivery, you are asked to divide *n* gifts into two groups such that the weight difference of these two groups is minimized. The weight of each gift is a positive integer. Please design an algorithm to find an optimal division minimizing the value

difference. The algorithm should find the minimal weight difference as well as the groupings in O(*nS*) time, where *S* is the total weight of these *n* gifts. Briefly justify the correctness of your algorithm.

**Solution:** This problem can be converted into making one set as close to ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.177.png) as possible. We consider an equivalent problem of making one set as close to ![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.178.png) as possible. Define

FD(*i*,*w*) to be the minimal gap between the weight of the bag and W when using the first *i* gifts only. WLOG, we can assume the weight of the bag is always less than or equal to W. Then fill the DPtable for 0≤i≤ *n* and 0≤ *w* ≤WinwhichF(0, *w*) = Wfor all *w*, and

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.179.png)

This takes O(*nS*) time. *FD*(*n,W*) is the minimum gap. Finally, to reconstruct the answer, we backtrack from (*n,W*). During backtracking, if *FD*(*i,j*) *= FD*(*i –* 1*,j*) then *i* is not selected in the bagand we move to F(i – 1*,j*). Otherwise, *i* is selected and we move to F(i – 1*,j – wi*).

**Problem-48**  A circus is designing a tower routine consisting of people standing atop one

another’s shoulders. For practical and aesthetic reasons, each person must be both shorter and lighter than the person below himor her. Given the heights and weights of each person in the circus, write a method to compute the largest possible number of people in such a tower.

**Solution:** It is same as Boxstackingand Longest increasingsubsequence (LIS) problem.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.180.png)

1. **Introduction**

In the previous chapters we have solved problems of different complexities. Some algorithms have lower rates of growth while others have higher rates of growth. The problems with lower rates of growthare called *easy* problems (or *easy solved problems*) and the problems with higher rates of growth are called *hard* problems (or *hard solved problems*). This classification is done based onthe runningtime (or memory) that analgorithmtakes for solvingthe problem.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.181.png)

There are lots of problems for which we do not know the solutions. All the problems we have seen so far are the ones which can be solved by computer in deterministic time. Before starting our discussionlet us lookat the basic terminologywe use inthis chapter.

2. **Polynomial/ExponentialTime**

Exponential time means, in essence, trying every possibility (for example, backtracking algorithms) and they are very slow in nature. Polynomial time means having some clever

algorithm to solve a problem, and we don’t try every possibility. Mathematically, we can represent these as:

- Polynomial time is O(*nk*), for some *k.*
- Exponential time is O(*kn*), for some *k.*

3. **What is a Decision Problem?**

A decision problem is a question with a *yes/no* answer and the answer depends on the values of input. For example, the problem “Given an array of *n* numbers, check whether there are any duplicates or not?” is a decision problem. The answer for this problem can be either *yes* or *no* dependingonthe values of the input array.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.182.png)

4. **Decision Procedure**

For a given decision problem let us assume we have given some algorithm for solving it. The process of solving a given decision problem in the form of an algorithm is called a *decision procedure* for that problem.

5. **What is a Complexity Class?**

In computer science, in order to understand the problems for which solutions are not there, the problems are divided into classes and we call themas complexityclasses. Incomplexitytheory, a *complexity class* is a set of problems with related complexity. It is the branch of theory of computationthat studies the resources required duringcomputationto solve a givenproblem.

The most commonresources are time (how muchtime the algorithmtakes to solve a problem) and space (how muchmemoryit takes).

6. **Types of Complexity Classes P Class**

The complexity class *P* is the set of decision problems that can be solved by a deterministic machine in polynomial time (*P* stands for polynomial time). *P* problems are a set of problems whose solutions are easyto find.

**NP Class**

The complexity class *NP* (*NP* stands for non-deterministic polynomial time) is the set of decision problems that can be solved by a non-deterministic machine in polynomial time. *NP* class problems refer to a set of problems whose solutions are hard to find, but easyto verify.

For better understanding let us consider a college which has 500 students on its roll. Also, assume that there are 100 rooms available for students. Aselectionof 100 students must be paired together in rooms, but the dean of students has a list of pairings of certain students who cannot roomtogether for some reason.

The total possible number of pairings is too large. But the solutions (the list of pairings) provided to the dean, are easyto checkfor errors. If one of the prohibited pairs is onthe list, that’s anerror. In this problem, we can see that checking every possibility is very difficult, but the result is easy to validate.

That means, if someone gives us a solution to the problem, we can tell themwhether it is right or not in polynomial time. Based on the above discussion, for *NP* class problems if the answer is *yes*, thenthere is a proof of this fact, whichcanbe verified inpolynomial time.

**Co-NP Class**

*Co – NP* is the opposite of *NP* (complement of *NP*). If the answer to a problemin *Co – NP* is *no*, thenthere is a proof of this fact that canbe checked inpolynomial time.



| *P*                                      | Solvable inpolynomial time                    |
| ---------------------------------------- | --------------------------------------------- |
| *NP*                                     | *Yes* answers canbe checked inpolynomial time |
| *Co-NP*                                  | *No* answers canbe checked inpolynomial time  |
| **Relationship between P, NP and Co-NP** |                                               |

Every decision problem in *P* is also in *NP*. If a problem is in *P*, we can verify YES answers in polynomial time. Similarly, anyprobleminPis also in*Co – NP.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.183.png)

One of the important open questions in theoretical computer science is whether or not *P = NP*. Nobodyknows. Intuitively, it should be obvious that *P* ≠ *NP*, but nobodyknows how to prove it.

Another open question is whether *NP* and *Co – NP* are different. Even if we can verify every YES answer quickly, there’s no reasonto thinkthat we canalso verifyNO answers quickly.

It is generallybelieved that *NP* ≠ *Co – NP*, but againnobodyknows how to prove it.

**NP-hard Class**

It is a class of problems such that every problem in *NP* reduces to it. All *NP*-hard problems are not in *NP*, so it takes a long time to even check them. That means, if someone gives us a solution for *NP*-hard problem, it takes a longtime for us to checkwhether it is right or not.

Aproblem*K* is *NP*-hard indicates that if a polynomial-time algorithm(solution) exists for *K* then a polynomial-time algorithmfor everyproblemis *NP*. Thus:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.184.png)

**NP-complete Class**

Finally, a problem is *NP*-complete if it is part of both *NP*-hard and *NP. NP*-complete problems are the hardest problems in *NP*. If anyone finds a polynomial-time algorithmfor one *NP*-complete problem, then we can find polynomial-time algorithm for every *NP*-complete problem. This means that we cancheckananswer fast and everyproblemin*NP* reduces to it.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.185.jpeg)

**Relationship between P, NP Co-NP, NP-Hard and NP-Complete**

From the above discussion, we can write the relationships between different components as shownbelow (remember, this is just anassumption).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b3bfdf01-4277-4d13-8d5d-f33a0e4d9f52.186.jpeg)

The set of problems that are *NP*-hard is a strict superset of the problems that are *NP*-complete. Some problems (like the haltingproblem) are *NP*-hard, but not in*NP. NP-hard* problems might be impossible to solve in general. We can tell the difference in difficulty between *NP*-hard and *NP*- complete problems because the class *NP* includes everythingeasier thanits “toughest” problems - if a problemis not in*NP*, it is harder thanall the problems in*NP.*

**Does P==NP?**

If *P = NP*, it means that every problem that can be checked quickly can be solved quickly (remember the difference betweencheckingif ananswer is right and actuallysolvinga problem).

This is a big question (and nobody knows the answer), because right now there are lots of *NP*- complete problems that can’t be solved quickly. If *P = NP*, that means there is a way to solve themfast. Remember that “quickly” means not trial-and-error. It could take a billion years, but as long as we didn’t use trial and error, it was quick. In future, a computer will be able to change that billionyears into a few minutes.

7. **Reductions**

Before discussing reductions, let us consider the following scenario. Assume that we want to solve problem*X* but feel it’s verycomplicated. Inthis case what do we do?

The first thing that comes to mind is, if we have a similar problemto that of *X* (let us say *Y*), then we tryto map *X* to *Y*and use *Y’s* solutionto solve *X* also. This process is called reduction.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.001.png)

Inorder to map problem*X* to problem*Y*, we need some algorithmand that may take linear time or more. Based onthis discussionthe cost of solvingproblem*X* canbe givenas:

*Cost of solving X = Cost of solving Y+ Reduction time*

Now, let us consider the other scenario. For solving problem *X*, sometimes we may need to use *Y’s* algorithm(solution) multiple times. Inthat case,

*Cost of solving X = Number of Times \* Cost of solving X + Reduction time*

The main thing in *NP*-Complete is reducibility. That means, we reduce (or transform) given *NP*- Complete problems to other known *NP*-Complete problem. Since the *NP*-Complete problems are hard to solve and inorder to prove that given*NP*-Complete problemis hard, we take one existing

hard problem (which we can prove is hard) and try to map given problem to that and finally we prove that the givenproblemis hard.

**Note:** It’s not compulsory to reduce the given problem to known hard problem to prove its hardness. Sometimes, we reduce the knownhard problemto givenproblem.

**Important NP-Complete Problems (Reductions)**

**Satisfiability Problem:** A boolean formula is in *conjunctive normal form* (CNF) if it is a conjunction (AND) of several clauses, each of which is the disjunction (OR) of several literals, each of which is either a variable or its negation. For example: (a ∨ *b* ∨ *c ∨ d* ∨ *e*)∧(*b* ∨ *~c* ∨ *~d*) ∧ (~a ∨ *c* ∨ *d*) ∨ (a ∨ *~b*)

A 3-CNF formula is a CNF formula with exactly three literals per clause. The previous example is not a 3-CNF formula, since its first clause has five literals and its last clause has onlytwo.

2-SAT Problem: 3-SAT is just SAT restricted to 3-CNF formulas: Given a 3-CNF formula, is there anassignment to the variables so that the formula evaluates to TRUE?

2-SAT Problem: 2-SAT is just SAT restricted to 2-CNF formulas: Given a 2-CNF formula, is there anassignment to the variables so that the formula evaluates to TRUE?

**Circuit-Satisfiability Problem:** Given a boolean combinational circuit composed of AND, OR and NOT gates, is it satisfiable?. That means, given a boolean circuit consisting of AND, OR and NOT gates properly connected by wires, the Circuit-SAT problem is to decide whether there exists aninput assignment for whichthe output is TRUE.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.002.jpeg)

**Hamiltonian Path Problem (Ham-Path):** Given an undirected graph, is there a path that visits

everyvertexexactlyonce?

**Hamiltonian Cycle Problem (Ham-Cycle):** Given an undirected graph, is there a cycle (where start and end vertices are same) that visits everyvertexexactlyonce?

**Directed Hamiltonian Cycle Problem (Dir-Ham-Cycle):** Given a directed graph, is there a cycle (where start and end vertices are same) that visits everyvertexexactlyonce?

**Travelling Salesman Problem (TSP):** Given a list of cities and their pair-wise distances, the problemis to find the shortest possible tour that visits eachcityexactlyonce.

**Shortest Path Problem(Shortest-Path):** Given a directed graph and two vertices s and t, check whether there is a shortest simple pathfroms to *t.*

**GraphColoring:** A*k*-coloring of a graph is to map one of *k* ‘colors’ to each vertex, so that every edge has two different colors at its endpoints. The graph coloring problem is to find the smallest possible number of colors ina legal coloring.

3-Color problem: Given a graph, is it possible to color the graph with 3 colors in such a way that everyedge has two different colors?

**Clique (also called complete graph):** Given a graph, the *CLIQUE* problem is to compute the number of nodes in its largest complete subgraph. That means, we need to find the maximum subgraphwhichis also a complete graph.

**Independent Set Problem (Ind\_Set):** Let *G* be an arbitrary graph. An independent set in *G* is a subset of the vertices of *G* withno edges betweenthem. The maximumindependent set problemis the size of the largest independent set ina givengraph.

**Vertex Cover Problem (Vertex-Cover):** A vertex cover of a graph is a set of vertices that touches every edge in the graph. The vertex cover problem is to find the smallest vertex cover in a givengraph.

**Subset Sum Problem (Subset-Sum):** Given a set *S* of integers and an integer *T*, determine whether 5 has a subset whose elements sumto *T.*

**Integer Programming:** Given integers *bi*, aij find 0/1 variables xi that satisfy a linear system of equations.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.003.png)

In the figure, arrows indicate the reductions. For example, Ham-Cycle (Hamiltonian Cycle Problem) can be reduced to CNF-SAT. Same is the case with any pair of problems. For our discussion, we can ignore the reduction process for each of the problems. There is a theorem called *Cook’s Theorem* which proves that Circuit satisfiability problem is NP-hard. That means, Circuit satisfiabilityis a known*NP*-hard problem.

**Note:** Since the problems below are *NP*-Complete, they are *NP* and *NP*-hard too. For simplicity we canignore the proofs for these reductions.

**20.8 Complexity Classes: Problems & Solutions**

**Problem-1**  What is a quickalgorithm?

**Solution:** A quick algorithm (solution) means not trial-and-error solution. It could take a billion years, but as long as we do not use trial and error, it is efficient. Future computers will change those billionyears to a few minutes.

**Problem-2**  What is anefficient algorithm?

**Solution:** Analgorithmis said to be efficient if it satisfies the followingproperties:

- Scale withinput size.
- Don’t care about constants.
- Asymptotic runningtime: polynomial time.

**Problem-3**  Canwe solve all problems inpolynomial time?

**Solution: No.** The answer is trivial because we have seen lots of problems which take more than polynomial time.

**Problem-4**  Are there anyproblems whichare *NP*-hard?

**Solution:** By definition, *NP*-hard implies that it is very hard. That means it is very hard to prove and to verifythat it is hard. Cook’s Theoremproves that Circuit satisfiabilityproblemis *NP*-hard.

**Problem-5**  For 2-SAT problem, whichof the followingare applicable?

1) *P*
1) *NP*
1) *CoNP*
1) *NP*-Hard
1) *CoNP*-Hard
1) *NP*-Complete
1) *CoNP*-Complete

**Solution:** 2-SAT is solvable inpoly-time. So it is *P*, *NP*, and *CoNP.* **Problem-6**  For 3-SAT problem, whichof the followingare applicable?

1) *P*
1) *NP*
1) *CoNP*
1) *NP*-Hard
1) *CoNP*-Hard
1) *NP*-Complete
1) *CoNP*-Complete

**Solution:** 3-SAT is NP-complete. So it is NP, NP-Hard, and NP-complete.

**Problem-7**  For 2-Clique problem, whichof the followingare applicable?

1) *P*
1) *NP*
1) *CoNP*
1) *NP*-Hard
1) *CoNP*-Hard
1) *NP*-Complete
1) *CoNP*-Complete

**Solution:** 2-Clique is solvable in poly-time (check for an edge between all vertex-pairs in O(*n*2) time). So it is *P.NP*, and *CoNP.*

**Problem-8**  For 3-Clique problem, whichof the followingare applicable?

1) *P*
1) *NP*
1) *CoNP*
1) *NP*-Hard
1) *CoNP*-Hard
1) *NP*-Complete
1) *CoNP*-Complete

**Solution:** 3-Clique is solvable in poly-time (check for a triangle between all vertex-triplets in O(*n*3) time). So it is *P, NP*, and *CoNP.*

**Problem-9**  Consider the problem of determining. For a given boolean formula, check

whether every assignment to the variables satisfies it. Which of the following is applicable?

1) *P*
1) *NP*
1) *CoNP*
1) *NP*-Hard
1) *CoNP*-Hard
1) *NP*-Complete
1) *CoNP*-Complete

**Solution:** Tautology is the complimentary problem to Satisfiability, which is NP-complete, so Tautologyis *CoNP-*complete. So it is *CoNP, CoNP-*hard, and *CoNP*-complete.

**Problem-10**  Let *S* be an *NP*-complete problem and *Q* and *R* be two other problems not

knownto be in*NP. Q* is polynomial time reducible to *S* and *S* is polynomial-time reducible to *R*. Whichone of the followingstatements is true?

1) *R* is *NP*-complete
1) *R* is *NP*-hard
1) *Q* is *NP*-complete
1) *Q* is *NP* -hard.

**Solution:** *R* is *NP*-hard (b).

**Problem-11**  Let *A* be the problemof finding a Hamiltonian cycle in a graph *G =* (*V ,E*), with

|*V*| divisible by 3 and *B* the problem of determining if Hamiltonian cycle exists in such graphs. Whichone of the followingis true?

1) Both*A*and *B* are *NP*-hard
1) *A*is *NP*-hard, but *B* is not
1) *A*is *NP*-hard, but *B* is not
1) Neither *A*nor *B* is *NP*-hard

**Solution:** Both*A*and *B* are *NP*-hard (a).

**Problem-12**  Let *A* be a problemthat belongs to the class *NP*. State which of the following is

true?

1) There is no polynomial time algorithmfor *A.*
1) If *A*canbe solved deterministicallyinpolynomial time, then*P* = *NP.*
1) If *A*is *NP*-hard, thenit is *NP*-complete.
1) *A*maybe undecidable.

**Solution:** If *A*is *NP*-hard, thenit is *NP*-complete (c).

**Problem-13**  Suppose we assume *Vertex – Cover* is known to be *NP*-complete. Based on our

reduction, canwe say*Independent – Set* is *NP*-complete?

**Solution: Yes.** This follows fromthe two conditions necessaryto be *NP*-complete:

- Independent Set is in*NP*, as stated inthe problem.
- Areductionfroma known*NP*-complete problem.

**Problem-14**  Suppose *Independent Set* is known to be *NP*-complete. Based on our reduction,

is *Vertex Cover NP*-complete?

**Solution: No.** By reduction from Vertex-Cover to Independent-Set, we do not know the difficulty of solvingIndependent-Set. This is because Independent-Set could still be a muchharder problem thanVertex-Cover. We have not proved that.

**Problem-15**  The class of NP is the class of languages that cannot be accepted in polynomial

time. Is it true? Explain.

**Solution:**

- The class of NPis the class of languages that canbe *verified* in*polynomial time.*
- The class of Pis the class of languages that canbe *decided* in*polynomial time.*
- The class of Pis the class of languages that canbe *accepted* in*polynomial time.*

*P* ⊆ *NP* and “languages in P can be accepted in polynomial time”, the description “languages in NPcannot be accepted inpolynomial time” is wrong.

The term NP comes from nondeterministic polynomial time and is derived from an alternative characterization by using nondeterministic polynomial time Turing machines. It has nothing to do with“cannot be accepted inpolynomial time”.

**Problem-16**  Different encodings would cause different time complexity for the same

algorithm. Is it true?

**Solution:** True. The time complexity of the same algorithm is different between unary encoding and binary encoding. But if the two encodings are polynomially related (e.g. base 2 & base 3 encodings), thenchangingbetweenthemwill not cause the time complexityto change.

**Problem-17**  If P= NP, thenNPC (NPComplete) ⊆ P. Is it true?

**Solution:** True. If P = NP, then for any language L∈ NP C (1) L∈ NPC (2) Lis NP-hard. By the first condition, L∈ NPC ⊆ NP= P⇒ NPC ⊆ P.

**Problem-18**  If NPC ⊆ P, thenP= NP. Is it true?

**Solution:** True. All the NPproblemcanbe reduced to arbitraryNPC probleminpolynomial time, and NPC problems can be solved in polynomial time because NPC ⊆ P. ⇒ NP problemsolvable inpolynomial time ⇒ NP⊆ Pand triviallyP⊆ NPimplies NP= P.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.004.png)

1. **Introduction**

Inthis chapter we will cover the topics whichare useful for interviews and exams.

2. **Hacks on Bitwise Programming**

In *C* and *C* + + we can work with bits effectively. First let us see the definitions of each bit operation and then move onto different techniques for solving the problems. Basically, there are sixoperators that *C* and *C* + + support for bit manipulation:



| Symbol                | Operation            |
| --------------------- | -------------------- |
| &                     | Bitwise AND          |
| **1**                 | Bitwise OR           |
| A                     | Bitwise Exclusive-OR |
| ≪                     | Bitwise left shift   |
| ≫ Bitwise right shift |                      |

~ Bitwise complement

1. **Bitwise AND**

The bitwise AND tests two binary numbers and returns bit values of 1 for positions where both numbers had a one, and bit values of 0 where bothnumbers did not have one:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.005.png)

2. **Bitwise OR**

The bitwise OR tests two binarynumbers and returns bit values of 1 for positions where either bit or bothbits are one, the result of 0 onlyhappens whenbothbits are 0:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.006.png)

3. **Bitwise Exclusive-OR**

The bitwise Exclusive-OR tests two binary numbers and returns bit values of 1 for positions where bothbits are different; if theyare the same thenthe result is 0:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.007.png)

4. **Bitwise Left Shift**

The bitwise left shift moves all bits inthe number to the left and fills vacated bit positions with0.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.008.png)

5. **Bitwise Right Shift**

The bitwise right shift moves all bits inthe number to the right.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.009.png)

Note the use of ? for the fill bits. Where the left shift filled the vacated positions with 0, a right shift will do the same only when the value is unsigned. If the value is signed then a right shift will fill the vacated bit positions with the sign bit or 0, whichever one is implementation-defined. So the best optionis to never right shift signed values.

6. **Bitwise Complement**

The bitwise complement inverts the bits ina single binarynumber.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.010.png)

7. **Checking Whether K-th Bit is Set or Not**

Let us assume that the given number is *n*. Then for checking the *Kth* bit we can use the expression: *n* & (1 ≪ *K* 1). If the expressionis true thenwe cansaythe *Kth* bit is set (that means, set to 1).

*Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.011.png)

8. **Setting K-th Bit**

For a givennumber *n*, to set the *Kth* bit we canuse the expression: *n* |1 ≪ (*K* – 1) *Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.012.png)

9. **Clearing K-th Bit**

To clear *Kth* bit of a givennumber *n*, we canuse the expression: *n* & ~(1 ≪ *K* – 1) *Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.013.png)

10. **Toggling K-th Bit**

For a givennumber *n*, for togglingthe *Kth* bit we canuse the expression: *n* ^(1 ≪ *K –* 1) *Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.014.png)

11. **Toggling Rightmost One Bit**

For a givennumber *n*, for togglingrightmost one bit we canuse the expression: *n* & *n* – 1 *Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.015.png)

12. **Isolating Rightmost One Bit**

For a givennumber *n*, for isolatingrightmost one bit we canuse the expression: *n* & *– n Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.016.png)

**Note:** For computing –*n*, use two’s complement representation. That means, toggle all bits and add 1.

13. **Isolating Rightmost Zero Bit**

For a givennumber *n*, for isolatingrightmost zero bit we canuse the expression: ~*n* & *n* + 1 *Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.017.png)

14. **Checking Whether Number is Power of 2 or Not**

Given number *n*, to check whether the number is in 2*n* form for not, we can use the expression: *if*(*n* & *n –* 1 == 0)

*Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.018.png)

15. **Multiplying Number by Power of 2**

For a givennumber *n*, to multiplythe number with2*K* we canuse the expression: *n* ≪ *K*

*Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.019.png)

16. **Dividing Number by Power of 2**

For a givennumber *n*, to divide the number with2*K* we canuse the expression: *n* ≫ *K Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.020.png)

17. **Finding Modulo of a Given Number**

For a given number *n*, to find the %8 we can use the expression: *n* & 0*x*7. Similarly, to find %32, use the expression: *n* & 0*x*1*F*

**Note:** Similarly, we canfind modulo value of anynumber.

18. **Reversing the Binary Number**

For a given number *n*, to reverse the bits (reverse (mirror) of binary number) we can use the followingcode snippet:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.021.png)

Time Complexity: This requires one iteration per bit and the number of iterations depends on the size of the number.

19. **Counting Number of One’s in Number**

For a givennumber *n*, to count the number of 1*’s* in its binary representation we can use any of the followingmethods.

**Method1:** Process bit bybit withbitwise and operator

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.022.png)

Time Complexity: This approach requires one iteration per bit and the number of iterations depends onsystem.

**Method2:** Usingmodulo approach

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.023.png)

Time Complexity: This requires one iteration per bit and the number of iterations depends on system.

**Method3:** Usingtogglingapproach: *n* & *n –* 1

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.024.png)

Time Complexity: The number of iterations depends onthe number of 1 bits inthe number.

**Method4:** Using preprocessing idea. In this method, we process the bits in groups. For example if we process them in groups of 4 bits at a time, we create a table which indicates the number of one’s for eachof those possibilities (as shownbelow).

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.025.png)

The followingcode to count the number of Is inthe number withthis approach:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.026.png)

Time Complexity: This approach requires one iteration per 4 bits and the number of iterations depends onsystem.

20. **Creating Mask for Trailing Zero’s**

For a givennumber *n*, to create a maskfor trailingzeros, we canuse the expression: (*n* & – *n*) – 1 *Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.027.png)

**Note:** Inthe above case we are gettingthe maskas all zeros because there are no trailingzeros.

**27.2.21 Swap allodd and even bits**

*Example:*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.028.png)

**21.2.22 Performing Average without Division**

Is there a bit-twiddling algorithm to replace *mid =* (*low + high*) */* 2 (used in Binary Search and Merge Sort) withsomethingmuchfaster?

We can use *mid =* (*low + high*) >> 1. Note that using (*low + high*) */* 2 for midpoint calculations won’t work correctly when integer overflow becomes an issue. We can use bit shifting and also overcome a possible overflow issue: *low +* ((*high – low*)*/* 2) and the bit shifting operation for this is *low +* ((*high – low*) >> 1).

3. **Other Programming Questions with Solutions**

**Problem-1**  Give analgorithmfor printingthe matrixelements inspiral order.

**Solution:** Non-recursive solution involves directions right, left, up, down, and dealing their corresponding indices. Once the first row is printed, direction changes (from right) to down, the row is discarded by incrementing the upper limit. Once the last column is printed, direction changes to left, the columnis discarded bydecrementingthe right hand limit.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.029.png)

Time Complexity: O(*n*2). Space Complexity: O(1).

**Problem-2**  Give analgorithmfor shufflingthe deskof cards.

**Solution:** Assume that we want to shuffle an array of 52 cards, from0 to 51 with no repeats, such as we might want for a deck of cards. First fill the array with the values in order, then go through the array and exchange each element with a randomly chosen element in the range from itself to the end. It’s possible that anelement will swap withitself, but there is no problemwiththat.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.030.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-3**  Reversal algorithm for array rotation: Write a function rotate(A[], d, n) that

rotates A[] of size *n* by *d* elements. For example, the array 1,2,3,4,5,6,7 becomes 3,4,5,6,7,1,2 after 2 rotations.

**Solution:** Consider the followingalgorithm. **Algorithm:**

rotate(Array[], d, n)

reverse(Array[], 1, d) ; reverse(Array[], d + 1, n); reverse(Array[], 1, n);

Let AB be the two parts of the input Arrays where A = Array[0..d-1] and B = Array[d..n-1]. The idea of the algorithmis:

Reverse Ato get ArB. /\*Ar is reverse of A\*/

Reverse B to get ArBr. /\*Br is reverse of B \*/

Reverse all to get (ArBr) r = BA.

For example, if Array[] = [1, 2, 3, 4, 5, 6, 7], d =2 and n = 7 then, A= [1, 2] and B = [3, 4, 5, 6, 7]

Reverse A, we get ArB = [2, 1, 3, 4, 5, 6, 7], Reverse B, we get ArBr = [2, 1, 7, 6, 5, 4, 3]

Reverse all, we get (ArBr)r = [3, 4, 5, 6, 7, 1, 2]

**Implementation**:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.031.jpeg)

**Problem-4**  Suppose you are given an array s[1...n] and a procedure reverse (s,i,j) which

reverses the order of elements in between positions i and j (both inclusive). What does the followingsequence

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.032.png)

1) Rotates s left bykpositions
1) Leaves s unchanged
1) Reverses all elements of s
1) None of the above

**Solution:** (b). Effect of the above 3 reversals for any*k* is equivalent to left rotation of the array of size nby*k* [refer [Problem-3](#_page16_x66.91_y363.42)].

**Problem-5**  Finding Anagrams in Dictionary: you are given these 2 files: dictionary.txt and

jumbles.txt

Thejumbles.txt file contains a bunch of scrambled words. Your job is to print out those jumbles words, 1 word to a line. After each jumbled word, print a list of real dictionary words that could be formed by unscrambling the jumbled word. The dictionary words that you have to choose from are inthe dictionary.txt file. Sample content of jumbles.txt:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.033.png)

**Solution:** Step-By-Step *Step* 1: Initialization

- Open the dictionary.txt file and read the words into an array (before going further verifybyechoingout the words backfromthe arrayout to the screen).
- Declare a hashtable variable.

*Step* 2: Process the Dictionaryfor eachdictionaryword inthe array. Do the following:

We now have a hash table where each key is the sorted form of a dictionary word and the value associated to it is a stringor arrayof dictionarywords that sort to that same key.

- Remove the newline off the end of eachword via chomp($word);
- Make a sorted copy of the word - i.e. rearrange the individual chars in the string to be sorted alphabetically
- Think of the sorted word as the key value and think of the set of all dictionary words that sort to the exact same keyword as beingthe value of the key
- Querythe hashtable to see if the sortedWord is alreadyone of the keys
- If it is not already present then insert the sorted word as key and the unsorted original of the word as the value
- Else concat the unsorted word onto the value string already out there (put a space in between)

*Step* 3: Process the jumbled word file

- Read through the jumbled word file one word at a time. As you read each jumbled word chomp it and make a sorted copy(the sorted copyis your key)
- Print the unsorted jumble word
- Query the hashtable for the sorted copy. If found, print the associated value on same line as keyand thena new line.

*Step* 4: Celebrate, we are all done Sample code inPerl:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.034.jpeg)

**Problem-6 Pathways:** Given a matrix as shown below, calculate the number of ways for

reachingdestination*B* from*A.*

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.035.png)

**Solution:** Before finding the solution, we try to understand the problem with a simpler version. The smallest problemthat we canconsider is the number of possible routes ina 1 × 1 grid.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.036.png)

Fromthe above figure, it canbe seenthat:

- Fromboth the bottom-left and the top-right corners there’s only one possible route to the destination.
- Fromthe top-left corner there are triviallytwo possible routes.

Similarly, for 2*x*2 and 3*x*3 grids, we canfill the matrixas:

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.037.png)

Fromthe above discussion, it is clear that to reachthe bottomright corner fromleft top corner, the paths are overlapping. As unique paths could overlap at certain points (grid cells), we could try to alter the previous algorithm, as a wayto avoid followingthe same pathagain. If we start filling 4*x*4 and 5*x*5, we caneasilyfigure out the solutionbased onour childhood mathematics concepts.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.038.png)

Are you able to figure out the pattern? It is the same as *Pascals* triangle. So, to find the number of ways, we can simply scan through the table and keep counting them while we move from left to right and top to bottom(starting with left-top). We can even solve this problemwith mathematical equation*of Pascals* triangle.

**Problem-7**  Given a string that has a set of words and spaces, write a program to move the

spaces to *front* of string. You need to traverse the array only once and you need to adjust the stringinplace.

*Input =* “move these spaces to beginning” *Output* =“ movethesepacestobeginning”

**Solution:** Maintain two indices *i* and *j;* traverse from end to beginning. If the current index contains char, swap chars in index *i* with index *j*. This will move all the spaces to beginning of the array.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.039.png)

Time Complexity: O(*n*) where n is the number of characters in the input array. Space Complexity: O(1).

**Problem-8**  For the [Problem-7](#_page22_x66.91_y27.36), canwe improve the complexity?

**Solution:** We can avoid a swap operation with a simple counter. But, it does not reduce the overall complexity.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.040.png)

Time Complexity: O(*n*) where n is the number of characters in input array. Space Complexity: O(1).


**Problem-9**  Given a string that has a set of words and spaces, write a program to move the

spaces to *end* of string. You need to traverse the array only once and you need to adjust the stringinplace.

*Input =* “move these spaces to end” *Output =* “movethesepacestoend “

**Solution:** Traverse the array fromleft to right. While traversing, maintain a counter for non-space elements in array. For every non-space character *A*[*i*], put the element at A[count] and increment *count*. After complete traversal, all non-space elements have alreadybeenshifted to front end and *count* is set as index of first 0. Now, all we need to do is run a loop which fills all elements with spaces from*count* till end of the array.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.041.png)

Time Complexity: O(*n*) where nis number of characters ininput array. Space Complexity: O(1).

**Problem-10**  MovingZeros to end: Givenanarrayof *n* integers, move all the zeros of a given

array to the end of the array. For example, if the given array is {1, 9, 8, 4, 0, 0, 2, 7, 0, 6, 0}, it should be changed to {1, 9, 8, 4, 2, 7, 6, 0, 0, 0, 0}. The order of all other elements should be same.

**Solution:** Maintaintwo variables *i* and *j;* and initialize with0. For eachof the arrayelement *A*[*i*], if *A*[*i*] non-zero element, then replace the element *A*[*j*] with element *A*[*i*]. Variable *i* will always be incremented till *n* - 1 but we will increment *j* onlywhenthe element pointed by*i* is non-zero.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.042.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-11**  For [Problem-10](#_page23_x66.91_y447.36), canwe improve the complexity?

**Solution:** Usingsimple swap technique we canavoid the unnecessarysecond *while* loop fromthe above code.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.043.png)

Time Complexity: O(*n*). Space Complexity: O(1).

**Problem-12**  Variant of [Problem-10](#_page23_x66.91_y447.36) and [Problem-11](#_page24_x66.91_y262.51): Given an array containing negative and

positive numbers; give an algorithm for separating positive and negative numbers in it. Also, maintain the relative order of positive and negative numbers. Input: -5, 3, 2, -1, 4, -8 Output: -5-1 -8342

**Solution:** Inthe *moveZerosToEnd* function, just replace the condition*A*[*i*] !=0 with*A*[*i*] < 0. **Problem-13**  Givena number, swap odd and evenbits.

**Solution:**

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.044.png)

**Problem-14**  Count the number of set bits inall numbers from1 to n

**Solution:** We can use the technique of [section 21.2.19](#_page12_x28.00_y724.16) and iterate through all the numbers from 1 to n.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.045.png)

**Problem-15**  Count the number of set bits inall numbers from1 to n

**Solution:** We can use the technique of [section 21.2.19](#_page12_x28.00_y724.16) and iterate through all the numbers from 1 to n.

![](https://raw.githubusercontent.com/xuelove0001/DataEasyImg/main/Aspose.Words.b4cc196f-9a28-41db-a3f3-1f433db8d9ca.046.png)

Time complexity: O(number of set bits inall numbers from1 to n).

**REFERENCES**

1. Akash. ProgrammingInterviews, [tech-queries.blogspot.com](http://tech-queries.blogspot.com).
2. Alfred V.Aho,J. E. (1983). Data Structures and Algorithms. Addison-Wesley.
3. Algorithms.Retrieved from[cs.princeton.edu/algs4/home](http://cs.princeton.edu/algs4/home)
4. Anderson., S. E. Bit Twiddling Hacks. Retrieved 2010, from Bit Twiddling Hacks: graphics. Stanford. edu
5. Bentley, J. AT&T Bell Laboratories. Retrieved fromAT&T Bell Laboratories.
6. Bondalapati, K. Interview Question Bank. Retrieved 2010, fromInterview Question Bank: halcyon.usc.edu/~kiran/msqs.html
7. Chen. Algorithms hawaii.edu/~chenx.
8. Database, P.Problem Database. Retrieved 2010, from Problem Database: [datastructures.net](http://datastructures.net)
9. Drozdek, A. (1996). Data Structures and Algorithms inC++.
10. Ellis Horowitz, S. S. Fundamentals of Data Structures.
11. Gilles Brassard, P. B. (1996). Fundamentals of Algorithmics.
12. Hunter., J. Introduction to Data Structures and Algorithms. Retrieved 2010, from Introductionto Data Structures and Algorithms.
13. James F. Korsh, L. J. Data Structures, Algorithms and ProgramStyle UsingC.
14. JohnMongan, N. S. (2002). ProgrammingInterviews Exposed. Wiley-India. .
15. Ju[dges. Comments on Problems and Solutions. http://www.informatik.uni- ulm.de/acm/Locals/2003/html/judge, html.](http://www.informatik.uni-ulm.de/acm/Locals/2003/html/judge)
16. Kalid. P, NP, and NP-Complete. Retrieved from P, NP, and NP-Complete.: cs.princeton.edu/~kazad
17. Knuth., D. E. (1973). Fundamental Algorithms, volume 1 of The Art of Computer Programming. Addison-Wesley.
18. Leon, J. S. Computer Algorithms. Retrieved 2010, from Computer Algorithms : [math.uic.edu/~leon](http://math.uic.edu/~leon)
19. Leon., J. S. Computer Algorithms, [math.uic.edu/~leon/cs-mcs401-s08](http://math.uic.edu/~leon/cs-mcs401-s08).
20. OCF. Algorithms. Retrieved 2010, fromAlgorithms: [ocf.berkeley.edu](http://ocf.berkeley.edu)
21. Parlante., N. Binary Trees. Retrieved 2010, from [cslibrary.stanford.edu](http://cslibrary.stanford.edu): [cslibrary.stanford.edu](http://cslibrary.stanford.edu)
22. Patil., V. Fundamentals of data structures. Nirali Prakashan.
23. Poundstone., W. HOW WOULD YOU MOVE MOUNT FUJI? New York Boston.: Little, Brownand Company.
24. Pryor, M. TechInterview. Retrieved 2010, fromTechInterview: [techinterview.org](http://techinterview.org)
25. Questions, A. C. A Collection of Technical Interview Questions. Retrieved 2010, from A Collectionof Technical Interview Questions
26. S. Dasgupta, C. P. Algorithms [cs.berkeley.edu/~vazirani](http://cs.berkeley.edu/~vazirani).
27. Sedgewick., R. (1988). Algorithms. Addison-Wesley.
28. Sells, C. (2010). Interviewing at Microsoft. Retrieved 2010, from Interviewing at Microsoft
29. Shene, C.-K. Linked Lists Merge Sort Implementation.
30. Sinha, P. LinuxJournal. Retrieved 2010, from: [linuxjournal.com/article/6828](http://linuxjournal.com/article/6828).
31. Str[uctures., d. D. www.math-cs.gordon.edu. Retrieved 2010, from www.math- cs.gordon.edu](http://www.math-cs.gordon.edu)
32. T. H. Cormen, C. E. (1997). Introductionto Algorithms. Cambridge: The MIT press.
33. Tsiombikas, J. Pointers Explained, nuclear.sdf-eu.org.
34. Warren., H. S. (2003). Hackers Delight. Addison-Wesley.
35. Weiss., M. A. (1992). Data Structures and AlgorithmAnalysis inC.
36. SANDRASI <http://sandrasi-sw.blogspot.in/>

Why this repo
-------------

+ 5
+ 6
+ 7
+ 8

[1]: https://github.com/allejo/jekyll-toc
